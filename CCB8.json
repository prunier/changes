{
    "LE2": {
        "PF-MER": {
            "PF-MER/MER_ProcessingUtils": {
                "start date": "2023-06-09 09:00",
                "end date": "2023-08-23 15:00",
                "start tag": "> 9.1.1",
                "end tag": "> 10.1.4",
                "count_files_modified": "17",
                "modifications_by_file": {
                    "MER_ProcessingUtils/python/MER_ProcessingUtils/MER_CreateMerAnalyseTileGaiaPPO.py": [
                        [
                            "@@ -229,6 +229,13 @@ def mainMethod(args):\n         products_ids=products_ids[\"DpdMerBksMosaic\"]\n     )\n \n+    ppo.add_input_port(\n+        port_products_id=ppo.InputProducts.Id + \"_MerSegmentationMap\",\n+        port_name=\"final_segmentation_map\",\n+        product_type=\"DpdMerSegmentationMap\",\n+        products_ids=products_ids[\"DpdMerSegmentationMap\"]\n+    )\n+\n     ppo.add_input_port(\n         port_products_id=ppo.InputProducts.Id + \"_ExtGaiaCutouts\",\n         port_name=\"gaia_cutout\",\n",
                            "Adds new input port",
                            "Javier Gracia Carpio",
                            "2023-08-16T11:56:13.000+00:00",
                            "cb07607b417772c49bc41816abf67be9d7753f95"
                        ],
                        [
                            "@@ -181,7 +181,7 @@ def mainMethod(args):\n     ppo.ParentPlanId = \"EUC_MER_ANALYSIS_GAIA_%s_%s\" % (pipeline_branch, database)\n \n     # Get the MER pipeline version, the EDEN version and the cvmfs path\n-    pipeline_version = \"10.1.0\"\n+    pipeline_version = \"10.1.3\"\n     eden_version = \"Eden-3.1\"\n     cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n",
                            "Update release versions",
                            "Javier Gracia Carpio",
                            "2023-08-14T16:43:51.000+00:00",
                            "0a5062d61cf546f1fc8e0de51220838393512104"
                        ],
                        [
                            "@@ -222,6 +222,13 @@ def mainMethod(args):\n         products_ids=products_ids[\"DpdMerFinalCatalog\"]\n     )\n \n+    ppo.add_input_port(\n+        port_products_id=ppo.InputProducts.Id + \"_MerBksMosaics\",\n+        port_name=\"all_mosaics\",\n+        product_type=\"DpdMerBksMosaic\",\n+        products_ids=products_ids[\"DpdMerBksMosaic\"]\n+    )\n+\n     ppo.add_input_port(\n         port_products_id=ppo.InputProducts.Id + \"_ExtGaiaCutouts\",\n         port_name=\"gaia_cutout\",\n",
                            "Add mosaics input ports to the gaia validation PPOs",
                            "Javier Gracia Carpio",
                            "2023-08-10T14:36:59.000+00:00",
                            "8ecc014525957f5c01be9bb42cccb129d45b746e"
                        ],
                        [
                            "@@ -102,6 +102,7 @@ def mainMethod(args):\n \n     # Get the input parameters\n     ppo_id = args.ppo_id\n+    gaia_release = args.gaia_release\n     ppo_counter = args.ppo_counter\n     target_sdc = args.target_sdc\n     pipeline_branch = args.pipeline_branch\n",
                            "Corrects missing variable",
                            "Javier Gracia Carpio",
                            "2023-08-09T09:29:47.000+00:00",
                            "89fec23e2df06d8f38c0de95f92a1f00a40fada5"
                        ],
                        [
                            "@@ -154,7 +154,12 @@ def mainMethod(args):\n     logger.info(\"Querying EAS to get the EXT Gaia cutout product ids...\")\n     ext_gaia_cutout_query = \"Header.ManualValidationStatus!=INVALID\"\n     ext_gaia_cutout_query += \"&Data.TileIndex=%s\" % tile_index\n-    ext_gaia_cutout_query += \"&Data.Comment=like*%s*\" % args.gaia_release\n+\n+    if \"*\" in gaia_release:\n+        ext_gaia_cutout_query += \"&Header.DataSetRelease=like%s\" % gaia_release\n+    else:\n+        ext_gaia_cutout_query += \"&Header.DataSetRelease=%s\" % gaia_release\n+\n     ext_gaia_cutout_ids = archive_utils.get_products_ids(\n         \"DpdExtGaiaCutout\", ext_gaia_cutout_query, database, project)\n \n",
                            "Update gaia cutouts query",
                            "Javier Gracia Carpio",
                            "2023-08-09T09:27:57.000+00:00",
                            "6d86e91136cf3eaaaf6bb8faa6a58f5a40eb6ef2"
                        ],
                        [
                            "@@ -152,8 +152,8 @@ def mainMethod(args):\n \n     # Get the EXT Gaia cutout catalog ids\n     logger.info(\"Querying EAS to get the EXT Gaia cutout product ids...\")\n-    #ext_gaia_cutout_query = \"Header.ManualValidationStatus!=INVALID\"\n-    ext_gaia_cutout_query = \"&Data.TileIndex=%s\" % tile_index\n+    ext_gaia_cutout_query = \"Header.ManualValidationStatus!=INVALID\"\n+    ext_gaia_cutout_query += \"&Data.TileIndex=%s\" % tile_index\n     ext_gaia_cutout_query += \"&Data.Comment=like*%s*\" % args.gaia_release\n     ext_gaia_cutout_ids = archive_utils.get_products_ids(\n         \"DpdExtGaiaCutout\", ext_gaia_cutout_query, database, project)\n",
                            "Remove hack",
                            "Javier Gracia Carpio",
                            "2023-07-25T10:18:38.000+00:00",
                            "4eedcd228329f28b9276784b9b2096b557d7a138"
                        ],
                        [
                            "@@ -152,8 +152,8 @@ def mainMethod(args):\n \n     # Get the EXT Gaia cutout catalog ids\n     logger.info(\"Querying EAS to get the EXT Gaia cutout product ids...\")\n-    ext_gaia_cutout_query = \"Header.ManualValidationStatus!=INVALID\"\n-    ext_gaia_cutout_query += \"&Data.TileIndex=%s\" % tile_index\n+    #ext_gaia_cutout_query = \"Header.ManualValidationStatus!=INVALID\"\n+    ext_gaia_cutout_query = \"&Data.TileIndex=%s\" % tile_index\n     ext_gaia_cutout_query += \"&Data.Comment=like*%s*\" % args.gaia_release\n     ext_gaia_cutout_ids = archive_utils.get_products_ids(\n         \"DpdExtGaiaCutout\", ext_gaia_cutout_query, database, project)\n",
                            "temporal hack",
                            "Javier Gracia Carpio",
                            "2023-07-25T10:15:15.000+00:00",
                            "593f791692cc4bb3aab732202d4fe0a145b1fe3f"
                        ],
                        [
                            "@@ -223,6 +223,13 @@ def mainMethod(args):\n         products_ids=ext_gaia_cutout_ids\n     )\n \n+    ppo.add_input_port(\n+        port_products_id=ppo.InputProducts.Id + \"_MerTile\",\n+        port_name=\"tile\",\n+        product_type=\"DpdMerTile\",\n+        products_ids=products_ids[\"DpdMerTile\"]\n+    )\n+\n     ppo.add_input_port(\n         port_products_id=ppo.InputProducts.Id + \"_MerConfigurationSet\",\n         port_name=\"configuration_set\",\n",
                            "Adds tile port",
                            "Javier Gracia Carpio",
                            "2023-07-25T09:42:21.000+00:00",
                            "63b10ccb56037c7ee056743626bc52bfbc518792"
                        ],
                        [
                            "@@ -72,7 +72,7 @@ def defineSpecificProgramOptions():\n \n     parser.add_argument(\"--project\", dest=\"project\",\n                         type=str, help=\"The EAS project where the PPO input \"\n-                        \"products metadata are stored (TEST or EUCLID).\")\n+                        \"products metadata are stored (TEST, EUCLID or ANY).\")\n \n     parser.add_argument(\"--outdir\", dest=\"output_directory\",\n                         type=str, help=\"The complete path to the output \"\n",
                            "Updates doc",
                            "Javier Gracia Carpio",
                            "2023-07-19T16:47:32.000+00:00",
                            "8e3e01d5d47fc8672b2a949292b5eeb9a10e8a05"
                        ],
                        [
                            "@@ -0,0 +1,240 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+File: python/MER_ProcessingUtils/MER_CreateMerAnalyseTileGaiaPPO.py\n+\n+Created on: 04/07/23\n+Author: Javier Gracia Carpio (jgracia@mpe.mpg.de)\n+\"\"\"\n+\n+import os.path\n+import argparse\n+import xml.etree.ElementTree as ElementTree\n+\n+import ElementsKernel.Logging as log\n+\n+import ST_DM_DmUtils.OrcDmUtils as orc_utils\n+\n+import MER_DataModelUtils.ArchiveUtils as archive_utils\n+import MER_DataModelUtils.DmUtils as dm_utils\n+\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"Defines the command line input and output parameters specific to this\n+    program.\n+\n+    Returns\n+    -------\n+    ArgumentParser\n+\n+    \"\"\"\n+    # Get the parser instance\n+    parser = argparse.ArgumentParser()\n+\n+    # Add the input parameters\n+    parser.add_argument(\"--ppo_id\", dest=\"ppo_id\",\n+                        type=str, help=\"The PPO id that generated the MER \"\n+                        \"products to analyse.\")\n+\n+    parser.add_argument(\"--gaia_release\", dest=\"gaia_release\",\n+                        type=str, required=False, default=\"no_data\",\n+                        help=\"The GAIA cutout catalog release.\")\n+\n+    parser.add_argument(\"--configuration_set_id\", dest=\"configuration_set_id\",\n+                        type=str, help=\"The MER configuration set product id.\")\n+\n+    parser.add_argument(\"--ppo_counter\", dest=\"ppo_counter\",\n+                        type=str, help=\"The PPO id counter.\")\n+\n+    parser.add_argument(\"--target_sdc\", dest=\"target_sdc\",\n+                        type=str, help=\"The SDC where the PPO should be \"\n+                        \"executed.\")\n+\n+    parser.add_argument(\"--pipeline_branch\", dest=\"pipeline_branch\",\n+                        type=str, help=\"The MER pipeline branch (RELEASE or \"\n+                        \"DEVELOP).\")\n+\n+    parser.add_argument(\"--project\", dest=\"project\",\n+                        type=str, help=\"The EAS project where the PPO input \"\n+                        \"products metadata are stored (TEST or EUCLID).\")\n+\n+    parser.add_argument(\"--outdir\", dest=\"output_directory\",\n+                        type=str, help=\"The complete path to the output \"\n+                        \"directory where the PPO XML file will be saved.\")\n+\n+    parser.add_argument(\"--mer_release\", dest=\"mer_release\",\n+                       type=str, required=False, default=\"\",\n+                        help=\"The MER data set release that the PPO output \"\n+                        \"products should have.\")\n+\n+    return parser\n+\n+\n+def mainMethod(args):\n+    \"\"\" The \"main\" method.\n+\n+    \"\"\"\n+    # Get a logger instance\n+    logger = log.getLogger(\"MER_CreateMerAnalyseTileGaiaPPO\")\n+\n+    logger.info(\"#\")\n+    logger.info(\"# Entering MER_CreateMerAnalyseTileGaiaPPO mainMethod()\")\n+    logger.info(\"#\")\n+\n+    # Add some extra functionality to the ORC data product bindings\n+    orc_utils.init()\n+\n+    # Get the input parameters\n+    ppo_id = args.ppo_id\n+    ppo_counter = args.ppo_counter\n+    target_sdc = args.target_sdc\n+    pipeline_branch = args.pipeline_branch\n+    project = args.project\n+    output_directory = args.output_directory\n+    mer_release = args.mer_release\n+\n+    # Check that the output directory exists\n+    if output_directory is None or not os.path.exists(output_directory):\n+        raise Exception(\"The directory %s does not exist!\" % output_directory)\n+\n+    # Download the PPO metadata\n+    logger.info(\"Downloading PPO metadata with Id: %s\", ppo_id)\n+    database = \"DM9.2\"\n+    ppo_metadata = archive_utils.get_ppo_metadata(ppo_id, database, project)\n+\n+    # Get the PPO input and output ports\n+    ports = ElementTree.fromstring(ppo_metadata).findall(\".//Product\")\n+\n+    # Loop over the ports and save the product ids in a python dictionary\n+    products_ids = {}\n+\n+    for port in ports:\n+        # Get the port name and the product type\n+        port_name = port.find(\"PortName\").text\n+        product_type = port.find(\"ProductType\").text\n+\n+        # Create a port id that doesn't depend on the naming in the pipeline\n+        # script\n+        port_id = product_type\n+\n+        if \"vis\" in port_name:\n+            port_id += \"_vis\"\n+        elif \"nir\" in port_name:\n+            port_id += \"_nir\"\n+\n+        # Save the complete list of products ids\n+        products_ids[port_id] = [id.text for id in port.findall(\"ProductId\")]\n+\n+    # Download the MER final catalog metadata\n+    final_catalog_id = products_ids[\"DpdMerFinalCatalog\"][0]\n+    logger.info(\"Downloading MER final catalog metadata with Id: %s\", final_catalog_id)\n+    catalog_metadata = archive_utils.get_product_metadata(\n+        \"DpdMerFinalCatalog\", final_catalog_id, database, project)\n+\n+    # Extract the tile index from the final catalog metadata\n+    tile_index = ElementTree.fromstring(catalog_metadata).find(\".//TileIndex\").text\n+\n+    # Get the EXT Gaia cutout catalog ids\n+    logger.info(\"Querying EAS to get the EXT Gaia cutout product ids...\")\n+    ext_gaia_cutout_query = \"Header.ManualValidationStatus!=INVALID\"\n+    ext_gaia_cutout_query += \"&Data.TileIndex=%s\" % tile_index\n+    ext_gaia_cutout_query += \"&Data.Comment=like*%s*\" % args.gaia_release\n+    ext_gaia_cutout_ids = archive_utils.get_products_ids(\n+        \"DpdExtGaiaCutout\", ext_gaia_cutout_query, database, project)\n+\n+    # Make sure that there is only one EXT Gaia cutout catalog id\n+    if len(ext_gaia_cutout_ids) != 1:\n+        raise Exception(\n+            \"There is zero or more than one gaia cutout product in EAS for the \"\n+            \"specified query: %s\" % ext_gaia_cutout_ids)\n+\n+    # Create a new PPO instance for the target SDC\n+    ppo = orc_utils.create_ppo(target_sdc)\n+\n+    # Set the PPO id and the parent plan id\n+    database = database.replace(\".\", \"\")\n+    ppo.Id = \"EUC_MER_ANALYSIS_GAIA_%s_%s_%s_TILE%s_%s_%s\" % (\n+        target_sdc.replace(\"-\", \"\"), pipeline_branch, database, tile_index,\n+        mer_release, ppo_counter)\n+    ppo.ParentPlanId = \"EUC_MER_ANALYSIS_GAIA_%s_%s\" % (pipeline_branch, database)\n+\n+    # Get the MER pipeline version, the EDEN version and the cvmfs path\n+    pipeline_version = \"10.1.0\"\n+    eden_version = \"Eden-3.1\"\n+    cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n+\n+    if pipeline_branch == \"DEVELOP\":\n+        pipeline_version = \"10.2\"\n+        eden_version = \"Eden-3.1-dev\"\n+        cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid\"\n+\n+    # Set the execution environment information\n+    execution_env = ppo.PipelineExecEnv\n+    execution_env.Id = \"\"\n+    execution_env.PipelineDefinitionId = \"PipDef_MER_ANALYSE_TILE_GAIA_XXXX\"\n+    execution_env.EdenVersion = eden_version\n+    execution_env.PipelineRootPath = (\n+        \"%s/MER_IAL_Pipelines/%s/InstallArea/x86_64-conda_ry9-gcc11-o2g/\"\n+        \"auxdir/MER_AnalyseTile_Pipeline\" % (cvmfs_path, pipeline_version))\n+    execution_env.EstimatedWordirSizeGB = 500\n+    execution_env.WorkdirRetentionSuccessPolicy = \"RETAIN_ALL\"\n+    execution_env.WorkdirRetentionFailurePolicy = \"RETAIN_ALL\"\n+\n+    # Set the pipeline script path\n+    ppo.set_pipeline_script_path(\"PipScript_MER_AnalyseTileGaia.py\")\n+\n+    # Set the MER data set release\n+    if mer_release == \"\":\n+        mer_release = \"MER_%s_%s\" % (database, pipeline_version)\n+\n+    ppo.DataSetRelease = mer_release\n+\n+    # Add all the input ports\n+    ppo.InputProducts.Id = \"EUC_MER_ANALYSIS_GAIA_INPUTS_%s_TILE%s_%s\" % (\n+        database, tile_index, ppo_counter)\n+\n+    ppo.add_input_port(\n+        port_products_id=ppo.InputProducts.Id + \"_MerFinalCatalog\",\n+        port_name=\"final_catalog\",\n+        product_type=\"DpdMerFinalCatalog\",\n+        products_ids=products_ids[\"DpdMerFinalCatalog\"]\n+    )\n+\n+    ppo.add_input_port(\n+        port_products_id=ppo.InputProducts.Id + \"_ExtGaiaCutouts\",\n+        port_name=\"gaia_cutout\",\n+        product_type=\"DpdExtGaiaCutout\",\n+        products_ids=ext_gaia_cutout_ids\n+    )\n+\n+    ppo.add_input_port(\n+        port_products_id=ppo.InputProducts.Id + \"_MerConfigurationSet\",\n+        port_name=\"configuration_set\",\n+        product_type=\"DpdMerConfigurationSet\",\n+        products_ids=[args.configuration_set_id]\n+    )\n+\n+    # Save the PPO as an XML file in the output directory\n+    xml_file_name = \"PPO_ANALYSIS_GAIA_%s_%s_TILE%s.xml\" % (\n+        target_sdc.replace(\"-\", \"\"), pipeline_branch, tile_index)\n+    ppo.save_xml(os.path.join(output_directory, xml_file_name))\n+\n+    logger.info(\"#\")\n+    logger.info(\"# Exiting MER_CreateMerAnalyseTileGaiaPPO mainMethod()\")\n+    logger.info(\"#\")\n",
                            "Adds a new executable to create analysis PPOs for real data",
                            "Javier Gracia Carpio",
                            "2023-07-04T12:36:40.000+00:00",
                            "af7019db1ba01597bed244d40a81ed551d9ec2dc"
                        ]
                    ],
                    "MER_ProcessingUtils/python/MER_ProcessingUtils/MER_CreateMerAnalyseTileMorphologyPPO.py": [
                        [
                            "@@ -246,7 +246,7 @@ def mainMethod(args):\n         pipeline_branch, database)\n \n     # Get the MER pipeline version, the EDEN version and the cvmfs path\n-    pipeline_version = \"10.1.0\"\n+    pipeline_version = \"10.1.3\"\n     eden_version = \"Eden-3.1\"\n     cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n",
                            "Update release versions",
                            "Javier Gracia Carpio",
                            "2023-08-14T16:43:51.000+00:00",
                            "0a5062d61cf546f1fc8e0de51220838393512104"
                        ],
                        [
                            "@@ -73,7 +73,7 @@ def defineSpecificProgramOptions():\n \n     parser.add_argument(\"--project\", dest=\"project\",\n                         type=str, help=\"The EAS project where the PPO input \"\n-                        \"products metadata are stored (TEST or EUCLID).\")\n+                        \"products metadata are stored (TEST, EUCLID or ANY).\")\n \n     parser.add_argument(\"--outdir\", dest=\"output_directory\",\n                         type=str, help=\"The complete path to the output \"\n",
                            "Updates doc",
                            "Javier Gracia Carpio",
                            "2023-07-19T16:47:32.000+00:00",
                            "8e3e01d5d47fc8672b2a949292b5eeb9a10e8a05"
                        ],
                        [
                            "@@ -251,7 +251,7 @@ def mainMethod(args):\n     cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     if pipeline_branch == \"DEVELOP\":\n-        pipeline_version = \"10.1\"\n+        pipeline_version = \"10.2\"\n         eden_version = \"Eden-3.1-dev\"\n         cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n",
                            "Increases develop versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T20:23:02.000+00:00",
                            "000847717abdedcde0f6a26efbf57b5a0df82a2e"
                        ],
                        [
                            "@@ -118,7 +118,7 @@ def mainMethod(args):\n \n     # Download the PPO metadata\n     logger.info(\"Downloading PPO metadata with Id: %s\", ppo_id)\n-    database = \"DM9.1\"\n+    database = \"DM9.2\"\n     ppo_metadata = archive_utils.get_ppo_metadata(ppo_id, database, project)\n \n     # Get the PPO input and output ports\n@@ -246,14 +246,14 @@ def mainMethod(args):\n         pipeline_branch, database)\n \n     # Get the MER pipeline version, the EDEN version and the cvmfs path\n-    pipeline_version = \"9.1.1\"\n-    eden_version = \"Eden-3.0\"\n-    cvmfs_path = \"/cvmfs/euclid.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid\"\n+    pipeline_version = \"10.1.0\"\n+    eden_version = \"Eden-3.1\"\n+    cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     if pipeline_branch == \"DEVELOP\":\n-        pipeline_version = \"10.0\"\n-        eden_version = \"Eden-3.0-dev\"\n-        cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid\"\n+        pipeline_version = \"10.1\"\n+        eden_version = \"Eden-3.1-dev\"\n+        cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     # Set the execution environment information\n     execution_env = ppo.PipelineExecEnv\n@@ -261,7 +261,7 @@ def mainMethod(args):\n     execution_env.PipelineDefinitionId = \"PipDef_MER_ANALYSE_MORPHOLOGY_TILE_XXXX\"\n     execution_env.EdenVersion = eden_version\n     execution_env.PipelineRootPath = (\n-        \"%s/MER_IAL_Pipelines/%s/InstallArea/x86_64-conda_cos6-gcc93-o2g/\"\n+        \"%s/MER_IAL_Pipelines/%s/InstallArea/x86_64-conda_ry9-gcc11-o2g/\"\n         \"auxdir/MER_AnalyseTile_Pipeline\" % (cvmfs_path, pipeline_version))\n     execution_env.EstimatedWordirSizeGB = 500\n     execution_env.WorkdirRetentionSuccessPolicy = \"RETAIN_ALL\"\n",
                            "Update to DM9.2 and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-22T10:20:56.000+00:00",
                            "ba4aaae064df5d0a1922d394ff86f78bf393a0a6"
                        ],
                        [
                            "@@ -0,0 +1,366 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+File: python/MER_ProcessingUtils/MER_CreateMerAnalyseTileMorphologyPPO.py\n+\n+Created on: 12/06/23\n+Author: Javier Gracia Carpio (jgracia@mpe.mpg.de)\n+\"\"\"\n+\n+import os.path\n+import argparse\n+import xml.etree.ElementTree as ElementTree\n+\n+import ElementsKernel.Logging as log\n+\n+import ST_DM_DmUtils.OrcDmUtils as orc_utils\n+\n+import MER_DataModelUtils.ArchiveUtils as archive_utils\n+import MER_DataModelUtils.DmUtils as dm_utils\n+\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"Defines the command line input and output parameters specific to this\n+    program.\n+\n+    Returns\n+    -------\n+    ArgumentParser\n+\n+    \"\"\"\n+    # Get the parser instance\n+    parser = argparse.ArgumentParser()\n+\n+    # Add the input parameters\n+    parser.add_argument(\"--ppo_id\", dest=\"ppo_id\",\n+                        type=str, help=\"The PPO id that generated the MER \"\n+                        \"products to analyze.\")\n+\n+    parser.add_argument(\"--tu_star_release\", dest=\"tu_star_release\",\n+                        type=str, help=\"The MER tile True Universe start \"\n+                        \"catalog release.\")\n+\n+    parser.add_argument(\"--tu_galaxy_release\", dest=\"tu_galaxy_release\",\n+                        type=str, help=\"The MER tile True Universe galaxy \"\n+                        \"catalog release.\")\n+\n+    parser.add_argument(\"--ppo_counter\", dest=\"ppo_counter\",\n+                        type=str, help=\"The PPO id counter.\")\n+\n+    parser.add_argument(\"--target_sdc\", dest=\"target_sdc\",\n+                        type=str, help=\"The SDC where the PPO should be \"\n+                        \"executed.\")\n+\n+    parser.add_argument(\"--pipeline_branch\", dest=\"pipeline_branch\",\n+                        type=str, help=\"The MER pipeline branch (RELEASE or \"\n+                        \"DEVELOP).\")\n+\n+    parser.add_argument(\"--project\", dest=\"project\",\n+                        type=str, help=\"The EAS project where the PPO input \"\n+                        \"products metadata are stored (TEST or EUCLID).\")\n+\n+    parser.add_argument(\"--outdir\", dest=\"output_directory\",\n+                        type=str, help=\"The complete path to the output \"\n+                        \"directory where the PPO XML file will be saved.\")\n+\n+    parser.add_argument(\"--mer_release\", dest=\"mer_release\",\n+                       type=str, required=False, default=\"\",\n+                        help=\"The MER data set release that the PPO output \"\n+                        \"products should have.\")\n+\n+    return parser\n+\n+\n+def mainMethod(args):\n+    \"\"\" The \"main\" method.\n+\n+    \"\"\"\n+    # Get a logger instance\n+    logger = log.getLogger(\"MER_CreateMerAnalyseTileMorphologyPPO\")\n+\n+    logger.info(\"#\")\n+    logger.info(\"# Entering MER_CreateMerAnalyseTileMorphologyPPO mainMethod()\")\n+    logger.info(\"#\")\n+\n+    # Add some extra functionality to the ORC data product bindings\n+    orc_utils.init()\n+\n+    # Get the input parameters\n+    ppo_id = args.ppo_id\n+    tu_star_release = args.tu_star_release\n+    tu_galaxy_release = args.tu_galaxy_release\n+    ppo_counter = args.ppo_counter\n+    target_sdc = args.target_sdc\n+    pipeline_branch = args.pipeline_branch\n+    project = args.project\n+    output_directory = args.output_directory\n+    mer_release = args.mer_release\n+\n+    # Check that the output directory exists\n+    if output_directory is None or not os.path.exists(output_directory):\n+        raise Exception(\"The directory %s does not exist!\" % output_directory)\n+\n+    # Download the PPO metadata\n+    logger.info(\"Downloading PPO metadata with Id: %s\", ppo_id)\n+    database = \"DM9.1\"\n+    ppo_metadata = archive_utils.get_ppo_metadata(ppo_id, database, project)\n+\n+    # Get the PPO input and output ports\n+    ports = ElementTree.fromstring(ppo_metadata).findall(\".//Product\")\n+\n+    # Loop over the ports and save the final catalog product ids in a python\n+    # dictionary\n+    products_ids = {}\n+\n+    for port in ports:\n+        # Get the port name and the product type\n+        port_name = port.find(\"PortName\").text\n+        product_type = port.find(\"ProductType\").text\n+\n+        # Save only the MER final catalogs info\n+        if product_type == \"DpdMerFinalCatalog\":\n+            port_id = product_type\n+\n+            if port_name == \"final_catalog\":\n+                port_id += \"_input\"\n+            else:\n+                port_id += \"_output\"\n+\n+            # Save the complete list of products ids\n+            products_ids[port_id] = [id.text for id in port.findall(\"ProductId\")]\n+\n+    # Get the input catalog metadata\n+    input_catalog_id = products_ids[\"DpdMerFinalCatalog_input\"][0]\n+    logger.info(\n+        \"Downloading MER final catalog metadata with Id: %s\", input_catalog_id)\n+    input_catalog = ElementTree.fromstring(\n+        archive_utils.get_product_metadata(\n+            \"DpdMerFinalCatalog\", input_catalog_id, database, project))\n+\n+    # Get the PPO that generated the catalog\n+    ppo_id = input_catalog.find(\".//PPOId\").text\n+\n+    # Extract the tile index\n+    tile_index = input_catalog.find(\".//TileIndex\").text\n+\n+    # Download the PPO metadata associated with the input products\n+    logger.info(\"Downloading PPO metadata with Id: %s\", ppo_id)\n+    database = \"DM9.1\"\n+    ppo_metadata = archive_utils.get_ppo_metadata(ppo_id, database, project)\n+\n+    # Get the PPO input and output ports\n+    ports = ElementTree.fromstring(ppo_metadata).findall(\".//Product\")\n+\n+    # Loop over the ports and save the product ids in a python dictionary\n+    for port in ports:\n+        # Get the port name and the product type\n+        port_name = port.find(\"PortName\").text\n+        product_type = port.find(\"ProductType\").text\n+\n+        # Create a port id that doesn't depend on the naming in the pipeline\n+        # script\n+        port_id = product_type\n+\n+        if \"vis\" in port_name:\n+            port_id += \"_vis\"\n+        elif \"nir\" in port_name:\n+            port_id += \"_nir\"\n+\n+        # Save the complete list of products ids\n+        products_ids[port_id] = [id.text for id in port.findall(\"ProductId\")]\n+\n+    # Define the validation status query and the tile index query\n+    validation_query = \"Header.ManualValidationStatus!=INVALID\"\n+    tile_index_query = \"Data.TileIndex=%s\" % tile_index\n+\n+    # Build the MER True Universe star catalogs query\n+    tu_star_catalogs_query = validation_query + \"&\" + tile_index_query\n+\n+    if tu_star_release != \"\":\n+        tu_star_catalogs_query += \"&Header.DataSetRelease=%s\" % tu_star_release\n+\n+    # Get the MER True Universe star catalogs products ids\n+    logger.info(\"Querying EAS to get the MER TU star catalogs products ids...\")\n+    tu_star_catalogs_ids = archive_utils.get_products_ids(\n+        \"DpdMerTrueUniverseStarCatalog\", tu_star_catalogs_query, database,\n+        project)\n+\n+    # Make sure that there is only one MER True Universe star catalog id\n+    if len(tu_star_catalogs_ids) > 1:\n+        raise Exception(\n+            \"There is more than one MER True Universe star catalog in EAS for \"\n+            \"the specified query: %s\" % tu_star_catalogs_ids)\n+    elif len(tu_star_catalogs_ids) == 0:\n+        raise Exception(\n+            \"There is no MER True Universe star catalog in EAS for the \"\n+            \"specified query.\")\n+\n+    # Build the MER True Universe galaxy catalogs query\n+    tu_galaxy_catalogs_query = validation_query + \"&\" + tile_index_query\n+\n+    if tu_galaxy_release != \"\":\n+        tu_galaxy_catalogs_query += \"&Header.DataSetRelease=%s\" % tu_galaxy_release\n+\n+    # Get the MER True Universe galaxy catalogs products ids\n+    logger.info(\n+        \"Querying EAS to get the MER TU galaxy catalogs products ids...\")\n+    tu_galaxy_catalogs_ids = archive_utils.get_products_ids(\n+        \"DpdMerTrueUniverseGalaxyCatalog\", tu_galaxy_catalogs_query, database,\n+        project)\n+\n+    # Make sure that there is only one MER True Universe galaxy catalog id\n+    if len(tu_galaxy_catalogs_ids) > 1:\n+        raise Exception(\n+            \"There is more than one MER True Universe galaxy catalog in EAS \"\n+            \"for the specified query: %s\" % tu_galaxy_catalogs_ids)\n+    elif len(tu_galaxy_catalogs_ids) == 0:\n+        raise Exception(\n+            \"There is no MER True Universe galaxy catalog in EAS for the \"\n+            \"specified query.\")\n+\n+    # Create a new PPO instance for the target SDC\n+    ppo = orc_utils.create_ppo(target_sdc)\n+\n+    # Set the PPO id and the parent plan id\n+    database = database.replace(\".\", \"\")\n+    ppo.Id = \"EUC_MER_ANALYSIS_MORPHOLOGY_%s_%s_%s_TILE%s_%s_%s\" % (\n+        target_sdc.replace(\"-\", \"\"), pipeline_branch, database, tile_index,\n+        mer_release, ppo_counter)\n+    ppo.ParentPlanId = \"EUC_MER_ANALYSIS_MORPHOLOGY_%s_%s\" % (\n+        pipeline_branch, database)\n+\n+    # Get the MER pipeline version, the EDEN version and the cvmfs path\n+    pipeline_version = \"9.1.1\"\n+    eden_version = \"Eden-3.0\"\n+    cvmfs_path = \"/cvmfs/euclid.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid\"\n+\n+    if pipeline_branch == \"DEVELOP\":\n+        pipeline_version = \"10.0\"\n+        eden_version = \"Eden-3.0-dev\"\n+        cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid\"\n+\n+    # Set the execution environment information\n+    execution_env = ppo.PipelineExecEnv\n+    execution_env.Id = \"\"\n+    execution_env.PipelineDefinitionId = \"PipDef_MER_ANALYSE_MORPHOLOGY_TILE_XXXX\"\n+    execution_env.EdenVersion = eden_version\n+    execution_env.PipelineRootPath = (\n+        \"%s/MER_IAL_Pipelines/%s/InstallArea/x86_64-conda_cos6-gcc93-o2g/\"\n+        \"auxdir/MER_AnalyseTile_Pipeline\" % (cvmfs_path, pipeline_version))\n+    execution_env.EstimatedWordirSizeGB = 500\n+    execution_env.WorkdirRetentionSuccessPolicy = \"RETAIN_ALL\"\n+    execution_env.WorkdirRetentionFailurePolicy = \"RETAIN_ALL\"\n+\n+    # Set the pipeline script path\n+    ppo.set_pipeline_script_path(\"PipScript_MER_AnalyseTile.py\")\n+\n+    # Set the MER data set release\n+    if mer_release == \"\":\n+        mer_release = \"MER_%s_%s\" % (database, pipeline_version)\n+\n+    ppo.DataSetRelease = mer_release\n+\n+    # Add all the input ports\n+    ppo.InputProducts.Id = \"EUC_MER_ANALYSIS_MORPHOLOGY_INPUTS_%s_TILE%s_%s\" % (\n+        database, tile_index, ppo_counter)\n+\n+    ppo.add_input_port(\n+        port_products_id=ppo.InputProducts.Id + \"_MerFinalCatalog\",\n+        port_name=\"final_catalog\",\n+        product_type=\"DpdMerFinalCatalog\",\n+        products_ids=products_ids[\"DpdMerFinalCatalog_output\"]\n+    )\n+\n+    ppo.add_input_port(\n+        port_products_id=ppo.InputProducts.Id + \"_MerBksMosaics\",\n+        port_name=\"all_mosaics\",\n+        product_type=\"DpdMerBksMosaic\",\n+        products_ids=products_ids[\"DpdMerBksMosaic\"]\n+    )\n+\n+    ppo.add_input_port(\n+        port_products_id=ppo.InputProducts.Id + \"_MerVisDetectionMosaic\",\n+        port_name=\"vis_detection_mosaic\",\n+        product_type=\"DpdMerDetectionMosaic\",\n+        products_ids=products_ids[\"DpdMerDetectionMosaic_vis\"]\n+    )\n+\n+    ppo.add_input_port(\n+        port_products_id=ppo.InputProducts.Id + \"_MerNirDetectionMosaic\",\n+        port_name=\"nir_detection_mosaic\",\n+        product_type=\"DpdMerDetectionMosaic\",\n+        products_ids=products_ids[\"DpdMerDetectionMosaic_nir\"]\n+    )\n+\n+    ppo.add_input_port(\n+        port_products_id=ppo.InputProducts.Id + \"_MerSegmentationMap\",\n+        port_name=\"final_segmentation_map\",\n+        product_type=\"DpdMerSegmentationMap\",\n+        products_ids=products_ids[\"DpdMerSegmentationMap\"]\n+    )\n+\n+    ppo.add_input_port(\n+        port_products_id=ppo.InputProducts.Id + \"_MerTile\",\n+        port_name=\"tile\",\n+        product_type=\"DpdMerTile\",\n+        products_ids=products_ids[\"DpdMerTile\"]\n+    )\n+\n+    ppo.add_input_port(\n+        port_products_id=ppo.InputProducts.Id + \"_MerTrueUniverseStarCatalog\",\n+        port_name=\"tu_star_catalog\",\n+        product_type=\"DpdMerTrueUniverseStarCatalog\",\n+        products_ids=tu_star_catalogs_ids\n+    )\n+\n+    ppo.add_input_port(\n+        port_products_id=ppo.InputProducts.Id + \"_MerTrueUniverseGalaxyCatalog\",\n+        port_name=\"tu_galaxy_catalog\",\n+        product_type=\"DpdMerTrueUniverseGalaxyCatalog\",\n+        products_ids=tu_galaxy_catalogs_ids\n+    )\n+\n+    ppo.add_input_port(\n+        port_products_id=ppo.InputProducts.Id + \"_MerConfigurationSet\",\n+        port_name=\"configuration_set\",\n+        product_type=\"DpdMerConfigurationSet\",\n+        products_ids=products_ids[\"DpdMerConfigurationSet\"]\n+    )\n+\n+    ppo.add_input_port(\n+        port_products_id=ppo.InputProducts.Id + \"_MDB\",\n+        port_name=\"mdb\",\n+        product_type=\"DpdMdbDataBase\",\n+        products_ids=products_ids[\"DpdMdbDataBase\"]\n+    )\n+\n+    # Add file filters to some of the input ports\n+    for input_port in ppo.InputProducts.Product:\n+        if input_port.PortName == \"mdb\":\n+            input_port.FileFiltering = dm_utils.create_file_filtering(\n+                files_to_include=[\"*_MER_*\", \"HFI_CompMap_ThermalDustModel_*\"])\n+\n+    # Save the PPO as an XML file in the output directory\n+    xml_file_name = \"PPO_ANALYSIS_MORPHOLOGY_%s_%s_TILE%s.xml\" % (\n+        target_sdc.replace(\"-\", \"\"), pipeline_branch, tile_index)\n+    ppo.save_xml(os.path.join(output_directory, xml_file_name))\n+\n+    logger.info(\"#\")\n+    logger.info(\"# Exiting MER_CreateMerAnalyseTileMorphologyPPO mainMethod()\")\n+    logger.info(\"#\")\n",
                            "Creates a new executable to create PPOs for the analysis pipeline",
                            "Javier Gracia Carpio",
                            "2023-06-12T14:10:06.000+00:00",
                            "6652eba80764345dd9233fbface29bf1f02bdf26"
                        ]
                    ],
                    "MER_ProcessingUtils/python/MER_ProcessingUtils/MER_CreateMerAnalyseTilePPO.py": [
                        [
                            "@@ -213,7 +213,7 @@ def mainMethod(args):\n     ppo.ParentPlanId = \"EUC_MER_ANALYSIS_%s_%s\" % (pipeline_branch, database)\n \n     # Get the MER pipeline version, the EDEN version and the cvmfs path\n-    pipeline_version = \"10.1.0\"\n+    pipeline_version = \"10.1.3\"\n     eden_version = \"Eden-3.1\"\n     cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n",
                            "Update release versions",
                            "Javier Gracia Carpio",
                            "2023-08-14T16:43:51.000+00:00",
                            "0a5062d61cf546f1fc8e0de51220838393512104"
                        ],
                        [
                            "@@ -73,7 +73,7 @@ def defineSpecificProgramOptions():\n \n     parser.add_argument(\"--project\", dest=\"project\",\n                         type=str, help=\"The EAS project where the PPO input \"\n-                        \"products metadata are stored (TEST or EUCLID).\")\n+                        \"products metadata are stored (TEST, EUCLID or ANY).\")\n \n     parser.add_argument(\"--outdir\", dest=\"output_directory\",\n                         type=str, help=\"The complete path to the output \"\n",
                            "Updates doc",
                            "Javier Gracia Carpio",
                            "2023-07-19T16:47:32.000+00:00",
                            "8e3e01d5d47fc8672b2a949292b5eeb9a10e8a05"
                        ],
                        [
                            "@@ -218,7 +218,7 @@ def mainMethod(args):\n     cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     if pipeline_branch == \"DEVELOP\":\n-        pipeline_version = \"10.1\"\n+        pipeline_version = \"10.2\"\n         eden_version = \"Eden-3.1-dev\"\n         cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n",
                            "Increases develop versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T20:23:02.000+00:00",
                            "000847717abdedcde0f6a26efbf57b5a0df82a2e"
                        ],
                        [
                            "@@ -118,7 +118,7 @@ def mainMethod(args):\n \n     # Download the PPO metadata\n     logger.info(\"Downloading PPO metadata with Id: %s\", ppo_id)\n-    database = \"DM9.1\"\n+    database = \"DM9.2\"\n     ppo_metadata = archive_utils.get_ppo_metadata(ppo_id, database, project)\n \n     # Get the PPO input and output ports\n@@ -213,14 +213,14 @@ def mainMethod(args):\n     ppo.ParentPlanId = \"EUC_MER_ANALYSIS_%s_%s\" % (pipeline_branch, database)\n \n     # Get the MER pipeline version, the EDEN version and the cvmfs path\n-    pipeline_version = \"9.1.1\"\n-    eden_version = \"Eden-3.0\"\n-    cvmfs_path = \"/cvmfs/euclid.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid\"\n+    pipeline_version = \"10.1.0\"\n+    eden_version = \"Eden-3.1\"\n+    cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     if pipeline_branch == \"DEVELOP\":\n-        pipeline_version = \"10.0\"\n-        eden_version = \"Eden-3.0-dev\"\n-        cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid\"\n+        pipeline_version = \"10.1\"\n+        eden_version = \"Eden-3.1-dev\"\n+        cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     # Set the execution environment information\n     execution_env = ppo.PipelineExecEnv\n@@ -228,7 +228,7 @@ def mainMethod(args):\n     execution_env.PipelineDefinitionId = \"PipDef_MER_ANALYSE_TILE_XXXX\"\n     execution_env.EdenVersion = eden_version\n     execution_env.PipelineRootPath = (\n-        \"%s/MER_IAL_Pipelines/%s/InstallArea/x86_64-conda_cos6-gcc93-o2g/\"\n+        \"%s/MER_IAL_Pipelines/%s/InstallArea/x86_64-conda_ry9-gcc11-o2g/\"\n         \"auxdir/MER_AnalyseTile_Pipeline\" % (cvmfs_path, pipeline_version))\n     execution_env.EstimatedWordirSizeGB = 500\n     execution_env.WorkdirRetentionSuccessPolicy = \"RETAIN_ALL\"\n",
                            "Update to DM9.2 and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-22T10:20:56.000+00:00",
                            "ba4aaae064df5d0a1922d394ff86f78bf393a0a6"
                        ]
                    ],
                    "MER_ProcessingUtils/python/MER_ProcessingUtils/MER_CreateMerAnalyseTileVisOnlyPPO.py": [
                        [
                            "@@ -203,7 +203,7 @@ def mainMethod(args):\n     ppo.ParentPlanId = \"EUC_MER_ANALYSIS_VISONLY_%s_%s\" % (pipeline_branch, database)\n \n     # Get the MER pipeline version, the EDEN version and the cvmfs path\n-    pipeline_version = \"10.1.0\"\n+    pipeline_version = \"10.1.3\"\n     eden_version = \"Eden-3.1\"\n     cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n",
                            "Update release versions",
                            "Javier Gracia Carpio",
                            "2023-08-14T16:43:51.000+00:00",
                            "0a5062d61cf546f1fc8e0de51220838393512104"
                        ],
                        [
                            "@@ -73,7 +73,7 @@ def defineSpecificProgramOptions():\n \n     parser.add_argument(\"--project\", dest=\"project\",\n                         type=str, help=\"The EAS project where the PPO input \"\n-                        \"products metadata are stored (TEST or EUCLID).\")\n+                        \"products metadata are stored (TEST, EUCLID or ANY).\")\n \n     parser.add_argument(\"--outdir\", dest=\"output_directory\",\n                         type=str, help=\"The complete path to the output \"\n",
                            "Updates doc",
                            "Javier Gracia Carpio",
                            "2023-07-19T16:47:32.000+00:00",
                            "8e3e01d5d47fc8672b2a949292b5eeb9a10e8a05"
                        ],
                        [
                            "@@ -208,7 +208,7 @@ def mainMethod(args):\n     cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     if pipeline_branch == \"DEVELOP\":\n-        pipeline_version = \"10.1\"\n+        pipeline_version = \"10.2\"\n         eden_version = \"Eden-3.1-dev\"\n         cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n",
                            "Increases develop versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T20:23:02.000+00:00",
                            "000847717abdedcde0f6a26efbf57b5a0df82a2e"
                        ],
                        [
                            "@@ -204,12 +204,12 @@ def mainMethod(args):\n \n     # Get the MER pipeline version, the EDEN version and the cvmfs path\n     pipeline_version = \"10.1.0\"\n-    eden_version = \"Eden-3.0\"\n+    eden_version = \"Eden-3.1\"\n     cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     if pipeline_branch == \"DEVELOP\":\n         pipeline_version = \"10.1\"\n-        eden_version = \"Eden-3.0-dev\"\n+        eden_version = \"Eden-3.1-dev\"\n         cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     # Set the execution environment information\n",
                            "Fixes eden version in PPO",
                            "Javier Gracia Carpio",
                            "2023-06-28T22:44:41.000+00:00",
                            "8f8a41fda9e375482323cb010902aae18848bc60"
                        ],
                        [
                            "@@ -118,7 +118,7 @@ def mainMethod(args):\n \n     # Download the PPO metadata\n     logger.info(\"Downloading PPO metadata with Id: %s\", ppo_id)\n-    database = \"DM9.1\"\n+    database = \"DM9.2\"\n     ppo_metadata = archive_utils.get_ppo_metadata(ppo_id, database, project)\n \n     # Get the PPO input and output ports\n@@ -203,14 +203,14 @@ def mainMethod(args):\n     ppo.ParentPlanId = \"EUC_MER_ANALYSIS_VISONLY_%s_%s\" % (pipeline_branch, database)\n \n     # Get the MER pipeline version, the EDEN version and the cvmfs path\n-    pipeline_version = \"9.1.1\"\n+    pipeline_version = \"10.1.0\"\n     eden_version = \"Eden-3.0\"\n-    cvmfs_path = \"/cvmfs/euclid.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid\"\n+    cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     if pipeline_branch == \"DEVELOP\":\n-        pipeline_version = \"10.0\"\n+        pipeline_version = \"10.1\"\n         eden_version = \"Eden-3.0-dev\"\n-        cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid\"\n+        cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     # Set the execution environment information\n     execution_env = ppo.PipelineExecEnv\n@@ -218,7 +218,7 @@ def mainMethod(args):\n     execution_env.PipelineDefinitionId = \"PipDef_MER_ANALYSE_TILE_VISONLY_XXXX\"\n     execution_env.EdenVersion = eden_version\n     execution_env.PipelineRootPath = (\n-        \"%s/MER_IAL_Pipelines/%s/InstallArea/x86_64-conda_cos6-gcc93-o2g/\"\n+        \"%s/MER_IAL_Pipelines/%s/InstallArea/x86_64-conda_ry9-gcc11-o2g/\"\n         \"auxdir/MER_AnalyseTile_Pipeline\" % (cvmfs_path, pipeline_version))\n     execution_env.EstimatedWordirSizeGB = 500\n     execution_env.WorkdirRetentionSuccessPolicy = \"RETAIN_ALL\"\n",
                            "Update to DM9.2 and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-22T10:20:56.000+00:00",
                            "ba4aaae064df5d0a1922d394ff86f78bf393a0a6"
                        ]
                    ],
                    "MER_ProcessingUtils/python/MER_ProcessingUtils/MER_CreateMerProcessTileMorphologyPPO.py": [
                        [
                            "@@ -169,7 +169,7 @@ def mainMethod(args):\n     ppo.ParentPlanId = \"EUC_MER_MORPHOLOGY_%s_%s\" % (pipeline_branch, database)\n \n     # Get the MER pipeline version, the EDEN version and the cvmfs path\n-    pipeline_version = \"10.1.0\"\n+    pipeline_version = \"10.1.3\"\n     eden_version = \"Eden-3.1\"\n     cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n",
                            "Update release versions",
                            "Javier Gracia Carpio",
                            "2023-08-14T16:43:51.000+00:00",
                            "0a5062d61cf546f1fc8e0de51220838393512104"
                        ],
                        [
                            "@@ -65,7 +65,7 @@ def defineSpecificProgramOptions():\n \n     parser.add_argument(\"--project\", dest=\"project\",\n                         type=str, help=\"The EAS project where the PPO input \"\n-                        \"products metadata are stored (TEST or EUCLID).\")\n+                        \"products metadata are stored (TTEST, EUCLID or ANY).\")\n \n     parser.add_argument(\"--outdir\", dest=\"output_directory\",\n                         type=str, help=\"The complete path to the output \"\n",
                            "Updates doc",
                            "Javier Gracia Carpio",
                            "2023-07-19T16:47:32.000+00:00",
                            "8e3e01d5d47fc8672b2a949292b5eeb9a10e8a05"
                        ],
                        [
                            "@@ -174,7 +174,7 @@ def mainMethod(args):\n     cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     if pipeline_branch == \"DEVELOP\":\n-        pipeline_version = \"10.1\"\n+        pipeline_version = \"10.2\"\n         eden_version = \"Eden-3.1-dev\"\n         cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n",
                            "Increases develop versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T20:23:02.000+00:00",
                            "000847717abdedcde0f6a26efbf57b5a0df82a2e"
                        ],
                        [
                            "@@ -108,7 +108,7 @@ def mainMethod(args):\n \n     # Download the PPO metadata\n     logger.info(\"Downloading PPO metadata with Id: %s\", ppo_id)\n-    database = \"DM9.1\"\n+    database = \"DM9.2\"\n     ppo_metadata = archive_utils.get_ppo_metadata(ppo_id, database, project)\n \n     # Get the PPO input and output ports\n@@ -169,14 +169,14 @@ def mainMethod(args):\n     ppo.ParentPlanId = \"EUC_MER_MORPHOLOGY_%s_%s\" % (pipeline_branch, database)\n \n     # Get the MER pipeline version, the EDEN version and the cvmfs path\n-    pipeline_version = \"9.1.1\"\n-    eden_version = \"Eden-3.0\"\n-    cvmfs_path = \"/cvmfs/euclid.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid\"\n+    pipeline_version = \"10.1.0\"\n+    eden_version = \"Eden-3.1\"\n+    cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     if pipeline_branch == \"DEVELOP\":\n-        pipeline_version = \"10.0\"\n-        eden_version = \"Eden-3.0-dev\"\n-        cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid\"\n+        pipeline_version = \"10.1\"\n+        eden_version = \"Eden-3.1-dev\"\n+        cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     # Set the execution environment information\n     execution_env = ppo.PipelineExecEnv\n@@ -184,7 +184,7 @@ def mainMethod(args):\n     execution_env.PipelineDefinitionId = \"PipDef_MER_MORPHOLOGY_TILE_XXXX\"\n     execution_env.EdenVersion = eden_version\n     execution_env.PipelineRootPath = (\n-        \"%s/MER_IAL_Pipelines/%s/InstallArea/x86_64-conda_cos6-gcc93-o2g/\"\n+        \"%s/MER_IAL_Pipelines/%s/InstallArea/x86_64-conda_ry9-gcc11-o2g/\"\n         \"auxdir/MER_ProcessTileMorpho_Pipeline\" % (cvmfs_path, pipeline_version))\n     execution_env.EstimatedWordirSizeGB = 500\n     execution_env.WorkdirRetentionSuccessPolicy = \"RETAIN_ALL\"\n",
                            "Update to DM9.2 and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-22T10:20:56.000+00:00",
                            "ba4aaae064df5d0a1922d394ff86f78bf393a0a6"
                        ]
                    ],
                    "MER_ProcessingUtils/python/MER_ProcessingUtils/MER_CreateMerProcessTilePPO.py": [
                        [
                            "@@ -293,7 +293,7 @@ def mainMethod(args):\n     ppo.ParentPlanId = \"EUC_MER_%s_%s\" % (pipeline_branch, database)\n \n     # Get the MER pipeline version, the EDEN version and the cvmfs path\n-    pipeline_version = \"10.1.0\"\n+    pipeline_version = \"10.1.3\"\n     eden_version = \"Eden-3.1\"\n     cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n",
                            "Update release versions",
                            "Javier Gracia Carpio",
                            "2023-08-14T16:43:51.000+00:00",
                            "0a5062d61cf546f1fc8e0de51220838393512104"
                        ],
                        [
                            "@@ -183,7 +183,7 @@ def mainMethod(args):\n \n     # Define the validation status query and the spatial intersection query\n     validation_query = \"Header.ManualValidationStatus!=INVALID\"\n-    spatial_query = \"spatial_query=INTERSECT_SHAPELY(0.01,100.0)DpdMerTile,%sREVERSE\" % mer_tiles_ids[0]\n+    spatial_query = \"spatial_query=INTERSECT(0.01,100.0)DpdMerTile,%sREVERSE\" % mer_tiles_ids[0]\n \n     # Get the EXT Gaia cutout catalog ids\n     logger.info(\"Querying EAS to get the EXT Gaia cutout product ids...\")\n",
                            "Test",
                            "Javier Gracia Carpio",
                            "2023-08-11T14:30:47.000+00:00",
                            "ac5722a1ffb5930e582b4aef6c2c121c01ef7c3e"
                        ],
                        [
                            "@@ -183,7 +183,7 @@ def mainMethod(args):\n \n     # Define the validation status query and the spatial intersection query\n     validation_query = \"Header.ManualValidationStatus!=INVALID\"\n-    spatial_query = \"spatial_query=INTERSECT(0.01,100.0)DpdMerTile,%sREVERSE\" % mer_tiles_ids[0]\n+    spatial_query = \"spatial_query=INTERSECT_SHAPELY(0.01,100.0)DpdMerTile,%sREVERSE\" % mer_tiles_ids[0]\n \n     # Get the EXT Gaia cutout catalog ids\n     logger.info(\"Querying EAS to get the EXT Gaia cutout product ids...\")\n",
                            "Use INTERSECT_SHAPELY",
                            "Javier Gracia Carpio",
                            "2023-08-11T14:06:15.000+00:00",
                            "3dbdd58bd70c5779f051a6871f9491490f8a38e8"
                        ],
                        [
                            "@@ -60,7 +60,8 @@ def defineSpecificProgramOptions():\n                         type=str, help=\"The VIS data set release.\")\n \n     parser.add_argument(\"--nir_release\", dest=\"nir_release\",\n-                        type=str, help=\"The NIR data set release.\")\n+                        type=str, required=False, default=\"no_data\",\n+                        help=\"The NIR data set release.\")\n \n     parser.add_argument(\"--des_release\", dest=\"des_release\",\n                         type=str, required=False, default=\"no_data\",\n",
                            "Make nir_release optional",
                            "Javier Gracia Carpio",
                            "2023-08-04T09:55:49.000+00:00",
                            "9bd1460514373c316ebeb8a8f7ec2f3d483b07ad"
                        ],
                        [
                            "@@ -242,7 +242,7 @@ def mainMethod(args):\n \n     # Make sure that there is at least one NIR calibrated frame id\n     if len(nir_calibrated_frames_ids) == 0:\n-        raise Exception(\n+        logger.info(\n             \"There is no NIR calibrated frames product in EAS for the \"\n             \"specified query.\")\n \n",
                            "Do not crash if there is no NIR products in the query",
                            "Javier Gracia Carpio",
                            "2023-08-04T09:37:33.000+00:00",
                            "dbc7741d838c9928d6ec21d48380b50479fa4d62"
                        ],
                        [
                            "@@ -215,7 +215,8 @@ def mainMethod(args):\n     # Get the VIS calibrated frames products ids\n     logger.info(\"Querying EAS to get the VIS calibrated frames products ids...\")\n     vis_calibrated_frames_ids = archive_utils.get_products_ids(\n-        \"DpdVisCalibratedFrame\", vis_calibrated_frames_query, database, project)\n+        \"DpdVisCalibratedFrame\", vis_calibrated_frames_query, database, project,\n+        make_asy=True)\n \n     # Make sure that there is at least one VIS calibrated frame id\n     if len(vis_calibrated_frames_ids) == 0:\n@@ -236,7 +237,8 @@ def mainMethod(args):\n     # Get the NIR calibrated frames product ids\n     logger.info(\"Querying EAS to get the NIR calibrated frames products ids...\")\n     nir_calibrated_frames_ids = archive_utils.get_products_ids(\n-        \"DpdNirCalibratedFrame\", nir_calibrated_frames_query, database, project)\n+        \"DpdNirCalibratedFrame\", nir_calibrated_frames_query, database, project,\n+        make_asy=True)\n \n     # Make sure that there is at least one NIR calibrated frame id\n     if len(nir_calibrated_frames_ids) == 0:\n",
                            "Make asynchronous queries for VIS and NIR products",
                            "Javier Gracia Carpio",
                            "2023-07-27T10:25:19.000+00:00",
                            "1ab2e9d9dcf8ad1419de2313c3bcb29c3b7abbc8"
                        ],
                        [
                            "@@ -112,7 +112,7 @@ def defineSpecificProgramOptions():\n \n     parser.add_argument(\"--project\", dest=\"project\",\n                         type=str, help=\"The EAS project where the PPO input \"\n-                        \"products metadata are stored (TEST or EUCLID).\")\n+                        \"products metadata are stored (TEST, EUCLID or ANY).\")\n \n     parser.add_argument(\"--outdir\", dest=\"output_directory\",\n                         type=str, help=\"The complete path to the output \"\n",
                            "Updates doc",
                            "Javier Gracia Carpio",
                            "2023-07-19T16:47:32.000+00:00",
                            "8e3e01d5d47fc8672b2a949292b5eeb9a10e8a05"
                        ],
                        [
                            "@@ -146,6 +146,7 @@ def mainMethod(args):\n     tile_version = args.tile_version\n     vis_release = args.vis_release\n     nir_release = args.nir_release\n+    gaia_release = args.gaia_release\n     ppo_counter = args.ppo_counter\n     target_sdc = args.target_sdc\n     pipeline_branch = args.pipeline_branch\n@@ -186,7 +187,12 @@ def mainMethod(args):\n     # Get the EXT Gaia cutout catalog ids\n     logger.info(\"Querying EAS to get the EXT Gaia cutout product ids...\")\n     ext_gaia_cutout_query = validation_query + \"&Data.TileIndex=%s\" % tile_index\n-    ext_gaia_cutout_query += \"&Data.Comment=like*%s*\" % args.gaia_release\n+\n+    if \"*\" in gaia_release:\n+        ext_gaia_cutout_query += \"&Header.DataSetRelease=like%s\" % gaia_release\n+    else:\n+        ext_gaia_cutout_query += \"&Header.DataSetRelease=%s\" % gaia_release\n+\n     ext_gaia_cutout_ids = archive_utils.get_products_ids(\n         \"DpdExtGaiaCutout\", ext_gaia_cutout_query, database, project)\n \n@@ -199,7 +205,9 @@ def mainMethod(args):\n     # Build the VIS calibrated frames query\n     vis_calibrated_frames_query = validation_query\n \n-    if vis_release != \"\":\n+    if \"*\" in vis_release:\n+        vis_calibrated_frames_query += \"&Header.DataSetRelease=like%s\" % vis_release\n+    else:\n         vis_calibrated_frames_query += \"&Header.DataSetRelease=%s\" % vis_release\n \n     vis_calibrated_frames_query += \"&\" + spatial_query\n@@ -218,7 +226,9 @@ def mainMethod(args):\n     # Build the NIR calibrated frames query\n     nir_calibrated_frames_query = validation_query\n \n-    if nir_release != \"\":\n+    if \"*\" in nir_release:\n+        nir_calibrated_frames_query += \"&Header.DataSetRelease=like%s\" % nir_release\n+    else:\n         nir_calibrated_frames_query += \"&Header.DataSetRelease=%s\" % nir_release\n \n     nir_calibrated_frames_query += \"&\" + spatial_query\n@@ -255,7 +265,9 @@ def mainMethod(args):\n         # Build the EXT stacks query\n         ext_stacks_query = validation_query\n \n-        if ext_release != \"\":\n+        if \"*\" in ext_release:\n+            ext_stacks_query += \"&Header.DataSetRelease=like%s\" % ext_release\n+        else:\n             ext_stacks_query += \"&Header.DataSetRelease=%s\" % ext_release\n \n         ext_stacks_query += \"&Data.TileIndex=%s\" % tile_index\n",
                            "Adds possibility to use like queries",
                            "Javier Gracia Carpio",
                            "2023-07-18T11:09:09.000+00:00",
                            "f12fe303ac2dc99558a741b828c71c8845f30e0d"
                        ],
                        [
                            "@@ -283,7 +283,7 @@ def mainMethod(args):\n     cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     if pipeline_branch == \"DEVELOP\":\n-        pipeline_version = \"10.1\"\n+        pipeline_version = \"10.2\"\n         eden_version = \"Eden-3.1-dev\"\n         cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n",
                            "Increases develop versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T20:23:02.000+00:00",
                            "000847717abdedcde0f6a26efbf57b5a0df82a2e"
                        ],
                        [
                            "@@ -186,7 +186,7 @@ def mainMethod(args):\n     # Get the EXT Gaia cutout catalog ids\n     logger.info(\"Querying EAS to get the EXT Gaia cutout product ids...\")\n     ext_gaia_cutout_query = validation_query + \"&Data.TileIndex=%s\" % tile_index\n-    ext_gaia_cutout_query += \"&Data.Comment=%s\" % args.gaia_release\n+    ext_gaia_cutout_query += \"&Data.Comment=like*%s*\" % args.gaia_release\n     ext_gaia_cutout_ids = archive_utils.get_products_ids(\n         \"DpdExtGaiaCutout\", ext_gaia_cutout_query, database, project)\n \n",
                            "Check like query",
                            "Javier Gracia Carpio",
                            "2023-06-27T20:55:39.000+00:00",
                            "0a4b0015172bf18a52457d4f8048117432268edc"
                        ],
                        [
                            "@@ -86,6 +86,10 @@ def defineSpecificProgramOptions():\n                         type=str, required=False, default=\"no_data\",\n                         help=\"The EXT WISHES data set release.\")\n \n+    parser.add_argument(\"--gaia_release\", dest=\"gaia_release\",\n+                        type=str, required=False, default=\"no_data\",\n+                        help=\"The GAIA cutout catalog release.\")\n+\n     parser.add_argument(\"--configuration_set_id\", dest=\"configuration_set_id\",\n                         type=str, help=\"The MER configuration set product id.\")\n \n@@ -182,6 +186,7 @@ def mainMethod(args):\n     # Get the EXT Gaia cutout catalog ids\n     logger.info(\"Querying EAS to get the EXT Gaia cutout product ids...\")\n     ext_gaia_cutout_query = validation_query + \"&Data.TileIndex=%s\" % tile_index\n+    ext_gaia_cutout_query += \"&Data.Comment=%s\" % args.gaia_release\n     ext_gaia_cutout_ids = archive_utils.get_products_ids(\n         \"DpdExtGaiaCutout\", ext_gaia_cutout_query, database, project)\n \n",
                            "Adds gaia_release parameter",
                            "Javier Gracia Carpio",
                            "2023-06-26T13:21:28.000+00:00",
                            "cecb61ba684463be8ae46d6408162e6e6cfce3cc"
                        ],
                        [
                            "@@ -162,7 +162,7 @@ def mainMethod(args):\n \n     # Get the MER tiles ids\n     logger.info(\"Querying EAS to get the MER tiles product ids...\")\n-    database = \"DM9.1\"\n+    database = \"DM9.2\"\n     mer_tiles_ids = archive_utils.get_products_ids(\n         \"DpdMerTile\", mer_tiles_query, database, project)\n \n@@ -273,14 +273,14 @@ def mainMethod(args):\n     ppo.ParentPlanId = \"EUC_MER_%s_%s\" % (pipeline_branch, database)\n \n     # Get the MER pipeline version, the EDEN version and the cvmfs path\n-    pipeline_version = \"9.1.1\"\n-    eden_version = \"Eden-3.0\"\n-    cvmfs_path = \"/cvmfs/euclid.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid\"\n+    pipeline_version = \"10.1.0\"\n+    eden_version = \"Eden-3.1\"\n+    cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     if pipeline_branch == \"DEVELOP\":\n-        pipeline_version = \"10.0\"\n-        eden_version = \"Eden-3.0-dev\"\n-        cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid\"\n+        pipeline_version = \"10.1\"\n+        eden_version = \"Eden-3.1-dev\"\n+        cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     # Set the execution environment information\n     execution_env = ppo.PipelineExecEnv\n@@ -288,7 +288,7 @@ def mainMethod(args):\n     execution_env.PipelineDefinitionId = \"PipDef_MER_PROCESS_TILE_%s_XXXX\" % tile_use_case\n     execution_env.EdenVersion = eden_version\n     execution_env.PipelineRootPath = (\n-        \"%s/MER_IAL_Pipelines/%s/InstallArea/x86_64-conda_cos6-gcc93-o2g/\"\n+        \"%s/MER_IAL_Pipelines/%s/InstallArea/x86_64-conda_ry9-gcc11-o2g/\"\n         \"auxdir/MER_ProcessTile_Pipeline\" % (cvmfs_path, pipeline_version))\n     execution_env.EstimatedWorkdirSizeGB = 500\n     execution_env.WorkdirRetentionSuccessPolicy = \"RETAIN_ALL\"\n",
                            "Update to DM9.2 and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-22T10:20:56.000+00:00",
                            "ba4aaae064df5d0a1922d394ff86f78bf393a0a6"
                        ]
                    ],
                    "MER_ProcessingUtils/python/MER_ProcessingUtils/MER_CreateMerProcessTileVisOnlyPPO.py": [
                        [
                            "@@ -207,7 +207,7 @@ def mainMethod(args):\n     ppo.ParentPlanId = \"EUC_MER_VISONLY_%s_%s\" % (pipeline_branch, database)\n \n     # Get the MER pipeline version, the EDEN version and the cvmfs path\n-    pipeline_version = \"10.1.0\"\n+    pipeline_version = \"10.1.3\"\n     eden_version = \"Eden-3.1\"\n     cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n",
                            "Update release versions",
                            "Javier Gracia Carpio",
                            "2023-08-14T16:43:51.000+00:00",
                            "0a5062d61cf546f1fc8e0de51220838393512104"
                        ],
                        [
                            "@@ -154,7 +154,7 @@ def mainMethod(args):\n \n     # Define the validation status query and the spatial intersection query\n     validation_query = \"Header.ManualValidationStatus!=INVALID\"\n-    spatial_query = \"spatial_query=INTERSECT_SHAPELY(0.01,100.0)DpdMerTile,%sREVERSE\" % mer_tiles_ids[0]\n+    spatial_query = \"spatial_query=INTERSECT(0.01,100.0)DpdMerTile,%sREVERSE\" % mer_tiles_ids[0]\n \n     # Get the EXT Gaia cutout catalog ids\n     logger.info(\"Querying EAS to get the EXT Gaia cutout product ids...\")\n",
                            "Go back to normal INTERSECT",
                            "Javier Gracia Carpio",
                            "2023-08-11T14:59:21.000+00:00",
                            "715fbf907d4a6390d61f0d2825d181af8c4cae26"
                        ],
                        [
                            "@@ -154,7 +154,7 @@ def mainMethod(args):\n \n     # Define the validation status query and the spatial intersection query\n     validation_query = \"Header.ManualValidationStatus!=INVALID\"\n-    spatial_query = \"spatial_query=INTERSECT(0.01,100.0)DpdMerTile,%sREVERSE\" % mer_tiles_ids[0]\n+    spatial_query = \"spatial_query=INTERSECT_SHAPELY(0.01,100.0)DpdMerTile,%sREVERSE\" % mer_tiles_ids[0]\n \n     # Get the EXT Gaia cutout catalog ids\n     logger.info(\"Querying EAS to get the EXT Gaia cutout product ids...\")\n",
                            "Use INTERSECT_SHAPELY",
                            "Javier Gracia Carpio",
                            "2023-08-11T14:06:15.000+00:00",
                            "3dbdd58bd70c5779f051a6871f9491490f8a38e8"
                        ],
                        [
                            "@@ -187,7 +187,8 @@ def mainMethod(args):\n     # Get the VIS calibrated frames products ids\n     logger.info(\"Querying EAS to get the VIS calibrated frames products ids...\")\n     vis_calibrated_frames_ids = archive_utils.get_products_ids(\n-        \"DpdVisCalibratedFrame\", vis_calibrated_frames_query, database, project)\n+        \"DpdVisCalibratedFrame\", vis_calibrated_frames_query, database, project,\n+        make_asy=True)\n \n     # Make sure that there is at least one VIS calibrated frame id\n     if len(vis_calibrated_frames_ids) == 0:\n",
                            "Make asynchronous queries for VIS and NIR products",
                            "Javier Gracia Carpio",
                            "2023-07-27T10:25:19.000+00:00",
                            "1ab2e9d9dcf8ad1419de2313c3bcb29c3b7abbc8"
                        ],
                        [
                            "@@ -187,7 +187,7 @@ def mainMethod(args):\n     # Get the VIS calibrated frames products ids\n     logger.info(\"Querying EAS to get the VIS calibrated frames products ids...\")\n     vis_calibrated_frames_ids = archive_utils.get_products_ids(\n-        \"DpdVisCalibratedFrame\", vis_calibrated_frames_query, database, project, logger)\n+        \"DpdVisCalibratedFrame\", vis_calibrated_frames_query, database, project)\n \n     # Make sure that there is at least one VIS calibrated frame id\n     if len(vis_calibrated_frames_ids) == 0:\n",
                            "Do not print the query in the logger",
                            "Javier Gracia Carpio",
                            "2023-07-20T13:38:45.000+00:00",
                            "941aa97bc7f04eb854ec49c77b46b99c730dc9f1"
                        ],
                        [
                            "@@ -85,7 +85,7 @@ def defineSpecificProgramOptions():\n \n     parser.add_argument(\"--project\", dest=\"project\",\n                         type=str, help=\"The EAS project where the PPO input \"\n-                        \"products metadata are stored (TEST or EUCLID).\")\n+                        \"products metadata are stored (TEST, EUCLID or ANY).\")\n \n     parser.add_argument(\"--outdir\", dest=\"output_directory\",\n                         type=str, help=\"The complete path to the output \"\n@@ -187,7 +187,7 @@ def mainMethod(args):\n     # Get the VIS calibrated frames products ids\n     logger.info(\"Querying EAS to get the VIS calibrated frames products ids...\")\n     vis_calibrated_frames_ids = archive_utils.get_products_ids(\n-        \"DpdVisCalibratedFrame\", vis_calibrated_frames_query, database, project)\n+        \"DpdVisCalibratedFrame\", vis_calibrated_frames_query, database, project, logger)\n \n     # Make sure that there is at least one VIS calibrated frame id\n     if len(vis_calibrated_frames_ids) == 0:\n",
                            "Updates doc",
                            "Javier Gracia Carpio",
                            "2023-07-19T16:47:32.000+00:00",
                            "8e3e01d5d47fc8672b2a949292b5eeb9a10e8a05"
                        ],
                        [
                            "@@ -118,6 +118,7 @@ def mainMethod(args):\n     tile_use_case = args.tile_use_case\n     tile_version = args.tile_version\n     vis_release = args.vis_release\n+    gaia_release = args.gaia_release\n     ppo_counter = args.ppo_counter\n     target_sdc = args.target_sdc\n     pipeline_branch = args.pipeline_branch\n@@ -158,7 +159,12 @@ def mainMethod(args):\n     # Get the EXT Gaia cutout catalog ids\n     logger.info(\"Querying EAS to get the EXT Gaia cutout product ids...\")\n     ext_gaia_cutout_query = validation_query + \"&Data.TileIndex=%s\" % tile_index\n-    ext_gaia_cutout_query += \"&Data.Comment=like*%s*\" % args.gaia_release\n+\n+    if \"*\" in gaia_release:\n+        ext_gaia_cutout_query += \"&Header.DataSetRelease=like%s\" % gaia_release\n+    else:\n+        ext_gaia_cutout_query += \"&Header.DataSetRelease=%s\" % gaia_release\n+\n     ext_gaia_cutout_ids = archive_utils.get_products_ids(\n         \"DpdExtGaiaCutout\", ext_gaia_cutout_query, database, project)\n \n@@ -171,7 +177,9 @@ def mainMethod(args):\n     # Build the VIS calibrated frames query\n     vis_calibrated_frames_query = validation_query\n \n-    if vis_release != \"\":\n+    if \"*\" in vis_release:\n+        vis_calibrated_frames_query += \"&Header.DataSetRelease=like%s\" % vis_release\n+    else:\n         vis_calibrated_frames_query += \"&Header.DataSetRelease=%s\" % vis_release\n \n     vis_calibrated_frames_query += \"&\" + spatial_query\n",
                            "Adds possibility to use like queries",
                            "Javier Gracia Carpio",
                            "2023-07-18T11:09:09.000+00:00",
                            "f12fe303ac2dc99558a741b828c71c8845f30e0d"
                        ],
                        [
                            "@@ -203,7 +203,7 @@ def mainMethod(args):\n     cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     if pipeline_branch == \"DEVELOP\":\n-        pipeline_version = \"10.1\"\n+        pipeline_version = \"10.2\"\n         eden_version = \"Eden-3.1-dev\"\n         cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n",
                            "Increases develop versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T20:23:02.000+00:00",
                            "000847717abdedcde0f6a26efbf57b5a0df82a2e"
                        ],
                        [
                            "@@ -158,7 +158,7 @@ def mainMethod(args):\n     # Get the EXT Gaia cutout catalog ids\n     logger.info(\"Querying EAS to get the EXT Gaia cutout product ids...\")\n     ext_gaia_cutout_query = validation_query + \"&Data.TileIndex=%s\" % tile_index\n-    ext_gaia_cutout_query += \"&Data.Comment=%s\" % args.gaia_release\n+    ext_gaia_cutout_query += \"&Data.Comment=like*%s*\" % args.gaia_release\n     ext_gaia_cutout_ids = archive_utils.get_products_ids(\n         \"DpdExtGaiaCutout\", ext_gaia_cutout_query, database, project)\n \n",
                            "Use like query also for VIS only PPOs",
                            "Javier Gracia Carpio",
                            "2023-06-27T21:04:49.000+00:00",
                            "2610ac9918c2bf942c3075713faf03ff559caaea"
                        ],
                        [
                            "@@ -213,7 +213,7 @@ def mainMethod(args):\n     execution_env.PipelineDefinitionId = \"PipDef_MER_PROCESS_TILE_VISONLY_XXXX\"\n     execution_env.EdenVersion = eden_version\n     execution_env.PipelineRootPath = (\n-        \"%s/MER_IAL_Pipelines/%s/InstallArea/x86_64-conda_cry9-gcc11-o2g/\"\n+        \"%s/MER_IAL_Pipelines/%s/InstallArea/x86_64-conda_ry9-gcc11-o2g/\"\n         \"auxdir/MER_ProcessTile_Pipeline\" % (cvmfs_path, pipeline_version))\n     execution_env.EstimatedWordirSizeGB = 500\n     execution_env.WorkdirRetentionSuccessPolicy = \"RETAIN_ALL\"\n",
                            "Fixes problem with cvmfs path",
                            "Javier Gracia Carpio",
                            "2023-06-26T18:01:49.000+00:00",
                            "273b1dcf3b722a561927bd1c80db32f2b583aae3"
                        ],
                        [
                            "@@ -59,6 +59,10 @@ def defineSpecificProgramOptions():\n     parser.add_argument(\"--vis_release\", dest=\"vis_release\",\n                         type=str, help=\"The VIS data set release.\")\n \n+    parser.add_argument(\"--gaia_release\", dest=\"gaia_release\",\n+                        type=str, required=False, default=\"no_data\",\n+                        help=\"The GAIA cutout catalog release.\")\n+\n     parser.add_argument(\"--configuration_set_id\", dest=\"configuration_set_id\",\n                         type=str, help=\"The MER configuration set product id.\")\n \n@@ -154,6 +158,7 @@ def mainMethod(args):\n     # Get the EXT Gaia cutout catalog ids\n     logger.info(\"Querying EAS to get the EXT Gaia cutout product ids...\")\n     ext_gaia_cutout_query = validation_query + \"&Data.TileIndex=%s\" % tile_index\n+    ext_gaia_cutout_query += \"&Data.Comment=%s\" % args.gaia_release\n     ext_gaia_cutout_ids = archive_utils.get_products_ids(\n         \"DpdExtGaiaCutout\", ext_gaia_cutout_query, database, project)\n \n",
                            "Adds gaia_release parameter",
                            "Javier Gracia Carpio",
                            "2023-06-26T13:21:28.000+00:00",
                            "cecb61ba684463be8ae46d6408162e6e6cfce3cc"
                        ],
                        [
                            "@@ -134,7 +134,7 @@ def mainMethod(args):\n \n     # Get the MER tiles ids\n     logger.info(\"Querying EAS to get the MER tiles product ids...\")\n-    database = \"DM9.1\"\n+    database = \"DM9.2\"\n     mer_tiles_ids = archive_utils.get_products_ids(\n         \"DpdMerTile\", mer_tiles_query, database, project)\n \n@@ -193,14 +193,14 @@ def mainMethod(args):\n     ppo.ParentPlanId = \"EUC_MER_VISONLY_%s_%s\" % (pipeline_branch, database)\n \n     # Get the MER pipeline version, the EDEN version and the cvmfs path\n-    pipeline_version = \"9.1.1\"\n-    eden_version = \"Eden-3.0\"\n-    cvmfs_path = \"/cvmfs/euclid.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid\"\n+    pipeline_version = \"10.1.0\"\n+    eden_version = \"Eden-3.1\"\n+    cvmfs_path = \"/cvmfs/euclid.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     if pipeline_branch == \"DEVELOP\":\n-        pipeline_version = \"10.0\"\n-        eden_version = \"Eden-3.0-dev\"\n-        cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid\"\n+        pipeline_version = \"10.1\"\n+        eden_version = \"Eden-3.1-dev\"\n+        cvmfs_path = \"/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid\"\n \n     # Set the execution environment information\n     execution_env = ppo.PipelineExecEnv\n@@ -208,7 +208,7 @@ def mainMethod(args):\n     execution_env.PipelineDefinitionId = \"PipDef_MER_PROCESS_TILE_VISONLY_XXXX\"\n     execution_env.EdenVersion = eden_version\n     execution_env.PipelineRootPath = (\n-        \"%s/MER_IAL_Pipelines/%s/InstallArea/x86_64-conda_cos6-gcc93-o2g/\"\n+        \"%s/MER_IAL_Pipelines/%s/InstallArea/x86_64-conda_cry9-gcc11-o2g/\"\n         \"auxdir/MER_ProcessTile_Pipeline\" % (cvmfs_path, pipeline_version))\n     execution_env.EstimatedWordirSizeGB = 500\n     execution_env.WorkdirRetentionSuccessPolicy = \"RETAIN_ALL\"\n",
                            "Update to DM9.2 and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-22T10:20:56.000+00:00",
                            "ba4aaae064df5d0a1922d394ff86f78bf393a0a6"
                        ]
                    ],
                    "CMakeLists.txt": [
                        [
                            "@@ -14,4 +14,4 @@ find_package(ElementsProject)\n \n elements_project(MER_ProcessingUtils 10.2 USE Elements 6.2.1 MER_DataModelUtils 10.2\n                                                              ST_DataModel 9.2.0\n-                                                             ST_DataModelTools 9.2.1)\n+                                                             ST_DataModelTools 9.2.2)\n",
                            "Merge branch 'develop' of git@gitlab.euclid-sgs.uk:PF-MER/MER_ProcessingUtils.git into develop",
                            "Javier Gracia Carpio",
                            "2023-08-11T14:06:29.000+00:00",
                            "fd8bee5a1a6ef6e6a9ef83bbf44ac68d6c96106c"
                        ],
                        [
                            "@@ -12,6 +12,6 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_ProcessingUtils 10.2 USE Elements 6.2.1 MER_DataModelUtils 10.1\n+elements_project(MER_ProcessingUtils 10.2 USE Elements 6.2.1 MER_DataModelUtils 10.2\n                                                              ST_DataModel 9.2.0\n                                                              ST_DataModelTools 9.2.1)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-07-03T14:59:47.000+00:00",
                            "cf4ea87072d9cfc025875fdc6538db0a578fd680"
                        ],
                        [
                            "@@ -12,6 +12,6 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_ProcessingUtils 10.1 USE Elements 6.2.1 MER_DataModelUtils 10.1\n-\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t ST_DataModel 9.2.0\n-\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t ST_DataModelTools 9.2.1)\n+elements_project(MER_ProcessingUtils 10.2 USE Elements 6.2.1 MER_DataModelUtils 10.1\n+                                                             ST_DataModel 9.2.0\n+                                                             ST_DataModelTools 9.2.1)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-07-03T14:59:38.000+00:00",
                            "fc1caea1fa6062617662918cbc6efe0be39577f3"
                        ],
                        [
                            "@@ -12,6 +12,6 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_ProcessingUtils 10.0 USE Elements 6.1.1 MER_DataModelUtils 10.0\n-\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t ST_DataModel 9.1.5\n-\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t ST_DataModelTools 9.1.2)\n+elements_project(MER_ProcessingUtils 10.1 USE Elements 6.2.1 MER_DataModelUtils 10.1\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t ST_DataModel 9.2.0\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t ST_DataModelTools 9.2.1)\n",
                            "Update to DM9.2 and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-22T10:20:56.000+00:00",
                            "ba4aaae064df5d0a1922d394ff86f78bf393a0a6"
                        ]
                    ],
                    "MER_ProcessingUtils/python/MER_ProcessingUtils/MER_DownloadProducts.py": [
                        [
                            "@@ -133,7 +133,7 @@ def mainMethod(args):\n \n     try:\n         products_metadata = archive_utils.get_products_metadata(\n-            product_class, query, database, project)\n+            product_class, query, database, project, make_asy=True)\n     except archive_utils.EASObjectNotFoundException as e:\n         logger.error(e)\n         return\n",
                            "Improve query",
                            "Javier Gracia Carpio",
                            "2023-08-07T18:31:32.000+00:00",
                            "b7a1ec8ff0747655c89f1f6ef6f636189443f65c"
                        ],
                        [
                            "@@ -58,7 +58,7 @@ def defineSpecificProgramOptions():\n \n     parser.add_argument(\"--database\", dest=\"database\",\n                         type=str, help=\"The EAS database where the PPO input \"\n-                        \"and output metadata are stored (DM9.1).\")\n+                        \"and output metadata are stored (DM9.2).\")\n \n     parser.add_argument(\"--project\", dest=\"project\",\n                         type=str, help=\"The EAS project where the PPO input \"\n",
                            "Update to DM9.2 and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-22T10:20:56.000+00:00",
                            "ba4aaae064df5d0a1922d394ff86f78bf393a0a6"
                        ]
                    ],
                    "MER_ProcessingUtils/python/MER_ProcessingUtils/MER_DownloadIntersectionMapsTiles.py": [
                        [
                            "@@ -58,7 +58,8 @@ def defineSpecificProgramOptions():\n \n     parser.add_argument(\"--project\", dest=\"project\",\n                         type=str, help=\"The EAS project where the tiles and \"\n-                        \"the intersection maps are stored (TEST or EUCLID).\")\n+                        \"the intersection maps are stored (TEST, EUCLID or \"\n+                        \"ANY).\")\n \n     parser.add_argument(\"--outdir\", dest=\"output_directory\",\n                         type=str, help=\"The complete path to the output \"\n",
                            "Updates doc",
                            "Javier Gracia Carpio",
                            "2023-07-19T16:47:32.000+00:00",
                            "8e3e01d5d47fc8672b2a949292b5eeb9a10e8a05"
                        ],
                        [
                            "@@ -91,7 +91,7 @@ def mainMethod(args):\n     # Get the intersection maps metadata\n     logger.info(\n         \"# Downloading intersection maps metadata with Id: %s\", product_id)\n-    database = \"DM9.1\"\n+    database = \"DM9.2\"\n \n     try:\n         intersection_maps_metadata = archive_utils.get_product_metadata(\n",
                            "Update to DM9.2 and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-22T10:20:56.000+00:00",
                            "ba4aaae064df5d0a1922d394ff86f78bf393a0a6"
                        ]
                    ],
                    "MER_ProcessingUtils/CMakeLists.txt": [
                        [
                            "@@ -72,6 +72,7 @@ elements_add_python_program(MER_CreateMerAnalyseTilePPO MER_ProcessingUtils.MER_\n elements_add_python_program(MER_CreateMerAnalyseTileVisOnlyPPO MER_ProcessingUtils.MER_CreateMerAnalyseTileVisOnlyPPO)\n elements_add_python_program(MER_CreateMerProcessTileMorphologyPPO MER_ProcessingUtils.MER_CreateMerProcessTileMorphologyPPO)\n elements_add_python_program(MER_CreateMerAnalyseTileMorphologyPPO MER_ProcessingUtils.MER_CreateMerAnalyseTileMorphologyPPO)\n+elements_add_python_program(MER_CreateMerAnalyseTileGaiaPPO MER_ProcessingUtils.MER_CreateMerAnalyseTileGaiaPPO)\n elements_add_python_program(MER_UpdateVisCalibratedFrames MER_ProcessingUtils.MER_UpdateVisCalibratedFrames)\n elements_add_python_program(MER_UpdateNirCalibratedFrames MER_ProcessingUtils.MER_UpdateNirCalibratedFrames)\n elements_add_python_program(MER_UpdateExtStackedFrames MER_ProcessingUtils.MER_UpdateExtStackedFrames)\n",
                            "Adds a new executable to create analysis PPOs for real data",
                            "Javier Gracia Carpio",
                            "2023-07-04T12:36:40.000+00:00",
                            "af7019db1ba01597bed244d40a81ed551d9ec2dc"
                        ],
                        [
                            "@@ -71,6 +71,7 @@ elements_add_python_program(MER_CreateMerProcessTileVisOnlyPPO MER_ProcessingUti\n elements_add_python_program(MER_CreateMerAnalyseTilePPO MER_ProcessingUtils.MER_CreateMerAnalyseTilePPO)\n elements_add_python_program(MER_CreateMerAnalyseTileVisOnlyPPO MER_ProcessingUtils.MER_CreateMerAnalyseTileVisOnlyPPO)\n elements_add_python_program(MER_CreateMerProcessTileMorphologyPPO MER_ProcessingUtils.MER_CreateMerProcessTileMorphologyPPO)\n+elements_add_python_program(MER_CreateMerAnalyseTileMorphologyPPO MER_ProcessingUtils.MER_CreateMerAnalyseTileMorphologyPPO)\n elements_add_python_program(MER_UpdateVisCalibratedFrames MER_ProcessingUtils.MER_UpdateVisCalibratedFrames)\n elements_add_python_program(MER_UpdateNirCalibratedFrames MER_ProcessingUtils.MER_UpdateNirCalibratedFrames)\n elements_add_python_program(MER_UpdateExtStackedFrames MER_ProcessingUtils.MER_UpdateExtStackedFrames)\n",
                            "Creates a new executable to create PPOs for the analysis pipeline",
                            "Javier Gracia Carpio",
                            "2023-06-12T14:10:06.000+00:00",
                            "6652eba80764345dd9233fbface29bf1f02bdf26"
                        ]
                    ],
                    "MER_ProcessingUtils/conf/MER_CreateMerAnalyseTileGaiaPPO.conf": [
                        [
                            "",
                            "Adds a new executable to create analysis PPOs for real data",
                            "Javier Gracia Carpio",
                            "2023-07-04T12:36:40.000+00:00",
                            "af7019db1ba01597bed244d40a81ed551d9ec2dc"
                        ]
                    ],
                    "MER_ProcessingUtils/tests/python/MER_CreateMerAnalyseTileGaiaPPO_test.py": [
                        [
                            "@@ -0,0 +1,37 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+File: tests/python/MER_CreateMerAnalyseTilePPO_test.py\n+\n+Collection of unit tests for the MER_CreateMerAnalsyseTilePPO executable.\n+\n+Created on: 16/08/22\n+Author: Javier Gracia Carpio (jgracia@mpe.mpg.de)\n+\"\"\"\n+\n+import MER_ProcessingUtils.MER_CreateMerAnalyseTileGaiaPPO as create_ppo\n+\n+\n+class TestMER_CreateMerAnalyseTileGaiaPPO(object):\n+    \"\"\"A collection of tests for the MER_CreateMerAnalyseTileGaiaPPO program.\n+\n+    \"\"\"\n+\n+    def test_main_method(self):\n+        assert True\n",
                            "Adds a new executable to create analysis PPOs for real data",
                            "Javier Gracia Carpio",
                            "2023-07-04T12:36:40.000+00:00",
                            "af7019db1ba01597bed244d40a81ed551d9ec2dc"
                        ]
                    ],
                    ".jenkinsFile": [
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\n-@Library('integration-library@release-9') _\n-pipelineElements(artifactId:\"MER_ProcessingUtils\", component:'eden.3.0')\n+@Library(value='integration-library@release-10') _\n+pipelineElements(name:\"MER_ProcessingUtils\", component:'eden.3.1')\n",
                            "Update to DM9.2 and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-22T10:20:56.000+00:00",
                            "ba4aaae064df5d0a1922d394ff86f78bf393a0a6"
                        ]
                    ],
                    "MER_ProcessingUtils/python/MER_ProcessingUtils/MER_DownloadPPOData.py": [
                        [
                            "@@ -59,7 +59,7 @@ def defineSpecificProgramOptions():\n \n     parser.add_argument(\"--database\", dest=\"database\",\n                         type=str, help=\"The EAS database where the PPO input \"\n-                        \"and output metadata are stored (DM9.1).\")\n+                        \"and output metadata are stored (DM9.2).\")\n \n     parser.add_argument(\"--project\", dest=\"project\",\n                         type=str, help=\"The EAS project where the PPO input \"\n",
                            "Update to DM9.2 and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-22T10:20:56.000+00:00",
                            "ba4aaae064df5d0a1922d394ff86f78bf393a0a6"
                        ]
                    ],
                    "MER_ProcessingUtils/python/MER_ProcessingUtils/MER_DownloadPPOLogs.py": [
                        [
                            "@@ -53,7 +53,7 @@ def defineSpecificProgramOptions():\n \n     parser.add_argument(\"--database\", dest=\"database\",\n                         type=str, help=\"The EAS database where the PPO is \"\n-                        \"stored (DM9.1).\")\n+                        \"stored (DM9.2).\")\n \n     parser.add_argument(\"--project\", dest=\"project\",\n                         type=str, help=\"The EAS project where the PPO is \"\n",
                            "Update to DM9.2 and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-22T10:20:56.000+00:00",
                            "ba4aaae064df5d0a1922d394ff86f78bf393a0a6"
                        ]
                    ],
                    "MER_ProcessingUtils/conf/MER_CreateMerAnalyseTileMorphologyPPO.conf": [
                        [
                            "",
                            "Creates a new executable to create PPOs for the analysis pipeline",
                            "Javier Gracia Carpio",
                            "2023-06-12T14:10:06.000+00:00",
                            "6652eba80764345dd9233fbface29bf1f02bdf26"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "9.1.1",
                        "created_at": "2023-03-08T17:35:02.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.0",
                        "created_at": "2023-07-03T14:58:48.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.1",
                        "created_at": "2023-07-28T14:43:59.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.2",
                        "created_at": "2023-08-07T15:41:38.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.3",
                        "created_at": "2023-08-14T12:01:55.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.4",
                        "created_at": "2023-08-14T14:23:42.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    }
                ]
            },
            "PF-MER/MER_Configuration": {
                "start date": "2023-06-09 09:00",
                "end date": "2023-08-23 15:00",
                "start tag": "> 8.0",
                "end tag": "> 8.0",
                "count_files_modified": "19",
                "modifications_by_file": {
                    "data/EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230817T180000.0Z_00.00.ini": [
                        [
                            "@@ -35,7 +35,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"DETECTION_TOTAL\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"YNISP\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GYNISP_line.fits\",\n@@ -43,7 +43,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Y_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"JNISP\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GJNISP_line.fits\",\n@@ -51,7 +51,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"J_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"HNISP\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GHNISP_line.fits\",\n@@ -59,7 +59,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"H_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"DECAM_G\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_G_line.fits\",\n@@ -67,7 +67,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"G_EXT_DECAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] !=-1)\"\n         },\n         \"DECAM_R\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_R_line.fits\",\n@@ -75,7 +75,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"R_EXT_DECAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"DECAM_I\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_I_line.fits\",\n@@ -83,7 +83,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"I_EXT_DECAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"DECAM_Z\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_Z_line.fits\",\n@@ -91,7 +91,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Z_EXT_DECAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"HSC_Z\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_HSC_Z_line.fits\",\n@@ -99,7 +99,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Z_EXT_HSC_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"JPCAM_G\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_JPCAM_G_line.fits\",\n@@ -107,7 +107,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"G_EXT_JPCAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"MEGACAM_R\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_MEGACAM_R_line.fits\",\n@@ -115,7 +115,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"R_EXT_MEGACAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"PANSTARRS_I\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_PANSTARRS_I_line.fits\",\n@@ -123,7 +123,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"I_EXT_PANSTARRS_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"PANSTARRS_Z\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_PANSTARRS_Z_line.fits\",\n@@ -131,7 +131,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Z_EXT_PANSTARRS_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"MEGACAM_U\": {\n             \"transformation_function\":\"EUC_SIM_STAR-CATALOG_06CC2173BBE8-0008009_20230120T200847.836558Z_DECAM_GR_I_MEGACAM_U_line.fits\",\n@@ -139,7 +139,7 @@\n             \"column_names\": [\"G_EXT_DECAM_TEMPLFIT\", \"R_EXT_DECAM_TEMPLFIT\", \"I_EXT_DECAM_TEMPLFIT\", \"U_EXT_MEGACAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"MER\", \"MER\", \"MER\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         }\n     }\n }\n",
                            "Updates ids",
                            "Javier Gracia Carpio",
                            "2023-08-17T09:00:02.000+00:00",
                            "62dbeca7c3485800676da71f32c67a33d594e53b"
                        ]
                    ],
                    "data/EUC_MER_CONF-FILE-ANALYSIS__20230817T180000.0Z_00.00.ini": [
                        [
                            "",
                            "Updates ids",
                            "Javier Gracia Carpio",
                            "2023-08-17T09:00:02.000+00:00",
                            "62dbeca7c3485800676da71f32c67a33d594e53b"
                        ]
                    ],
                    "inputs/configuration_set.xml": [
                        [
                            "@@ -1,7 +1,7 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230814</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230817</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n  \t\t<SoftwareRelease>10.1.3</SoftwareRelease>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-08-14T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-08-17T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>WIDE</ProcessingMode>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230814T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230817T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Updates ids",
                            "Javier Gracia Carpio",
                            "2023-08-17T09:00:02.000+00:00",
                            "62dbeca7c3485800676da71f32c67a33d594e53b"
                        ],
                        [
                            "@@ -1,11 +1,11 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230811</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230814</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n- \t\t<SoftwareRelease>10.1.2</SoftwareRelease>\n- \t\t<EuclidPipelineSoftwareRelease>10.1.2</EuclidPipelineSoftwareRelease>\n+ \t\t<SoftwareRelease>10.1.3</SoftwareRelease>\n+ \t\t<EuclidPipelineSoftwareRelease>10.1.3</EuclidPipelineSoftwareRelease>\n  \t\t<ProdSDC>SDC-IT</ProdSDC>\n  \t\t<DataSetRelease>NA</DataSetRelease>\n  \t\t<Purpose>UNKNOWN</Purpose>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-08-11T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-08-14T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>WIDE</ProcessingMode>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230811T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230814T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Renames files",
                            "Javier Gracia Carpio",
                            "2023-08-14T16:47:19.000+00:00",
                            "d69dae9c27c6b81c556bd5e6122a5c1a81cd7d90"
                        ],
                        [
                            "@@ -1,7 +1,7 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230807</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230811</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n  \t\t<SoftwareRelease>10.1.2</SoftwareRelease>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-08-07T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-08-11T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>WIDE</ProcessingMode>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230731T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230811T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Adds entry for classification validation",
                            "Javier Gracia Carpio",
                            "2023-08-11T08:53:05.000+00:00",
                            "4c2627f807e1aaa7a79edfd17ac84f6b8cff8761"
                        ],
                        [
                            "@@ -1,11 +1,11 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230731</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230807</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n- \t\t<SoftwareRelease>10.2</SoftwareRelease>\n- \t\t<EuclidPipelineSoftwareRelease>10.0</EuclidPipelineSoftwareRelease>\n+ \t\t<SoftwareRelease>10.1.2</SoftwareRelease>\n+ \t\t<EuclidPipelineSoftwareRelease>10.1.2</EuclidPipelineSoftwareRelease>\n  \t\t<ProdSDC>SDC-IT</ProdSDC>\n  \t\t<DataSetRelease>NA</DataSetRelease>\n  \t\t<Purpose>UNKNOWN</Purpose>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-07-31T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-08-07T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>WIDE</ProcessingMode>\n",
                            "Update product ids",
                            "Javier Gracia Carpio",
                            "2023-08-07T14:27:00.000+00:00",
                            "bd68732148271037defaed24d658de9bd07d2d9a"
                        ],
                        [
                            "@@ -1,7 +1,7 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230726</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230731</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n  \t\t<SoftwareRelease>10.2</SoftwareRelease>\n@@ -20,14 +20,14 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-07-26T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-07-31T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>WIDE</ProcessingMode>\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Mosaicing</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-MOSAICING__20230424T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-MOSAICING__20230731T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t\t<ConfigurationFile>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230726T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230731T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Update to new NIR image bit masks",
                            "Javier Gracia Carpio",
                            "2023-07-31T09:16:46.000+00:00",
                            "981fa02eff6bd1a1c29d1b7a2d483527d76187be"
                        ],
                        [
                            "@@ -1,7 +1,7 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230725</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230726</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n  \t\t<SoftwareRelease>10.2</SoftwareRelease>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-07-25T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-07-26T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>WIDE</ProcessingMode>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230725T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230726T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Fixes typo in configuration sets",
                            "Javier Gracia Carpio",
                            "2023-07-26T14:31:29.000+00:00",
                            "a55616da4457f53ff4478e1c68e952b780ffb3cd"
                        ],
                        [
                            "@@ -1,7 +1,7 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230704</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230725</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n  \t\t<SoftwareRelease>10.2</SoftwareRelease>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-07-04T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-07-25T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>WIDE</ProcessingMode>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230704T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230725T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Update time stamps",
                            "Javier Gracia Carpio",
                            "2023-07-25T11:54:32.000+00:00",
                            "23c2506c0cf9460c0e4377c2eab44e6060567d56"
                        ],
                        [
                            "@@ -1,10 +1,10 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230510</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230704</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n- \t\t<SoftwareRelease>10.0</SoftwareRelease>\n+ \t\t<SoftwareRelease>10.2</SoftwareRelease>\n  \t\t<EuclidPipelineSoftwareRelease>10.0</EuclidPipelineSoftwareRelease>\n  \t\t<ProdSDC>SDC-IT</ProdSDC>\n  \t\t<DataSetRelease>NA</DataSetRelease>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-05-09T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-07-04T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>WIDE</ProcessingMode>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230509T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230704T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Updates analysis configuration file",
                            "Javier Gracia Carpio",
                            "2023-07-04T12:49:32.000+00:00",
                            "a21d37db1eae58ab80aa11b8603056a9a38abf2c"
                        ]
                    ],
                    "inputs/configuration_set_DEEP.xml": [
                        [
                            "@@ -1,7 +1,7 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230814_DEEP</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230817_DEEP</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n  \t\t<SoftwareRelease>10.1.3</SoftwareRelease>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-08-14T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-08-17T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>DEEP</ProcessingMode>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230814T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230817T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Updates ids",
                            "Javier Gracia Carpio",
                            "2023-08-17T09:00:02.000+00:00",
                            "62dbeca7c3485800676da71f32c67a33d594e53b"
                        ],
                        [
                            "@@ -1,11 +1,11 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230811_DEEP</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230814_DEEP</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n- \t\t<SoftwareRelease>10.1.2</SoftwareRelease>\n- \t\t<EuclidPipelineSoftwareRelease>10.1.2</EuclidPipelineSoftwareRelease>\n+ \t\t<SoftwareRelease>10.1.3</SoftwareRelease>\n+ \t\t<EuclidPipelineSoftwareRelease>10.1.3</EuclidPipelineSoftwareRelease>\n  \t\t<ProdSDC>SDC-IT</ProdSDC>\n  \t\t<DataSetRelease>NA</DataSetRelease>\n  \t\t<Purpose>UNKNOWN</Purpose>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-08-11T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-08-14T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>DEEP</ProcessingMode>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230811T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230814T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Renames files",
                            "Javier Gracia Carpio",
                            "2023-08-14T16:47:19.000+00:00",
                            "d69dae9c27c6b81c556bd5e6122a5c1a81cd7d90"
                        ],
                        [
                            "@@ -1,7 +1,7 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230807_DEEP</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230811_DEEP</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n  \t\t<SoftwareRelease>10.1.2</SoftwareRelease>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-08-07T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-08-11T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>DEEP</ProcessingMode>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230731T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230811T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Adds entry for classification validation",
                            "Javier Gracia Carpio",
                            "2023-08-11T08:53:05.000+00:00",
                            "4c2627f807e1aaa7a79edfd17ac84f6b8cff8761"
                        ],
                        [
                            "@@ -1,11 +1,11 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230731_DEEP</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230807_DEEP</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n- \t\t<SoftwareRelease>10.2</SoftwareRelease>\n- \t\t<EuclidPipelineSoftwareRelease>10.0</EuclidPipelineSoftwareRelease>\n+ \t\t<SoftwareRelease>10.1.2</SoftwareRelease>\n+ \t\t<EuclidPipelineSoftwareRelease>10.1.2</EuclidPipelineSoftwareRelease>\n  \t\t<ProdSDC>SDC-IT</ProdSDC>\n  \t\t<DataSetRelease>NA</DataSetRelease>\n  \t\t<Purpose>UNKNOWN</Purpose>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-07-31T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-08-07T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>DEEP</ProcessingMode>\n",
                            "Update product ids",
                            "Javier Gracia Carpio",
                            "2023-08-07T14:27:00.000+00:00",
                            "bd68732148271037defaed24d658de9bd07d2d9a"
                        ],
                        [
                            "@@ -1,7 +1,7 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230726_DEEP</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230731_DEEP</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n  \t\t<SoftwareRelease>10.2</SoftwareRelease>\n@@ -20,14 +20,14 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-07-26T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-07-31T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>DEEP</ProcessingMode>\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Mosaicing</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-MOSAICING__20230424T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-MOSAICING__20230731T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t\t<ConfigurationFile>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230726T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230731T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Update to new NIR image bit masks",
                            "Javier Gracia Carpio",
                            "2023-07-31T09:16:46.000+00:00",
                            "981fa02eff6bd1a1c29d1b7a2d483527d76187be"
                        ],
                        [
                            "@@ -1,7 +1,7 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230725_DEEP</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230726_DEEP</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n  \t\t<SoftwareRelease>10.2</SoftwareRelease>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-07-25T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-07-26T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>DEEP</ProcessingMode>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230725T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230726T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Fixes typo in configuration sets",
                            "Javier Gracia Carpio",
                            "2023-07-26T14:31:29.000+00:00",
                            "a55616da4457f53ff4478e1c68e952b780ffb3cd"
                        ],
                        [
                            "@@ -1,7 +1,7 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230704_DEEP</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230725_DEEP</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n  \t\t<SoftwareRelease>10.2</SoftwareRelease>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-07-04T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-07-25T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>DEEP</ProcessingMode>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230704T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230725T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Update time stamps",
                            "Javier Gracia Carpio",
                            "2023-07-25T11:54:32.000+00:00",
                            "23c2506c0cf9460c0e4377c2eab44e6060567d56"
                        ],
                        [
                            "@@ -1,10 +1,10 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230510_DEEP</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230704_DEEP</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n- \t\t<SoftwareRelease>10.0</SoftwareRelease>\n+ \t\t<SoftwareRelease>10.2</SoftwareRelease>\n  \t\t<EuclidPipelineSoftwareRelease>10.0</EuclidPipelineSoftwareRelease>\n  \t\t<ProdSDC>SDC-IT</ProdSDC>\n  \t\t<DataSetRelease>NA</DataSetRelease>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-05-09T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-07-04T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>DEEP</ProcessingMode>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230509T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230704T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Updates analysis configuration file",
                            "Javier Gracia Carpio",
                            "2023-07-04T12:49:32.000+00:00",
                            "a21d37db1eae58ab80aa11b8603056a9a38abf2c"
                        ]
                    ],
                    "inputs/configuration_set_OTHERS.xml": [
                        [
                            "@@ -1,7 +1,7 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230814_OTHERS</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230817_OTHERS</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n  \t\t<SoftwareRelease>10.1.3</SoftwareRelease>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-08-14T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-08-17T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>OTHERS</ProcessingMode>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230814T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230817T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Updates ids",
                            "Javier Gracia Carpio",
                            "2023-08-17T09:00:02.000+00:00",
                            "62dbeca7c3485800676da71f32c67a33d594e53b"
                        ],
                        [
                            "@@ -1,11 +1,11 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230811_OTHERS</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230814_OTHERS</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n- \t\t<SoftwareRelease>10.1.2</SoftwareRelease>\n- \t\t<EuclidPipelineSoftwareRelease>10.1.2</EuclidPipelineSoftwareRelease>\n+ \t\t<SoftwareRelease>10.1.3</SoftwareRelease>\n+ \t\t<EuclidPipelineSoftwareRelease>10.1.3</EuclidPipelineSoftwareRelease>\n  \t\t<ProdSDC>SDC-IT</ProdSDC>\n  \t\t<DataSetRelease>NA</DataSetRelease>\n  \t\t<Purpose>UNKNOWN</Purpose>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-08-11T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-08-14T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>OTHERS</ProcessingMode>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230811T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230814T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Renames files",
                            "Javier Gracia Carpio",
                            "2023-08-14T16:47:19.000+00:00",
                            "d69dae9c27c6b81c556bd5e6122a5c1a81cd7d90"
                        ],
                        [
                            "@@ -1,7 +1,7 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230807_OTHERS</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230811_OTHERS</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n  \t\t<SoftwareRelease>10.1.2</SoftwareRelease>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-08-07T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-08-11T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>OTHERS</ProcessingMode>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230731T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230811T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Adds entry for classification validation",
                            "Javier Gracia Carpio",
                            "2023-08-11T08:53:05.000+00:00",
                            "4c2627f807e1aaa7a79edfd17ac84f6b8cff8761"
                        ],
                        [
                            "@@ -1,11 +1,11 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230731_OTHERS</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230807_OTHERS</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n- \t\t<SoftwareRelease>10.2</SoftwareRelease>\n- \t\t<EuclidPipelineSoftwareRelease>10.0</EuclidPipelineSoftwareRelease>\n+ \t\t<SoftwareRelease>10.1.2</SoftwareRelease>\n+ \t\t<EuclidPipelineSoftwareRelease>10.1.2</EuclidPipelineSoftwareRelease>\n  \t\t<ProdSDC>SDC-IT</ProdSDC>\n  \t\t<DataSetRelease>NA</DataSetRelease>\n  \t\t<Purpose>UNKNOWN</Purpose>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-07-26T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-08-07T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>OTHERS</ProcessingMode>\n",
                            "Update product ids",
                            "Javier Gracia Carpio",
                            "2023-08-07T14:27:00.000+00:00",
                            "bd68732148271037defaed24d658de9bd07d2d9a"
                        ],
                        [
                            "@@ -1,7 +1,7 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230726_OTHERS</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230731_OTHERS</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n  \t\t<SoftwareRelease>10.2</SoftwareRelease>\n@@ -27,7 +27,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Mosaicing</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-MOSAICING__20230424T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-MOSAICING__20230731T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t\t<ConfigurationFile>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230726T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230731T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Update to new NIR image bit masks",
                            "Javier Gracia Carpio",
                            "2023-07-31T09:16:46.000+00:00",
                            "981fa02eff6bd1a1c29d1b7a2d483527d76187be"
                        ],
                        [
                            "@@ -1,7 +1,7 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230725_OTHERS</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230726_OTHERS</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n  \t\t<SoftwareRelease>10.2</SoftwareRelease>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-07-25T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-07-26T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>OTHERS</ProcessingMode>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230725T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230726T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Fixes typo in configuration sets",
                            "Javier Gracia Carpio",
                            "2023-07-26T14:31:29.000+00:00",
                            "a55616da4457f53ff4478e1c68e952b780ffb3cd"
                        ],
                        [
                            "@@ -1,7 +1,7 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230704_OTHERS</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230725_OTHERS</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n  \t\t<SoftwareRelease>10.2</SoftwareRelease>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-07-04T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-07-25T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>OTHERS</ProcessingMode>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230704T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230725T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Update time stamps",
                            "Javier Gracia Carpio",
                            "2023-07-25T11:54:32.000+00:00",
                            "23c2506c0cf9460c0e4377c2eab44e6060567d56"
                        ],
                        [
                            "@@ -1,10 +1,10 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerConfigurationSet xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/configurationset\">\n \t<Header>\n-\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230510_OTHERS</ProductId>\n+\t\t<ProductId>EUC_MER_CONFIGURATION-SET_20230704_OTHERS</ProductId>\n  \t\t<ProductType>DpdMerConfigurationSet</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n- \t\t<SoftwareRelease>10.0</SoftwareRelease>\n+ \t\t<SoftwareRelease>10.2</SoftwareRelease>\n  \t\t<EuclidPipelineSoftwareRelease>10.0</EuclidPipelineSoftwareRelease>\n  \t\t<ProdSDC>SDC-IT</ProdSDC>\n  \t\t<DataSetRelease>NA</DataSetRelease>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-05-09T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-07-04T10:01:12.501000Z</CreationDate>\n \t</Header>\n \t<Data>\n \t\t<ProcessingMode>OTHERS</ProcessingMode>\n@@ -63,7 +63,7 @@\n \t\t<ConfigurationFile>\n \t\t\t<ModuleName>Analysis</ModuleName>\n \t\t\t<FileContainer filestatus=\"PROPOSED\">\n-\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230509T180000.0Z_00.00.ini</FileName>\n+\t\t\t\t<FileName>EUC_MER_CONF-FILE-ANALYSIS__20230704T180000.0Z_00.00.ini</FileName>\n \t\t\t</FileContainer>\n \t\t</ConfigurationFile>\n \t</Data>\n",
                            "Updates analysis configuration file",
                            "Javier Gracia Carpio",
                            "2023-07-04T12:49:32.000+00:00",
                            "a21d37db1eae58ab80aa11b8603056a9a38abf2c"
                        ]
                    ],
                    "data/EUC_MER_CONF-FILE-ANALYSIS__20230814T180000.0Z_00.00.ini": [
                        [
                            "@@ -35,7 +35,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"DETECTION_TOTAL\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"YNISP\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GYNISP_line.fits\",\n@@ -43,7 +43,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Y_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"JNISP\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GJNISP_line.fits\",\n@@ -51,7 +51,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"J_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"HNISP\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GHNISP_line.fits\",\n@@ -59,7 +59,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"H_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"DECAM_G\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_G_line.fits\",\n@@ -67,7 +67,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"G_EXT_DECAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] !=-1)\"\n         },\n         \"DECAM_R\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_R_line.fits\",\n@@ -75,7 +75,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"R_EXT_DECAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"DECAM_I\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_I_line.fits\",\n@@ -83,7 +83,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"I_EXT_DECAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"DECAM_Z\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_Z_line.fits\",\n@@ -91,7 +91,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Z_EXT_DECAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"HSC_Z\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_HSC_Z_line.fits\",\n@@ -99,7 +99,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Z_EXT_HSC_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"JPCAM_G\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_JPCAM_G_line.fits\",\n@@ -107,7 +107,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"G_EXT_JPCAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"MEGACAM_R\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_MEGACAM_R_line.fits\",\n@@ -115,7 +115,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"R_EXT_MEGACAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"PANSTARRS_I\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_PANSTARRS_I_line.fits\",\n@@ -123,7 +123,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"I_EXT_PANSTARRS_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"PANSTARRS_Z\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_PANSTARRS_Z_line.fits\",\n@@ -131,7 +131,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Z_EXT_PANSTARRS_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         },\n         \"MEGACAM_U\": {\n             \"transformation_function\":\"EUC_SIM_STAR-CATALOG_06CC2173BBE8-0008009_20230120T200847.836558Z_DECAM_GR_I_MEGACAM_U_line.fits\",\n@@ -139,7 +139,7 @@\n             \"column_names\": [\"G_EXT_DECAM_TEMPLFIT\", \"R_EXT_DECAM_TEMPLFIT\", \"I_EXT_DECAM_TEMPLFIT\", \"U_EXT_MEGACAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"MER\", \"MER\", \"MER\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] != -1)\"\n         }\n     }\n }\n",
                            "One bugfix",
                            "Martin Kuemmel",
                            "2023-08-16T22:52:55.000+02:00",
                            "3cdb803da1a7aeb869f1dfa9d19870bf2ddfe4c1"
                        ],
                        [
                            "",
                            "Renames files",
                            "Javier Gracia Carpio",
                            "2023-08-14T16:47:19.000+00:00",
                            "d69dae9c27c6b81c556bd5e6122a5c1a81cd7d90"
                        ]
                    ],
                    "data/EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230814T180000.0Z_00.00.ini": [
                        [
                            "",
                            "Renames files",
                            "Javier Gracia Carpio",
                            "2023-08-14T16:47:19.000+00:00",
                            "d69dae9c27c6b81c556bd5e6122a5c1a81cd7d90"
                        ]
                    ],
                    "data/EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230811T180000.0Z_00.00.ini": [
                        [
                            "@@ -25,7 +25,8 @@\n     \t\"density_min\": 30.0\n     },\n     \"classification_validation\": {\n-\n+        \"min_ratio_bright_pointlike_in_gaia\": 0.5,\n+        \"min_ratio_bright_highprob_in_gaia\": 0.5\n     },\n     \"photometry_validation\": {\n         \"VIS\": {\n",
                            "Merge branch 'esoubrie-develop-patch-88096' into 'develop'",
                            "Martin Kuemmel",
                            "2023-08-12T15:57:53.000+00:00",
                            "75fa4b0db3c1249fe4e6a58fd481e7b0e02ea5e2"
                        ],
                        [
                            "@@ -23,6 +23,9 @@\n     },\n     \"detection_validation\": {\n     \t\"density_min\": 30.0\n+    },\n+    \"classification_validation\": {\n+\n     },\n     \"photometry_validation\": {\n         \"VIS\": {\n",
                            "Adds entry for classification validation",
                            "Javier Gracia Carpio",
                            "2023-08-11T08:53:05.000+00:00",
                            "4c2627f807e1aaa7a79edfd17ac84f6b8cff8761"
                        ]
                    ],
                    "data/EUC_MER_CONF-FILE-ANALYSIS__20230811T180000.0Z_00.00.ini": [
                        [
                            "@@ -25,7 +25,8 @@\n     \t\"density_min\": 30.0\n     },\n     \"classification_validation\": {\n-\n+        \"min_ratio_bright_pointlike_in_gaia\": 0.5,\n+        \"min_ratio_bright_highprob_in_gaia\": 0.5\n     },\n     \"photometry_validation\": {\n         \"VIS\": {\n",
                            "Merge branch 'esoubrie-develop-patch-40885' into 'develop'",
                            "Martin Kuemmel",
                            "2023-08-12T15:57:35.000+00:00",
                            "3bdef2c5301ecbcf113b7fab99abf99d5529551c"
                        ],
                        [
                            "@@ -23,6 +23,9 @@\n     },\n     \"detection_validation\": {\n     \t\"density_min\": 30.0\n+    },\n+    \"classification_validation\": {\n+\n     },\n     \"photometry_validation\": {\n         \"VIS\": {\n",
                            "Adds entry for classification validation",
                            "Javier Gracia Carpio",
                            "2023-08-11T08:53:05.000+00:00",
                            "4c2627f807e1aaa7a79edfd17ac84f6b8cff8761"
                        ]
                    ],
                    "inputs/flag_limits.xml": [
                        [
                            "@@ -1,11 +1,11 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n <ns1:DpdMerDqcStaticFlagLimits xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/staticflaglimits\">\n     <Header>\n-\t\t<ProductId>EUC_MER_DQC-STATIC-FLAG-LIMITS_20230424</ProductId>\n+\t\t<ProductId>EUC_MER_DQC-STATIC-FLAG-LIMITS_20230807</ProductId>\n  \t\t<ProductType>DpdMerDqcStaticFlagLimits</ProductType>\n  \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n- \t\t<SoftwareRelease>10.0</SoftwareRelease>\n- \t\t<EuclidPipelineSoftwareRelease>10.0</EuclidPipelineSoftwareRelease>\n+ \t\t<SoftwareRelease>10.1.2</SoftwareRelease>\n+ \t\t<EuclidPipelineSoftwareRelease>10.1.2</EuclidPipelineSoftwareRelease>\n  \t\t<ProdSDC>SDC-IT</ProdSDC>\n  \t\t<DataSetRelease>NA</DataSetRelease>\n  \t\t<Purpose>UNKNOWN</Purpose>\n@@ -20,7 +20,7 @@\n  \t\t<ToBePublished>0</ToBePublished>\n  \t\t<Published>0</Published>\n  \t\t<Curator>Javier Gracia Carpio</Curator>\n- \t\t<CreationDate>2023-04-24T10:01:12.501000Z</CreationDate>\n+ \t\t<CreationDate>2023-08-07T10:01:12.501000Z</CreationDate>\n     </Header>\n     <Data>\n         <Selector></Selector>\n",
                            "Update product ids",
                            "Javier Gracia Carpio",
                            "2023-08-07T14:27:00.000+00:00",
                            "bd68732148271037defaed24d658de9bd07d2d9a"
                        ]
                    ],
                    "data/EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230731T180000.0Z_00.00.ini": [
                        [
                            "@@ -31,7 +31,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"DETECTION_TOTAL\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"YNISP\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GYNISP_line.fits\",\n@@ -39,7 +39,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Y_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"JNISP\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GJNISP_line.fits\",\n@@ -47,7 +47,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"J_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"HNISP\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GHNISP_line.fits\",\n@@ -55,7 +55,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"H_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"DECAM_G\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_G_line.fits\",\n@@ -63,7 +63,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"G_EXT_DECAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"DECAM_R\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_R_line.fits\",\n@@ -71,7 +71,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"R_EXT_DECAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"DECAM_I\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_I_line.fits\",\n@@ -79,7 +79,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"I_EXT_DECAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"DECAM_Z\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_Z_line.fits\",\n@@ -87,7 +87,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Z_EXT_DECAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"HSC_Z\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_HSC_Z_line.fits\",\n@@ -95,7 +95,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Z_EXT_HSC_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"JPCAM_G\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_JPCAM_G_line.fits\",\n@@ -103,7 +103,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"G_EXT_JPCAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"MEGACAM_R\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_MEGACAM_R_line.fits\",\n@@ -111,7 +111,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"R_EXT_MEGACAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"PANSTARRS_I\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_PANSTARRS_I_line.fits\",\n@@ -119,7 +119,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"I_EXT_PANSTARRS_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"PANSTARRS_Z\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_PANSTARRS_Z_line.fits\",\n@@ -127,7 +127,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Z_EXT_PANSTARRS_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"MEGACAM_U\": {\n             \"transformation_function\":\"EUC_SIM_STAR-CATALOG_06CC2173BBE8-0008009_20230120T200847.836558Z_DECAM_GR_I_MEGACAM_U_line.fits\",\n@@ -135,7 +135,7 @@\n             \"column_names\": [\"G_EXT_DECAM_TEMPLFIT\", \"R_EXT_DECAM_TEMPLFIT\", \"I_EXT_DECAM_TEMPLFIT\", \"U_EXT_MEGACAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"MER\", \"MER\", \"MER\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         }\n     }\n }\n",
                            "Update to new NIR image bit masks",
                            "Javier Gracia Carpio",
                            "2023-07-31T09:16:46.000+00:00",
                            "981fa02eff6bd1a1c29d1b7a2d483527d76187be"
                        ]
                    ],
                    "data/EUC_MER_CONF-FILE-ANALYSIS__20230731T180000.0Z_00.00.ini": [
                        [
                            "",
                            "Update to new NIR image bit masks",
                            "Javier Gracia Carpio",
                            "2023-07-31T09:16:46.000+00:00",
                            "981fa02eff6bd1a1c29d1b7a2d483527d76187be"
                        ]
                    ],
                    "data/EUC_MER_CONF-FILE-MOSAICING__20230731T180000.0Z_00.00.ini": [
                        [
                            "@@ -42,8 +42,8 @@\n   \"dec_column\": \"DECLINATION\",\n   \"bit_mask_image_vis\": \"33554430\",\n   \"bit_mask_flag_vis\": \"33554430\",\n-  \"bit_mask_image_nir\": \"4194300\",\n-  \"bit_mask_flag_nir\": \"4194300\",\n+  \"bit_mask_image_nir\": \"4194302\",\n+  \"bit_mask_flag_nir\": \"4194302\",\n   \"bit_mask_image_ext\": \"4294967295\",\n   \"bit_mask_flag_ext\": \"4294967295\",\n   \"swarp_config\": \"merMosaic.swarp\",\n",
                            "Update to new NIR image bit masks",
                            "Javier Gracia Carpio",
                            "2023-07-31T09:16:46.000+00:00",
                            "981fa02eff6bd1a1c29d1b7a2d483527d76187be"
                        ]
                    ],
                    "data/EUC_MER_CONF-FILE-ANALYSIS__20230726T180000.0Z_00.00.ini": [
                        [
                            "@@ -31,7 +31,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"DETECTION_TOTAL\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"YNISP\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GYNISP_line.fits\",\n@@ -39,7 +39,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Y_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"JNISP\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GJNISP_line.fits\",\n@@ -47,7 +47,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"J_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"HNISP\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GHNISP_line.fits\",\n@@ -55,7 +55,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"H_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"DECAM_G\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_G_line.fits\",\n@@ -63,7 +63,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"G_EXT_DECAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"DECAM_R\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_R_line.fits\",\n@@ -71,7 +71,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"R_EXT_DECAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"DECAM_I\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_I_line.fits\",\n@@ -79,7 +79,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"I_EXT_DECAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"DECAM_Z\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_Z_line.fits\",\n@@ -87,7 +87,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Z_EXT_DECAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"HSC_Z\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_HSC_Z_line.fits\",\n@@ -95,7 +95,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Z_EXT_HSC_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"JPCAM_G\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_JPCAM_G_line.fits\",\n@@ -103,7 +103,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"G_EXT_JPCAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"MEGACAM_R\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_MEGACAM_R_line.fits\",\n@@ -111,7 +111,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"R_EXT_MEGACAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"PANSTARRS_I\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_PANSTARRS_I_line.fits\",\n@@ -119,7 +119,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"I_EXT_PANSTARRS_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"PANSTARRS_Z\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_PANSTARRS_Z_line.fits\",\n@@ -127,7 +127,7 @@\n             \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Z_EXT_PANSTARRS_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         },\n         \"MEGACAM_U\": {\n             \"transformation_function\":\"EUC_SIM_STAR-CATALOG_06CC2173BBE8-0008009_20230120T200847.836558Z_DECAM_GR_I_MEGACAM_U_line.fits\",\n@@ -135,7 +135,7 @@\n             \"column_names\": [\"G_EXT_DECAM_TEMPLFIT\", \"R_EXT_DECAM_TEMPLFIT\", \"I_EXT_DECAM_TEMPLFIT\", \"U_EXT_MEGACAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"MER\", \"MER\", \"MER\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n-            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5)\"\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 18.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n         }\n     }\n }\n",
                            "change the magnitude lower bound for photometry validation to be 18.5",
                            "yfang",
                            "2023-07-27T17:15:45.000+02:00",
                            "94235e25f85c9f79ed300c9163b2cc3d072cabb4"
                        ],
                        [
                            "@@ -84,7 +84,7 @@\n         \"DECAM_Z\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_Z_line.fits\",\n             \"interpolation_range\": [-1, 3],\n-            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"I_EXT_DECAM_TEMPLFIT\"],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Z_EXT_DECAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n             \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n",
                            "Fixes typo in configuration sets",
                            "Javier Gracia Carpio",
                            "2023-07-26T14:31:29.000+00:00",
                            "a55616da4457f53ff4478e1c68e952b780ffb3cd"
                        ]
                    ],
                    "data/EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230726T180000.0Z_00.00.ini": [
                        [
                            "@@ -84,7 +84,7 @@\n         \"DECAM_Z\": {\n             \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_Z_line.fits\",\n             \"interpolation_range\": [-1, 3],\n-            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"I_EXT_DECAM_TEMPLFIT\"],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Z_EXT_DECAM_TEMPLFIT\"],\n             \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n             \"nmad_diff_limit\": 0.05,\n             \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n",
                            "Fixes typo in configuration sets",
                            "Javier Gracia Carpio",
                            "2023-07-26T14:31:29.000+00:00",
                            "a55616da4457f53ff4478e1c68e952b780ffb3cd"
                        ]
                    ],
                    "data/EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230704T180000.0Z_00.00.ini": [
                        [
                            "@@ -1,24 +0,0 @@\n-{\n-    \"crossmatch_analysis\": {\n-        \"max_star_distance\": 0.4,\n-        \"max_galaxy_distance\": 0.4,\n-        \"min_star_flux\": {\n-            \"VIS\" : 1e-8,\n-            \"NIR_Y\" : 3e-8,\n-            \"NIR_J\" : 3e-8,\n-            \"NIR_H\" : 3e-8\n-        },\n-        \"min_galaxy_flux\": {\n-            \"VIS\" : 1e-8,\n-            \"NIR_Y\" : 3e-8,\n-            \"NIR_J\" : 3e-8,\n-            \"NIR_H\" : 3e-8\n-        }\n-    },\n-    \"astrometry_validation\": {\n-        \"ra_mean_limit\": 0.1,\n-        \"dec_mean_limit\": 0.1,\n-        \"ra_std_limit\": 0.05,\n-        \"dec_std_limit\": 0.05\n-    }\n-}\n",
                            "Update time stamps",
                            "Javier Gracia Carpio",
                            "2023-07-25T11:54:32.000+00:00",
                            "23c2506c0cf9460c0e4377c2eab44e6060567d56"
                        ],
                        [
                            "@@ -14,5 +14,11 @@\n             \"NIR_J\" : 3e-8,\n             \"NIR_H\" : 3e-8\n         }\n+    },\n+    \"astrometry_validation\": {\n+        \"ra_mean_limit\": 0.1,\n+        \"dec_mean_limit\": 0.1,\n+        \"ra_std_limit\": 0.05,\n+        \"dec_std_limit\": 0.05\n     }\n }\n",
                            "Update also the DEEP conf file",
                            "Javier Gracia Carpio",
                            "2023-07-04T12:50:56.000+00:00",
                            "f57add3826335132b445ddfdba5141110f057e38"
                        ]
                    ],
                    "data/EUC_MER_CONF-FILE-ANALYSIS_DEEP_20230725T180000.0Z_00.00.ini": [
                        [
                            "@@ -0,0 +1,141 @@\n+{\n+    \"crossmatch_analysis\": {\n+        \"max_star_distance\": 0.4,\n+        \"max_galaxy_distance\": 0.4,\n+        \"min_star_flux\": {\n+            \"VIS\" : 1e-8,\n+            \"NIR_Y\" : 3e-8,\n+            \"NIR_J\" : 3e-8,\n+            \"NIR_H\" : 3e-8\n+        },\n+        \"min_galaxy_flux\": {\n+            \"VIS\" : 1e-8,\n+            \"NIR_Y\" : 3e-8,\n+            \"NIR_J\" : 3e-8,\n+            \"NIR_H\" : 3e-8\n+        }\n+    },\n+    \"astrometry_validation\": {\n+        \"ra_mean_limit\": 0.1,\n+        \"dec_mean_limit\": 0.1,\n+        \"ra_std_limit\": 0.05,\n+        \"dec_std_limit\": 0.05\n+    },\n+    \"detection_validation\": {\n+    \t\"density_min\": 30.0\n+    },\n+    \"photometry_validation\": {\n+        \"VIS\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF15-0002797_20230120T201904.492276Z_BPRP_GVIS_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"DETECTION_TOTAL\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"YNISP\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GYNISP_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Y_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"JNISP\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GJNISP_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"J_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"HNISP\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GHNISP_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"H_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"DECAM_G\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_G_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"G_EXT_DECAM_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"DECAM_R\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_R_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"R_EXT_DECAM_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"DECAM_I\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_I_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"I_EXT_DECAM_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"DECAM_Z\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_Z_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"I_EXT_DECAM_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"HSC_Z\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_HSC_Z_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Z_EXT_HSC_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"JPCAM_G\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_JPCAM_G_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"G_EXT_JPCAM_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"MEGACAM_R\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_MEGACAM_R_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"R_EXT_MEGACAM_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"PANSTARRS_I\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_PANSTARRS_I_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"I_EXT_PANSTARRS_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"PANSTARRS_Z\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_PANSTARRS_Z_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Z_EXT_PANSTARRS_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"MEGACAM_U\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-CATALOG_06CC2173BBE8-0008009_20230120T200847.836558Z_DECAM_GR_I_MEGACAM_U_line.fits\",\n+            \"interpolation_range\": [-0.5, 2.0],\n+            \"column_names\": [\"G_EXT_DECAM_TEMPLFIT\", \"R_EXT_DECAM_TEMPLFIT\", \"I_EXT_DECAM_TEMPLFIT\", \"U_EXT_MEGACAM_TEMPLFIT\"],\n+            \"column_catalogs\": [\"MER\", \"MER\", \"MER\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5)\"\n+        }\n+    }\n+}\n",
                            "Update time stamps",
                            "Javier Gracia Carpio",
                            "2023-07-25T11:54:32.000+00:00",
                            "23c2506c0cf9460c0e4377c2eab44e6060567d56"
                        ]
                    ],
                    "data/EUC_MER_CONF-FILE-ANALYSIS__20230725T180000.0Z_00.00.ini": [
                        [
                            "",
                            "Update time stamps",
                            "Javier Gracia Carpio",
                            "2023-07-25T11:54:32.000+00:00",
                            "23c2506c0cf9460c0e4377c2eab44e6060567d56"
                        ]
                    ],
                    "data/EUC_MER_CONF-FILE-ANALYSIS__20230704T180000.0Z_00.00.ini": [
                        [
                            "@@ -20,5 +20,122 @@\n         \"dec_mean_limit\": 0.1,\n         \"ra_std_limit\": 0.05,\n         \"dec_std_limit\": 0.05\n+    },\n+    \"detection_validation\": {\n+    \t\"density_min\": 30.0\n+    },\n+    \"photometry_validation\": {\n+        \"VIS\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF15-0002797_20230120T201904.492276Z_BPRP_GVIS_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"DETECTION_TOTAL\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"YNISP\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GYNISP_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Y_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"JNISP\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GJNISP_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"J_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"HNISP\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GHNISP_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"H_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"DECAM_G\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_G_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"G_EXT_DECAM_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"DECAM_R\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_R_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"R_EXT_DECAM_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"DECAM_I\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_I_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"I_EXT_DECAM_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"DECAM_Z\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_Z_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"I_EXT_DECAM_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"HSC_Z\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_HSC_Z_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Z_EXT_HSC_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"JPCAM_G\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_JPCAM_G_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"G_EXT_JPCAM_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"MEGACAM_R\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_MEGACAM_R_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"R_EXT_MEGACAM_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"PANSTARRS_I\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_PANSTARRS_I_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"I_EXT_PANSTARRS_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"PANSTARRS_Z\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_PANSTARRS_Z_line.fits\",\n+            \"interpolation_range\": [-1, 3],\n+            \"column_names\": [\"BP_GAIA\", \"RP_GAIA\", \"G_GAIA\", \"Z_EXT_PANSTARRS_TEMPLFIT\"],\n+            \"column_catalogs\": [\"Gaia\", \"Gaia\", \"Gaia\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG) & (mer_data['GAIA_ID'] > 0)\"\n+        },\n+        \"MEGACAM_U\": {\n+            \"transformation_function\":\"EUC_SIM_STAR-CATALOG_06CC2173BBE8-0008009_20230120T200847.836558Z_DECAM_GR_I_MEGACAM_U_line.fits\",\n+            \"interpolation_range\": [-0.5, 2.0],\n+            \"column_names\": [\"G_EXT_DECAM_TEMPLFIT\", \"R_EXT_DECAM_TEMPLFIT\", \"I_EXT_DECAM_TEMPLFIT\", \"U_EXT_MEGACAM_TEMPLFIT\"],\n+            \"column_catalogs\": [\"MER\", \"MER\", \"MER\", \"MER\"],\n+            \"nmad_diff_limit\": 0.05,\n+            \"selection\": \"(mer_data['VIS_DET'] == 1) & (mag['DETECTION_TOTAL'] > 16.5)\"\n+        }\n     }\n }\n",
                            "add parameters for detection_validation",
                            "yfang",
                            "2023-07-20T15:27:37.000+02:00",
                            "4d03e9ec807a0f430a810e41b0d7c0064bec130e"
                        ],
                        [
                            "@@ -14,5 +14,11 @@\n             \"NIR_J\" : 3e-7,\n             \"NIR_H\" : 3e-7\n         }\n+    },\n+    \"astrometry_validation\": {\n+        \"ra_mean_limit\": 0.1,\n+        \"dec_mean_limit\": 0.1,\n+        \"ra_std_limit\": 0.05,\n+        \"dec_std_limit\": 0.05\n     }\n }\n",
                            "Updates analysis configuration file",
                            "Javier Gracia Carpio",
                            "2023-07-04T12:49:32.000+00:00",
                            "a21d37db1eae58ab80aa11b8603056a9a38abf2c"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "8.0",
                        "created_at": "2021-11-09T11:42:22.000+01:00",
                        "author_name": "Javier Gracia Carpio"
                    }
                ]
            },
            "PF-MER/MER_IAL_Pipelines": {
                "start date": "2023-06-09 09:00",
                "end date": "2023-08-23 15:00",
                "start tag": "> 9.1.1",
                "end tag": "> 10.1.3",
                "count_files_modified": "35",
                "modifications_by_file": {
                    "doc/user_manual/chap8-Morpho.md": [
                        [
                            "@@ -45,13 +45,11 @@ flowchart LR\n \n     morph(DpdMerFinalCatalog)\n \n-    cat ==>|EUC_MER_FINAL-CAT<br>1..1| pipeline\n-    cat ==>|EUC_MER_FINAL-MORPH-CAT<br>1..1| pipeline\n-    bgkmos ==>|EUC_MER_BGSUB-MOSAIC<br>1..N| pipeline\n-    detmos ==>|EUC_MER_BGSUB-MOSAIC<br>1..2| pipeline\n+    cat ==>|final_catalog<br>1..1| pipeline\n+    bgkmos ==>|measurement_mosaics<br>1..N| pipeline\n+    detmos ==>|vis_detection_mosaic<br>1..2| pipeline\n \n-    pipeline ==>|EUC_MER_FINAL-CAT<br>1..1| morph\n-    pipeline ==>|EUC_MER_FINAL-MORPH-CAT<br>1..1| morph\n+    pipeline ==>|updated_final_catalog<br>1..1| morph\n ```\n \n **Ports description:**\n",
                            "chap8-Morpho updated",
                            "Erik Romelli",
                            "2023-08-21T10:48:10.000+02:00",
                            "6a698470cc7a57f8572b9a9a29fbc37ab2f19266"
                        ],
                        [
                            "@@ -86,7 +86,7 @@ The \"Execution Context\" of the `MER_ProcessTileMorpho` is always:\n \n | Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n | -------------------------- | ----- | ------------------------------ | ----- | ------- | ------- | ------- |\n-| MER_MorphoPatch  | 10.0 | MER_MorphoPatch | 8 | 20.0 | 6.0 | <1 |\n+| MER_MorphoPatch  | 10.1.0 | MER_MorphoPatch | 8 | 20.0 | 6.0 | <1 |\n \n ### Normal termination\n \n@@ -98,116 +98,3 @@ The runtime errors related to `MER_ProcessTileMorpho` are listed below:\n \n | Software Executable | Message | Operator Instruction |\n | ---------------------- | ----------------------------- |  ----------------------------- |\n-\n-\n-## Pipeline `MER_AnalyseTileVisOnly`\n-\n-### Pipeline Description\n-\n-The related GitLab projects are following [RD7]:\n-\n-* [`MER_IAL_Pipelines`](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines)\n-* [`MER_Validation`](https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation)\n-\n-### Pipeline ports with inputs/outputs\n-\n-The following diagram represents the ports of `MER_AnalyseTileVisOnly`. For each port, the product type, port name and cardinality are provided. The thick arrow is for the key input port. Optional ports are represented by dotted arrows.\n-\n-```mermaid\n-%%{init: { \"flowchart\": { \"curve\": \"monotoneX\" } } }%%\n-flowchart LR\n-    pipeline(MER_AnalysisTile)\n-\n-    cat(DpdMerFinalCatalog)\n-    detmos(DpdMerDetectionMosaic)\n-    seg(DpdMerSegmentationMap)\n-    mdb(DpdMdbDataBase)\n-    conf(DpdMerConfigurationSet)\n-    tile(DpdMerTile)\n-\n-    anal(DpdMerAnalysisResult)\n-\n-    tu_star(DpdMerTrueUniverseStarCatalog)\n-    tu_gal(DpdMerTrueUniverseGalaxyCatalog)\n-\n-    cat ==>|EUC_MER_FINAL-CAT<br>1..1| pipeline\n-    seg ==>|EUC_MER_FINAL-SEGMAP<br>1..1| pipeline\n-    detmos ==>|EUC_MER_BGSUB-MOSAIC<br>1..1| pipeline\n-    tu_star ==>|TU_star_catalog<br>1..1| pipeline\n-    tu_gal ==>|TU_galaxy_catalog<br>1..1| pipeline\n-\n-    mdb ==>|EUC_MER_STARPROBA_FOR_SC8_SWF1<br>1..1| pipeline\n-    mdb ==>|HFI_CompMap_ThermalDustModel_2048_R1.20_V2<br>1..1| pipeline\n-\n-    conf ==>|EUC_MER_CONF-FILE-MOSAICS| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-BACKGROUND| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-DETECTION| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-DEBLENDING| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-PHOTOMETRY| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-SPURIOUS| pipeline\n-\n-    tile ==> pipeline \n-\n-    pipeline ==>|EUC_MER_ANALYSIS_RESULTS<br>1..1| anal\n-```\n-\n-**Ports description:**\n-\n-* Input:\n-  * `vis_detection_mosaic`: Mosaic used to perform the object detection on VIS.\n-  * `final_segmentation_map`: Map showing the connected pixels of the objects detected on the corresponding detection mosaic.\n-  * `final_catalog`: Final merged catalog with photometric and morphological information.\n-  * `tile`: Tile definition.\n-  * `configuration_set`: List configuration files.\n-  * `mdb`: MDB Data Product.\n-  * `tu_star_catalog`: True Universe star catalog.\n-  * `tu_galaxy_catalog`: True Universe galaxy catalog..\n-\n-* Output:\n-  * `analysis_result`: Analysis report.\n-\n-\n-### Processing triggering assumptions\n-\n-* `MER_AnalyseTileVisOnly` triggered at Tile scale.\n-* `MER_AnalyseTileVisOnly` needs a completed `MER_ProcessTileVisOnly` on the same tile.\n-\n-| Scale(s) | Periodicity | Input DataProduct | Information for creating the pipeline definition |\n-| -------| ----------- | ----------- |  --------------- |\n-| Tile | As soon as a completed `MER_ProcessTileVisOnly` is available | See ports description |  |\n-\n-### Operational constraints\n-\n-`MER_AnalyseTileVisOnly` requires a completed `MER_ProcessTileVisOnly`.\n-\n-### Hardware configuration and related performances\n-\n-The \"Execution Context\" of the `MER_AnalyseTileVisOnly` is always:\n-\n-* Nominal\n-\n-| Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n-| -------------------------- | ----- | ------------------------------ | ----- | ------- | ------- | ------- |\n-| MosaicingValidation  | 9.0 | MER_MosaicingValidation | 1 | 16.0 | 2.0 | <1 |\n-| PsfAnalysis | 9.0 | MER_PsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n-| MerStarPsfAnalysis | 9.0 | MER_MerStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n-| TuStarPsfAnalysis | 9.0 | MER_TuStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n-| BackgroundValidation | 9.0 | MER_BackgroundValidationPrg | 1 | 26.0 | 2.0 | <1 |\n-| DetectionValidation | 9.0 | MER_DetectionValidationPrg | 1 | 2.0 | 2.0 | <1 |\n-| CrossmatchAnalysis | 9.0 | MER_CrossmatchAnalysis | 1 | 2.0 | 2.0 | <1 |\n-| MorphologyValidation | 9.0 | MER_MorphologyValidationPrg | 1 | 2.0 | 2.0 | <1 |\n-| PhotometryPlotCheck | 9.0 | MER_PhotometryPlotCheck | 1 | 2.0 | 2.0 | <1 |\n-| ClassificationValidation | 9.0 | MER_ClassificationValidationPrg | 1 | 2.0 | 2.0 | <1 |\n-| CheckFinalCat | 9.0 | MER_CheckFinalCat | 1 | 2.0 | 2.0 | <1 |\n-| MergeAnalysisResults | 9.0 | MER_MergeAnalysisResults | 1 | 2.0 | 0.5 | <1 |\n-\n-### Normal termination\n-\n-MER Pipeline is managed by the official EDEN pipeline runner. The standard output of the EDEN pipeline runner is expected if MER Pipeline runs through all the PEs. \n-\n-### Error condition\n-\n-The runtime errors related to `MER_AnalyseTileVisOnly` are listed below:\n-\n-| Software Executable | Message | Operator Instruction |\n-| ---------------------- | ----------------------------- |  ----------------------------- |\n\\ No newline at end of file\n",
                            "Updates the SUM",
                            "Javier Gracia Carpio",
                            "2023-08-07T13:24:00.000+00:00",
                            "fca8026919dd64c52dac3b0c920ffa0ba5cc04cc"
                        ],
                        [
                            "@@ -0,0 +1,213 @@\n+\\newpage\n+\n+# Group `Morpho`\n+\n+## Pipelines and dependencies\n+\n+The group `Morpho` is made of the following pipelines:\n+\n+* Group `WIDE`:\n+  * `MER_ProcessTileMorpho`\n+\n+The pipelines of the group `Morpho` depend on the respective processing pipelines.\n+\n+```mermaid\n+%%{init: { \"flowchart\": { \"curve\": \"monotoneX\" } } }%%\n+flowchart LR\n+    proc(MER_ProcessingTile)\n+    pipeline(MER_ProcessTileMorpho)\n+\n+    proc ==>|DpdMerFinalCatalog<br>1..1| pipeline\n+    proc ==>|DpdMerBksMosaic<br>1..N| pipeline\n+    proc ==>|DpdMerDetectionMosaic<br>1..2| pipeline\n+```\n+## Pipeline `MER_ProcessTileMorpho`\n+\n+### Pipeline Description\n+\n+The related GitLab projects are following [RD7]:\n+\n+* [`MER_IAL_Pipelines`](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines)\n+* [`MER_Pipeline`](https://gitlab.euclid-sgs.uk/PF-MER/MER_Pipeline)\n+\n+### Pipeline ports with inputs/outputs\n+\n+The following diagram represents the ports of `MER_ProcessTileMorpho`. For each port, the product type, port name and cardinality are provided. The thick arrow is for the key input port. Optional ports are represented by dotted arrows.\n+\n+```mermaid\n+%%{init: { \"flowchart\": { \"curve\": \"monotoneX\" } } }%%\n+flowchart LR\n+    pipeline(MER_ProcessTileMorpho)\n+\n+    cat(DpdMerFinalCatalog)\n+    bgkmos(DpdMerBksMosaic)\n+    detmos(DpdMerDetectionMosaic)\n+\n+    morph(DpdMerFinalCatalog)\n+\n+    cat ==>|EUC_MER_FINAL-CAT<br>1..1| pipeline\n+    cat ==>|EUC_MER_FINAL-MORPH-CAT<br>1..1| pipeline\n+    bgkmos ==>|EUC_MER_BGSUB-MOSAIC<br>1..N| pipeline\n+    detmos ==>|EUC_MER_BGSUB-MOSAIC<br>1..2| pipeline\n+\n+    pipeline ==>|EUC_MER_FINAL-CAT<br>1..1| morph\n+    pipeline ==>|EUC_MER_FINAL-MORPH-CAT<br>1..1| morph\n+```\n+\n+**Ports description:**\n+\n+* Input:\n+  * `measurement_mosaics`: Background-subtracted mosaics.\n+  * `vis_detection_mosaic`: Mosaic used to perform the object detection on VIS.\n+  * `final_catalog`: Final merged catalog with photometric and morphological information.\n+\n+* Output:\n+  * `updated_final_catalog`: Final merged catalog with photometric and updated morphological information.\n+\n+\n+### Processing triggering assumptions\n+\n+* `MER_ProcessTileMorpho` triggered at Tile scale.\n+* `MER_ProcessTileMorpho` needs a completed `MER_ProcessTile` on the same tile.\n+\n+| Scale(s) | Periodicity | Input DataProduct | Information for creating the pipeline definition |\n+| -------| ----------- | ----------- |  --------------- |\n+| Tile | As soon as a completed `MER_ProcessTile` is available | See ports description |  |\n+\n+### Operational constraints\n+\n+`MER_ProcessTileMorpho` requires a completed `MER_ProcessTile`.\n+\n+### Hardware configuration and related performances\n+\n+The \"Execution Context\" of the `MER_ProcessTileMorpho` is always:\n+\n+* Nominal\n+\n+| Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n+| -------------------------- | ----- | ------------------------------ | ----- | ------- | ------- | ------- |\n+| MER_MorphoPatch  | 10.0 | MER_MorphoPatch | 8 | 20.0 | 6.0 | <1 |\n+\n+### Normal termination\n+\n+MER Pipeline is managed by the official EDEN pipeline runner. The standard output of the EDEN pipeline runner is expected if MER Pipeline runs through all the PEs. \n+\n+### Error condition\n+\n+The runtime errors related to `MER_ProcessTileMorpho` are listed below:\n+\n+| Software Executable | Message | Operator Instruction |\n+| ---------------------- | ----------------------------- |  ----------------------------- |\n+\n+\n+## Pipeline `MER_AnalyseTileVisOnly`\n+\n+### Pipeline Description\n+\n+The related GitLab projects are following [RD7]:\n+\n+* [`MER_IAL_Pipelines`](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines)\n+* [`MER_Validation`](https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation)\n+\n+### Pipeline ports with inputs/outputs\n+\n+The following diagram represents the ports of `MER_AnalyseTileVisOnly`. For each port, the product type, port name and cardinality are provided. The thick arrow is for the key input port. Optional ports are represented by dotted arrows.\n+\n+```mermaid\n+%%{init: { \"flowchart\": { \"curve\": \"monotoneX\" } } }%%\n+flowchart LR\n+    pipeline(MER_AnalysisTile)\n+\n+    cat(DpdMerFinalCatalog)\n+    detmos(DpdMerDetectionMosaic)\n+    seg(DpdMerSegmentationMap)\n+    mdb(DpdMdbDataBase)\n+    conf(DpdMerConfigurationSet)\n+    tile(DpdMerTile)\n+\n+    anal(DpdMerAnalysisResult)\n+\n+    tu_star(DpdMerTrueUniverseStarCatalog)\n+    tu_gal(DpdMerTrueUniverseGalaxyCatalog)\n+\n+    cat ==>|EUC_MER_FINAL-CAT<br>1..1| pipeline\n+    seg ==>|EUC_MER_FINAL-SEGMAP<br>1..1| pipeline\n+    detmos ==>|EUC_MER_BGSUB-MOSAIC<br>1..1| pipeline\n+    tu_star ==>|TU_star_catalog<br>1..1| pipeline\n+    tu_gal ==>|TU_galaxy_catalog<br>1..1| pipeline\n+\n+    mdb ==>|EUC_MER_STARPROBA_FOR_SC8_SWF1<br>1..1| pipeline\n+    mdb ==>|HFI_CompMap_ThermalDustModel_2048_R1.20_V2<br>1..1| pipeline\n+\n+    conf ==>|EUC_MER_CONF-FILE-MOSAICS| pipeline\n+    conf ==>|EUC_MER_CONF-FILE-BACKGROUND| pipeline\n+    conf ==>|EUC_MER_CONF-FILE-DETECTION| pipeline\n+    conf ==>|EUC_MER_CONF-FILE-DEBLENDING| pipeline\n+    conf ==>|EUC_MER_CONF-FILE-PHOTOMETRY| pipeline\n+    conf ==>|EUC_MER_CONF-FILE-SPURIOUS| pipeline\n+\n+    tile ==> pipeline \n+\n+    pipeline ==>|EUC_MER_ANALYSIS_RESULTS<br>1..1| anal\n+```\n+\n+**Ports description:**\n+\n+* Input:\n+  * `vis_detection_mosaic`: Mosaic used to perform the object detection on VIS.\n+  * `final_segmentation_map`: Map showing the connected pixels of the objects detected on the corresponding detection mosaic.\n+  * `final_catalog`: Final merged catalog with photometric and morphological information.\n+  * `tile`: Tile definition.\n+  * `configuration_set`: List configuration files.\n+  * `mdb`: MDB Data Product.\n+  * `tu_star_catalog`: True Universe star catalog.\n+  * `tu_galaxy_catalog`: True Universe galaxy catalog..\n+\n+* Output:\n+  * `analysis_result`: Analysis report.\n+\n+\n+### Processing triggering assumptions\n+\n+* `MER_AnalyseTileVisOnly` triggered at Tile scale.\n+* `MER_AnalyseTileVisOnly` needs a completed `MER_ProcessTileVisOnly` on the same tile.\n+\n+| Scale(s) | Periodicity | Input DataProduct | Information for creating the pipeline definition |\n+| -------| ----------- | ----------- |  --------------- |\n+| Tile | As soon as a completed `MER_ProcessTileVisOnly` is available | See ports description |  |\n+\n+### Operational constraints\n+\n+`MER_AnalyseTileVisOnly` requires a completed `MER_ProcessTileVisOnly`.\n+\n+### Hardware configuration and related performances\n+\n+The \"Execution Context\" of the `MER_AnalyseTileVisOnly` is always:\n+\n+* Nominal\n+\n+| Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n+| -------------------------- | ----- | ------------------------------ | ----- | ------- | ------- | ------- |\n+| MosaicingValidation  | 9.0 | MER_MosaicingValidation | 1 | 16.0 | 2.0 | <1 |\n+| PsfAnalysis | 9.0 | MER_PsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n+| MerStarPsfAnalysis | 9.0 | MER_MerStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n+| TuStarPsfAnalysis | 9.0 | MER_TuStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n+| BackgroundValidation | 9.0 | MER_BackgroundValidationPrg | 1 | 26.0 | 2.0 | <1 |\n+| DetectionValidation | 9.0 | MER_DetectionValidationPrg | 1 | 2.0 | 2.0 | <1 |\n+| CrossmatchAnalysis | 9.0 | MER_CrossmatchAnalysis | 1 | 2.0 | 2.0 | <1 |\n+| MorphologyValidation | 9.0 | MER_MorphologyValidationPrg | 1 | 2.0 | 2.0 | <1 |\n+| PhotometryPlotCheck | 9.0 | MER_PhotometryPlotCheck | 1 | 2.0 | 2.0 | <1 |\n+| ClassificationValidation | 9.0 | MER_ClassificationValidationPrg | 1 | 2.0 | 2.0 | <1 |\n+| CheckFinalCat | 9.0 | MER_CheckFinalCat | 1 | 2.0 | 2.0 | <1 |\n+| MergeAnalysisResults | 9.0 | MER_MergeAnalysisResults | 1 | 2.0 | 0.5 | <1 |\n+\n+### Normal termination\n+\n+MER Pipeline is managed by the official EDEN pipeline runner. The standard output of the EDEN pipeline runner is expected if MER Pipeline runs through all the PEs. \n+\n+### Error condition\n+\n+The runtime errors related to `MER_AnalyseTileVisOnly` are listed below:\n+\n+| Software Executable | Message | Operator Instruction |\n+| ---------------------- | ----------------------------- |  ----------------------------- |\n\\ No newline at end of file\n",
                            "SUM update",
                            "Erik Romelli",
                            "2023-06-28T12:01:15.000+02:00",
                            "14e1cf60d97acdf4d0f5a0fce884848152ab2906"
                        ]
                    ],
                    "doc/user_manual/chap7-Analysis.md": [
                        [
                            "@@ -67,26 +67,21 @@ flowchart LR\n     tu_star(DpdMerTrueUniverseStarCatalog)\n     tu_gal(DpdMerTrueUniverseGalaxyCatalog)\n \n-    cat ==>|EUC_MER_FINAL-CAT<br>1..1| pipeline\n-    seg ==>|EUC_MER_FINAL-SEGMAP<br>1..1| pipeline\n-    bgkmos ==>|EUC_MER_BGSUB-MOSAIC<br>1..N| pipeline\n-    detmos ==>|EUC_MER_BGSUB-MOSAIC<br>1..2| pipeline\n-    tu_star ==>|TU_star_catalog<br>1..1| pipeline\n-    tu_gal ==>|TU_galaxy_catalog<br>1..1| pipeline\n-\n-    mdb ==>|EUC_MER_STARPROBA_FOR_SC8_SWF1<br>1..1| pipeline\n-    mdb ==>|HFI_CompMap_ThermalDustModel_2048_R1.20_V2<br>1..1| pipeline\n-\n-    conf ==>|EUC_MER_CONF-FILE-MOSAICS| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-BACKGROUND| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-DETECTION| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-DEBLENDING| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-PHOTOMETRY| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-SPURIOUS| pipeline\n-\n-    tile ==> pipeline \n-\n-    pipeline ==>|EUC_MER_ANALYSIS_RESULTS<br>1..1| anal\n+    cat ==>|final_catalog1..1| pipeline\n+    seg ==>|final_segmentation_map<br>1..1| pipeline\n+    bgkmos ==>|all_mosaics<br>1..N| pipeline\n+    detmos ==>|vis_detection_mosaic<br>1..1| pipeline\n+    detmos ==>|nir_detection_mosaic<br>1..1| pipeline\n+    tu_star ==>|tu_star_catalog<br>1..1| pipeline\n+    tu_gal ==>|tu_galaxy_catalog<br>1..1| pipeline\n+\n+    mdb ==>|mdb<br>1..1| pipeline\n+\n+    conf ==>|configuration_set<br>1..1| pipeline\n+\n+    tile ==>|tile<br>1..1| pipeline \n+\n+    pipeline ==>|analysis_result<br>1..1| anal\n ```\n \n **Ports description:**\n@@ -172,6 +167,7 @@ flowchart LR\n     pipeline(MER_AnalysisTile)\n \n     cat(DpdMerFinalCatalog)\n+    bgkmos(DpdMerBksMosaic)\n     detmos(DpdMerDetectionMosaic)\n     seg(DpdMerSegmentationMap)\n     mdb(DpdMdbDataBase)\n@@ -183,25 +179,20 @@ flowchart LR\n     tu_star(DpdMerTrueUniverseStarCatalog)\n     tu_gal(DpdMerTrueUniverseGalaxyCatalog)\n \n-    cat ==>|EUC_MER_FINAL-CAT<br>1..1| pipeline\n-    seg ==>|EUC_MER_FINAL-SEGMAP<br>1..1| pipeline\n-    detmos ==>|EUC_MER_BGSUB-MOSAIC<br>1..1| pipeline\n-    tu_star ==>|TU_star_catalog<br>1..1| pipeline\n-    tu_gal ==>|TU_galaxy_catalog<br>1..1| pipeline\n+    cat ==>|final_catalog1..1| pipeline\n+    seg ==>|final_segmentation_map<br>1..1| pipeline\n+    bgkmos ==>|all_mosaics<br>1..N| pipeline\n+    detmos ==>|vis_detection_mosaic<br>1..1| pipeline\n+    tu_star ==>|tu_star_catalog<br>1..1| pipeline\n+    tu_gal ==>|tu_galaxy_catalog<br>1..1| pipeline\n \n-    mdb ==>|EUC_MER_STARPROBA_FOR_SC8_SWF1<br>1..1| pipeline\n-    mdb ==>|HFI_CompMap_ThermalDustModel_2048_R1.20_V2<br>1..1| pipeline\n+    mdb ==>|mdb<br>1..1| pipeline\n \n-    conf ==>|EUC_MER_CONF-FILE-MOSAICS| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-BACKGROUND| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-DETECTION| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-DEBLENDING| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-PHOTOMETRY| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-SPURIOUS| pipeline\n+    conf ==>|configuration_set<br>1..1| pipeline\n \n-    tile ==> pipeline \n+    tile ==>|tile<br>1..1| pipeline \n \n-    pipeline ==>|EUC_MER_ANALYSIS_RESULTS<br>1..1| anal\n+    pipeline ==>|analysis_result<br>1..1| anal\n ```\n \n **Ports description:**\n",
                            "chap7-Analysis updated",
                            "Erik Romelli",
                            "2023-08-21T10:46:15.000+02:00",
                            "93d93a3c9abe43667a61037412e90a49bf8c23f5"
                        ],
                        [
                            "@@ -241,18 +241,18 @@ The \"Execution Context\" of the `MER_AnalyseTileVisOnly` is always:\n \n | Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n | -------------------------- | ----- | ------------------------------ | ----- | ------- | ------- | ------- |\n-| MosaicingValidation  | 10.0 | MER_MosaicingValidation | 1 | 16.0 | 2.0 | <1 |\n-| PsfAnalysis | 10.0 | MER_PsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n-| MerStarPsfAnalysis | 10.0 | MER_MerStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n-| TuStarPsfAnalysis | 10.0 | MER_TuStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n-| BackgroundValidation | 10.0 | MER_BackgroundValidationPrg | 1 | 26.0 | 2.0 | <1 |\n-| DetectionValidation | 10.0 | MER_DetectionValidationPrg | 1 | 2.0 | 2.0 | <1 |\n-| CrossmatchAnalysis | 10.0 | MER_CrossmatchAnalysis | 1 | 2.0 | 2.0 | <1 |\n-| MorphologyValidation | 10.0 | MER_MorphologyValidationPrg | 1 | 2.0 | 2.0 | <1 |\n-| PhotometryPlotCheck | 10.0 | MER_PhotometryPlotCheck | 1 | 2.0 | 2.0 | <1 |\n-| ClassificationValidation | 10.0 | MER_ClassificationValidationPrg | 1 | 2.0 | 2.0 | <1 |\n-| CheckFinalCat | 10.0 | MER_CheckFinalCat | 1 | 2.0 | 2.0 | <1 |\n-| MergeAnalysisResults | 10.0 | MER_MergeAnalysisResults | 1 | 2.0 | 0.5 | <1 |\n+| MosaicingValidation  | 10.1.0 | MER_MosaicingValidation | 1 | 16.0 | 2.0 | <1 |\n+| PsfAnalysis | 10.1.0 | MER_PsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n+| MerStarPsfAnalysis | 10.1.0 | MER_MerStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n+| TuStarPsfAnalysis | 10.1.0 | MER_TuStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n+| BackgroundValidation | 10.1.0 | MER_BackgroundValidationPrg | 1 | 26.0 | 2.0 | <1 |\n+| DetectionValidation | 10.1.0 | MER_DetectionValidationPrg | 1 | 2.0 | 2.0 | <1 |\n+| CrossmatchAnalysis | 10.1.0 | MER_CrossmatchAnalysis | 1 | 2.0 | 2.0 | <1 |\n+| MorphologyValidation | 10.1.0 | MER_MorphologyValidationPrg | 1 | 2.0 | 2.0 | <1 |\n+| PhotometryPlotCheck | 10.1.0 | MER_PhotometryPlotCheck | 1 | 2.0 | 2.0 | <1 |\n+| ClassificationValidation | 10.1.0 | MER_ClassificationValidationPrg | 1 | 2.0 | 2.0 | <1 |\n+| CheckFinalCat | 10.1.0 | MER_CheckFinalCat | 1 | 2.0 | 2.0 | <1 |\n+| MergeAnalysisResults | 10.1.0 | MER_MergeAnalysisResults | 1 | 2.0 | 0.5 | <1 |\n \n ### Normal termination\n \n",
                            "More small version changes",
                            "Javier Gracia Carpio",
                            "2023-08-07T13:30:46.000+00:00",
                            "fe47336de236acc56c4f3ec5cbc2ea429a9b881b"
                        ],
                        [
                            "@@ -32,6 +32,7 @@ flowchart LR\n \n     proc ==>|DpdMerFinalCatalog<br>1..1| pipeline\n     proc ==>|DpdMerSegmentationMap<br>1..1| pipeline\n+    proc ==>|DpdMerBksMosaic<br>1..1| pipeline\n     proc ==>|DpdMerDetectionMosaic<br>1..1| pipeline\n ```\n \n@@ -127,18 +128,18 @@ The \"Execution Context\" of the `MER_AnalyseTile` is always:\n \n | Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n | -------------------------- | ----- | ------------------------------ | ----- | ------- | ------- | ------- |\n-| MosaicingValidation  | 10.0 | MER_MosaicingValidation | 1 | 16.0 | 2.0 | <1 |\n-| PsfAnalysis | 10.0 | MER_PsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n-| MerStarPsfAnalysis | 10.0 | MER_MerStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n-| TuStarPsfAnalysis | 10.0 | MER_TuStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n-| BackgroundValidation | 10.0 | MER_BackgroundValidationPrg | 1 | 26.0 | 2.0 | <1 |\n-| DetectionValidation | 10.0 | MER_DetectionValidationPrg | 1 | 2.0 | 2.0 | <1 |\n-| CrossmatchAnalysis | 10.0 | MER_CrossmatchAnalysis | 1 | 2.0 | 2.0 | <1 |\n-| MorphologyValidation | 10.0 | MER_MorphologyValidationPrg | 1 | 2.0 | 2.0 | <1 |\n-| PhotometryPlotCheck | 10.0 | MER_PhotometryPlotCheck | 1 | 2.0 | 2.0 | <1 |\n-| ClassificationValidation | 10.0 | MER_ClassificationValidationPrg | 1 | 2.0 | 2.0 | <1 |\n-| CheckFinalCat | 10.0 | MER_CheckFinalCat | 1 | 2.0 | 2.0 | <1 |\n-| MergeAnalysisResults | 10.0 | MER_MergeAnalysisResults | 1 | 2.0 | 0.5 | <1 |\n+| MosaicingValidation  | 10.1.0 | MER_MosaicingValidation | 1 | 16.0 | 2.0 | <1 |\n+| PsfAnalysis | 10.1.0 | MER_PsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n+| MerStarPsfAnalysis | 10.1.0 | MER_MerStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n+| TuStarPsfAnalysis | 10.1.0 | MER_TuStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n+| BackgroundValidation | 10.1.0 | MER_BackgroundValidationPrg | 1 | 26.0 | 2.0 | <1 |\n+| DetectionValidation | 10.1.0 | MER_DetectionValidationPrg | 1 | 2.0 | 2.0 | <1 |\n+| CrossmatchAnalysis | 10.1.0 | MER_CrossmatchAnalysis | 1 | 2.0 | 2.0 | <1 |\n+| MorphologyValidation | 10.1.0 | MER_MorphologyValidationPrg | 1 | 2.0 | 2.0 | <1 |\n+| PhotometryPlotCheck | 10.1.0 | MER_PhotometryPlotCheck | 1 | 2.0 | 2.0 | <1 |\n+| ClassificationValidation | 10.1.0 | MER_ClassificationValidationPrg | 1 | 2.0 | 2.0 | <1 |\n+| CheckFinalCat | 10.1.0 | MER_CheckFinalCat | 1 | 2.0 | 2.0 | <1 |\n+| MergeAnalysisResults | 10.1.0 | MER_MergeAnalysisResults | 1 | 2.0 | 0.5 | <1 |\n \n ### Normal termination\n \n",
                            "Updates the SUM",
                            "Javier Gracia Carpio",
                            "2023-08-07T13:24:00.000+00:00",
                            "fca8026919dd64c52dac3b0c920ffa0ba5cc04cc"
                        ],
                        [
                            "@@ -6,7 +6,7 @@\n \n The group `Analysis` is made of the following pipelines:\n \n-* Group `WIDE`:\n+* Group `Analysis`:\n   * `MER_AnalyseTile`\n   * `MER_AnalyseTileVisOnly`\n \n@@ -127,18 +127,18 @@ The \"Execution Context\" of the `MER_AnalyseTile` is always:\n \n | Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n | -------------------------- | ----- | ------------------------------ | ----- | ------- | ------- | ------- |\n-| MosaicingValidation  | 9.0 | MER_MosaicingValidation | 1 | 16.0 | 2.0 | <1 |\n-| PsfAnalysis | 9.0 | MER_PsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n-| MerStarPsfAnalysis | 9.0 | MER_MerStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n-| TuStarPsfAnalysis | 9.0 | MER_TuStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n-| BackgroundValidation | 9.0 | MER_BackgroundValidationPrg | 1 | 26.0 | 2.0 | <1 |\n-| DetectionValidation | 9.0 | MER_DetectionValidationPrg | 1 | 2.0 | 2.0 | <1 |\n-| CrossmatchAnalysis | 9.0 | MER_CrossmatchAnalysis | 1 | 2.0 | 2.0 | <1 |\n-| MorphologyValidation | 9.0 | MER_MorphologyValidationPrg | 1 | 2.0 | 2.0 | <1 |\n-| PhotometryPlotCheck | 9.0 | MER_PhotometryPlotCheck | 1 | 2.0 | 2.0 | <1 |\n-| ClassificationValidation | 9.0 | MER_ClassificationValidationPrg | 1 | 2.0 | 2.0 | <1 |\n-| CheckFinalCat | 9.0 | MER_CheckFinalCat | 1 | 2.0 | 2.0 | <1 |\n-| MergeAnalysisResults | 9.0 | MER_MergeAnalysisResults | 1 | 2.0 | 0.5 | <1 |\n+| MosaicingValidation  | 10.0 | MER_MosaicingValidation | 1 | 16.0 | 2.0 | <1 |\n+| PsfAnalysis | 10.0 | MER_PsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n+| MerStarPsfAnalysis | 10.0 | MER_MerStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n+| TuStarPsfAnalysis | 10.0 | MER_TuStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n+| BackgroundValidation | 10.0 | MER_BackgroundValidationPrg | 1 | 26.0 | 2.0 | <1 |\n+| DetectionValidation | 10.0 | MER_DetectionValidationPrg | 1 | 2.0 | 2.0 | <1 |\n+| CrossmatchAnalysis | 10.0 | MER_CrossmatchAnalysis | 1 | 2.0 | 2.0 | <1 |\n+| MorphologyValidation | 10.0 | MER_MorphologyValidationPrg | 1 | 2.0 | 2.0 | <1 |\n+| PhotometryPlotCheck | 10.0 | MER_PhotometryPlotCheck | 1 | 2.0 | 2.0 | <1 |\n+| ClassificationValidation | 10.0 | MER_ClassificationValidationPrg | 1 | 2.0 | 2.0 | <1 |\n+| CheckFinalCat | 10.0 | MER_CheckFinalCat | 1 | 2.0 | 2.0 | <1 |\n+| MergeAnalysisResults | 10.0 | MER_MergeAnalysisResults | 1 | 2.0 | 0.5 | <1 |\n \n ### Normal termination\n \n@@ -240,18 +240,18 @@ The \"Execution Context\" of the `MER_AnalyseTileVisOnly` is always:\n \n | Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n | -------------------------- | ----- | ------------------------------ | ----- | ------- | ------- | ------- |\n-| MosaicingValidation  | 9.0 | MER_MosaicingValidation | 1 | 16.0 | 2.0 | <1 |\n-| PsfAnalysis | 9.0 | MER_PsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n-| MerStarPsfAnalysis | 9.0 | MER_MerStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n-| TuStarPsfAnalysis | 9.0 | MER_TuStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n-| BackgroundValidation | 9.0 | MER_BackgroundValidationPrg | 1 | 26.0 | 2.0 | <1 |\n-| DetectionValidation | 9.0 | MER_DetectionValidationPrg | 1 | 2.0 | 2.0 | <1 |\n-| CrossmatchAnalysis | 9.0 | MER_CrossmatchAnalysis | 1 | 2.0 | 2.0 | <1 |\n-| MorphologyValidation | 9.0 | MER_MorphologyValidationPrg | 1 | 2.0 | 2.0 | <1 |\n-| PhotometryPlotCheck | 9.0 | MER_PhotometryPlotCheck | 1 | 2.0 | 2.0 | <1 |\n-| ClassificationValidation | 9.0 | MER_ClassificationValidationPrg | 1 | 2.0 | 2.0 | <1 |\n-| CheckFinalCat | 9.0 | MER_CheckFinalCat | 1 | 2.0 | 2.0 | <1 |\n-| MergeAnalysisResults | 9.0 | MER_MergeAnalysisResults | 1 | 2.0 | 0.5 | <1 |\n+| MosaicingValidation  | 10.0 | MER_MosaicingValidation | 1 | 16.0 | 2.0 | <1 |\n+| PsfAnalysis | 10.0 | MER_PsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n+| MerStarPsfAnalysis | 10.0 | MER_MerStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n+| TuStarPsfAnalysis | 10.0 | MER_TuStarPsfAnalysis | 1 | 12.0 | 2.0 | <1 |\n+| BackgroundValidation | 10.0 | MER_BackgroundValidationPrg | 1 | 26.0 | 2.0 | <1 |\n+| DetectionValidation | 10.0 | MER_DetectionValidationPrg | 1 | 2.0 | 2.0 | <1 |\n+| CrossmatchAnalysis | 10.0 | MER_CrossmatchAnalysis | 1 | 2.0 | 2.0 | <1 |\n+| MorphologyValidation | 10.0 | MER_MorphologyValidationPrg | 1 | 2.0 | 2.0 | <1 |\n+| PhotometryPlotCheck | 10.0 | MER_PhotometryPlotCheck | 1 | 2.0 | 2.0 | <1 |\n+| ClassificationValidation | 10.0 | MER_ClassificationValidationPrg | 1 | 2.0 | 2.0 | <1 |\n+| CheckFinalCat | 10.0 | MER_CheckFinalCat | 1 | 2.0 | 2.0 | <1 |\n+| MergeAnalysisResults | 10.0 | MER_MergeAnalysisResults | 1 | 2.0 | 0.5 | <1 |\n \n ### Normal termination\n \n",
                            "SUM update",
                            "Erik Romelli",
                            "2023-06-28T12:01:15.000+02:00",
                            "14e1cf60d97acdf4d0f5a0fce884848152ab2906"
                        ]
                    ],
                    "doc/user_manual/chap6-DEEP.md": [
                        [
                            "@@ -56,40 +56,28 @@ flowchart LR\n     cat(DpdMerFinalCatalog)\n     anal(DpdMerAnalysisResult)\n \n-    vis ==>|EUC_VIS_SWL-DET/BKG/PSF<br>1..N| pipeline\n-    vis ==>|EUC_VIS_SWL-BKG<br>1..N| pipeline\n-    vis ==>|EUC_VIS_SWL-PSF<br>1..N| pipeline\n+    vis ==>|vis_calibrated_frames<br>1..N| pipeline\n \n-    nir ==>|EUC_NIR_W-CALIB_band<br>1..N| pipeline\n-    nir ==>|EUC_NIR_W-CALIB-BKG_NIR-band<br>1..N| pipeline\n-    nir ==>|EUC_NIR_W-CALIB-PSF_NIR-band<br>1..N| pipeline\n+    nir ==>|nir_calibrated_frames<br>1..N| pipeline\n \n-    ext ==>|EUC_EXT_ext_TILE-tile-band<br>1..N| pipeline\n-    ext ==>|EUC_EXT_ext_TILE-tile-band-STACKEDPSF<br>1..N| pipeline\n+    ext ==>|ext_stacks<br>1..N| pipeline\n \n-    mdb ==>|EUC_MER_STARPROBA_FOR_SC8_SWF1<br>1..1| pipeline\n-    mdb ==>|HFI_CompMap_ThermalDustModel_2048_R1.20_V2<br>1..1| pipeline\n+    mdb ==>|mdb<br>1..1| pipeline\n \n-    conf ==>|EUC_MER_CONF-FILE-MOSAICS| pipeline\n+    conf ==>|configuration_set<br>1..1| pipeline\n \n-    conf ==>|EUC_MER_CONF-FILE-BACKGROUND| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-DETECTION| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-DEBLENDING| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-PHOTOMETRY| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-SPURIOUS| pipeline\n+    flag ==>|flag_limits<br>1..1| pipeline \n \n-    flag ==> pipeline \n+    tile ==>|tile<br>1..1| pipeline \n \n-    tile ==> pipeline \n+    gaia ==>|gaia_cutouts<br>| pipeline\n \n-    gaia ==>|EUC_EXT_GAIACUTOUT<br>0..1| pipeline\n-\n-    pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..N| bgkmos\n-    pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..2| detmos\n-    pipeline ==>|EUC_MER_FINAL-SEGMAP<br>1..1| seg\n-    pipeline ==>|EUC_MER_FINAL-CAT<br>1..1| cat\n-    pipeline ==>|EUC_MER_FINAL-CUTOUT-CAT<br>1..1| cat\n-    pipeline ==>|EUC_MER_QUICK-ANALYSIS-REPORT<br>1..4| anal\n+    pipeline ==>|compressed_mosaics<br>1..N| bgkmos\n+    pipeline ==>|compressed_vis_detection_mosaic<br>1..1| detmos\n+    pipeline ==>|compressed_nir_detection_mosaic<br>1..1| detmos\n+    pipeline ==>|compressed_segmentation_map<br>1..1| seg\n+    pipeline ==>|compressed_catalog<br>1..1| cat\n+    pipeline ==>|analysis_result<br>1..1| anal\n ```\n \n **Ports description:**\n@@ -282,32 +270,23 @@ flowchart LR\n     cat(DpdMerFinalCatalog)\n     anal(DpdMerAnalysisResult)\n \n-    vis ==>|EUC_VIS_SWL-DET/BKG/PSF<br>1..N| pipeline\n-    vis ==>|EUC_VIS_SWL-BKG<br>1..N| pipeline\n-    vis ==>|EUC_VIS_SWL-PSF<br>1..N| pipeline\n+    vis ==>|vis_calibrated_frames<br>1..N| pipeline\n \n-    mdb ==>|EUC_MER_STARPROBA_FOR_SC8_SWF1<br>1..1| pipeline\n-    mdb ==>|HFI_CompMap_ThermalDustModel_2048_R1.20_V2<br>1..1| pipeline\n+    mdb ==>|mdb<br>1..1| pipeline\n \n-    conf ==>|EUC_MER_CONF-FILE-MOSAICS| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-BACKGROUND| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-DETECTION| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-DEBLENDING| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-PHOTOMETRY| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-SPURIOUS| pipeline\n+    conf ==>|configuration_set<br>1..1| pipeline\n \n-    flag ==> pipeline \n+    flag ==>|flag_limits<br>1..1| pipeline \n \n-    tile ==> pipeline \n+    tile ==>|tile<br>1..1| pipeline \n \n-    gaia ==>|EUC_EXT_GAIACUTOUT<br>0..1| pipeline\n+    gaia ==>|gaia_cutouts<br>0..1| pipeline\n \n-    pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..1| bgkmos\n-    pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..1| detmos\n-    pipeline ==>|EUC_MER_FINAL-SEGMAP<br>1..1| seg\n-    pipeline ==>|EUC_MER_FINAL-CAT<br>1..1| cat\n-    pipeline ==>|EUC_MER_FINAL-CUTOUT-CAT<br>1..1| cat\n-    pipeline ==>|EUC_MER_QUICK-ANALYSIS-REPORT<br>1..4| anal\n+    pipeline ==>|compressed_vis_mosaic<br>1..1| bgkmos\n+    pipeline ==>|compressed_vis_detection_mosaic<br>1..1| detmos\n+    pipeline ==>|compressed_segmentation_map<br>1..1| seg\n+    pipeline ==>|compressed_catalog<br>1..1| cat\n+    pipeline ==>|analysis_result<br>1..1| anal\n ```\n \n **Ports description:**\n",
                            "chap5-DEEP updated",
                            "Erik Romelli",
                            "2023-08-21T10:39:21.000+02:00",
                            "ebb21c171499b909d71e2a3215e3f300eb9b3ec6"
                        ],
                        [
                            "@@ -82,7 +82,7 @@ flowchart LR\n \n     tile ==> pipeline \n \n-    gaia ==>|EUC_EXT_GAIACUTOUT<br>1..1| pipeline\n+    gaia ==>|EUC_EXT_GAIACUTOUT<br>0..1| pipeline\n \n     pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..N| bgkmos\n     pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..2| detmos\n@@ -300,7 +300,7 @@ flowchart LR\n \n     tile ==> pipeline \n \n-    gaia ==>|EUC_EXT_GAIACUTOUT<br>1..1| pipeline\n+    gaia ==>|EUC_EXT_GAIACUTOUT<br>0..1| pipeline\n \n     pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..1| bgkmos\n     pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..1| detmos\n",
                            "Corrects ordinality of Gaia catalogs",
                            "Javier Gracia Carpio",
                            "2023-08-07T13:33:39.000+00:00",
                            "3c1c04dcadb4839218d3690f8fae49ccd0a5df4b"
                        ],
                        [
                            "@@ -48,6 +48,7 @@ flowchart LR\n     conf(DpdMerConfigurationSet)\n     flag(DpdMerDqcStaticFlagLimits)\n     tile(DpdMerTile)\n+    gaia(DpdExtGaiaCutout)\n \n     bgkmos(DpdMerBksMosaic)\n     detmos(DpdMerDetectionMosaic)\n@@ -81,6 +82,8 @@ flowchart LR\n \n     tile ==> pipeline \n \n+    gaia ==>|EUC_EXT_GAIACUTOUT<br>1..1| pipeline\n+\n     pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..N| bgkmos\n     pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..2| detmos\n     pipeline ==>|EUC_MER_FINAL-SEGMAP<br>1..1| seg\n@@ -99,13 +102,14 @@ flowchart LR\n   * `configuration_set`: List configuration files.\n   * `flag_limits`: Data Model flags.\n   * `mdb`: MDB Data Product.\n+  * `gaia_cutouts`: List of EXT Gaia cutout catalogs.\n \n * Output:\n-  * `all_mosaics`: Background-subtracted mosaics.\n-  * `vis_detection_mosaic`: Mosaic used to perform the object detection on VIS.\n-  * `nir_detection_mosaic`: Mosaic used to perform the object detection on NIR.\n-  * `final_segmentation_map`: Map showing the connected pixels of the objects detected on the corresponding detection mosaic.\n-  * `final_catalog`: Final merged catalog with photometric and morphological information.\n+  * `compressed_mosaics`: Background-subtracted mosaics.\n+  * `compressed_vis_detection_mosaic`: Mosaic used to perform the object detection on VIS.\n+  * `compressed_nir_detection_mosaic`: Mosaic used to perform the object detection on NIR.\n+  * `compressed_segmentation_map`: Map showing the connected pixels of the objects detected on the corresponding detection mosaic.\n+  * `compressed_catalog`: Final merged catalog with photometric and morphological information.\n   * `analysis_result`: Results of the quick analysis step.\n \n \n@@ -113,6 +117,7 @@ flowchart LR\n \n * `MER_ProcessTile` triggered at Tile scale.\n * `MER_ProcessTile` can run without EXT data.\n+* `MER_ProcessTile` can run without NIR data, but it needs a NIR calibrated frame that doesn't fall in the tile.\n \n | Scale(s) | Periodicity | Input DataProduct | Information for creating the pipeline definition |\n | -------| ----------- | ----------- |  --------------- |\n@@ -130,30 +135,31 @@ The \"Execution Context\" of the `MER_ProcessTile` is always:\n \n | Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n | ----------------------------- | ----- | --------------------------- | ----- | ------- | ------- | ------- |\n-| Initialize  | 10.0 | MER_Initializze | 1 | 1.0 | 0.3 | - |\n-| Mosaicing | 10.0 | MER_Mosaicing | 1 | 6.0 | 6.0 | 363.0 |\n-| Background | 10.0 | MER_Background | 1 | 8.0 | 4.0 | 96.6 |\n-| MosaicSelection | 10.0 | MER_MosaicSelection | 1 | 1.0 | 0.3 | - |\n-| VisDetection | 10.0 | MER_VisDetection | 1 | 20.0 | 6.0 | 1.4 |\n-| NirDetection | 10.0 | MER_NirDetection | 1 | 20.0 | 6.0 | 2.8 |\n-| Deblending_1 | 10.0 | MER_Deblending | 1 | 22.0 | 14.0 | 2.4 |\n-| Deblending_2 | 10.0 | MER_Deblending | 1 | 22.0 | 14.0 | 1.4 |\n-| Morphology | 10.0 | MER_Morphology | 1 | 10.0 | 2.0 | 2.5 |\n-| MBCombine | 10.0 | MER_MBCombine | 1 | 8.0 | 0.5 | - |\n-| CatalogPsfCalculation | 10.0 | MER_CatalogPsfCalculation | 1 | 6.0 | 4.0 | 173.0 |\n-| LowResPsfExtraction | 10.0 | MER_LowResPsfExtraction | 1 | 14.0 | 3.0 | - |\n-| NirCatalogMerging | 10.0 | MER_NirCatalogMerging | 1 | 1.0 | 0.3 | <1.0 |\n-| KernelAPhot | 10.0 | MER_KernelAPhot | 1 | 16.0 | 3.0 | 76.0 |\n-| KernelTPhot | 10.0 | MER_KernelTPhot | 1 | 12.0 | 3.0 | 76.0 |\n-| KernelAPhotNIRStack | 10.0 | MER_KernelAPhot | 1 | 16.0 | 3.0 | 5.0 |\n-| Photometry_FilterTransmission | 10.0 | MER_APhotTransmission | 1 | 10.0 | 1.0 | <1.0 |\n-| Photometry_Det | 10.0 | MER_APhotDetection | 1 | 12.0 | 1.0 | <1.0 |\n-| Photometry_A | 10.0 | MER_APhotCircular | 1 | 12.0 | 2.0 | <1.0 |\n-| Photometry_T | 10.0 | MER_TPhotProgram | 1 | 36.0 | 14.0 | 440.0 |\n-| Photometry_PsfFitting | 10.0 | MER_PsfFitting | 1 | 16.0 | 12.0 | 7.5 |\n-| Photometry_Morpho | 10.0 | MER_APhotMorphology | 1 | 12.0 | 2.0 | <1.0 |\n-| Catalog | 10.0 | MER_CatalogAssembly | 1 | 22.0 | 1.0 | 2.9 |\n-| QuickAnalysis | 10.0 | MER_QuickAnalysis | 1 | 2.0 | 1.0 | <1.0 |\n+| Initialize  | 10.1.0 | MER_Initializze | 1 | 1.0 | 0.3 | - |\n+| Mosaicing | 10.1.0 | MER_Mosaicing | 1 | 6.0 | 6.0 | 363.0 |\n+| Background | 10.1.0 | MER_Background | 1 | 8.0 | 4.0 | 96.6 |\n+| MosaicSelection | 10.1.0 | MER_MosaicSelection | 1 | 1.0 | 0.3 | - |\n+| VisDetection | 10.1.0 | MER_VisDetection | 1 | 20.0 | 6.0 | 1.4 |\n+| NirDetection | 10.1.0 | MER_NirDetection | 1 | 20.0 | 6.0 | 2.8 |\n+| Deblending_1 | 10.1.0 | MER_Deblending | 1 | 22.0 | 14.0 | 2.4 |\n+| Deblending_2 | 10.1.0 | MER_Deblending | 1 | 22.0 | 14.0 | 1.4 |\n+| Morphology | 10.1.0 | MER_Morphology | 1 | 10.0 | 2.0 | 2.5 |\n+| MBCombine | 10.1.0 | MER_MBCombine | 1 | 8.0 | 0.5 | - |\n+| CatalogPsfCalculation | 10.1.0 | MER_CatalogPsfCalculation | 1 | 6.0 | 4.0 | 173.0 |\n+| LowResPsfExtraction | 10.1.0 | MER_LowResPsfExtraction | 1 | 14.0 | 3.0 | - |\n+| NirCatalogMerging | 10.1.0 | MER_NirCatalogMerging | 1 | 1.0 | 0.3 | <1.0 |\n+| KernelAPhot | 10.1.0 | MER_KernelAPhot | 1 | 16.0 | 3.0 | 76.0 |\n+| KernelTPhot | 10.1.0 | MER_KernelTPhot | 1 | 12.0 | 3.0 | 76.0 |\n+| KernelAPhotNIRStack | 10.1.0 | MER_KernelAPhot | 1 | 16.0 | 3.0 | 5.0 |\n+| Photometry_FilterTransmission | 10.1.0 | MER_APhotTransmission | 1 | 10.0 | 1.0 | <1.0 |\n+| Photometry_Det | 10.1.0 | MER_APhotDetection | 1 | 12.0 | 1.0 | <1.0 |\n+| Photometry_A | 10.1.0 | MER_APhotCircular | 1 | 12.0 | 2.0 | <1.0 |\n+| Photometry_T | 10.1.0 | MER_TPhotProgram | 1 | 36.0 | 14.0 | 440.0 |\n+| Photometry_PsfFitting | 10.1.0 | MER_PsfFitting | 1 | 16.0 | 12.0 | 7.5 |\n+| Photometry_Morpho | 10.1.0 | MER_APhotMorphology | 1 | 12.0 | 2.0 | <1.0 |\n+| Catalog | 10.1.1 | MER_CatalogAssembly | 1 | 22.0 | 1.0 | 2.9 |\n+| QuickAnalysis | 10.1.0 | MER_QuickAnalysis | 1 | 2.0 | 1.0 | <1.0 |\n+| Compression | 10.1.0 | MER_Compression | 1 | 4.0 | 1.0 | <100.0 |\n \n ### Normal termination\n \n@@ -268,7 +274,9 @@ flowchart LR\n     conf(DpdMerConfigurationSet)\n     flag(DpdMerDqcStaticFlagLimits)\n     tile(DpdMerTile)\n+    gaia(DpdExtGaiaCutout)\n \n+    bgkmos(DpdMerBksMosaic)\n     detmos(DpdMerDetectionMosaic)\n     seg(DpdMerSegmentationMap)\n     cat(DpdMerFinalCatalog)\n@@ -282,16 +290,19 @@ flowchart LR\n     mdb ==>|HFI_CompMap_ThermalDustModel_2048_R1.20_V2<br>1..1| pipeline\n \n     conf ==>|EUC_MER_CONF-FILE-MOSAICS| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-PHOTOMETRY| pipeline\n     conf ==>|EUC_MER_CONF-FILE-BACKGROUND| pipeline\n     conf ==>|EUC_MER_CONF-FILE-DETECTION| pipeline\n     conf ==>|EUC_MER_CONF-FILE-DEBLENDING| pipeline\n+    conf ==>|EUC_MER_CONF-FILE-PHOTOMETRY| pipeline\n     conf ==>|EUC_MER_CONF-FILE-SPURIOUS| pipeline\n \n     flag ==> pipeline \n \n     tile ==> pipeline \n \n+    gaia ==>|EUC_EXT_GAIACUTOUT<br>1..1| pipeline\n+\n+    pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..1| bgkmos\n     pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..1| detmos\n     pipeline ==>|EUC_MER_FINAL-SEGMAP<br>1..1| seg\n     pipeline ==>|EUC_MER_FINAL-CAT<br>1..1| cat\n@@ -307,11 +318,13 @@ flowchart LR\n   * `configuration_set`: List configuration files.\n   * `flag_limits`: Data Model flags.\n   * `mdb`: MDB Data Product.\n+  * `gaia_cutouts`: List of EXT Gaia cutout catalogs.\n \n * Output:\n-  * `vis_detection_mosaic`: Mosaic used to perform the object detection on VIS.\n-  * `final_segmentation_map`: Map showing the connected pixels of the objects detected on the corresponding detection mosaic.\n-  * `final_catalog`: Final merged catalog with photometric and morphological information.\n+  * `compressed_vis_mosaic`: VIS background-subtracted mosaic.\n+  * `compressed_vis_detection_mosaic`: Mosaic used to perform the object detection on VIS.\n+  * `compressed_segmentation_map`: Map showing the connected pixels of the objects detected on the corresponding detection mosaic.\n+  * `compressed_catalog`: Final merged catalog with photometric and morphological information.\n   * `analysis_result`: Results of the quick analysis step.\n \n \n@@ -336,18 +349,19 @@ The \"Execution Context\" of the `MER_ProcessTileVisOnly` is always:\n \n | Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n | ----------------------------- | ----- | --------------------------- | ----- | ------- | ------- | ------- |\n-| Initialize  | 10.0 | MER_Initializze | 1 | 1.0 | 0.3 | - |\n-| Mosaicing | 10.0 | MER_Mosaicing | 1 | 6.0 | 6.0 | 68.2 |\n-| Background | 10.0 | MER_Background | 1 | 8.0 | 4.0 | 4.2 |\n-| VisDetection | 10.0 | MER_VisDetection | 1 | 20.0 | 6.0 | 1.4 |\n-| Deblending_1 | 10.0 | MER_Deblending | 1 | 22.0 | 14.0 | 2.4 |\n-| Morphology | 10.0 | MER_Morphology | 1 | 10.0 | 2.0 | 2.5 |\n-| CatalogPsfCalculation | 10.0 | MER_CatalogPsfCalculation | 1 | 6.0 | 4.0 | 88.0 |\n-| Photometry_Det | 10.0 | MER_APhotDetection | 1 | 12.0 | 1.0 | <1.0 |\n-| Photometry_PsfFitting | 10.0 | MER_PsfFitting | 1 | 16.0 | 12.0 | 7.5 |\n-| Photometry_Morpho | 10.0 | MER_APhotMorphology | 1 | 12.0 | 2.0 | <1.0 |\n-| Catalog | 10.0 | MER_CatalogAssembly | 1 | 22.0 | 1.0 | 2.9 |\n-| QuickAnalysis | 10.0 | MER_QuickAnalysis | 1 | 2.0 | 1.0 | <1.0 |\n+| Initialize  | 10.1.0 | MER_Initializze | 1 | 1.0 | 0.3 | - |\n+| Mosaicing | 10.1.0 | MER_Mosaicing | 1 | 6.0 | 6.0 | 68.2 |\n+| Background | 10.1.0 | MER_Background | 1 | 8.0 | 4.0 | 4.2 |\n+| VisDetection | 10.1.0 | MER_VisDetection | 1 | 20.0 | 6.0 | 1.4 |\n+| Deblending_1 | 10.1.0 | MER_Deblending | 1 | 22.0 | 14.0 | 2.4 |\n+| Morphology | 10.1.0 | MER_Morphology | 1 | 10.0 | 2.0 | 2.5 |\n+| CatalogPsfCalculation | 10.1.0 | MER_CatalogPsfCalculation | 1 | 6.0 | 4.0 | 88.0 |\n+| Photometry_Det | 10.1.0 | MER_APhotDetection | 1 | 12.0 | 1.0 | <1.0 |\n+| Photometry_PsfFitting | 10.1.0 | MER_PsfFitting | 1 | 16.0 | 12.0 | 7.5 |\n+| Photometry_Morpho | 10.1.0 | MER_APhotMorphology | 1 | 12.0 | 2.0 | <1.0 |\n+| Catalog | 10.1.1 | MER_CatalogAssembly | 1 | 22.0 | 1.0 | 2.9 |\n+| QuickAnalysis | 10.1.0 | MER_QuickAnalysis | 1 | 2.0 | 1.0 | <1.0 |\n+| Compression | 10.1.0 | MER_Compression | 1 | 4.0 | 1.0 | <100.0 |\n \n ### Normal termination\n \n",
                            "Updates the SUM",
                            "Javier Gracia Carpio",
                            "2023-08-07T13:24:00.000+00:00",
                            "fca8026919dd64c52dac3b0c920ffa0ba5cc04cc"
                        ],
                        [
                            "@@ -6,7 +6,7 @@\n \n The group `DEEP` is made of the following pipelines:\n \n-* Group `WIDE`:\n+* Group `DEEP`:\n   * `MER_ProcessTile`\n   * `MER_ProcessTileVisOnly`\n \n@@ -130,30 +130,30 @@ The \"Execution Context\" of the `MER_ProcessTile` is always:\n \n | Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n | ----------------------------- | ----- | --------------------------- | ----- | ------- | ------- | ------- |\n-| Initialize  | 9.0 | MER_Initializze | 1 | 1.0 | 0.3 | - |\n-| Mosaicing | 9.0 | MER_Mosaicing | 1 | 6.0 | 6.0 | 363.0 |\n-| Background | 9.0 | MER_Background | 1 | 8.0 | 4.0 | 96.6 |\n-| MosaicSelection | 9.0 | MER_MosaicSelection | 1 | 1.0 | 0.3 | - |\n-| VisDetection | 9.0 | MER_VisDetection | 1 | 20.0 | 6.0 | 1.4 |\n-| NirDetection | 9.0 | MER_NirDetection | 1 | 20.0 | 6.0 | 2.8 |\n-| Deblending_1 | 9.0 | MER_Deblending | 1 | 22.0 | 14.0 | 2.4 |\n-| Deblending_2 | 9.0 | MER_Deblending | 1 | 22.0 | 14.0 | 1.4 |\n-| Morphology | 9.0 | MER_Morphology | 1 | 10.0 | 2.0 | 2.5 |\n-| MBCombine | 9.0 | MER_MBCombine | 1 | 8.0 | 0.5 | - |\n-| CatalogPsfCalculation | 9.0 | MER_CatalogPsfCalculation | 1 | 6.0 | 4.0 | 173.0 |\n-| LowResPsfExtraction | 9.0 | MER_LowResPsfExtraction | 1 | 14.0 | 3.0 | - |\n-| NirCatalogMerging | 9.0 | MER_NirCatalogMerging | 1 | 1.0 | 0.3 | <1.0 |\n-| KernelAPhot | 9.0 | MER_KernelAPhot | 1 | 16.0 | 3.0 | 76.0 |\n-| KernelTPhot | 9.0 | MER_KernelTPhot | 1 | 12.0 | 3.0 | 76.0 |\n-| KernelAPhotNIRStack | 9.0 | MER_KernelAPhot | 1 | 16.0 | 3.0 | 5.0 |\n-| Photometry_FilterTransmission | 9.0 | MER_APhotTransmission | 1 | 10.0 | 1.0 | <1.0 |\n-| Photometry_Det | 9.0 | MER_APhotDetection | 1 | 12.0 | 1.0 | <1.0 |\n-| Photometry_A | 9.0 | MER_APhotCircular | 1 | 12.0 | 2.0 | <1.0 |\n-| Photometry_T | 9.0 | MER_TPhotProgram | 1 | 36.0 | 14.0 | 440.0 |\n-| Photometry_PsfFitting | 9.0 | MER_PsfFitting | 1 | 16.0 | 12.0 | 7.5 |\n-| Photometry_Morpho | 9.0 | MER_APhotMorphology | 1 | 12.0 | 2.0 | <1.0 |\n-| Catalog | 9.0 | MER_CatalogAssembly | 1 | 22.0 | 1.0 | 2.9 |\n-| QuickAnalysis | 9.0 | MER_QuickAnalysis | 1 | 2.0 | 1.0 | <1.0 |\n+| Initialize  | 10.0 | MER_Initializze | 1 | 1.0 | 0.3 | - |\n+| Mosaicing | 10.0 | MER_Mosaicing | 1 | 6.0 | 6.0 | 363.0 |\n+| Background | 10.0 | MER_Background | 1 | 8.0 | 4.0 | 96.6 |\n+| MosaicSelection | 10.0 | MER_MosaicSelection | 1 | 1.0 | 0.3 | - |\n+| VisDetection | 10.0 | MER_VisDetection | 1 | 20.0 | 6.0 | 1.4 |\n+| NirDetection | 10.0 | MER_NirDetection | 1 | 20.0 | 6.0 | 2.8 |\n+| Deblending_1 | 10.0 | MER_Deblending | 1 | 22.0 | 14.0 | 2.4 |\n+| Deblending_2 | 10.0 | MER_Deblending | 1 | 22.0 | 14.0 | 1.4 |\n+| Morphology | 10.0 | MER_Morphology | 1 | 10.0 | 2.0 | 2.5 |\n+| MBCombine | 10.0 | MER_MBCombine | 1 | 8.0 | 0.5 | - |\n+| CatalogPsfCalculation | 10.0 | MER_CatalogPsfCalculation | 1 | 6.0 | 4.0 | 173.0 |\n+| LowResPsfExtraction | 10.0 | MER_LowResPsfExtraction | 1 | 14.0 | 3.0 | - |\n+| NirCatalogMerging | 10.0 | MER_NirCatalogMerging | 1 | 1.0 | 0.3 | <1.0 |\n+| KernelAPhot | 10.0 | MER_KernelAPhot | 1 | 16.0 | 3.0 | 76.0 |\n+| KernelTPhot | 10.0 | MER_KernelTPhot | 1 | 12.0 | 3.0 | 76.0 |\n+| KernelAPhotNIRStack | 10.0 | MER_KernelAPhot | 1 | 16.0 | 3.0 | 5.0 |\n+| Photometry_FilterTransmission | 10.0 | MER_APhotTransmission | 1 | 10.0 | 1.0 | <1.0 |\n+| Photometry_Det | 10.0 | MER_APhotDetection | 1 | 12.0 | 1.0 | <1.0 |\n+| Photometry_A | 10.0 | MER_APhotCircular | 1 | 12.0 | 2.0 | <1.0 |\n+| Photometry_T | 10.0 | MER_TPhotProgram | 1 | 36.0 | 14.0 | 440.0 |\n+| Photometry_PsfFitting | 10.0 | MER_PsfFitting | 1 | 16.0 | 12.0 | 7.5 |\n+| Photometry_Morpho | 10.0 | MER_APhotMorphology | 1 | 12.0 | 2.0 | <1.0 |\n+| Catalog | 10.0 | MER_CatalogAssembly | 1 | 22.0 | 1.0 | 2.9 |\n+| QuickAnalysis | 10.0 | MER_QuickAnalysis | 1 | 2.0 | 1.0 | <1.0 |\n \n ### Normal termination\n \n@@ -336,18 +336,18 @@ The \"Execution Context\" of the `MER_ProcessTileVisOnly` is always:\n \n | Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n | ----------------------------- | ----- | --------------------------- | ----- | ------- | ------- | ------- |\n-| Initialize  | 9.0 | MER_Initializze | 1 | 1.0 | 0.3 | - |\n-| Mosaicing | 9.0 | MER_Mosaicing | 1 | 6.0 | 6.0 | 68.2 |\n-| Background | 9.0 | MER_Background | 1 | 8.0 | 4.0 | 4.2 |\n-| VisDetection | 9.0 | MER_VisDetection | 1 | 20.0 | 6.0 | 1.4 |\n-| Deblending_1 | 9.0 | MER_Deblending | 1 | 22.0 | 14.0 | 2.4 |\n-| Morphology | 9.0 | MER_Morphology | 1 | 10.0 | 2.0 | 2.5 |\n-| CatalogPsfCalculation | 9.0 | MER_CatalogPsfCalculation | 1 | 6.0 | 4.0 | 88.0 |\n-| Photometry_Det | 9.0 | MER_APhotDetection | 1 | 12.0 | 1.0 | <1.0 |\n-| Photometry_PsfFitting | 9.0 | MER_PsfFitting | 1 | 16.0 | 12.0 | 7.5 |\n-| Photometry_Morpho | 9.0 | MER_APhotMorphology | 1 | 12.0 | 2.0 | <1.0 |\n-| Catalog | 9.0 | MER_CatalogAssembly | 1 | 22.0 | 1.0 | 2.9 |\n-| QuickAnalysis | 9.0 | MER_QuickAnalysis | 1 | 2.0 | 1.0 | <1.0 |\n+| Initialize  | 10.0 | MER_Initializze | 1 | 1.0 | 0.3 | - |\n+| Mosaicing | 10.0 | MER_Mosaicing | 1 | 6.0 | 6.0 | 68.2 |\n+| Background | 10.0 | MER_Background | 1 | 8.0 | 4.0 | 4.2 |\n+| VisDetection | 10.0 | MER_VisDetection | 1 | 20.0 | 6.0 | 1.4 |\n+| Deblending_1 | 10.0 | MER_Deblending | 1 | 22.0 | 14.0 | 2.4 |\n+| Morphology | 10.0 | MER_Morphology | 1 | 10.0 | 2.0 | 2.5 |\n+| CatalogPsfCalculation | 10.0 | MER_CatalogPsfCalculation | 1 | 6.0 | 4.0 | 88.0 |\n+| Photometry_Det | 10.0 | MER_APhotDetection | 1 | 12.0 | 1.0 | <1.0 |\n+| Photometry_PsfFitting | 10.0 | MER_PsfFitting | 1 | 16.0 | 12.0 | 7.5 |\n+| Photometry_Morpho | 10.0 | MER_APhotMorphology | 1 | 12.0 | 2.0 | <1.0 |\n+| Catalog | 10.0 | MER_CatalogAssembly | 1 | 22.0 | 1.0 | 2.9 |\n+| QuickAnalysis | 10.0 | MER_QuickAnalysis | 1 | 2.0 | 1.0 | <1.0 |\n \n ### Normal termination\n \n",
                            "SUM update",
                            "Erik Romelli",
                            "2023-06-28T12:01:15.000+02:00",
                            "14e1cf60d97acdf4d0f5a0fce884848152ab2906"
                        ]
                    ],
                    "doc/user_manual/chap5-WIDE.md": [
                        [
                            "@@ -59,40 +59,28 @@ flowchart LR\n     cat(DpdMerFinalCatalog)\n     anal(DpdMerAnalysisResult)\n \n-    vis ==>|EUC_VIS_SWL-DET/BKG/PSF<br>1..N| pipeline\n-    vis ==>|EUC_VIS_SWL-BKG<br>1..N| pipeline\n-    vis ==>|EUC_VIS_SWL-PSF<br>1..N| pipeline\n+    vis ==>|vis_calibrated_frames<br>1..N| pipeline\n \n-    nir ==>|EUC_NIR_W-CALIB_band<br>1..N| pipeline\n-    nir ==>|EUC_NIR_W-CALIB-BKG_NIR-band<br>1..N| pipeline\n-    nir ==>|EUC_NIR_W-CALIB-PSF_NIR-band<br>1..N| pipeline\n+    nir ==>|nir_calibrated_frames<br>1..N| pipeline\n \n-    ext ==>|EUC_EXT_ext_TILE-tile-band<br>1..N| pipeline\n-    ext ==>|EUC_EXT_ext_TILE-tile-band-STACKEDPSF<br>1..N| pipeline\n+    ext ==>|ext_stacks<br>1..N| pipeline\n \n-    mdb ==>|EUC_MER_STARPROBA_FOR_SC8_SWF1<br>1..1| pipeline\n-    mdb ==>|HFI_CompMap_ThermalDustModel_2048_R1.20_V2<br>1..1| pipeline\n+    mdb ==>|mdb<br>1..1| pipeline\n \n-    conf ==>|EUC_MER_CONF-FILE-MOSAICS| pipeline\n+    conf ==>|configuration_set<br>1..1| pipeline\n \n-    conf ==>|EUC_MER_CONF-FILE-BACKGROUND| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-DETECTION| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-DEBLENDING| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-PHOTOMETRY| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-SPURIOUS| pipeline\n+    flag ==>|flag_limits<br>1..1| pipeline \n \n-    flag ==> pipeline \n+    tile ==>|tile<br>1..1| pipeline \n \n-    tile ==> pipeline \n+    gaia ==>|gaia_cutouts<br>| pipeline\n \n-    gaia ==>|EUC_EXT_GAIACUTOUT<br>0..1| pipeline\n-\n-    pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..N| bgkmos\n-    pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..2| detmos\n-    pipeline ==>|EUC_MER_FINAL-SEGMAP<br>1..1| seg\n-    pipeline ==>|EUC_MER_FINAL-CAT<br>1..1| cat\n-    pipeline ==>|EUC_MER_FINAL-CUTOUT-CAT<br>1..1| cat\n-    pipeline ==>|EUC_MER_QUICK-ANALYSIS-REPORT<br>1..4| anal\n+    pipeline ==>|compressed_mosaics<br>1..N| bgkmos\n+    pipeline ==>|compressed_vis_detection_mosaic<br>1..1| detmos\n+    pipeline ==>|compressed_nir_detection_mosaic<br>1..1| detmos\n+    pipeline ==>|compressed_segmentation_map<br>1..1| seg\n+    pipeline ==>|compressed_catalog<br>1..1| cat\n+    pipeline ==>|analysis_result<br>1..1| anal\n ```\n \n **Ports description:**\n@@ -285,32 +273,23 @@ flowchart LR\n     cat(DpdMerFinalCatalog)\n     anal(DpdMerAnalysisResult)\n \n-    vis ==>|EUC_VIS_SWL-DET/BKG/PSF<br>1..N| pipeline\n-    vis ==>|EUC_VIS_SWL-BKG<br>1..N| pipeline\n-    vis ==>|EUC_VIS_SWL-PSF<br>1..N| pipeline\n+    vis ==>|vis_calibrated_frames<br>1..N| pipeline\n \n-    mdb ==>|EUC_MER_STARPROBA_FOR_SC8_SWF1<br>1..1| pipeline\n-    mdb ==>|HFI_CompMap_ThermalDustModel_2048_R1.20_V2<br>1..1| pipeline\n+    mdb ==>|mdb<br>1..1| pipeline\n \n-    conf ==>|EUC_MER_CONF-FILE-MOSAICS| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-BACKGROUND| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-DETECTION| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-DEBLENDING| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-PHOTOMETRY| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-SPURIOUS| pipeline\n+    conf ==>|configuration_set<br>1..1| pipeline\n \n-    flag ==> pipeline \n+    flag ==>|flag_limits<br>1..1| pipeline \n \n-    tile ==> pipeline \n+    tile ==>|tile<br>1..1| pipeline \n \n-    gaia ==>|EUC_EXT_GAIACUTOUT<br>0..1| pipeline\n+    gaia ==>|gaia_cutouts<br>0..1| pipeline\n \n-    pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..1| bgkmos\n-    pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..1| detmos\n-    pipeline ==>|EUC_MER_FINAL-SEGMAP<br>1..1| seg\n-    pipeline ==>|EUC_MER_FINAL-CAT<br>1..1| cat\n-    pipeline ==>|EUC_MER_FINAL-CUTOUT-CAT<br>1..1| cat\n-    pipeline ==>|EUC_MER_QUICK-ANALYSIS-REPORT<br>1..4| anal\n+    pipeline ==>|compressed_vis_mosaic<br>1..1| bgkmos\n+    pipeline ==>|compressed_vis_detection_mosaic<br>1..1| detmos\n+    pipeline ==>|compressed_segmentation_map<br>1..1| seg\n+    pipeline ==>|compressed_catalog<br>1..1| cat\n+    pipeline ==>|analysis_result<br>1..1| anal\n ```\n \n **Ports description:**\n",
                            "chap5-WIDE updated",
                            "Erik Romelli",
                            "2023-08-21T10:37:04.000+02:00",
                            "389546fa4aaef5dd4c986b39d55b55afc74c4960"
                        ],
                        [
                            "@@ -85,7 +85,7 @@ flowchart LR\n \n     tile ==> pipeline \n \n-    gaia ==>|EUC_EXT_GAIACUTOUT<br>1..1| pipeline\n+    gaia ==>|EUC_EXT_GAIACUTOUT<br>0..1| pipeline\n \n     pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..N| bgkmos\n     pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..2| detmos\n@@ -303,7 +303,7 @@ flowchart LR\n \n     tile ==> pipeline \n \n-    gaia ==>|EUC_EXT_GAIACUTOUT<br>1..1| pipeline\n+    gaia ==>|EUC_EXT_GAIACUTOUT<br>0..1| pipeline\n \n     pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..1| bgkmos\n     pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..1| detmos\n",
                            "Corrects ordinality of Gaia catalogs",
                            "Javier Gracia Carpio",
                            "2023-08-07T13:33:39.000+00:00",
                            "3c1c04dcadb4839218d3690f8fae49ccd0a5df4b"
                        ],
                        [
                            "@@ -51,6 +51,7 @@ flowchart LR\n     conf(DpdMerConfigurationSet)\n     flag(DpdMerDqcStaticFlagLimits)\n     tile(DpdMerTile)\n+    gaia(DpdExtGaiaCutout)\n \n     bgkmos(DpdMerBksMosaic)\n     detmos(DpdMerDetectionMosaic)\n@@ -84,6 +85,8 @@ flowchart LR\n \n     tile ==> pipeline \n \n+    gaia ==>|EUC_EXT_GAIACUTOUT<br>1..1| pipeline\n+\n     pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..N| bgkmos\n     pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..2| detmos\n     pipeline ==>|EUC_MER_FINAL-SEGMAP<br>1..1| seg\n@@ -102,13 +105,14 @@ flowchart LR\n   * `configuration_set`: List configuration files.\n   * `flag_limits`: Data Model flags.\n   * `mdb`: MDB Data Product.\n+  * `gaia_cutouts`: List of EXT Gaia cutout catalogs.\n \n * Output:\n-  * `all_mosaics`: Background-subtracted mosaics.\n-  * `vis_detection_mosaic`: Mosaic used to perform the object detection on VIS.\n-  * `nir_detection_mosaic`: Mosaic used to perform the object detection on NIR.\n-  * `final_segmentation_map`: Map showing the connected pixels of the objects detected on the corresponding detection mosaic.\n-  * `final_catalog`: Final merged catalog with photometric and morphological information.\n+  * `compressed_mosaics`: Background-subtracted mosaics.\n+  * `compressed_vis_detection_mosaic`: Mosaic used to perform the object detection on VIS.\n+  * `compressed_nir_detection_mosaic`: Mosaic used to perform the object detection on NIR.\n+  * `compressed_segmentation_map`: Map showing the connected pixels of the objects detected on the corresponding detection mosaic.\n+  * `compressed_catalog`: Final merged catalog with photometric and morphological information.\n   * `analysis_result`: Results of the quick analysis step.\n \n \n@@ -116,6 +120,7 @@ flowchart LR\n \n * `MER_ProcessTile` triggered at Tile scale.\n * `MER_ProcessTile` can run without EXT data.\n+* `MER_ProcessTile` can run without NIR data, but it needs a NIR calibrated frame that doesn't fall in the tile.\n \n | Scale(s) | Periodicity | Input DataProduct | Information for creating the pipeline definition |\n | -------| ----------- | ----------- |  --------------- |\n@@ -133,30 +138,31 @@ The \"Execution Context\" of the `MER_ProcessTile` is always:\n \n | Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n | ----------------------------- | ----- | --------------------------- | ----- | ------- | ------- | ------- |\n-| Initialize  | 10.0 | MER_Initializze | 1 | 1.0 | 0.3 | - |\n-| Mosaicing | 10.0 | MER_Mosaicing | 1 | 6.0 | 6.0 | 363.0 |\n-| Background | 10.0 | MER_Background | 1 | 8.0 | 4.0 | 96.6 |\n-| MosaicSelection | 10.0 | MER_MosaicSelection | 1 | 1.0 | 0.3 | - |\n-| VisDetection | 10.0 | MER_VisDetection | 1 | 20.0 | 6.0 | 1.4 |\n-| NirDetection | 10.0 | MER_NirDetection | 1 | 20.0 | 6.0 | 2.8 |\n-| Deblending_1 | 10.0 | MER_Deblending | 1 | 22.0 | 14.0 | 2.4 |\n-| Deblending_2 | 10.0 | MER_Deblending | 1 | 22.0 | 14.0 | 1.4 |\n-| Morphology | 10.0 | MER_Morphology | 1 | 10.0 | 2.0 | 2.5 |\n-| MBCombine | 10.0 | MER_MBCombine | 1 | 8.0 | 0.5 | - |\n-| CatalogPsfCalculation | 10.0 | MER_CatalogPsfCalculation | 1 | 6.0 | 4.0 | 173.0 |\n-| LowResPsfExtraction | 10.0 | MER_LowResPsfExtraction | 1 | 14.0 | 3.0 | - |\n-| NirCatalogMerging | 10.0 | MER_NirCatalogMerging | 1 | 1.0 | 0.3 | <1.0 |\n-| KernelAPhot | 10.0 | MER_KernelAPhot | 1 | 16.0 | 3.0 | 76.0 |\n-| KernelTPhot | 10.0 | MER_KernelTPhot | 1 | 12.0 | 3.0 | 76.0 |\n-| KernelAPhotNIRStack | 10.0 | MER_KernelAPhot | 1 | 16.0 | 3.0 | 5.0 |\n-| Photometry_FilterTransmission | 10.0 | MER_APhotTransmission | 1 | 10.0 | 1.0 | <1.0 |\n-| Photometry_Det | 10.0 | MER_APhotDetection | 1 | 12.0 | 1.0 | <1.0 |\n-| Photometry_A | 10.0 | MER_APhotCircular | 1 | 12.0 | 2.0 | <1.0 |\n-| Photometry_T | 10.0 | MER_TPhotProgram | 1 | 36.0 | 14.0 | 440.0 |\n-| Photometry_PsfFitting | 10.0 | MER_PsfFitting | 1 | 16.0 | 12.0 | 7.5 |\n-| Photometry_Morpho | 10.0 | MER_APhotMorphology | 1 | 12.0 | 2.0 | <1.0 |\n-| Catalog | 10.0 | MER_CatalogAssembly | 1 | 22.0 | 1.0 | 2.9 |\n-| QuickAnalysis | 10.0 | MER_QuickAnalysis | 1 | 2.0 | 1.0 | <1.0 |\n+| Initialize  | 10.1.0 | MER_Initializze | 1 | 1.0 | 0.3 | - |\n+| Mosaicing | 10.1.0 | MER_Mosaicing | 1 | 6.0 | 6.0 | 363.0 |\n+| Background | 10.1.0 | MER_Background | 1 | 8.0 | 4.0 | 96.6 |\n+| MosaicSelection | 10.1.0 | MER_MosaicSelection | 1 | 1.0 | 0.3 | - |\n+| VisDetection | 10.1.0 | MER_VisDetection | 1 | 20.0 | 6.0 | 1.4 |\n+| NirDetection | 10.1.0 | MER_NirDetection | 1 | 20.0 | 6.0 | 2.8 |\n+| Deblending_1 | 10.1.0 | MER_Deblending | 1 | 22.0 | 14.0 | 2.4 |\n+| Deblending_2 | 10.1.0 | MER_Deblending | 1 | 22.0 | 14.0 | 1.4 |\n+| Morphology | 10.1.0 | MER_Morphology | 1 | 10.0 | 2.0 | 2.5 |\n+| MBCombine | 10.1.0 | MER_MBCombine | 1 | 8.0 | 0.5 | - |\n+| CatalogPsfCalculation | 10.1.0 | MER_CatalogPsfCalculation | 1 | 6.0 | 4.0 | 173.0 |\n+| LowResPsfExtraction | 10.1.0 | MER_LowResPsfExtraction | 1 | 14.0 | 3.0 | - |\n+| NirCatalogMerging | 10.1.0 | MER_NirCatalogMerging | 1 | 1.0 | 0.3 | <1.0 |\n+| KernelAPhot | 10.1.0 | MER_KernelAPhot | 1 | 16.0 | 3.0 | 76.0 |\n+| KernelTPhot | 10.1.0 | MER_KernelTPhot | 1 | 12.0 | 3.0 | 76.0 |\n+| KernelAPhotNIRStack | 10.1.0 | MER_KernelAPhot | 1 | 16.0 | 3.0 | 5.0 |\n+| Photometry_FilterTransmission | 10.1.0 | MER_APhotTransmission | 1 | 10.0 | 1.0 | <1.0 |\n+| Photometry_Det | 10.1.0 | MER_APhotDetection | 1 | 12.0 | 1.0 | <1.0 |\n+| Photometry_A | 10.1.0 | MER_APhotCircular | 1 | 12.0 | 2.0 | <1.0 |\n+| Photometry_T | 10.1.0 | MER_TPhotProgram | 1 | 36.0 | 14.0 | 440.0 |\n+| Photometry_PsfFitting | 10.1.0 | MER_PsfFitting | 1 | 16.0 | 12.0 | 7.5 |\n+| Photometry_Morpho | 10.1.0 | MER_APhotMorphology | 1 | 12.0 | 2.0 | <1.0 |\n+| Catalog | 10.1.1 | MER_CatalogAssembly | 1 | 22.0 | 1.0 | 2.9 |\n+| QuickAnalysis | 10.1.0 | MER_QuickAnalysis | 1 | 2.0 | 1.0 | <1.0 |\n+| Compression | 10.1.0 | MER_Compression | 1 | 4.0 | 1.0 | <100.0 |\n \n ### Normal termination\n \n@@ -166,7 +172,6 @@ MER Pipeline is managed by the official EDEN pipeline runner. The standard outpu\n \n The runtime errors related to `MER_ProcessTile` are listed below:\n \n-\n | Software Executable | Message | Operator Instruction |\n | ---------------------- | ----------------------------- |  ----------------------------- |\n | All | Data product [product] does not belong to MER. | This error must be handled by the OU-MER development team. Open a Redmine \u201cbug\u201d issue.  |\n@@ -272,7 +277,9 @@ flowchart LR\n     conf(DpdMerConfigurationSet)\n     flag(DpdMerDqcStaticFlagLimits)\n     tile(DpdMerTile)\n+    gaia(DpdExtGaiaCutout)\n \n+    bgkmos(DpdMerBksMosaic)\n     detmos(DpdMerDetectionMosaic)\n     seg(DpdMerSegmentationMap)\n     cat(DpdMerFinalCatalog)\n@@ -296,6 +303,9 @@ flowchart LR\n \n     tile ==> pipeline \n \n+    gaia ==>|EUC_EXT_GAIACUTOUT<br>1..1| pipeline\n+\n+    pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..1| bgkmos\n     pipeline ==>|EUC_MER_BGSUB-MOSAIC<br>1..1| detmos\n     pipeline ==>|EUC_MER_FINAL-SEGMAP<br>1..1| seg\n     pipeline ==>|EUC_MER_FINAL-CAT<br>1..1| cat\n@@ -311,11 +321,13 @@ flowchart LR\n   * `configuration_set`: List configuration files.\n   * `flag_limits`: Data Model flags.\n   * `mdb`: MDB Data Product.\n+  * `gaia_cutouts`: List of EXT Gaia cutout catalogs.\n \n * Output:\n-  * `vis_detection_mosaic`: Mosaic used to perform the object detection on VIS.\n-  * `final_segmentation_map`: Map showing the connected pixels of the objects detected on the corresponding detection mosaic.\n-  * `final_catalog`: Final merged catalog with photometric and morphological information.\n+  * `compressed_vis_mosaic`: VIS background-subtracted mosaic.\n+  * `compressed_vis_detection_mosaic`: Mosaic used to perform the object detection on VIS.\n+  * `compressed_segmentation_map`: Map showing the connected pixels of the objects detected on the corresponding detection mosaic.\n+  * `compressed_catalog`: Final merged catalog with photometric and morphological information.\n   * `analysis_result`: Results of the quick analysis step.\n \n \n@@ -340,18 +352,19 @@ The \"Execution Context\" of the `MER_ProcessTileVisOnly` is always:\n \n | Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n | ----------------------------- | ----- | --------------------------- | ----- | ------- | ------- | ------- |\n-| Initialize  | 10.0 | MER_Initializze | 1 | 1.0 | 0.3 | - |\n-| Mosaicing | 10.0 | MER_Mosaicing | 1 | 6.0 | 6.0 | 68.2 |\n-| Background | 10.0 | MER_Background | 1 | 8.0 | 4.0 | 4.2 |\n-| VisDetection | 10.0 | MER_VisDetection | 1 | 20.0 | 6.0 | 1.4 |\n-| Deblending_1 | 10.0 | MER_Deblending | 1 | 22.0 | 14.0 | 2.4 |\n-| Morphology | 10.0 | MER_Morphology | 1 | 10.0 | 2.0 | 2.5 |\n-| CatalogPsfCalculation | 10.0 | MER_CatalogPsfCalculation | 1 | 6.0 | 4.0 | 88.0 |\n-| Photometry_Det | 10.0 | MER_APhotDetection | 1 | 12.0 | 1.0 | <1.0 |\n-| Photometry_PsfFitting | 10.0 | MER_PsfFitting | 1 | 16.0 | 12.0 | 7.5 |\n-| Photometry_Morpho | 10.0 | MER_APhotMorphology | 1 | 12.0 | 2.0 | <1.0 |\n-| Catalog | 10.0 | MER_CatalogAssembly | 1 | 22.0 | 1.0 | 2.9 |\n-| QuickAnalysis | 10.0 | MER_QuickAnalysis | 1 | 2.0 | 1.0 | <1.0 |\n+| Initialize  | 10.1.0 | MER_Initializze | 1 | 1.0 | 0.3 | - |\n+| Mosaicing | 10.1.0 | MER_Mosaicing | 1 | 6.0 | 6.0 | 68.2 |\n+| Background | 10.1.0 | MER_Background | 1 | 8.0 | 4.0 | 4.2 |\n+| VisDetection | 10.1.0 | MER_VisDetection | 1 | 20.0 | 6.0 | 1.4 |\n+| Deblending_1 | 10.1.0 | MER_Deblending | 1 | 22.0 | 14.0 | 2.4 |\n+| Morphology | 10.1.0 | MER_Morphology | 1 | 10.0 | 2.0 | 2.5 |\n+| CatalogPsfCalculation | 10.1.0 | MER_CatalogPsfCalculation | 1 | 6.0 | 4.0 | 88.0 |\n+| Photometry_Det | 10.1.0 | MER_APhotDetection | 1 | 12.0 | 1.0 | <1.0 |\n+| Photometry_PsfFitting | 10.1.0 | MER_PsfFitting | 1 | 16.0 | 12.0 | 7.5 |\n+| Photometry_Morpho | 10.1.0 | MER_APhotMorphology | 1 | 12.0 | 2.0 | <1.0 |\n+| Catalog | 10.1.1 | MER_CatalogAssembly | 1 | 22.0 | 1.0 | 2.9 |\n+| QuickAnalysis | 10.1.0 | MER_QuickAnalysis | 1 | 2.0 | 1.0 | <1.0 |\n+| Compression | 10.1.0 | MER_Compression | 1 | 4.0 | 1.0 | <100.0 |\n \n ### Normal termination\n \n",
                            "Updates the SUM",
                            "Javier Gracia Carpio",
                            "2023-08-07T13:24:00.000+00:00",
                            "fca8026919dd64c52dac3b0c920ffa0ba5cc04cc"
                        ],
                        [
                            "@@ -9,6 +9,9 @@ The group `WIDE` is made of the following pipelines:\n * Group `WIDE`:\n   * `MER_ProcessTile`\n   * `MER_ProcessTileVisOnly`\n+* Group `WIDE_ONTHEFLY`:\n+  * `MER_ProcessTile`\n+  * `MER_ProcessTileVisOnly`\n \n There is no dependency between the pipelines of the group `WIDE`.\n \n@@ -130,30 +133,30 @@ The \"Execution Context\" of the `MER_ProcessTile` is always:\n \n | Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n | ----------------------------- | ----- | --------------------------- | ----- | ------- | ------- | ------- |\n-| Initialize  | 9.0 | MER_Initializze | 1 | 1.0 | 0.3 | - |\n-| Mosaicing | 9.0 | MER_Mosaicing | 1 | 6.0 | 6.0 | 363.0 |\n-| Background | 9.0 | MER_Background | 1 | 8.0 | 4.0 | 96.6 |\n-| MosaicSelection | 9.0 | MER_MosaicSelection | 1 | 1.0 | 0.3 | - |\n-| VisDetection | 9.0 | MER_VisDetection | 1 | 20.0 | 6.0 | 1.4 |\n-| NirDetection | 9.0 | MER_NirDetection | 1 | 20.0 | 6.0 | 2.8 |\n-| Deblending_1 | 9.0 | MER_Deblending | 1 | 22.0 | 14.0 | 2.4 |\n-| Deblending_2 | 9.0 | MER_Deblending | 1 | 22.0 | 14.0 | 1.4 |\n-| Morphology | 9.0 | MER_Morphology | 1 | 10.0 | 2.0 | 2.5 |\n-| MBCombine | 9.0 | MER_MBCombine | 1 | 8.0 | 0.5 | - |\n-| CatalogPsfCalculation | 9.0 | MER_CatalogPsfCalculation | 1 | 6.0 | 4.0 | 173.0 |\n-| LowResPsfExtraction | 9.0 | MER_LowResPsfExtraction | 1 | 14.0 | 3.0 | - |\n-| NirCatalogMerging | 9.0 | MER_NirCatalogMerging | 1 | 1.0 | 0.3 | <1.0 |\n-| KernelAPhot | 9.0 | MER_KernelAPhot | 1 | 16.0 | 3.0 | 76.0 |\n-| KernelTPhot | 9.0 | MER_KernelTPhot | 1 | 12.0 | 3.0 | 76.0 |\n-| KernelAPhotNIRStack | 9.0 | MER_KernelAPhot | 1 | 16.0 | 3.0 | 5.0 |\n-| Photometry_FilterTransmission | 9.0 | MER_APhotTransmission | 1 | 10.0 | 1.0 | <1.0 |\n-| Photometry_Det | 9.0 | MER_APhotDetection | 1 | 12.0 | 1.0 | <1.0 |\n-| Photometry_A | 9.0 | MER_APhotCircular | 1 | 12.0 | 2.0 | <1.0 |\n-| Photometry_T | 9.0 | MER_TPhotProgram | 1 | 36.0 | 14.0 | 440.0 |\n-| Photometry_PsfFitting | 9.0 | MER_PsfFitting | 1 | 16.0 | 12.0 | 7.5 |\n-| Photometry_Morpho | 9.0 | MER_APhotMorphology | 1 | 12.0 | 2.0 | <1.0 |\n-| Catalog | 9.0 | MER_CatalogAssembly | 1 | 22.0 | 1.0 | 2.9 |\n-| QuickAnalysis | 9.0 | MER_QuickAnalysis | 1 | 2.0 | 1.0 | <1.0 |\n+| Initialize  | 10.0 | MER_Initializze | 1 | 1.0 | 0.3 | - |\n+| Mosaicing | 10.0 | MER_Mosaicing | 1 | 6.0 | 6.0 | 363.0 |\n+| Background | 10.0 | MER_Background | 1 | 8.0 | 4.0 | 96.6 |\n+| MosaicSelection | 10.0 | MER_MosaicSelection | 1 | 1.0 | 0.3 | - |\n+| VisDetection | 10.0 | MER_VisDetection | 1 | 20.0 | 6.0 | 1.4 |\n+| NirDetection | 10.0 | MER_NirDetection | 1 | 20.0 | 6.0 | 2.8 |\n+| Deblending_1 | 10.0 | MER_Deblending | 1 | 22.0 | 14.0 | 2.4 |\n+| Deblending_2 | 10.0 | MER_Deblending | 1 | 22.0 | 14.0 | 1.4 |\n+| Morphology | 10.0 | MER_Morphology | 1 | 10.0 | 2.0 | 2.5 |\n+| MBCombine | 10.0 | MER_MBCombine | 1 | 8.0 | 0.5 | - |\n+| CatalogPsfCalculation | 10.0 | MER_CatalogPsfCalculation | 1 | 6.0 | 4.0 | 173.0 |\n+| LowResPsfExtraction | 10.0 | MER_LowResPsfExtraction | 1 | 14.0 | 3.0 | - |\n+| NirCatalogMerging | 10.0 | MER_NirCatalogMerging | 1 | 1.0 | 0.3 | <1.0 |\n+| KernelAPhot | 10.0 | MER_KernelAPhot | 1 | 16.0 | 3.0 | 76.0 |\n+| KernelTPhot | 10.0 | MER_KernelTPhot | 1 | 12.0 | 3.0 | 76.0 |\n+| KernelAPhotNIRStack | 10.0 | MER_KernelAPhot | 1 | 16.0 | 3.0 | 5.0 |\n+| Photometry_FilterTransmission | 10.0 | MER_APhotTransmission | 1 | 10.0 | 1.0 | <1.0 |\n+| Photometry_Det | 10.0 | MER_APhotDetection | 1 | 12.0 | 1.0 | <1.0 |\n+| Photometry_A | 10.0 | MER_APhotCircular | 1 | 12.0 | 2.0 | <1.0 |\n+| Photometry_T | 10.0 | MER_TPhotProgram | 1 | 36.0 | 14.0 | 440.0 |\n+| Photometry_PsfFitting | 10.0 | MER_PsfFitting | 1 | 16.0 | 12.0 | 7.5 |\n+| Photometry_Morpho | 10.0 | MER_APhotMorphology | 1 | 12.0 | 2.0 | <1.0 |\n+| Catalog | 10.0 | MER_CatalogAssembly | 1 | 22.0 | 1.0 | 2.9 |\n+| QuickAnalysis | 10.0 | MER_QuickAnalysis | 1 | 2.0 | 1.0 | <1.0 |\n \n ### Normal termination\n \n@@ -337,18 +340,18 @@ The \"Execution Context\" of the `MER_ProcessTileVisOnly` is always:\n \n | Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n | ----------------------------- | ----- | --------------------------- | ----- | ------- | ------- | ------- |\n-| Initialize  | 9.0 | MER_Initializze | 1 | 1.0 | 0.3 | - |\n-| Mosaicing | 9.0 | MER_Mosaicing | 1 | 6.0 | 6.0 | 68.2 |\n-| Background | 9.0 | MER_Background | 1 | 8.0 | 4.0 | 4.2 |\n-| VisDetection | 9.0 | MER_VisDetection | 1 | 20.0 | 6.0 | 1.4 |\n-| Deblending_1 | 9.0 | MER_Deblending | 1 | 22.0 | 14.0 | 2.4 |\n-| Morphology | 9.0 | MER_Morphology | 1 | 10.0 | 2.0 | 2.5 |\n-| CatalogPsfCalculation | 9.0 | MER_CatalogPsfCalculation | 1 | 6.0 | 4.0 | 88.0 |\n-| Photometry_Det | 9.0 | MER_APhotDetection | 1 | 12.0 | 1.0 | <1.0 |\n-| Photometry_PsfFitting | 9.0 | MER_PsfFitting | 1 | 16.0 | 12.0 | 7.5 |\n-| Photometry_Morpho | 9.0 | MER_APhotMorphology | 1 | 12.0 | 2.0 | <1.0 |\n-| Catalog | 9.0 | MER_CatalogAssembly | 1 | 22.0 | 1.0 | 2.9 |\n-| QuickAnalysis | 9.0 | MER_QuickAnalysis | 1 | 2.0 | 1.0 | <1.0 |\n+| Initialize  | 10.0 | MER_Initializze | 1 | 1.0 | 0.3 | - |\n+| Mosaicing | 10.0 | MER_Mosaicing | 1 | 6.0 | 6.0 | 68.2 |\n+| Background | 10.0 | MER_Background | 1 | 8.0 | 4.0 | 4.2 |\n+| VisDetection | 10.0 | MER_VisDetection | 1 | 20.0 | 6.0 | 1.4 |\n+| Deblending_1 | 10.0 | MER_Deblending | 1 | 22.0 | 14.0 | 2.4 |\n+| Morphology | 10.0 | MER_Morphology | 1 | 10.0 | 2.0 | 2.5 |\n+| CatalogPsfCalculation | 10.0 | MER_CatalogPsfCalculation | 1 | 6.0 | 4.0 | 88.0 |\n+| Photometry_Det | 10.0 | MER_APhotDetection | 1 | 12.0 | 1.0 | <1.0 |\n+| Photometry_PsfFitting | 10.0 | MER_PsfFitting | 1 | 16.0 | 12.0 | 7.5 |\n+| Photometry_Morpho | 10.0 | MER_APhotMorphology | 1 | 12.0 | 2.0 | <1.0 |\n+| Catalog | 10.0 | MER_CatalogAssembly | 1 | 22.0 | 1.0 | 2.9 |\n+| QuickAnalysis | 10.0 | MER_QuickAnalysis | 1 | 2.0 | 1.0 | <1.0 |\n \n ### Normal termination\n \n",
                            "SUM update",
                            "Erik Romelli",
                            "2023-06-28T12:01:15.000+02:00",
                            "14e1cf60d97acdf4d0f5a0fce884848152ab2906"
                        ]
                    ],
                    "doc/user_manual/title.md": [
                        [
                            "@@ -6,7 +6,7 @@ body-includes: no\n |             | **Document Identification** |\n |-------------|--------------------------------------------------------------------------------------------------|\n |Title      | Software User Manual MER Pipeline |\n-|Date       |07-Aug-2023 |\n+|Date       |17-Aug-2023 |\n |Issue      |5.1 |\n |Reference: |EUCL-OTS-MA-8-001 |\n |Custodian: |Erik Romelli |\n",
                            "Adding docref and pfname to SUM version.md",
                            "Erik Romelli",
                            "2023-08-17T15:05:13.000+02:00",
                            "07acd0c0e62c07ec1e1292dd7c9d1840824b1384"
                        ],
                        [
                            "@@ -6,8 +6,8 @@ body-includes: no\n |             | **Document Identification** |\n |-------------|--------------------------------------------------------------------------------------------------|\n |Title      | Software User Manual MER Pipeline |\n-|Date       |28-Jun-2023 |\n-|Issue      |5.0 |\n+|Date       |07-Aug-2023 |\n+|Issue      |5.1 |\n |Reference: |EUCL-OTS-MA-8-001 |\n |Custodian: |Erik Romelli |\n \n@@ -56,5 +56,6 @@ body-includes: no\n  3.0 | 01/08/22 | all | GSRR release                     | Official GSRR release of the Software User Manual of the MER Pipeline |\n  4.0 | 29/08/22 | all | GSRR release                     | Porting to new Markdown template, as requested by the PA/QA team |\n  5.0 | 28/06/23 | all | PV release                       | Updating the document for the PV phase |\n+ 5.1 | 07/08/23 | all | PV release update                | Updates versions and new input ports |\n \n ![](images/dot.png) \\\n",
                            "Updates the SUM",
                            "Javier Gracia Carpio",
                            "2023-08-07T13:24:00.000+00:00",
                            "fca8026919dd64c52dac3b0c920ffa0ba5cc04cc"
                        ],
                        [
                            "@@ -6,8 +6,8 @@ body-includes: no\n |             | **Document Identification** |\n |-------------|--------------------------------------------------------------------------------------------------|\n |Title      | Software User Manual MER Pipeline |\n-|Date       |29-Aug-2022 |\n-|Issue      |4.0 |\n+|Date       |28-Jun-2023 |\n+|Issue      |5.0 |\n |Reference: |EUCL-OTS-MA-8-001 |\n |Custodian: |Erik Romelli |\n \n@@ -55,5 +55,6 @@ body-includes: no\n  2.1 | 29/10/20 | all | Update of SW packages versions after official SC8 CCB release | Official CCB release of the Software User Manual of the MER Pipeline for SC8 |\n  3.0 | 01/08/22 | all | GSRR release                     | Official GSRR release of the Software User Manual of the MER Pipeline |\n  4.0 | 29/08/22 | all | GSRR release                     | Porting to new Markdown template, as requested by the PA/QA team |\n+ 5.0 | 28/06/23 | all | PV release                       | Updating the document for the PV phase |\n \n ![](images/dot.png) \\\n",
                            "SUM update",
                            "Erik Romelli",
                            "2023-06-28T12:01:15.000+02:00",
                            "14e1cf60d97acdf4d0f5a0fce884848152ab2906"
                        ]
                    ],
                    "doc/user_manual/version.md": [
                        [
                            "@@ -1,4 +1,6 @@\n ---\n version: 5.1\n-versiondate: 07-Aug-2023\n+versiondate: 17-Aug-2023\n+docref: EUCL-OTS-MA-8-001\n+pfname: MER\n ---\n",
                            "Adding docref and pfname to SUM version.md",
                            "Erik Romelli",
                            "2023-08-17T15:05:13.000+02:00",
                            "07acd0c0e62c07ec1e1292dd7c9d1840824b1384"
                        ],
                        [
                            "@@ -1,4 +1,4 @@\n ---\n-version: 5.0\n-versiondate: 28-Jun-2023\n+version: 5.1\n+versiondate: 07-Aug-2023\n ---\n",
                            "Updates the SUM",
                            "Javier Gracia Carpio",
                            "2023-08-07T13:24:00.000+00:00",
                            "fca8026919dd64c52dac3b0c920ffa0ba5cc04cc"
                        ],
                        [
                            "@@ -1,4 +1,4 @@\n ---\n-version: 4.0\n-versiondate: 29-Aug-2022\n+version: 5.0\n+versiondate: 28-Jun-2023\n ---\n",
                            "SUM update",
                            "Erik Romelli",
                            "2023-06-28T12:01:15.000+02:00",
                            "14e1cf60d97acdf4d0f5a0fce884848152ab2906"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_ProcessTile_Pipeline/PipScript_MER_ProcessTile.py": [
                        [
                            "@@ -181,9 +181,7 @@ def mer_pipeline(tile, vis_calibrated_frames, nir_calibrated_frames, ext_stacks,\n     vis_detection_mosaic, vis_segmentation_map, vis_object_catalog = MER_VisDetection(\n         mosaic=vis_bks_mosaic,\n         configuration=configuration_set,\n-        flag_limits=flag_limits,\n-        nir_mosaics=nir_bks_mosaics,\n-        ext_mosaics=ext_mosaics\n+        flag_limits=flag_limits\n     )\n \n     vis_deblended_segmentation_map, vis_deblended_catalog, vis_toaphot_catalog = MER_Deblending(\n@@ -198,9 +196,7 @@ def mer_pipeline(tile, vis_calibrated_frames, nir_calibrated_frames, ext_stacks,\n         nir_mosaics=nir_bks_mosaics,\n         tile=tile,\n         configuration=configuration_set,\n-        flag_limits=flag_limits,\n-        vis_mosaic=vis_bks_mosaic,\n-        ext_mosaics=ext_mosaics\n+        flag_limits=flag_limits\n     )\n \n     nir_deblended_segmentation_map, nir_deblended_catalog, nir_toaphot_catalog = MER_Deblending(\n",
                            "Merge branch 'feature/slim_detection' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T14:07:39.000+00:00",
                            "83523e87084abc2c20a56604754a0f138bbe0467"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_ProcessTile_Pipeline/PkgDef_MER_ProcessTile.py": [
                        [
                            "@@ -62,9 +62,7 @@ MER_Background = Executable(command=\"E-Run MER_Background 10.2 MER_BackgroundPrg\n MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.2 MER_VisDetectionPrg\",\n                               inputs=[Input(\"mosaic\"),\n                                       Input(\"configuration\"),\n-                                      Input(\"flag_limits\"),\n-                                      Input(\"nir_mosaics\", content_type=\"listfile\"),\n-                                      Input(\"ext_mosaics\", content_type=\"listfile\")],\n+                                      Input(\"flag_limits\")],\n                               outputs=[Output(\"detection_mosaic\", mime_type=\"xml\"),\n                                        Output(\"segmentation_map\", mime_type=\"xml\"),\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n@@ -74,9 +72,7 @@ MER_NirDetection = Executable(command=\"E-Run MER_Detection 10.2 MER_NirDetection\n                               inputs=[Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                       Input(\"tile\"),\n                                       Input(\"configuration\"),\n-                                      Input(\"flag_limits\"),\n-                                      Input(\"vis_mosaic\"),\n-                                      Input(\"ext_mosaics\", content_type=\"listfile\")],\n+                                      Input(\"flag_limits\")],\n                               outputs=[Output(\"detection_mosaic\", mime_type=\"xml\"),\n                                        Output(\"segmentation_map\", mime_type=\"xml\"),\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n",
                            "Merge branch 'feature/slim_detection' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T14:07:39.000+00:00",
                            "83523e87084abc2c20a56604754a0f138bbe0467"
                        ],
                        [
                            "@@ -56,9 +56,7 @@ MER_Background = Executable(command=\"E-Run MER_Background 10.2 MER_BackgroundPrg\n MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.2 MER_VisDetectionPrg\",\n                               inputs=[Input(\"mosaic\"),\n                                       Input(\"configuration\"),\n-                                      Input(\"flag_limits\"),\n-                                      Input(\"nir_mosaics\", content_type=\"listfile\"),\n-                                      Input(\"ext_mosaics\", content_type=\"listfile\")],\n+                                      Input(\"flag_limits\")],\n                               outputs=[Output(\"detection_mosaic\", mime_type=\"xml\"),\n                                        Output(\"segmentation_map\", mime_type=\"xml\"),\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n@@ -68,9 +66,7 @@ MER_NirDetection = Executable(command=\"E-Run MER_Detection 10.2 MER_NirDetection\n                               inputs=[Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                       Input(\"tile\"),\n                                       Input(\"configuration\"),\n-                                      Input(\"flag_limits\"),\n-                                      Input(\"vis_mosaic\"),\n-                                      Input(\"ext_mosaics\", content_type=\"listfile\")],\n+                                      Input(\"flag_limits\")],\n                               outputs=[Output(\"detection_mosaic\", mime_type=\"xml\"),\n                                        Output(\"segmentation_map\", mime_type=\"xml\"),\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n",
                            "Detection now *without* the model fitting interface.",
                            "Martin Kuemmel",
                            "2023-08-16T15:59:45.000+02:00",
                            "27cff94a74e37a58c7ac2be5e9d40888e25fb37d"
                        ],
                        [
                            "@@ -25,7 +25,13 @@ from euclidwf.framework.taskdefs import (Executable, Input, Output,\n \n \n ENV_VARIABLES = {\n-    \"MPLCONFIGDIR\": \"/dev/null\"\n+    \"MPLCONFIGDIR\": \"/dev/null\",\n+    \"MKL_NUM_THREADS\": \"1\",\n+    \"NUMEXPR_NUM_THREADS\": \"1\",\n+    \"OMP_NUM_THREADS\": \"1\",\n+    \"OPENBLAS_NUM_THREADS\": \"1\", \n+    \"VECLIB_MAXIMUM_THREADS\": \"1\", \n+    \"NTHREADS\":  \"1\" \n }\n \n MER_Initialize = Executable(command=\"E-Run MER_Pipeline 10.2 MER_Initialize\",\n",
                            "Pass the same environment variables in all package defs",
                            "Javier Gracia Carpio",
                            "2023-08-16T13:20:46.000+00:00",
                            "09023779349a879cd1ad6aa851e1d12e5edea37e"
                        ],
                        [
                            "@@ -28,7 +28,7 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n-MER_Initialize = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Initialize\",\n+MER_Initialize = Executable(command=\"E-Run MER_Pipeline 10.2 MER_Initialize\",\n                             inputs=[Input(\"vis_calibrated_frames\", content_type=\"listfile\"),\n                                     Input(\"nir_calibrated_frames\", content_type=\"listfile\"),\n                                     Input(\"ext_stacks\", content_type=\"listfile\")],\n@@ -37,7 +37,7 @@ MER_Initialize = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Initialize\",\n                                      Output(\"ext_image_lists\", content_type=\"listfile\", mime_type=\"json\")],\n                             resources=ComputingResources(cores=1, ram=1.0, walltime=0.3))\n \n-MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Mosaicing\",\n+MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.2 MER_Mosaicing\",\n                            inputs=[Input(\"image_list\", content_type=\"listfile\"),\n                                    Input(\"tile\"),\n                                    Input(\"configuration\"),\n@@ -46,14 +46,14 @@ MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Mosaicing\",\n                            outputs=[Output(\"mosaic\", mime_type=\"xml\")],\n                            resources=ComputingResources(cores=2, ram=6.0, walltime=6.0, tmpsize=999))\n \n-MER_Background = Executable(command=\"E-Run MER_Background 10.1 MER_BackgroundPrg\",\n+MER_Background = Executable(command=\"E-Run MER_Background 10.2 MER_BackgroundPrg\",\n                             inputs=[Input(\"mosaic\"),\n                                     Input(\"configuration\"),\n                                     Input(\"flag_limits\")],\n                             outputs=[Output(\"background_subtracted_mosaic\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=8.0, walltime=4.0))\n \n-MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.1 MER_VisDetectionPrg\",\n+MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.2 MER_VisDetectionPrg\",\n                               inputs=[Input(\"mosaic\"),\n                                       Input(\"configuration\"),\n                                       Input(\"flag_limits\"),\n@@ -64,7 +64,7 @@ MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.1 MER_VisDetection\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=4, ram=20.0, walltime=6.0))\n \n-MER_NirDetection = Executable(command=\"E-Run MER_Detection 10.1 MER_NirDetectionPrg\",\n+MER_NirDetection = Executable(command=\"E-Run MER_Detection 10.2 MER_NirDetectionPrg\",\n                               inputs=[Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                       Input(\"tile\"),\n                                       Input(\"configuration\"),\n@@ -76,7 +76,7 @@ MER_NirDetection = Executable(command=\"E-Run MER_Detection 10.1 MER_NirDetection\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=4, ram=20.0, walltime=6.0))\n \n-MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.1 MER_Deblending\",\n+MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.2 MER_Deblending\",\n                             inputs=[Input(\"input_mosaic\"),\n                                     Input(\"detection_segmap\"),\n                                     Input(\"configuration\"),\n@@ -86,7 +86,7 @@ MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.1 MER_Deblending\",\n                                      Output(\"to_aphot_catalog\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=22.0, walltime=14.0))\n \n-MER_MBCombine = Executable(command=\"E-Run MER_Detection 10.1 MER_MBCombinePrg\",\n+MER_MBCombine = Executable(command=\"E-Run MER_Detection 10.2 MER_MBCombinePrg\",\n                            inputs=[Input(\"visSegmentMap\"),\n                                    Input(\"visDetectionCatalog\"),\n                                    Input(\"nirSegmentMap\"),\n@@ -98,7 +98,7 @@ MER_MBCombine = Executable(command=\"E-Run MER_Detection 10.1 MER_MBCombinePrg\",\n                                     Output(\"combinedDetectionCat\", mime_type=\"xml\")],\n                            resources=ComputingResources(cores=1, ram=8.0, walltime=0.5))\n \n-MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.1 MER_CatalogPsfCalculation\",\n+MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.2 MER_CatalogPsfCalculation\",\n                            inputs=[Input(\"image_list\", content_type=\"listfile\"),\n                                    Input(\"mosaic\"),\n                                    Input(\"catalog\"),\n@@ -107,20 +107,20 @@ MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Cata\n                            outputs=[Output(\"output_mosaic\", mime_type=\"xml\")],\n                            resources=ComputingResources(cores=2, ram=6.0, walltime=4.0, tmpsize=999))\n \n-MER_PsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.1 MER_PsfExtraction\",\n+MER_PsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.2 MER_PsfExtraction\",\n                                inputs=[Input(\"mosaic\"),\n                                        Input(\"catalog\")],\n                                outputs=[Output(\"psf_stamp_collection\", mime_type=\"xml\")],\n                                resources=ComputingResources(cores=1, ram=3.0, walltime=1.0))\n \n-MER_LowResPsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.1 MER_LowResPsfExtraction\",\n+MER_LowResPsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.2 MER_LowResPsfExtraction\",\n                                      inputs=[Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                              Input(\"ext_mosaics\", content_type=\"listfile\"),\n                                              Input(\"catalog\")],\n                                      outputs=[Output(\"psf_stamp_collection\", mime_type=\"xml\")],\n                                      resources=ComputingResources(cores=1, ram=14.0, walltime=3.0))\n \n-MER_MosaicSelection = Executable(command=\"E-Run MER_Pipeline 10.1 MER_MosaicSelection\",\n+MER_MosaicSelection = Executable(command=\"E-Run MER_Pipeline 10.2 MER_MosaicSelection\",\n                                  inputs=[Input(\"vis_mosaic\"),\n                                          Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                          Input(\"ext_mosaics\", content_type=\"listfile\")],\n@@ -128,7 +128,7 @@ MER_MosaicSelection = Executable(command=\"E-Run MER_Pipeline 10.1 MER_MosaicSele\n                                           Output(\"nir_and_ext_mosaics\", content_type=\"listfile\", mime_type=\"json\")],\n                                  resources=ComputingResources(cores=1, ram=1.0, walltime=0.3))\n \n-MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.1 MER_Morphology\",\n+MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.2 MER_Morphology\",\n                             inputs=[Input(\"input_mosaic\"),\n                                     Input(\"input_segmap\"),\n                                     Input(\"input_catalog\"),\n@@ -136,19 +136,19 @@ MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.1 MER_Morphology\",\n                             outputs=[Output(\"morph_catalog\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=10.0, walltime=2.0))\n \n-MER_NirCatalogMerging = Executable(command=\"E-Run MER_Pipeline 10.1 MER_NirCatalogMerging\",\n+MER_NirCatalogMerging = Executable(command=\"E-Run MER_Pipeline 10.2 MER_NirCatalogMerging\",\n                                    inputs=[Input(\"catalogs\", content_type=\"listfile\")],\n                                    outputs=[Output(\"nir_merged_catalog\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=1.0, walltime=0.3))\n \n-MER_KernelAPhot = Executable(command=\"E-Run MER_Pipeline 10.1 MER_KernelAPhot\",\n+MER_KernelAPhot = Executable(command=\"E-Run MER_Pipeline 10.2 MER_KernelAPhot\",\n                              inputs=[Input(\"mosaic_input\"),\n                                      Input(\"low_resolution_psf\"),\n                                      Input(\"catalog\")],\n                              outputs=[Output(\"transformation_kernel\", mime_type=\"xml\")],\n                              resources=ComputingResources(cores=1, ram=16.0, walltime=3.0))\n \n-MER_KernelAPhotNIRStack = Executable(command=\"E-Run MER_Pipeline 10.1 MER_KernelAPhotNIRStack\",\n+MER_KernelAPhotNIRStack = Executable(command=\"E-Run MER_Pipeline 10.2 MER_KernelAPhotNIRStack\",\n                                      inputs=[Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                              Input(\"low_resolution_psf\"),\n                                              Input(\"catalog\"),\n@@ -156,7 +156,7 @@ MER_KernelAPhotNIRStack = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Kernel\n                                      outputs=[Output(\"transformation_kernel\", mime_type=\"xml\")],\n                                      resources=ComputingResources(cores=1, ram=16.0, walltime=3.0))\n \n-MER_KernelTPhot = Executable(command=\"E-Run MER_Pipeline 10.1 MER_KernelTPhot\",\n+MER_KernelTPhot = Executable(command=\"E-Run MER_Pipeline 10.2 MER_KernelTPhot\",\n                              inputs=[Input(\"vis_mosaic\"),\n                                      Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                      Input(\"mosaic_target\"),\n@@ -165,7 +165,7 @@ MER_KernelTPhot = Executable(command=\"E-Run MER_Pipeline 10.1 MER_KernelTPhot\",\n                              outputs=[Output(\"transformation_kernel\", mime_type=\"xml\")],\n                              resources=ComputingResources(cores=1, ram=12.0, walltime=3.0))\n \n-MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotMorphology\",\n+MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.2 MER_APhotMorphology\",\n                                    inputs=[Input(\"configuration\"),\n                                            Input(\"input_image\"),\n                                            Input(\"input_catalog\"),\n@@ -173,7 +173,7 @@ MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotM\n                                    outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=10.0, walltime=1.0))\n \n-MER_Photometry_FilterTransmission = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotTrasmission\",\n+MER_Photometry_FilterTransmission = Executable(command=\"E-Run MER_Photometry 10.2 MER_APhotTrasmission\",\n                                                inputs=[Input(\"input_image\"),\n                                                        Input(\"configuration\"),\n                                                        Input(\"input_catalog\"),\n@@ -181,7 +181,7 @@ MER_Photometry_FilterTransmission = Executable(command=\"E-Run MER_Photometry 10.\n                                                outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                                resources=ComputingResources(cores=1, ram=10.0, walltime=1.0))\n \n-MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotDetection\",\n+MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.2 MER_APhotDetection\",\n                                 inputs=[Input(\"configuration\"),\n                                         Input(\"input_image\"),\n                                         Input(\"nir_input_image\"),\n@@ -192,7 +192,7 @@ MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotDete\n                                 outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                 resources=ComputingResources(cores=1, ram=12.0, walltime=1.0))\n \n-MER_Photometry_A = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotCircular\",\n+MER_Photometry_A = Executable(command=\"E-Run MER_Photometry 10.2 MER_APhotCircular\",\n                               inputs=[Input(\"configuration\"),\n                                       Input(\"input_image\"),\n                                       Input(\"input_catalog\"),\n@@ -201,7 +201,7 @@ MER_Photometry_A = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotCircul\n                               outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=1, ram=12.0, walltime=2.0))\n \n-MER_Photometry_T = Executable(command=\"E-Run MER_Photometry 10.1 MER_TPhotProgram\",\n+MER_Photometry_T = Executable(command=\"E-Run MER_Photometry 10.2 MER_TPhotProgram\",\n                               inputs=[Input(\"configuration\"),\n                                       Input(\"vis_image\"),\n                                       Input(\"nir_image\"),\n@@ -214,7 +214,7 @@ MER_Photometry_T = Executable(command=\"E-Run MER_Photometry 10.1 MER_TPhotProgra\n                                        Output(\"stats_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=1, ram=36.0, walltime=14.0))\n \n-MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.1 MER_PsfFitting\",\n+MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.2 MER_PsfFitting\",\n                                        inputs=[Input(\"configuration\"),\n                                                Input(\"vis_image\"),\n                                                Input(\"input_catalog\"),\n@@ -223,7 +223,7 @@ MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.1 MER_Ps\n                                        outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                        resources=ComputingResources(cores=1, ram=16.0, walltime=12.0))\n \n-MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.1 MER_CatalogAssembly\",\n+MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.2 MER_CatalogAssembly\",\n                          inputs=[Input(\"vis_mosaic\"),\n                                  Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                  Input(\"gaia_cutouts\", content_type=\"listfile\"),\n@@ -246,13 +246,13 @@ MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.1 MER_CatalogAsse\n                                   Output(\"final_segmap\", mime_type=\"xml\")],\n                          resources=ComputingResources(cores=1, ram=22.0, walltime=1.0))\n \n-MER_QuickAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_QuickAnalysis\",\n+MER_QuickAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_QuickAnalysis\",\n                                inputs=[Input(\"final_catalog\")],\n                                outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                resources=ComputingResources(cores=1, ram=2.0, walltime=1.0),\n                                env_variables=ENV_VARIABLES)\n \n-MER_Compression = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Compression\",\n+MER_Compression = Executable(command=\"E-Run MER_Pipeline 10.2 MER_Compression\",\n                          inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                  Input(\"vis_detection_mosaic\"),\n                                  Input(\"nir_detection_mosaic\"),\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -28,7 +28,7 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n-MER_Initialize = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Initialize\",\n+MER_Initialize = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Initialize\",\n                             inputs=[Input(\"vis_calibrated_frames\", content_type=\"listfile\"),\n                                     Input(\"nir_calibrated_frames\", content_type=\"listfile\"),\n                                     Input(\"ext_stacks\", content_type=\"listfile\")],\n@@ -37,7 +37,7 @@ MER_Initialize = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Initialize\",\n                                      Output(\"ext_image_lists\", content_type=\"listfile\", mime_type=\"json\")],\n                             resources=ComputingResources(cores=1, ram=1.0, walltime=0.3))\n \n-MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Mosaicing\",\n+MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Mosaicing\",\n                            inputs=[Input(\"image_list\", content_type=\"listfile\"),\n                                    Input(\"tile\"),\n                                    Input(\"configuration\"),\n@@ -46,14 +46,14 @@ MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Mosaicing\",\n                            outputs=[Output(\"mosaic\", mime_type=\"xml\")],\n                            resources=ComputingResources(cores=2, ram=6.0, walltime=6.0, tmpsize=999))\n \n-MER_Background = Executable(command=\"E-Run MER_Background 10.0 MER_BackgroundPrg\",\n+MER_Background = Executable(command=\"E-Run MER_Background 10.1 MER_BackgroundPrg\",\n                             inputs=[Input(\"mosaic\"),\n                                     Input(\"configuration\"),\n                                     Input(\"flag_limits\")],\n                             outputs=[Output(\"background_subtracted_mosaic\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=8.0, walltime=4.0))\n \n-MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.0 MER_VisDetectionPrg\",\n+MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.1 MER_VisDetectionPrg\",\n                               inputs=[Input(\"mosaic\"),\n                                       Input(\"configuration\"),\n                                       Input(\"flag_limits\"),\n@@ -64,7 +64,7 @@ MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.0 MER_VisDetection\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=4, ram=20.0, walltime=6.0))\n \n-MER_NirDetection = Executable(command=\"E-Run MER_Detection 10.0 MER_NirDetectionPrg\",\n+MER_NirDetection = Executable(command=\"E-Run MER_Detection 10.1 MER_NirDetectionPrg\",\n                               inputs=[Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                       Input(\"tile\"),\n                                       Input(\"configuration\"),\n@@ -76,7 +76,7 @@ MER_NirDetection = Executable(command=\"E-Run MER_Detection 10.0 MER_NirDetection\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=4, ram=20.0, walltime=6.0))\n \n-MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.0 MER_Deblending\",\n+MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.1 MER_Deblending\",\n                             inputs=[Input(\"input_mosaic\"),\n                                     Input(\"detection_segmap\"),\n                                     Input(\"configuration\"),\n@@ -86,7 +86,7 @@ MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.0 MER_Deblending\",\n                                      Output(\"to_aphot_catalog\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=22.0, walltime=14.0))\n \n-MER_MBCombine = Executable(command=\"E-Run MER_Detection 10.0 MER_MBCombinePrg\",\n+MER_MBCombine = Executable(command=\"E-Run MER_Detection 10.1 MER_MBCombinePrg\",\n                            inputs=[Input(\"visSegmentMap\"),\n                                    Input(\"visDetectionCatalog\"),\n                                    Input(\"nirSegmentMap\"),\n@@ -98,7 +98,7 @@ MER_MBCombine = Executable(command=\"E-Run MER_Detection 10.0 MER_MBCombinePrg\",\n                                     Output(\"combinedDetectionCat\", mime_type=\"xml\")],\n                            resources=ComputingResources(cores=1, ram=8.0, walltime=0.5))\n \n-MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.0 MER_CatalogPsfCalculation\",\n+MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.1 MER_CatalogPsfCalculation\",\n                            inputs=[Input(\"image_list\", content_type=\"listfile\"),\n                                    Input(\"mosaic\"),\n                                    Input(\"catalog\"),\n@@ -107,20 +107,20 @@ MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Cata\n                            outputs=[Output(\"output_mosaic\", mime_type=\"xml\")],\n                            resources=ComputingResources(cores=2, ram=6.0, walltime=4.0, tmpsize=999))\n \n-MER_PsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.0 MER_PsfExtraction\",\n+MER_PsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.1 MER_PsfExtraction\",\n                                inputs=[Input(\"mosaic\"),\n                                        Input(\"catalog\")],\n                                outputs=[Output(\"psf_stamp_collection\", mime_type=\"xml\")],\n                                resources=ComputingResources(cores=1, ram=3.0, walltime=1.0))\n \n-MER_LowResPsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.0 MER_LowResPsfExtraction\",\n+MER_LowResPsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.1 MER_LowResPsfExtraction\",\n                                      inputs=[Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                              Input(\"ext_mosaics\", content_type=\"listfile\"),\n                                              Input(\"catalog\")],\n                                      outputs=[Output(\"psf_stamp_collection\", mime_type=\"xml\")],\n                                      resources=ComputingResources(cores=1, ram=14.0, walltime=3.0))\n \n-MER_MosaicSelection = Executable(command=\"E-Run MER_Pipeline 10.0 MER_MosaicSelection\",\n+MER_MosaicSelection = Executable(command=\"E-Run MER_Pipeline 10.1 MER_MosaicSelection\",\n                                  inputs=[Input(\"vis_mosaic\"),\n                                          Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                          Input(\"ext_mosaics\", content_type=\"listfile\")],\n@@ -128,7 +128,7 @@ MER_MosaicSelection = Executable(command=\"E-Run MER_Pipeline 10.0 MER_MosaicSele\n                                           Output(\"nir_and_ext_mosaics\", content_type=\"listfile\", mime_type=\"json\")],\n                                  resources=ComputingResources(cores=1, ram=1.0, walltime=0.3))\n \n-MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.0 MER_Morphology\",\n+MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.1 MER_Morphology\",\n                             inputs=[Input(\"input_mosaic\"),\n                                     Input(\"input_segmap\"),\n                                     Input(\"input_catalog\"),\n@@ -136,19 +136,19 @@ MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.0 MER_Morphology\",\n                             outputs=[Output(\"morph_catalog\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=10.0, walltime=2.0))\n \n-MER_NirCatalogMerging = Executable(command=\"E-Run MER_Pipeline 10.0 MER_NirCatalogMerging\",\n+MER_NirCatalogMerging = Executable(command=\"E-Run MER_Pipeline 10.1 MER_NirCatalogMerging\",\n                                    inputs=[Input(\"catalogs\", content_type=\"listfile\")],\n                                    outputs=[Output(\"nir_merged_catalog\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=1.0, walltime=0.3))\n \n-MER_KernelAPhot = Executable(command=\"E-Run MER_Pipeline 10.0 MER_KernelAPhot\",\n+MER_KernelAPhot = Executable(command=\"E-Run MER_Pipeline 10.1 MER_KernelAPhot\",\n                              inputs=[Input(\"mosaic_input\"),\n                                      Input(\"low_resolution_psf\"),\n                                      Input(\"catalog\")],\n                              outputs=[Output(\"transformation_kernel\", mime_type=\"xml\")],\n                              resources=ComputingResources(cores=1, ram=16.0, walltime=3.0))\n \n-MER_KernelAPhotNIRStack = Executable(command=\"E-Run MER_Pipeline 10.0 MER_KernelAPhotNIRStack\",\n+MER_KernelAPhotNIRStack = Executable(command=\"E-Run MER_Pipeline 10.1 MER_KernelAPhotNIRStack\",\n                                      inputs=[Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                              Input(\"low_resolution_psf\"),\n                                              Input(\"catalog\"),\n@@ -156,7 +156,7 @@ MER_KernelAPhotNIRStack = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Kernel\n                                      outputs=[Output(\"transformation_kernel\", mime_type=\"xml\")],\n                                      resources=ComputingResources(cores=1, ram=16.0, walltime=3.0))\n \n-MER_KernelTPhot = Executable(command=\"E-Run MER_Pipeline 10.0 MER_KernelTPhot\",\n+MER_KernelTPhot = Executable(command=\"E-Run MER_Pipeline 10.1 MER_KernelTPhot\",\n                              inputs=[Input(\"vis_mosaic\"),\n                                      Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                      Input(\"mosaic_target\"),\n@@ -165,7 +165,7 @@ MER_KernelTPhot = Executable(command=\"E-Run MER_Pipeline 10.0 MER_KernelTPhot\",\n                              outputs=[Output(\"transformation_kernel\", mime_type=\"xml\")],\n                              resources=ComputingResources(cores=1, ram=12.0, walltime=3.0))\n \n-MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotMorphology\",\n+MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotMorphology\",\n                                    inputs=[Input(\"configuration\"),\n                                            Input(\"input_image\"),\n                                            Input(\"input_catalog\"),\n@@ -173,7 +173,7 @@ MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotM\n                                    outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=10.0, walltime=1.0))\n \n-MER_Photometry_FilterTransmission = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotTrasmission\",\n+MER_Photometry_FilterTransmission = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotTrasmission\",\n                                                inputs=[Input(\"input_image\"),\n                                                        Input(\"configuration\"),\n                                                        Input(\"input_catalog\"),\n@@ -181,7 +181,7 @@ MER_Photometry_FilterTransmission = Executable(command=\"E-Run MER_Photometry 10.\n                                                outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                                resources=ComputingResources(cores=1, ram=10.0, walltime=1.0))\n \n-MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotDetection\",\n+MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotDetection\",\n                                 inputs=[Input(\"configuration\"),\n                                         Input(\"input_image\"),\n                                         Input(\"nir_input_image\"),\n@@ -192,7 +192,7 @@ MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotDete\n                                 outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                 resources=ComputingResources(cores=1, ram=12.0, walltime=1.0))\n \n-MER_Photometry_A = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotCircular\",\n+MER_Photometry_A = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotCircular\",\n                               inputs=[Input(\"configuration\"),\n                                       Input(\"input_image\"),\n                                       Input(\"input_catalog\"),\n@@ -201,7 +201,7 @@ MER_Photometry_A = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotCircul\n                               outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=1, ram=12.0, walltime=2.0))\n \n-MER_Photometry_T = Executable(command=\"E-Run MER_Photometry 10.0 MER_TPhotProgram\",\n+MER_Photometry_T = Executable(command=\"E-Run MER_Photometry 10.1 MER_TPhotProgram\",\n                               inputs=[Input(\"configuration\"),\n                                       Input(\"vis_image\"),\n                                       Input(\"nir_image\"),\n@@ -214,7 +214,7 @@ MER_Photometry_T = Executable(command=\"E-Run MER_Photometry 10.0 MER_TPhotProgra\n                                        Output(\"stats_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=1, ram=36.0, walltime=14.0))\n \n-MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.0 MER_PsfFitting\",\n+MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.1 MER_PsfFitting\",\n                                        inputs=[Input(\"configuration\"),\n                                                Input(\"vis_image\"),\n                                                Input(\"input_catalog\"),\n@@ -223,7 +223,7 @@ MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.0 MER_Ps\n                                        outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                        resources=ComputingResources(cores=1, ram=16.0, walltime=12.0))\n \n-MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.0 MER_CatalogAssembly\",\n+MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.1 MER_CatalogAssembly\",\n                          inputs=[Input(\"vis_mosaic\"),\n                                  Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                  Input(\"gaia_cutouts\", content_type=\"listfile\"),\n@@ -246,13 +246,13 @@ MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.0 MER_CatalogAsse\n                                   Output(\"final_segmap\", mime_type=\"xml\")],\n                          resources=ComputingResources(cores=1, ram=22.0, walltime=1.0))\n \n-MER_QuickAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_QuickAnalysis\",\n+MER_QuickAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_QuickAnalysis\",\n                                inputs=[Input(\"final_catalog\")],\n                                outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                resources=ComputingResources(cores=1, ram=2.0, walltime=1.0),\n                                env_variables=ENV_VARIABLES)\n \n-MER_Compression = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Compression\",\n+MER_Compression = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Compression\",\n                          inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                  Input(\"vis_detection_mosaic\"),\n                                  Input(\"nir_detection_mosaic\"),\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_AnalyseTile_Pipeline/PkgDef_MER_AnalyseTile.py": [
                        [
                            "@@ -26,7 +26,13 @@ from euclidwf.framework.taskdefs import (Executable, Input, Output,\n \n \n ENV_VARIABLES = {\n-    \"MPLCONFIGDIR\": \"/dev/null\"\n+    \"MPLCONFIGDIR\": \"/dev/null\",\n+    \"MKL_NUM_THREADS\": \"1\",\n+    \"NUMEXPR_NUM_THREADS\": \"1\",\n+    \"OMP_NUM_THREADS\": \"1\",\n+    \"OPENBLAS_NUM_THREADS\": \"1\", \n+    \"VECLIB_MAXIMUM_THREADS\": \"1\", \n+    \"NTHREADS\":  \"1\" \n }\n \n MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_MosaicingValidation\",\n",
                            "Pass the same environment variables in all package defs",
                            "Javier Gracia Carpio",
                            "2023-08-16T13:20:46.000+00:00",
                            "09023779349a879cd1ad6aa851e1d12e5edea37e"
                        ],
                        [
                            "@@ -29,34 +29,34 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n-MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MosaicingValidation\",\n+MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_MosaicingValidation\",\n                                    inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                            Input(\"segmap\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=16.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_PsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PsfAnalysis\",\n+MER_PsfAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_PsfAnalysis\",\n                              inputs=[Input(\"mosaics\", content_type=\"listfile\")],\n                              outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                              resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                              env_variables=ENV_VARIABLES)\n \n-MER_MerStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MerStarPsfAnalysis\",\n+MER_MerStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_MerStarPsfAnalysis\",\n                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                             Input(\"final_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_TuStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_TuStarPsfAnalysis\",\n+MER_TuStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_TuStarPsfAnalysis\",\n                                    inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                            Input(\"tu_star_catalog\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_BackgroundValidationPrg\",\n+MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_BackgroundValidationPrg\",\n                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                             Input(\"final_catalog\"),\n                                             Input(\"final_segmap\")],\n@@ -64,7 +64,7 @@ MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_Backg\n                                     resources=ComputingResources(cores=1, ram=26.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_DetectionValidationPrg\",\n+MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_DetectionValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"tile_file\"),\n                                            Input(\"tu_stars\"),\n@@ -73,7 +73,7 @@ MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_Detect\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_CrossmatchAnalysis\",\n+MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_CrossmatchAnalysis\",\n                                     inputs=[Input(\"final_catalog\"),\n                                             Input(\"vis_detection_mosaic\"),\n                                             Input(\"nir_detection_mosaic\"),\n@@ -85,19 +85,19 @@ MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_Cross\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_MorphologyAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MorphologyValidationPrg\",\n+MER_MorphologyAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_MorphologyValidationPrg\",\n                                     inputs=[Input(\"matched_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_PhotometryAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PhotometryAnalysis\",\n+MER_PhotometryAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_PhotometryAnalysis\",\n                                     inputs=[Input(\"crossmatched_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PhotometryPlotCheck\",\n+MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_PhotometryPlotCheck\",\n                                          inputs=[Input(\"final_catalog\"),\n                                                  Input(\"TU_gal_catalog\"),\n                                                  Input(\"TU_star_catalog\")],\n@@ -105,7 +105,7 @@ MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_\n                                          resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                          env_variables=ENV_VARIABLES)\n \n-MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_ClassificationValidationPrg\",\n+MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_ClassificationValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"tile_file\"),\n                                            Input(\"tu_stars\"),\n@@ -115,13 +115,13 @@ MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_C\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_FinalCatalogAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_CheckFinalCat\",\n+MER_FinalCatalogAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_CheckFinalCat\",\n                                    inputs=[Input(\"final_cat\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_MergeAnalysisResults = Executable(command=\"E-Run MER_Validation 10.1 MER_MergeAnalysisResults\",\n+MER_MergeAnalysisResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeAnalysisResults\",\n                                       inputs=[Input(\"mosaicing_analysis_result\"),\n                                               Input(\"psf_analysis_result\"),\n                                               Input(\"mer_star_psf_analysis_result\"),\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -29,34 +29,34 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n-MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_MosaicingValidation\",\n+MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MosaicingValidation\",\n                                    inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                            Input(\"segmap\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=16.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_PsfAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_PsfAnalysis\",\n+MER_PsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PsfAnalysis\",\n                              inputs=[Input(\"mosaics\", content_type=\"listfile\")],\n                              outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                              resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                              env_variables=ENV_VARIABLES)\n \n-MER_MerStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_MerStarPsfAnalysis\",\n+MER_MerStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MerStarPsfAnalysis\",\n                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                             Input(\"final_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_TuStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_TuStarPsfAnalysis\",\n+MER_TuStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_TuStarPsfAnalysis\",\n                                    inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                            Input(\"tu_star_catalog\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_BackgroundValidationPrg\",\n+MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_BackgroundValidationPrg\",\n                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                             Input(\"final_catalog\"),\n                                             Input(\"final_segmap\")],\n@@ -64,7 +64,7 @@ MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_Backg\n                                     resources=ComputingResources(cores=1, ram=26.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_DetectionValidationPrg\",\n+MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_DetectionValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"tile_file\"),\n                                            Input(\"tu_stars\"),\n@@ -73,7 +73,7 @@ MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_Detect\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_CrossmatchAnalysis\",\n+MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_CrossmatchAnalysis\",\n                                     inputs=[Input(\"final_catalog\"),\n                                             Input(\"vis_detection_mosaic\"),\n                                             Input(\"nir_detection_mosaic\"),\n@@ -85,19 +85,19 @@ MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_Cross\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_MorphologyAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_MorphologyValidationPrg\",\n+MER_MorphologyAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MorphologyValidationPrg\",\n                                     inputs=[Input(\"matched_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_PhotometryAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_PhotometryAnalysis\",\n+MER_PhotometryAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PhotometryAnalysis\",\n                                     inputs=[Input(\"crossmatched_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_PhotometryPlotCheck\",\n+MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PhotometryPlotCheck\",\n                                          inputs=[Input(\"final_catalog\"),\n                                                  Input(\"TU_gal_catalog\"),\n                                                  Input(\"TU_star_catalog\")],\n@@ -105,7 +105,7 @@ MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_\n                                          resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                          env_variables=ENV_VARIABLES)\n \n-MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_ClassificationValidationPrg\",\n+MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_ClassificationValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"tile_file\"),\n                                            Input(\"tu_stars\"),\n@@ -115,13 +115,13 @@ MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_C\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_FinalCatalogAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_CheckFinalCat\",\n+MER_FinalCatalogAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_CheckFinalCat\",\n                                    inputs=[Input(\"final_cat\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_MergeAnalysisResults = Executable(command=\"E-Run MER_Validation 10.0 MER_MergeAnalysisResults\",\n+MER_MergeAnalysisResults = Executable(command=\"E-Run MER_Validation 10.1 MER_MergeAnalysisResults\",\n                                       inputs=[Input(\"mosaicing_analysis_result\"),\n                                               Input(\"psf_analysis_result\"),\n                                               Input(\"mer_star_psf_analysis_result\"),\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_AnalyseTile_Pipeline/PkgDef_MER_AnalyseTileGaia.py": [
                        [
                            "@@ -26,7 +26,13 @@ from euclidwf.framework.taskdefs import (Executable, Input, Output,\n \n \n ENV_VARIABLES = {\n-    \"MPLCONFIGDIR\": \"/dev/null\"\n+    \"MPLCONFIGDIR\": \"/dev/null\",\n+    \"MKL_NUM_THREADS\": \"1\",\n+    \"NUMEXPR_NUM_THREADS\": \"1\",\n+    \"OMP_NUM_THREADS\": \"1\",\n+    \"OPENBLAS_NUM_THREADS\": \"1\", \n+    \"VECLIB_MAXIMUM_THREADS\": \"1\", \n+    \"NTHREADS\":  \"1\" \n }\n \n MER_PhotometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_PhotometryValidationPrg\",\n",
                            "Pass the same environment variables in all package defs",
                            "Javier Gracia Carpio",
                            "2023-08-16T13:20:46.000+00:00",
                            "09023779349a879cd1ad6aa851e1d12e5edea37e"
                        ],
                        [
                            "@@ -97,7 +97,9 @@ MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_M\n                                            Input(\"classification_result\"),\n                                            Input(\"psf_result\"),\n                                            Input(\"mer_star_psf_result\"),\n-                                           Input(\"gaia_psf_result\")],\n+                                           Input(\"gaia_psf_result\"),\n+                                           Input(\"mosaicing_result\"),\n+                                           Input(\"background_result\")],\n                                    outputs=[Output(\"merged_analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n",
                            "Adds missing inputs",
                            "Javier Gracia Carpio",
                            "2023-08-16T12:56:11.000+00:00",
                            "c76466bc4cc840bafe6e0071f42dc10566f84dcd"
                        ],
                        [
                            "@@ -85,7 +85,7 @@ MER_GaiaPsfValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_GaiaPs\n MER_MosaicingValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_MosaicingValidationPrg\",\n                                      inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                              Input(\"segmap\")],\n-                                     outputs=[Ouput(\"mosaicing_result\", mime_type=\"xml\"),\n+                                     outputs=[Output(\"mosaicing_result\", mime_type=\"xml\"),\n                                               Output(\"background_result\", mime_type=\"xml\")],\n                                      resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                      env_variables=ENV_VARIABLES)\n",
                            "Fixes typo in package def",
                            "Javier Gracia Carpio",
                            "2023-08-16T12:36:42.000+00:00",
                            "4227e74f1138bb64d7cbc7231babb41b0cf4f2b3"
                        ],
                        [
                            "@@ -82,6 +82,14 @@ MER_GaiaPsfValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_GaiaPs\n                                    resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n+MER_MosaicingValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_MosaicingValidationPrg\",\n+                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n+                                             Input(\"segmap\")],\n+                                     outputs=[Ouput(\"mosaicing_result\", mime_type=\"xml\"),\n+                                              Output(\"background_result\", mime_type=\"xml\")],\n+                                     resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n+                                     env_variables=ENV_VARIABLES)\n+\n MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeValidationResults\",\n                                    inputs=[Input(\"astrometry_result\"),\n                                            Input(\"detection_result\"),\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T11:47:15.000+00:00",
                            "9d681bfaa9e90d2e3d8279e2616d18ef13eef190"
                        ],
                        [
                            "@@ -82,6 +82,14 @@ MER_GaiaPsfValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_GaiaPs\n                                    resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n+MER_MosaicingValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_MosaicingValidationPrg\",\n+                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n+                                             Input(\"segmap\")],\n+                                     outputs=[Ouput(\"mosaicing_result\", mime_type=\"xml\"),\n+                                              Output(\"background_result\", mime_type=\"xml\")],\n+                                     resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n+                                     env_variables=ENV_VARIABLES)\n+\n MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeValidationResults\",\n                                    inputs=[Input(\"astrometry_result\"),\n                                            Input(\"detection_result\"),\n",
                            "add MosaicingValidationPrg to the AnalyseTileGaia pipeline",
                            "yfang",
                            "2023-08-14T18:25:53.000+02:00",
                            "3a7b450e921778912f6ffc79366157ad2c0b1184"
                        ],
                        [
                            "@@ -54,7 +54,7 @@ MER_DetectionValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_DetV\n                                      resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                      env_variables=ENV_VARIABLES)\n \n-MER_ClassificationValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_ClassificationValidationPrg\",\n+MER_ClassificationValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_ClassificationValidationGaiaPrg\",\n                                           inputs=[Input(\"final_catalog\"),\n                                                   Input(\"gaia_cutout\"),\n                                                   Input(\"configuration_set\")],\n",
                            "Use new executable name",
                            "Javier Gracia Carpio",
                            "2023-08-10T20:02:51.000+00:00",
                            "94379932bc4284c0e7098d45b67788bd36dc7a92"
                        ],
                        [
                            "@@ -54,6 +54,14 @@ MER_DetectionValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_DetV\n                                      resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                      env_variables=ENV_VARIABLES)\n \n+MER_ClassificationValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_ClassificationValidationPrg\",\n+                                          inputs=[Input(\"final_catalog\"),\n+                                                  Input(\"gaia_cutout\"),\n+                                                  Input(\"configuration_set\")],\n+                                          outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                          resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                          env_variables=ENV_VARIABLES)\n+\n MER_PsfValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_PsfAnalysis\",\n                                inputs=[Input(\"mosaics\", content_type=\"listfile\")],\n                                outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n@@ -78,6 +86,7 @@ MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_M\n                                    inputs=[Input(\"astrometry_result\"),\n                                            Input(\"detection_result\"),\n                                            Input(\"photometry_result\"),\n+                                           Input(\"classification_result\"),\n                                            Input(\"psf_result\"),\n                                            Input(\"mer_star_psf_result\"),\n                                            Input(\"gaia_psf_result\")],\n",
                            "Adds the classification step",
                            "Javier Gracia Carpio",
                            "2023-08-10T19:42:23.000+00:00",
                            "62735fd620a56e5e537f75a5cdabcaaa17a9bee5"
                        ],
                        [
                            "@@ -67,12 +67,20 @@ MER_MerStarPsfValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_Mer\n                                       resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                       env_variables=ENV_VARIABLES)\n \n+MER_GaiaPsfValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_GaiaPsfAnalysis\",\n+                                   inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n+                                           Input(\"gaia_cutout\")],\n+                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n+\n MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeValidationResults\",\n                                    inputs=[Input(\"astrometry_result\"),\n                                            Input(\"detection_result\"),\n                                            Input(\"photometry_result\"),\n                                            Input(\"psf_result\"),\n-                                           Input(\"mer_star_psf_result\")],\n+                                           Input(\"mer_star_psf_result\"),\n+                                           Input(\"gaia_psf_result\")],\n                                    outputs=[Output(\"merged_analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n",
                            "Adds Gaia PSF validation step",
                            "Javier Gracia Carpio",
                            "2023-08-10T16:23:09.000+00:00",
                            "77feb68869a4a208c50a97b3d3e80dd84b14afc7"
                        ],
                        [
                            "@@ -29,44 +29,50 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n-MER_DetValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_DetValidationPrg\",\n-                               inputs=[Input(\"final_catalog\"),\n-                                       Input(\"gaia_cutout\"),\n-                                       Input(\"tile_file\"),\n-                                       Input(\"configuration_set\")],\n-                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n-                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n-                                   env_variables=ENV_VARIABLES)\n+MER_PhotometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_PhotometryValidationPrg\",\n+                                      inputs=[Input(\"final_catalog\"),\n+                                              Input(\"gaia_cutout\"),\n+                                              Input(\"configuration_set\")],\n+                                      outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                      resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                      env_variables=ENV_VARIABLES)\n \n MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_AstrometryValidationPrg\",\n-                                   inputs=[Input(\"final_catalog\"),\n-                                           Input(\"gaia_cutout\"),\n-                                           Input(\"configuration_set\")],\n-                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n-                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n-                                   env_variables=ENV_VARIABLES)\n+                                      inputs=[Input(\"final_catalog\"),\n+                                              Input(\"gaia_cutout\"),\n+                                              Input(\"configuration_set\")],\n+                                      outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                      resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                      env_variables=ENV_VARIABLES)\n \n MER_DetectionValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_DetValidationPrg\",\n-                                   inputs=[Input(\"final_catalog\"),\n-                                           Input(\"gaia_cutout\"),\n-                                           Input(\"tile_file\"),\n-                                           Input(\"configuration_set\")],\n-                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n-                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n-                                   env_variables=ENV_VARIABLES)\n+                                     inputs=[Input(\"final_catalog\"),\n+                                             Input(\"gaia_cutout\"),\n+                                             Input(\"tile_file\"),\n+                                             Input(\"configuration_set\")],\n+                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                     resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                     env_variables=ENV_VARIABLES)\n \n-MER_PhotometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_PhotometryValidationPrg\",\n-                                   inputs=[Input(\"final_catalog\"),\n-                                           Input(\"gaia_cutout\"),\n-                                           Input(\"configuration_set\")],\n-                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n-                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n-                                   env_variables=ENV_VARIABLES)\n+MER_PsfValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_PsfAnalysis\",\n+                               inputs=[Input(\"mosaics\", content_type=\"listfile\")],\n+                               outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                               resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n+                               env_variables=ENV_VARIABLES)\n+\n+MER_MerStarPsfValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_MerStarPsfAnalysis\",\n+                                      inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n+                                              Input(\"final_catalog\")],\n+                                      outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                      resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n+                                      env_variables=ENV_VARIABLES)\n \n MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeValidationResults\",\n                                    inputs=[Input(\"astrometry_result\"),\n                                            Input(\"detection_result\"),\n-                                           Input(\"photometry_result\")],\n+                                           Input(\"photometry_result\"),\n+                                           Input(\"psf_result\"),\n+                                           Input(\"mer_star_psf_result\")],\n                                    outputs=[Output(\"merged_analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n",
                            "Adds mosaics inputs to the gaia validation pipeline",
                            "Javier Gracia Carpio",
                            "2023-08-10T14:30:31.000+00:00",
                            "c60aef018ad53b4f543701cee1592e90c3a469e4"
                        ],
                        [
                            "@@ -29,6 +29,15 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n+MER_DetValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_DetValidationPrg\",\n+                               inputs=[Input(\"final_catalog\"),\n+                                       Input(\"gaia_cutout\"),\n+                                       Input(\"tile_file\"),\n+                                       Input(\"configuration_set\")],\n+                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n+\n MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_AstrometryValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"gaia_cutout\"),\n@@ -37,8 +46,27 @@ MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_Ast\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n+MER_DetectionValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_DetValidationPrg\",\n+                                   inputs=[Input(\"final_catalog\"),\n+                                           Input(\"gaia_cutout\"),\n+                                           Input(\"tile_file\"),\n+                                           Input(\"configuration_set\")],\n+                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n+\n+MER_PhotometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_PhotometryValidationPrg\",\n+                                   inputs=[Input(\"final_catalog\"),\n+                                           Input(\"gaia_cutout\"),\n+                                           Input(\"configuration_set\")],\n+                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n+\n MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeValidationResults\",\n-                                   inputs=[Input(\"astrometry_result\")],\n+                                   inputs=[Input(\"astrometry_result\"),\n+                                           Input(\"detection_result\"),\n+                                           Input(\"photometry_result\")],\n                                    outputs=[Output(\"merged_analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:50:41.000+00:00",
                            "b61999f44bcba73649185b197918dd343601a31d"
                        ],
                        [
                            "@@ -29,6 +29,15 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n+MER_DetValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_DetValidationPrg\",\n+                               inputs=[Input(\"final_catalog\"),\n+                                       Input(\"gaia_cutout\"),\n+                                       Input(\"tile_file\"),\n+                                       Input(\"configuration_set\")],\n+                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n+\n MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_AstrometryValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"gaia_cutout\"),\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines into develop",
                            "yfang",
                            "2023-07-20T14:52:13.000+02:00",
                            "435e24aa5c3078f91782c91fe687450349b25e0f"
                        ],
                        [
                            "@@ -37,8 +37,27 @@ MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_Ast\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n+MER_DetectionValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_DetValidationPrg\",\n+                                   inputs=[Input(\"final_catalog\"),\n+                                           Input(\"gaia_cutout\"),\n+                                           Input(\"tile_file\"),\n+                                           Input(\"configuration_set\")],\n+                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n+\n+MER_PhotometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_PhotometryValidationPrg\",\n+                                   inputs=[Input(\"final_catalog\"),\n+                                           Input(\"gaia_cutout\"),\n+                                           Input(\"configuration_set\")],\n+                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n+\n MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeValidationResults\",\n-                                   inputs=[Input(\"astrometry_result\")],\n+                                   inputs=[Input(\"astrometry_result\"),\n+                                           Input(\"detection_result\"),\n+                                           Input(\"photometry_result\")],\n                                    outputs=[Output(\"merged_analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n",
                            "add photometry validation to pipeline",
                            "yfang",
                            "2023-07-20T14:50:03.000+02:00",
                            "55942f26187474b2de694e8eb9d05be36f7cf234"
                        ],
                        [
                            "@@ -29,6 +29,15 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n+MER_DetValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_DetValidationPrg\",\n+                               inputs=[Input(\"final_catalog\"),\n+                                       Input(\"gaia_cutout\"),\n+                                       Input(\"tile_file\"),\n+                                       Input(\"configuration_set\")],\n+                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n+\n MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_AstrometryValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"gaia_cutout\"),\n@@ -38,7 +47,8 @@ MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_Ast\n                                    env_variables=ENV_VARIABLES)\n \n MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeValidationResults\",\n-                                   inputs=[Input(\"astrometry_result\")],\n+                                   inputs=[Input(\"detection_result\"),\n+                                           Input(\"astrometry_result\")],\n                                    outputs=[Output(\"merged_analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n",
                            "Integrated the detection validation.",
                            "Martin Kuemmel",
                            "2023-07-20T14:41:54.000+02:00",
                            "96efffdda590a304b80cedb01061dc4f62f37b50"
                        ],
                        [
                            "@@ -30,9 +30,15 @@ ENV_VARIABLES = {\n }\n \n MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_AstrometryValidationPrg\",\n-                                   inputs=[Input(\"mer_catalog\"),\n+                                   inputs=[Input(\"final_catalog\"),\n                                            Input(\"gaia_cutout\"),\n                                            Input(\"configuration_set\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n+\n+MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeValidationResults\",\n+                                   inputs=[Input(\"astrometry_result\")],\n+                                   outputs=[Output(\"merged_analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n",
                            "Merge branch 'feature/gaia_index' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T21:40:49.000+00:00",
                            "b5c7c0d135177fbca99d1a973a2207fc5ee7d6dc"
                        ],
                        [
                            "@@ -30,9 +30,15 @@ ENV_VARIABLES = {\n }\n \n MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_AstrometryValidationPrg\",\n-                                   inputs=[Input(\"mer_catalog\"),\n+                                   inputs=[Input(\"final_catalog\"),\n                                            Input(\"gaia_cutout\"),\n                                            Input(\"configuration_set\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n+\n+MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeValidationResults\",\n+                                   inputs=[Input(\"astrometry_result\")],\n+                                   outputs=[Output(\"merged_analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n",
                            "Added the index to the GAIA validation",
                            "Martin Kuemmel",
                            "2023-07-04T23:18:12.000+02:00",
                            "53c7a3a924b3acb720ccc5a2d7137737ed711069"
                        ],
                        [
                            "",
                            "Use better names",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:36:54.000+00:00",
                            "a9ff684e194f0bbf670427c515527a348a9b7da3"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_AnalyseTile_Pipeline/PkgDef_MER_AnalyseTileVisOnly.py": [
                        [
                            "@@ -26,7 +26,13 @@ from euclidwf.framework.taskdefs import (Executable, Input, Output,\n \n \n ENV_VARIABLES = {\n-    \"MPLCONFIGDIR\": \"/dev/null\"\n+    \"MPLCONFIGDIR\": \"/dev/null\",\n+    \"MKL_NUM_THREADS\": \"1\",\n+    \"NUMEXPR_NUM_THREADS\": \"1\",\n+    \"OMP_NUM_THREADS\": \"1\",\n+    \"OPENBLAS_NUM_THREADS\": \"1\", \n+    \"VECLIB_MAXIMUM_THREADS\": \"1\", \n+    \"NTHREADS\":  \"1\" \n }\n \n MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_MosaicingValidation\",\n",
                            "Pass the same environment variables in all package defs",
                            "Javier Gracia Carpio",
                            "2023-08-16T13:20:46.000+00:00",
                            "09023779349a879cd1ad6aa851e1d12e5edea37e"
                        ],
                        [
                            "@@ -29,34 +29,34 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n-MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MosaicingValidation\",\n+MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_MosaicingValidation\",\n                                    inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                            Input(\"segmap\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=16.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_PsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PsfAnalysis\",\n+MER_PsfAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_PsfAnalysis\",\n                              inputs=[Input(\"mosaics\", content_type=\"listfile\")],\n                              outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                              resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                              env_variables=ENV_VARIABLES)\n \n-MER_MerStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MerStarPsfAnalysis\",\n+MER_MerStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_MerStarPsfAnalysis\",\n                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                             Input(\"final_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_TuStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_TuStarPsfAnalysis\",\n+MER_TuStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_TuStarPsfAnalysis\",\n                                    inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                            Input(\"tu_star_catalog\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_BackgroundValidationPrg\",\n+MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_BackgroundValidationPrg\",\n                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                             Input(\"final_catalog\"),\n                                             Input(\"final_segmap\")],\n@@ -64,7 +64,7 @@ MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_Backg\n                                     resources=ComputingResources(cores=1, ram=26.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_DetectionValidationPrg\",\n+MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_DetectionValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"tile_file\"),\n                                            Input(\"tu_stars\"),\n@@ -73,7 +73,7 @@ MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_Detect\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_CrossmatchAnalysis\",\n+MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_CrossmatchAnalysis\",\n                                     inputs=[Input(\"final_catalog\"),\n                                             Input(\"vis_detection_mosaic\"),\n                                             Input(\"tu_star_catalog\"),\n@@ -84,19 +84,19 @@ MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_Cross\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_MorphologyAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MorphologyValidationPrg\",\n+MER_MorphologyAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_MorphologyValidationPrg\",\n                                     inputs=[Input(\"matched_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_PhotometryAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PhotometryAnalysis\",\n+MER_PhotometryAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_PhotometryAnalysis\",\n                                     inputs=[Input(\"crossmatched_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PhotometryPlotCheck\",\n+MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_PhotometryPlotCheck\",\n                                          inputs=[Input(\"final_catalog\"),\n                                                  Input(\"TU_gal_catalog\"),\n                                                  Input(\"TU_star_catalog\")],\n@@ -104,7 +104,7 @@ MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_\n                                          resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                          env_variables=ENV_VARIABLES)\n \n-MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_ClassificationValidationPrg\",\n+MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_ClassificationValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"tile_file\"),\n                                            Input(\"tu_stars\"),\n@@ -114,13 +114,13 @@ MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_C\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_FinalCatalogAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_CheckFinalCat\",\n+MER_FinalCatalogAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_CheckFinalCat\",\n                                    inputs=[Input(\"final_cat\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_MergeAnalysisResults = Executable(command=\"E-Run MER_Validation 10.1 MER_MergeAnalysisResults\",\n+MER_MergeAnalysisResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeAnalysisResults\",\n                                       inputs=[Input(\"mosaicing_analysis_result\"),\n                                               Input(\"psf_analysis_result\"),\n                                               Input(\"mer_star_psf_analysis_result\"),\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -29,34 +29,34 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n-MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_MosaicingValidation\",\n+MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MosaicingValidation\",\n                                    inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                            Input(\"segmap\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=16.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_PsfAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_PsfAnalysis\",\n+MER_PsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PsfAnalysis\",\n                              inputs=[Input(\"mosaics\", content_type=\"listfile\")],\n                              outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                              resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                              env_variables=ENV_VARIABLES)\n \n-MER_MerStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_MerStarPsfAnalysis\",\n+MER_MerStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MerStarPsfAnalysis\",\n                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                             Input(\"final_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_TuStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_TuStarPsfAnalysis\",\n+MER_TuStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_TuStarPsfAnalysis\",\n                                    inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                            Input(\"tu_star_catalog\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_BackgroundValidationPrg\",\n+MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_BackgroundValidationPrg\",\n                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                             Input(\"final_catalog\"),\n                                             Input(\"final_segmap\")],\n@@ -64,7 +64,7 @@ MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_Backg\n                                     resources=ComputingResources(cores=1, ram=26.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_DetectionValidationPrg\",\n+MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_DetectionValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"tile_file\"),\n                                            Input(\"tu_stars\"),\n@@ -73,7 +73,7 @@ MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_Detect\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_CrossmatchAnalysis\",\n+MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_CrossmatchAnalysis\",\n                                     inputs=[Input(\"final_catalog\"),\n                                             Input(\"vis_detection_mosaic\"),\n                                             Input(\"tu_star_catalog\"),\n@@ -84,19 +84,19 @@ MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_Cross\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_MorphologyAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_MorphologyValidationPrg\",\n+MER_MorphologyAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MorphologyValidationPrg\",\n                                     inputs=[Input(\"matched_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_PhotometryAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_PhotometryAnalysis\",\n+MER_PhotometryAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PhotometryAnalysis\",\n                                     inputs=[Input(\"crossmatched_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_PhotometryPlotCheck\",\n+MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PhotometryPlotCheck\",\n                                          inputs=[Input(\"final_catalog\"),\n                                                  Input(\"TU_gal_catalog\"),\n                                                  Input(\"TU_star_catalog\")],\n@@ -104,7 +104,7 @@ MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_\n                                          resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                          env_variables=ENV_VARIABLES)\n \n-MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_ClassificationValidationPrg\",\n+MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_ClassificationValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"tile_file\"),\n                                            Input(\"tu_stars\"),\n@@ -114,13 +114,13 @@ MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_C\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_FinalCatalogAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_CheckFinalCat\",\n+MER_FinalCatalogAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_CheckFinalCat\",\n                                    inputs=[Input(\"final_cat\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_MergeAnalysisResults = Executable(command=\"E-Run MER_Validation 10.0 MER_MergeAnalysisResults\",\n+MER_MergeAnalysisResults = Executable(command=\"E-Run MER_Validation 10.1 MER_MergeAnalysisResults\",\n                                       inputs=[Input(\"mosaicing_analysis_result\"),\n                                               Input(\"psf_analysis_result\"),\n                                               Input(\"mer_star_psf_analysis_result\"),\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_ProcessTileMorpho_Pipeline/PkgDef_MER_ProcessTileMorpho.py": [
                        [
                            "@@ -25,12 +25,13 @@ from euclidwf.framework.taskdefs import (Executable, Input, Output,\n \n \n ENV_VARIABLES = {\n-        \"MKL_NUM_THREADS\": \"1\",\n-        \"NUMEXPR_NUM_THREADS\": \"1\",\n-        \"OMP_NUM_THREADS\": \"1\",\n-        \"OPENBLAS_NUM_THREADS\": \"1\", \n-        \"VECLIB_MAXIMUM_THREADS\": \"1\", \n-        \"NTHREADS\":  \"1\" \n+    \"MPLCONFIGDIR\": \"/dev/null\",\n+    \"MKL_NUM_THREADS\": \"1\",\n+    \"NUMEXPR_NUM_THREADS\": \"1\",\n+    \"OMP_NUM_THREADS\": \"1\",\n+    \"OPENBLAS_NUM_THREADS\": \"1\", \n+    \"VECLIB_MAXIMUM_THREADS\": \"1\", \n+    \"NTHREADS\":  \"1\" \n }\n \n MER_MorphoPatch = Executable(command=\"E-Run MER_Pipeline 10.2 MER_MorphoPatch\",\n",
                            "Pass the same environment variables in all package defs",
                            "Javier Gracia Carpio",
                            "2023-08-16T13:20:46.000+00:00",
                            "09023779349a879cd1ad6aa851e1d12e5edea37e"
                        ],
                        [
                            "@@ -33,7 +33,7 @@ ENV_VARIABLES = {\n         \"NTHREADS\":  \"1\" \n }\n \n-MER_MorphoPatch = Executable(command=\"E-Run MER_Pipeline 10.1 MER_MorphoPatch\",\n+MER_MorphoPatch = Executable(command=\"E-Run MER_Pipeline 10.2 MER_MorphoPatch\",\n                                  inputs=[Input(\"final_catalog\"),\n                                          Input(\"vis_detection_mosaic\"),\n                                          Input(\"measurement_mosaics\", content_type=\"listfile\")],\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -33,7 +33,7 @@ ENV_VARIABLES = {\n         \"NTHREADS\":  \"1\" \n }\n \n-MER_MorphoPatch = Executable(command=\"E-Run MER_Pipeline 10.0 MER_MorphoPatch\",\n+MER_MorphoPatch = Executable(command=\"E-Run MER_Pipeline 10.1 MER_MorphoPatch\",\n                                  inputs=[Input(\"final_catalog\"),\n                                          Input(\"vis_detection_mosaic\"),\n                                          Input(\"measurement_mosaics\", content_type=\"listfile\")],\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_ProcessTile_Pipeline/PkgDef_MER_ProcessTileVisOnly.py": [
                        [
                            "@@ -25,7 +25,13 @@ from euclidwf.framework.taskdefs import (Executable, Input, Output,\n \n \n ENV_VARIABLES = {\n-    \"MPLCONFIGDIR\": \"/dev/null\"\n+    \"MPLCONFIGDIR\": \"/dev/null\",\n+    \"MKL_NUM_THREADS\": \"1\",\n+    \"NUMEXPR_NUM_THREADS\": \"1\",\n+    \"OMP_NUM_THREADS\": \"1\",\n+    \"OPENBLAS_NUM_THREADS\": \"1\", \n+    \"VECLIB_MAXIMUM_THREADS\": \"1\", \n+    \"NTHREADS\":  \"1\" \n }\n \n MER_InitializeVisOnly = Executable(command=\"E-Run MER_Pipeline 10.2 MER_InitializeVisOnly\",\n",
                            "Pass the same environment variables in all package defs",
                            "Javier Gracia Carpio",
                            "2023-08-16T13:20:46.000+00:00",
                            "09023779349a879cd1ad6aa851e1d12e5edea37e"
                        ],
                        [
                            "@@ -28,12 +28,12 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n-MER_InitializeVisOnly = Executable(command=\"E-Run MER_Pipeline 10.1 MER_InitializeVisOnly\",\n+MER_InitializeVisOnly = Executable(command=\"E-Run MER_Pipeline 10.2 MER_InitializeVisOnly\",\n                                    inputs=[Input(\"vis_calibrated_frames\", content_type=\"listfile\")],\n                                    outputs=[Output(\"vis_image_list\", content_type=\"listfile\", mime_type=\"json\")],\n                                    resources=ComputingResources(cores=1, ram=1.0, walltime=0.3))\n \n-MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Mosaicing\",\n+MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.2 MER_Mosaicing\",\n                            inputs=[Input(\"image_list\", content_type=\"listfile\"),\n                                    Input(\"tile\"),\n                                    Input(\"configuration\"),\n@@ -42,14 +42,14 @@ MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Mosaicing\",\n                            outputs=[Output(\"mosaic\", mime_type=\"xml\")],\n                            resources=ComputingResources(cores=2, ram=6.0, walltime=6.0, tmpsize=999))\n \n-MER_Background = Executable(command=\"E-Run MER_Background 10.1 MER_BackgroundPrg\",\n+MER_Background = Executable(command=\"E-Run MER_Background 10.2 MER_BackgroundPrg\",\n                             inputs=[Input(\"mosaic\"),\n                                     Input(\"configuration\"),\n                                     Input(\"flag_limits\")],\n                             outputs=[Output(\"background_subtracted_mosaic\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=8.0, walltime=4.0))\n \n-MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.1 MER_VisDetectionPrg\",\n+MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.2 MER_VisDetectionPrg\",\n                               inputs=[Input(\"mosaic\"),\n                                       Input(\"configuration\"),\n                                       Input(\"flag_limits\")],\n@@ -58,7 +58,7 @@ MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.1 MER_VisDetection\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=4, ram=14.0, walltime=6.0))\n \n-MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.1 MER_Deblending\",\n+MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.2 MER_Deblending\",\n                             inputs=[Input(\"input_mosaic\"),\n                                     Input(\"detection_segmap\"),\n                                     Input(\"configuration\"),\n@@ -68,7 +68,7 @@ MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.1 MER_Deblending\",\n                                      Output(\"to_aphot_catalog\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=22.0, walltime=14.0))\n \n-MER_MBCombineNone = Executable(command=\"E-Run MER_Detection 10.1 MER_MBCombineNonePrg\",\n+MER_MBCombineNone = Executable(command=\"E-Run MER_Detection 10.2 MER_MBCombineNonePrg\",\n                                   inputs=[Input(\"visSegmentMap\"),\n                                           Input(\"visDetectionCatalog\"),\n                                           Input(\"configuration\"),\n@@ -77,7 +77,7 @@ MER_MBCombineNone = Executable(command=\"E-Run MER_Detection 10.1 MER_MBCombineNo\n                                            Output(\"combinedDetectionCat\", mime_type=\"xml\")],\n                                   resources=ComputingResources(cores=1, ram=4.0, walltime=0.5))\n \n-MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.1 MER_CatalogPsfCalculation\",\n+MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.2 MER_CatalogPsfCalculation\",\n                                        inputs=[Input(\"image_list\", content_type=\"listfile\"),\n                                                Input(\"mosaic\"),\n                                                Input(\"catalog\"),\n@@ -86,13 +86,13 @@ MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Cata\n                                        outputs=[Output(\"output_mosaic\", mime_type=\"xml\")],\n                                        resources=ComputingResources(cores=2, ram=6.0, walltime=4.0, tmpsize=999))\n \n-MER_PsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.1 MER_PsfExtraction\",\n+MER_PsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.2 MER_PsfExtraction\",\n                                inputs=[Input(\"mosaic\"),\n                                        Input(\"catalog\")],\n                                outputs=[Output(\"psf_stamp_collection\", mime_type=\"xml\")],\n                                resources=ComputingResources(cores=1, ram=3.0, walltime=1.0))\n \n-MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotMorphology\",\n+MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.2 MER_APhotMorphology\",\n                                    inputs=[Input(\"configuration\"),\n                                            Input(\"input_image\"),\n                                            Input(\"input_catalog\"),\n@@ -100,7 +100,7 @@ MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotM\n                                    outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=10.0, walltime=1.0))\n \n-MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.1 MER_Morphology\",\n+MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.2 MER_Morphology\",\n                             inputs=[Input(\"input_mosaic\"),\n                                     Input(\"input_segmap\"),\n                                     Input(\"input_catalog\"),\n@@ -108,7 +108,7 @@ MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.1 MER_Morphology\",\n                             outputs=[Output(\"morph_catalog\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=10.0, walltime=2.0))\n \n-MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotDetectionVisOnly\",\n+MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.2 MER_APhotDetectionVisOnly\",\n                                 inputs=[Input(\"configuration\"),\n                                         Input(\"input_image\"),\n                                         Input(\"input_catalog\"),\n@@ -117,7 +117,7 @@ MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotDete\n                                          Output(\"aphot_catalogs\", content_type=\"listfile\", mime_type=\"json\")],\n                                 resources=ComputingResources(cores=1, ram=12.0, walltime=1.0))\n \n-MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.1 MER_PsfFitting\",\n+MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.2 MER_PsfFitting\",\n                                        inputs=[Input(\"configuration\"),\n                                                Input(\"vis_image\"),\n                                                Input(\"input_catalog\"),\n@@ -126,7 +126,7 @@ MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.1 MER_Ps\n                                        outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                        resources=ComputingResources(cores=1, ram=16.0, walltime=12.0))\n \n-MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.1 MER_CatalogAssembly\",\n+MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.2 MER_CatalogAssembly\",\n                          inputs=[Input(\"vis_mosaic\"),\n                                  Input(\"gaia_cutouts\", content_type=\"listfile\"),\n                                  Input(\"photA_list\", content_type=\"listfile\"),\n@@ -143,13 +143,13 @@ MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.1 MER_CatalogAsse\n                                   Output(\"final_segmap\", mime_type=\"xml\")],\n                          resources=ComputingResources(cores=1, ram=22.0, walltime=1.0))\n \n-MER_QuickAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_QuickAnalysis\",\n+MER_QuickAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_QuickAnalysis\",\n                                inputs=[Input(\"final_catalog\")],\n                                outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                resources=ComputingResources(cores=1, ram=2.0, walltime=1.0),\n                                env_variables=ENV_VARIABLES)\n \n-MER_Compression = Executable(command=\"E-Run MER_Pipeline 10.1 MER_CompressionVisOnly\",\n+MER_Compression = Executable(command=\"E-Run MER_Pipeline 10.2 MER_CompressionVisOnly\",\n                          inputs=[Input(\"vis_mosaic\"),\n                                  Input(\"vis_detection_mosaic\"),\n                                  Input(\"segmentation_map\"),\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -28,12 +28,12 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n-MER_InitializeVisOnly = Executable(command=\"E-Run MER_Pipeline 10.0 MER_InitializeVisOnly\",\n+MER_InitializeVisOnly = Executable(command=\"E-Run MER_Pipeline 10.1 MER_InitializeVisOnly\",\n                                    inputs=[Input(\"vis_calibrated_frames\", content_type=\"listfile\")],\n                                    outputs=[Output(\"vis_image_list\", content_type=\"listfile\", mime_type=\"json\")],\n                                    resources=ComputingResources(cores=1, ram=1.0, walltime=0.3))\n \n-MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Mosaicing\",\n+MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Mosaicing\",\n                            inputs=[Input(\"image_list\", content_type=\"listfile\"),\n                                    Input(\"tile\"),\n                                    Input(\"configuration\"),\n@@ -42,14 +42,14 @@ MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Mosaicing\",\n                            outputs=[Output(\"mosaic\", mime_type=\"xml\")],\n                            resources=ComputingResources(cores=2, ram=6.0, walltime=6.0, tmpsize=999))\n \n-MER_Background = Executable(command=\"E-Run MER_Background 10.0 MER_BackgroundPrg\",\n+MER_Background = Executable(command=\"E-Run MER_Background 10.1 MER_BackgroundPrg\",\n                             inputs=[Input(\"mosaic\"),\n                                     Input(\"configuration\"),\n                                     Input(\"flag_limits\")],\n                             outputs=[Output(\"background_subtracted_mosaic\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=8.0, walltime=4.0))\n \n-MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.0 MER_VisDetectionPrg\",\n+MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.1 MER_VisDetectionPrg\",\n                               inputs=[Input(\"mosaic\"),\n                                       Input(\"configuration\"),\n                                       Input(\"flag_limits\")],\n@@ -58,7 +58,7 @@ MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.0 MER_VisDetection\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=4, ram=14.0, walltime=6.0))\n \n-MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.0 MER_Deblending\",\n+MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.1 MER_Deblending\",\n                             inputs=[Input(\"input_mosaic\"),\n                                     Input(\"detection_segmap\"),\n                                     Input(\"configuration\"),\n@@ -68,7 +68,7 @@ MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.0 MER_Deblending\",\n                                      Output(\"to_aphot_catalog\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=22.0, walltime=14.0))\n \n-MER_MBCombineNone = Executable(command=\"E-Run MER_Detection 10.0 MER_MBCombineNonePrg\",\n+MER_MBCombineNone = Executable(command=\"E-Run MER_Detection 10.1 MER_MBCombineNonePrg\",\n                                   inputs=[Input(\"visSegmentMap\"),\n                                           Input(\"visDetectionCatalog\"),\n                                           Input(\"configuration\"),\n@@ -77,7 +77,7 @@ MER_MBCombineNone = Executable(command=\"E-Run MER_Detection 10.0 MER_MBCombineNo\n                                            Output(\"combinedDetectionCat\", mime_type=\"xml\")],\n                                   resources=ComputingResources(cores=1, ram=4.0, walltime=0.5))\n \n-MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.0 MER_CatalogPsfCalculation\",\n+MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.1 MER_CatalogPsfCalculation\",\n                                        inputs=[Input(\"image_list\", content_type=\"listfile\"),\n                                                Input(\"mosaic\"),\n                                                Input(\"catalog\"),\n@@ -86,13 +86,13 @@ MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Cata\n                                        outputs=[Output(\"output_mosaic\", mime_type=\"xml\")],\n                                        resources=ComputingResources(cores=2, ram=6.0, walltime=4.0, tmpsize=999))\n \n-MER_PsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.0 MER_PsfExtraction\",\n+MER_PsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.1 MER_PsfExtraction\",\n                                inputs=[Input(\"mosaic\"),\n                                        Input(\"catalog\")],\n                                outputs=[Output(\"psf_stamp_collection\", mime_type=\"xml\")],\n                                resources=ComputingResources(cores=1, ram=3.0, walltime=1.0))\n \n-MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotMorphology\",\n+MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotMorphology\",\n                                    inputs=[Input(\"configuration\"),\n                                            Input(\"input_image\"),\n                                            Input(\"input_catalog\"),\n@@ -100,7 +100,7 @@ MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotM\n                                    outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=10.0, walltime=1.0))\n \n-MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.0 MER_Morphology\",\n+MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.1 MER_Morphology\",\n                             inputs=[Input(\"input_mosaic\"),\n                                     Input(\"input_segmap\"),\n                                     Input(\"input_catalog\"),\n@@ -108,7 +108,7 @@ MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.0 MER_Morphology\",\n                             outputs=[Output(\"morph_catalog\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=10.0, walltime=2.0))\n \n-MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotDetectionVisOnly\",\n+MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotDetectionVisOnly\",\n                                 inputs=[Input(\"configuration\"),\n                                         Input(\"input_image\"),\n                                         Input(\"input_catalog\"),\n@@ -117,7 +117,7 @@ MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotDete\n                                          Output(\"aphot_catalogs\", content_type=\"listfile\", mime_type=\"json\")],\n                                 resources=ComputingResources(cores=1, ram=12.0, walltime=1.0))\n \n-MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.0 MER_PsfFitting\",\n+MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.1 MER_PsfFitting\",\n                                        inputs=[Input(\"configuration\"),\n                                                Input(\"vis_image\"),\n                                                Input(\"input_catalog\"),\n@@ -126,7 +126,7 @@ MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.0 MER_Ps\n                                        outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                        resources=ComputingResources(cores=1, ram=16.0, walltime=12.0))\n \n-MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.0 MER_CatalogAssembly\",\n+MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.1 MER_CatalogAssembly\",\n                          inputs=[Input(\"vis_mosaic\"),\n                                  Input(\"gaia_cutouts\", content_type=\"listfile\"),\n                                  Input(\"photA_list\", content_type=\"listfile\"),\n@@ -143,13 +143,13 @@ MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.0 MER_CatalogAsse\n                                   Output(\"final_segmap\", mime_type=\"xml\")],\n                          resources=ComputingResources(cores=1, ram=22.0, walltime=1.0))\n \n-MER_QuickAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_QuickAnalysis\",\n+MER_QuickAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_QuickAnalysis\",\n                                inputs=[Input(\"final_catalog\")],\n                                outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                resources=ComputingResources(cores=1, ram=2.0, walltime=1.0),\n                                env_variables=ENV_VARIABLES)\n \n-MER_Compression = Executable(command=\"E-Run MER_Pipeline 10.0 MER_CompressionVisOnly\",\n+MER_Compression = Executable(command=\"E-Run MER_Pipeline 10.1 MER_CompressionVisOnly\",\n                          inputs=[Input(\"vis_mosaic\"),\n                                  Input(\"vis_detection_mosaic\"),\n                                  Input(\"segmentation_map\"),\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_AnalyseTile_Pipeline/PipScript_MER_AnalyseTileGaia.py": [
                        [
                            "@@ -68,7 +68,7 @@ def mer_pipeline(final_catalog, all_mosaics, final_segmentation_map, gaia_cutout\n         mosaics=all_mosaics,\n         gaia_cutout=gaia_cutout\n     )\n-    mosaicing_result, background_result = MER_MosaicingValidationPrg(\n+    mosaicing_result, background_result = MER_MosaicingValidation(\n         mosaics=all_mosaics,\n         segmap=final_segmentation_map\n     )\n",
                            "Fixes typo in executable name",
                            "Javier Gracia Carpio",
                            "2023-08-16T12:16:37.000+00:00",
                            "a1bba0778113c41ba11f6ac72ba7c944db2cc224"
                        ],
                        [
                            "@@ -26,7 +26,7 @@ from euclidwf.framework.workflow_dsl import pipeline\n from PkgDef_MER_AnalyseTileGaia import *\n \n @pipeline(outputs=(\"merged_analysis_result\"))\n-def mer_pipeline(final_catalog, all_mosaics, segmap, gaia_cutout, tile, configuration_set):\n+def mer_pipeline(final_catalog, all_mosaics, final_segmentation_map, gaia_cutout, tile, configuration_set):\n     \"\"\"\n     Main analysis pipeline for the MER PF\n     \"\"\"\n@@ -70,7 +70,7 @@ def mer_pipeline(final_catalog, all_mosaics, segmap, gaia_cutout, tile, configur\n     )\n     mosaicing_result, background_result = MER_MosaicingValidationPrg(\n         mosaics=all_mosaics,\n-        segmap=segmap\n+        segmap=final_segmentation_map\n     )\n \n     merged_analysis_result = MER_MergeValidationResults(\n",
                            "Updates pipeline def and renames segmap input port",
                            "Javier Gracia Carpio",
                            "2023-08-16T11:54:22.000+00:00",
                            "73e7c9748d2348152d680bd50f99ea8291c54b44"
                        ],
                        [
                            "@@ -26,7 +26,7 @@ from euclidwf.framework.workflow_dsl import pipeline\n from PkgDef_MER_AnalyseTileGaia import *\n \n @pipeline(outputs=(\"merged_analysis_result\"))\n-def mer_pipeline(final_catalog, all_mosaics, gaia_cutout, tile, configuration_set):\n+def mer_pipeline(final_catalog, all_mosaics, segmap, gaia_cutout, tile, configuration_set):\n     \"\"\"\n     Main analysis pipeline for the MER PF\n     \"\"\"\n@@ -68,6 +68,10 @@ def mer_pipeline(final_catalog, all_mosaics, gaia_cutout, tile, configuration_se\n         mosaics=all_mosaics,\n         gaia_cutout=gaia_cutout\n     )\n+    mosaicing_result, background_result = MER_MosaicingValidationPrg(\n+        mosaics=all_mosaics,\n+        segmap=segmap\n+    )\n \n     merged_analysis_result = MER_MergeValidationResults(\n         photometry_result=photometry_result,\n@@ -76,7 +80,9 @@ def mer_pipeline(final_catalog, all_mosaics, gaia_cutout, tile, configuration_se\n         classification_result=classification_result,\n         psf_result=psf_result,\n         mer_star_psf_result=mer_star_psf_result,\n-        gaia_psf_result=gaia_psf_result\n+        gaia_psf_result=gaia_psf_result,\n+        mosaicing_result=mosaicing_result,\n+        background_result=background_result\n     )\n \n     return merged_analysis_result\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T11:47:15.000+00:00",
                            "9d681bfaa9e90d2e3d8279e2616d18ef13eef190"
                        ],
                        [
                            "@@ -26,7 +26,7 @@ from euclidwf.framework.workflow_dsl import pipeline\n from PkgDef_MER_AnalyseTileGaia import *\n \n @pipeline(outputs=(\"merged_analysis_result\"))\n-def mer_pipeline(final_catalog, all_mosaics, gaia_cutout, tile, configuration_set):\n+def mer_pipeline(final_catalog, all_mosaics, segmap, gaia_cutout, tile, configuration_set):\n     \"\"\"\n     Main analysis pipeline for the MER PF\n     \"\"\"\n@@ -68,6 +68,10 @@ def mer_pipeline(final_catalog, all_mosaics, gaia_cutout, tile, configuration_se\n         mosaics=all_mosaics,\n         gaia_cutout=gaia_cutout\n     )\n+    mosaicing_result, background_result = MER_MosaicingValidationPrg(\n+        mosaics=all_mosaics,\n+        segmap=segmap\n+    )\n \n     merged_analysis_result = MER_MergeValidationResults(\n         photometry_result=photometry_result,\n@@ -76,7 +80,9 @@ def mer_pipeline(final_catalog, all_mosaics, gaia_cutout, tile, configuration_se\n         classification_result=classification_result,\n         psf_result=psf_result,\n         mer_star_psf_result=mer_star_psf_result,\n-        gaia_psf_result=gaia_psf_result\n+        gaia_psf_result=gaia_psf_result,\n+        mosaicing_result=mosaicing_result,\n+        background_result=background_result\n     )\n \n     return merged_analysis_result\n",
                            "add MosaicingValidationPrg to the AnalyseTileGaia pipeline",
                            "yfang",
                            "2023-08-14T18:25:53.000+02:00",
                            "3a7b450e921778912f6ffc79366157ad2c0b1184"
                        ],
                        [
                            "@@ -49,6 +49,12 @@ def mer_pipeline(final_catalog, all_mosaics, gaia_cutout, tile, configuration_se\n         configuration_set=configuration_set\n     )\n \n+    classification_result = MER_ClassificationValidation(\n+        final_catalog=final_catalog,\n+        gaia_cutout=gaia_cutout,\n+        configuration_set=configuration_set\n+    )\n+\n     psf_result = MER_PsfValidation(\n         mosaics=all_mosaics\n     )\n@@ -67,6 +73,7 @@ def mer_pipeline(final_catalog, all_mosaics, gaia_cutout, tile, configuration_se\n         photometry_result=photometry_result,\n         astrometry_result=astrometry_result,\n         detection_result=detection_result,\n+        classification_result=classification_result,\n         psf_result=psf_result,\n         mer_star_psf_result=mer_star_psf_result,\n         gaia_psf_result=gaia_psf_result\n",
                            "Adds the classification step",
                            "Javier Gracia Carpio",
                            "2023-08-10T19:42:23.000+00:00",
                            "62735fd620a56e5e537f75a5cdabcaaa17a9bee5"
                        ],
                        [
                            "@@ -58,12 +58,18 @@ def mer_pipeline(final_catalog, all_mosaics, gaia_cutout, tile, configuration_se\n         final_catalog=final_catalog\n     )\n \n+    gaia_psf_result = MER_GaiaPsfValidation(\n+        mosaics=all_mosaics,\n+        gaia_cutout=gaia_cutout\n+    )\n+\n     merged_analysis_result = MER_MergeValidationResults(\n         photometry_result=photometry_result,\n         astrometry_result=astrometry_result,\n         detection_result=detection_result,\n         psf_result=psf_result,\n-        mer_star_psf_result=mer_star_psf_result\n+        mer_star_psf_result=mer_star_psf_result,\n+        gaia_psf_result=gaia_psf_result\n     )\n \n     return merged_analysis_result\n",
                            "Adds Gaia PSF validation step",
                            "Javier Gracia Carpio",
                            "2023-08-10T16:23:09.000+00:00",
                            "77feb68869a4a208c50a97b3d3e80dd84b14afc7"
                        ],
                        [
                            "@@ -26,14 +26,13 @@ from euclidwf.framework.workflow_dsl import pipeline\n from PkgDef_MER_AnalyseTileGaia import *\n \n @pipeline(outputs=(\"merged_analysis_result\"))\n-def mer_pipeline(final_catalog, gaia_cutout, tile, configuration_set):\n+def mer_pipeline(final_catalog, all_mosaics, gaia_cutout, tile, configuration_set):\n     \"\"\"\n     Main analysis pipeline for the MER PF\n     \"\"\"\n-    detection_result = MER_DetValidation(\n+    photometry_result = MER_PhotometryValidation(\n         final_catalog=final_catalog,\n         gaia_cutout=gaia_cutout,\n-        tile_file=tile,\n         configuration_set=configuration_set\n     )\n \n@@ -50,16 +49,21 @@ def mer_pipeline(final_catalog, gaia_cutout, tile, configuration_set):\n         configuration_set=configuration_set\n     )\n \n-    photometry_result = MER_PhotometryValidation(\n-        final_catalog=final_catalog,\n-        gaia_cutout=gaia_cutout,\n-        configuration_set=configuration_set\n+    psf_result = MER_PsfValidation(\n+        mosaics=all_mosaics\n+    )\n+\n+    mer_star_psf_result = MER_MerStarPsfValidation(\n+        mosaics=all_mosaics,\n+        final_catalog=final_catalog\n     )\n \n     merged_analysis_result = MER_MergeValidationResults(\n+        photometry_result=photometry_result,\n         astrometry_result=astrometry_result,\n         detection_result=detection_result,\n-        photometry_result=photometry_result\n+        psf_result=psf_result,\n+        mer_star_psf_result=mer_star_psf_result\n     )\n \n     return merged_analysis_result\n",
                            "Adds mosaics inputs to the gaia validation pipeline",
                            "Javier Gracia Carpio",
                            "2023-08-10T14:30:31.000+00:00",
                            "c60aef018ad53b4f543701cee1592e90c3a469e4"
                        ],
                        [
                            "@@ -26,14 +26,14 @@ from euclidwf.framework.workflow_dsl import pipeline\n from PkgDef_MER_AnalyseTileGaia import *\n \n @pipeline(outputs=(\"merged_analysis_result\"))\n-def mer_pipeline(final_catalog, gaia_cutout, tile_file, configuration_set):\n+def mer_pipeline(final_catalog, gaia_cutout, tile, configuration_set):\n     \"\"\"\n     Main analysis pipeline for the MER PF\n     \"\"\"\n     detection_result = MER_DetValidation(\n         final_catalog=final_catalog,\n         gaia_cutout=gaia_cutout,\n-        tile_file=tile_file,\n+        tile_file=tile,\n         configuration_set=configuration_set\n     )\n \n@@ -46,7 +46,7 @@ def mer_pipeline(final_catalog, gaia_cutout, tile_file, configuration_set):\n     detection_result = MER_DetectionValidation(\n         final_catalog=final_catalog,\n         gaia_cutout=gaia_cutout,\n-        tile_file=tile_file,\n+        tile_file=tile,\n         configuration_set=configuration_set\n     )\n \n",
                            "Update pipeline def",
                            "Javier Gracia Carpio",
                            "2023-07-21T14:01:34.000+00:00",
                            "b440cbd673835a5ba3d3e5ad7fa64838cd540433"
                        ],
                        [
                            "@@ -26,18 +26,40 @@ from euclidwf.framework.workflow_dsl import pipeline\n from PkgDef_MER_AnalyseTileGaia import *\n \n @pipeline(outputs=(\"merged_analysis_result\"))\n-def mer_pipeline(final_catalog, gaia_cutout, configuration_set):\n+def mer_pipeline(final_catalog, gaia_cutout, tile_file, configuration_set):\n     \"\"\"\n     Main analysis pipeline for the MER PF\n     \"\"\"\n+    detection_result = MER_DetValidation(\n+        final_catalog=final_catalog,\n+        gaia_cutout=gaia_cutout,\n+        tile_file=tile_file,\n+        configuration_set=configuration_set\n+    )\n+\n     astrometry_result = MER_AstrometryValidation(\n         final_catalog=final_catalog,\n         gaia_cutout=gaia_cutout,\n         configuration_set=configuration_set\n     )\n \n+    detection_result = MER_DetectionValidation(\n+        final_catalog=final_catalog,\n+        gaia_cutout=gaia_cutout,\n+        tile_file=tile_file,\n+        configuration_set=configuration_set\n+    )\n+\n+    photometry_result = MER_PhotometryValidation(\n+        final_catalog=final_catalog,\n+        gaia_cutout=gaia_cutout,\n+        configuration_set=configuration_set\n+    )\n+\n     merged_analysis_result = MER_MergeValidationResults(\n-        astrometry_result=astrometry_result\n+        astrometry_result=astrometry_result,\n+        detection_result=detection_result,\n+        photometry_result=photometry_result\n     )\n \n     return merged_analysis_result\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:50:41.000+00:00",
                            "b61999f44bcba73649185b197918dd343601a31d"
                        ],
                        [
                            "@@ -30,6 +30,13 @@ def mer_pipeline(final_catalog, gaia_cutout, tile_file, configuration_set):\n     \"\"\"\n     Main analysis pipeline for the MER PF\n     \"\"\"\n+    detection_result = MER_DetValidation(\n+        final_catalog=final_catalog,\n+        gaia_cutout=gaia_cutout,\n+        tile_file=tile_file,\n+        configuration_set=configuration_set\n+    )\n+\n     astrometry_result = MER_AstrometryValidation(\n         final_catalog=final_catalog,\n         gaia_cutout=gaia_cutout,\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines into develop",
                            "yfang",
                            "2023-07-20T14:52:13.000+02:00",
                            "435e24aa5c3078f91782c91fe687450349b25e0f"
                        ],
                        [
                            "@@ -26,7 +26,7 @@ from euclidwf.framework.workflow_dsl import pipeline\n from PkgDef_MER_AnalyseTileGaia import *\n \n @pipeline(outputs=(\"merged_analysis_result\"))\n-def mer_pipeline(final_catalog, gaia_cutout, configuration_set):\n+def mer_pipeline(final_catalog, gaia_cutout, tile_file, configuration_set):\n     \"\"\"\n     Main analysis pipeline for the MER PF\n     \"\"\"\n@@ -36,8 +36,23 @@ def mer_pipeline(final_catalog, gaia_cutout, configuration_set):\n         configuration_set=configuration_set\n     )\n \n+    detection_result = MER_DetectionValidation(\n+        final_catalog=final_catalog,\n+        gaia_cutout=gaia_cutout,\n+        tile_file=tile_file,\n+        configuration_set=configuration_set\n+    )\n+\n+    photometry_result = MER_PhotometryValidation(\n+        final_catalog=final_catalog,\n+        gaia_cutout=gaia_cutout,\n+        configuration_set=configuration_set\n+    )\n+\n     merged_analysis_result = MER_MergeValidationResults(\n-        astrometry_result=astrometry_result\n+        astrometry_result=astrometry_result,\n+        detection_result=detection_result,\n+        photometry_result=photometry_result\n     )\n \n     return merged_analysis_result\n",
                            "add photometry validation to pipeline",
                            "yfang",
                            "2023-07-20T14:50:03.000+02:00",
                            "55942f26187474b2de694e8eb9d05be36f7cf234"
                        ],
                        [
                            "@@ -26,10 +26,17 @@ from euclidwf.framework.workflow_dsl import pipeline\n from PkgDef_MER_AnalyseTileGaia import *\n \n @pipeline(outputs=(\"merged_analysis_result\"))\n-def mer_pipeline(final_catalog, gaia_cutout, configuration_set):\n+def mer_pipeline(final_catalog, gaia_cutout, tile_file, configuration_set):\n     \"\"\"\n     Main analysis pipeline for the MER PF\n     \"\"\"\n+    detection_result = MER_DetValidation(\n+        final_catalog=final_catalog,\n+        gaia_cutout=gaia_cutout,\n+        tile_file=tile_file,\n+        configuration_set=configuration_set\n+    )\n+\n     astrometry_result = MER_AstrometryValidation(\n         final_catalog=final_catalog,\n         gaia_cutout=gaia_cutout,\n@@ -37,7 +44,8 @@ def mer_pipeline(final_catalog, gaia_cutout, configuration_set):\n     )\n \n     merged_analysis_result = MER_MergeValidationResults(\n-        astrometry_result=astrometry_result\n+        astrometry_result=astrometry_result,\n+        detection_result=detection_result\n     )\n \n     return merged_analysis_result\n",
                            "Integrated the detection validation.",
                            "Martin Kuemmel",
                            "2023-07-20T14:41:54.000+02:00",
                            "96efffdda590a304b80cedb01061dc4f62f37b50"
                        ],
                        [
                            "@@ -25,15 +25,19 @@ from euclidwf.framework.workflow_dsl import pipeline\n \n from PkgDef_MER_AnalyseTileGaia import *\n \n-@pipeline(outputs=(\"analysis_result\"))\n+@pipeline(outputs=(\"merged_analysis_result\"))\n def mer_pipeline(final_catalog, gaia_cutout, configuration_set):\n     \"\"\"\n     Main analysis pipeline for the MER PF\n     \"\"\"\n-    analysis_result = MER_AstrometryValidation(\n-        mer_catalog=final_catalog,\n+    astrometry_result = MER_AstrometryValidation(\n+        final_catalog=final_catalog,\n         gaia_cutout=gaia_cutout,\n         configuration_set=configuration_set\n     )\n \n-    return analysis_result\n+    merged_analysis_result = MER_MergeValidationResults(\n+        astrometry_result=astrometry_result\n+    )\n+\n+    return merged_analysis_result\n",
                            "Merge branch 'feature/gaia_index' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T21:40:49.000+00:00",
                            "b5c7c0d135177fbca99d1a973a2207fc5ee7d6dc"
                        ],
                        [
                            "@@ -25,15 +25,19 @@ from euclidwf.framework.workflow_dsl import pipeline\n \n from PkgDef_MER_AnalyseTileGaia import *\n \n-@pipeline(outputs=(\"analysis_result\"))\n+@pipeline(outputs=(\"merged_analysis_result\"))\n def mer_pipeline(final_catalog, gaia_cutout, configuration_set):\n     \"\"\"\n     Main analysis pipeline for the MER PF\n     \"\"\"\n-    analysis_result = MER_AstrometryValidation(\n-        mer_catalog=final_catalog,\n+    astrometry_result = MER_AstrometryValidation(\n+        final_catalog=final_catalog,\n         gaia_cutout=gaia_cutout,\n         configuration_set=configuration_set\n     )\n \n-    return analysis_result\n+    merged_analysis_result = MER_MergeValidationResults(\n+        astrometry_result=astrometry_result\n+    )\n+\n+    return merged_analysis_result\n",
                            "Added the index to the GAIA validation",
                            "Martin Kuemmel",
                            "2023-07-04T23:18:12.000+02:00",
                            "53c7a3a924b3acb720ccc5a2d7137737ed711069"
                        ],
                        [
                            "@@ -23,7 +23,7 @@ MER analysis pipeline script file for real data\n \n from euclidwf.framework.workflow_dsl import pipeline\n \n-from PkgDef_MER_GaiaAnalyseTile import *\n+from PkgDef_MER_AnalyseTileGaia import *\n \n @pipeline(outputs=(\"analysis_result\"))\n def mer_pipeline(final_catalog, gaia_cutout, configuration_set):\n",
                            "Use better names",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:36:54.000+00:00",
                            "a9ff684e194f0bbf670427c515527a348a9b7da3"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_AnalyseTile_Pipeline/PipDef_MER_AnalyseTile_GAIA.xml": [
                        [
                            "@@ -3,7 +3,7 @@\n     <EdenVersion>Eden-3.1-dev</EdenVersion>\n     <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_ANALYSE_TILE_GAIA_DEV_10.2_2023-07-21</Id>\n+    <Id>PipDef_MER_ANALYSE_TILE_GAIA_DEV_10.2_2023-08-16</Id>\n     <PipelineVersion>10.2</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n@@ -32,6 +32,15 @@\n                 <Max>27</Max>\n             </Cardinality>\n         </InputDataPlan>\n+        <InputDataPlan>\n+            <InputPortName>final_segmentation_map</InputPortName>\n+            <DataProductType>DpdMerSegmentationMap</DataProductType>\n+            <Cardinality>\n+                <Optionality>MANDATORY</Optionality>\n+                <Min>1</Min>\n+                <Max>1</Max>\n+            </Cardinality>\n+        </InputDataPlan>\n         <InputDataPlan>\n             <InputPortName>gaia_cutout</InputPortName>\n             <DataProductType>DpdExtGaiaCutout</DataProductType>\n@@ -67,6 +76,9 @@\n             <LinkedBy refPort=\"final_catalog\">\n                 <Query>final_catalog.Header.PPOId == all_mosaics.Header.PPOId</Query>\n             </LinkedBy>\n+            <LinkedBy refPort=\"final_catalog\">\n+                <Query>final_catalog.Header.PPOId == final_segmentation_map.Header.PPOId</Query>\n+            </LinkedBy>\n             <LinkedBy refPort=\"final_catalog\">\n                 <Query>final_catalog.Data.TileIndex == gaia_cutouts.Data.TileIndex</Query>\n             </LinkedBy>\n",
                            "Updates pipeline def and renames segmap input port",
                            "Javier Gracia Carpio",
                            "2023-08-16T11:54:22.000+00:00",
                            "73e7c9748d2348152d680bd50f99ea8291c54b44"
                        ],
                        [
                            "@@ -23,6 +23,15 @@\n                 <Max>1</Max>\n             </Cardinality>\n         </KeyProductInputDataPlan>\n+        <InputDataPlan>\n+            <InputPortName>all_mosaics</InputPortName>\n+            <DataProductType>DpdMerBksMosaic</DataProductType>\n+            <Cardinality>\n+                <Optionality>MANDATORY</Optionality>\n+                <Min>1</Min>\n+                <Max>27</Max>\n+            </Cardinality>\n+        </InputDataPlan>\n         <InputDataPlan>\n             <InputPortName>gaia_cutout</InputPortName>\n             <DataProductType>DpdExtGaiaCutout</DataProductType>\n@@ -55,6 +64,9 @@\n             </Cardinality>\n         </InputDataPlan>\n         <Dependencies>\n+            <LinkedBy refPort=\"final_catalog\">\n+                <Query>final_catalog.Header.PPOId == all_mosaics.Header.PPOId</Query>\n+            </LinkedBy>\n             <LinkedBy refPort=\"final_catalog\">\n                 <Query>final_catalog.Data.TileIndex == gaia_cutouts.Data.TileIndex</Query>\n             </LinkedBy>\n",
                            "Adds mosaics inputs to the gaia validation pipeline",
                            "Javier Gracia Carpio",
                            "2023-08-10T14:30:31.000+00:00",
                            "c60aef018ad53b4f543701cee1592e90c3a469e4"
                        ],
                        [
                            "@@ -3,7 +3,7 @@\n     <EdenVersion>Eden-3.1-dev</EdenVersion>\n     <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_ANALYSE_TILE_GAIA_DEV_10.2_2023-07-04</Id>\n+    <Id>PipDef_MER_ANALYSE_TILE_GAIA_DEV_10.2_2023-07-21</Id>\n     <PipelineVersion>10.2</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n@@ -34,6 +34,16 @@\n                 <Max>1</Max>\n             </Cardinality>\n         </InputDataPlan>\n+        <InputDataPlan>\n+            <InputPortName>tile</InputPortName>\n+            <DataProductType>DpdMerTile</DataProductType>\n+            <InputQuerySpecPlan>(tile.Header.ManualValidationStatus != \"INVALID\") &amp; (tile.Header.DataSetRelease == \"UNKNOWN\") &amp; (tile.Data.TileUseCase == \"UNKNOWN\")</InputQuerySpecPlan>\n+            <Cardinality>\n+                <Optionality>MANDATORY</Optionality>\n+                <Min>1</Min>\n+                <Max>1</Max>\n+            </Cardinality>\n+        </InputDataPlan>\n         <InputDataPlan>\n             <InputPortName>configuration_set</InputPortName>\n             <DataProductType>DpdMerConfigurationSet</DataProductType>\n@@ -48,6 +58,9 @@\n             <LinkedBy refPort=\"final_catalog\">\n                 <Query>final_catalog.Data.TileIndex == gaia_cutouts.Data.TileIndex</Query>\n             </LinkedBy>\n+            <LinkedBy refPort=\"final_catalog\">\n+                <Query>final_catalog.Data.TileIndex == tile.Data.TileIndex</Query>\n+            </LinkedBy>\n         </Dependencies>\n     </InputDataSet>\n     <OutputDataSet>\n",
                            "Update pipeline def",
                            "Javier Gracia Carpio",
                            "2023-07-21T14:01:34.000+00:00",
                            "b440cbd673835a5ba3d3e5ad7fa64838cd540433"
                        ],
                        [
                            "@@ -3,11 +3,11 @@\n     <EdenVersion>Eden-3.1-dev</EdenVersion>\n     <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_GAIA_ANALYSE_TILE_DEV_10.2_2023-07-04</Id>\n+    <Id>PipDef_MER_ANALYSE_TILE_GAIA_DEV_10.2_2023-07-04</Id>\n     <PipelineVersion>10.2</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n-    <PipelineScriptPath>PipScript_MER_GaiaAnalyseTile.py</PipelineScriptPath>\n+    <PipelineScriptPath>PipScript_MER_AnalyseTileGaia.py</PipelineScriptPath>\n     <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.2/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_AnalyseTile_Pipeline/</PipelineRootPath>\n     <InputDataSet>\n         <KeyProductInputDataPlan>\n",
                            "Use better names",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:36:54.000+00:00",
                            "a9ff684e194f0bbf670427c515527a348a9b7da3"
                        ]
                    ],
                    "doc/release_note/MER_Software_Release_Note.md": [
                        [
                            "@@ -4,7 +4,7 @@\n | PF Release | 10.1.2                                  |\n | Date:      | 07/08/2023                              |\n | Doc. Issue | 1.0                                     |\n-| Reference: | EUCL-???                                |\n+| Reference: | EUCL-OTS-SW-8-001                       |\n | Custodian: | J. Gracia Carpio                        |\n \n # Table of Contents\n",
                            "Adds document reference id",
                            "Javier Gracia Carpio",
                            "2023-08-11T13:06:50.000+00:00",
                            "60c37757a507175d4ba8c190e3fda4cd29b59026"
                        ],
                        [
                            "@@ -44,7 +44,7 @@ The release 10.1.2 of the MER PF has been developed for the Performance Verifica\n | [STS](https://euclid.roe.ac.uk/dmsf/files/16218/view) | Validation Plan & Software Tests Specifications| EUCL-OAR-PL-8-002 | 1.74 |\n | [SDD](https://euclid.roe.ac.uk/dmsf/files/3922/view) | Software Design Document| EUCL-OTS-DDD-8-003 | 1.71 |\n | [STR](https://euclid.roe.ac.uk/dmsf/files/19746/view) | Software Test Report| EUCL-OTS-TR-8-002 | 1.0 |\n-| [SUM](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines/-/tree/release-10.1/doc/user_manual) | Software User Manual MER Pipeline | EUCL-OTS-MA-8-001 | 5.0 |\n+| [SUM](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines/-/tree/release-10.1/doc/user_manual) | Software User Manual MER Pipeline | EUCL-OTS-MA-8-001 | 5.1 |\n \n \n # 3. PF Software products <a name=\"software\"></a>\n",
                            "Use new SUM version",
                            "Javier Gracia Carpio",
                            "2023-08-07T14:51:58.000+00:00",
                            "76b7c412bf0515059be58af0de315331efc53353"
                        ],
                        [
                            "@@ -40,6 +40,10 @@ The release 10.1.2 of the MER PF has been developed for the Performance Verifica\n \n | RD | Title / Author | Document reference | Doc. Release |\n | -----------   | ----------- | ----------- |----------- |\n+| [RSD](https://euclid.roe.ac.uk/dmsf/files/16098/view) | Requirements Specification Document | EUCL-OAR-RS-8-002 | 1.1 |\n+| [STS](https://euclid.roe.ac.uk/dmsf/files/16218/view) | Validation Plan & Software Tests Specifications| EUCL-OAR-PL-8-002 | 1.74 |\n+| [SDD](https://euclid.roe.ac.uk/dmsf/files/3922/view) | Software Design Document| EUCL-OTS-DDD-8-003 | 1.71 |\n+| [STR](https://euclid.roe.ac.uk/dmsf/files/19746/view) | Software Test Report| EUCL-OTS-TR-8-002 | 1.0 |\n | [SUM](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines/-/tree/release-10.1/doc/user_manual) | Software User Manual MER Pipeline | EUCL-OTS-MA-8-001 | 5.0 |\n \n \n",
                            "Merge branch 'develop' of git@gitlab.euclid-sgs.uk:PF-MER/MER_IAL_Pipelines into develop",
                            "Javier Gracia Carpio",
                            "2023-08-07T14:49:47.000+00:00",
                            "0bcb9a77cd097c672c43e58b130a4ad7d204605e"
                        ],
                        [
                            "@@ -3,7 +3,7 @@\n | Title      | Euclid SGS MER PF Software Release Note |\n | PF Release | 10.1.2                                  |\n | Date:      | 07/08/2023                              |\n-| Doc. Issue | 10.1.2                                  |\n+| Doc. Issue | 1.0                                     |\n | Reference: | EUCL-???                                |\n | Custodian: | J. Gracia Carpio                        |\n \n@@ -56,7 +56,7 @@ The PF User Manual [SUM] describes the principal software parts of the system, i\n | Envt                   | Version                                                                       |\n |------------------------|-------------------------------------------------------------------------------|\n | EDEN                   | 3.1                                                                           |\n-| Data Model             | 9.2.1                                                                         |\n+| Data Model             | 9.2.0                                                                         |\n | PF IAL Pipelines conf. | [10.1.2](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines/-/tree/10.1.2) |\n \n \n@@ -79,8 +79,8 @@ The PF User Manual [SUM] describes the principal software parts of the system, i\n | [MER_CatalogAssembly](https://gitlab.euclid-sgs.uk/PF-MER/MER_CatalogAssembly)     | [10.1.1](https://gitlab.euclid-sgs.uk/PF-MER/MER_CatalogAssembly/-/tree/10.1.1)   | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_CatalogAssembly) |\n | [MER_Validation](https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation)               | [10.1.0](https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation/-/tree/10.1.0)        | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_Validation) |\n | [MER_Pipeline](https://gitlab.euclid-sgs.uk/PF-MER/MER_Pipeline)                   | [10.1.0](https://gitlab.euclid-sgs.uk/PF-MER/MER_Pipeline/-/tree/10.1.0)          | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_Pipeline) |\n-| [MER_ProcessingUtils](https://gitlab.euclid-sgs.uk/PF-MER/MER_ProcessingUtils)     | [10.1.1](https://gitlab.euclid-sgs.uk/PF-MER/MER_ProcessingUtils/-/tree/10.1.1)   | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_ProcessingUtils) |\n-| [MER_IAL_Pipelines](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines)         | [10.1.1](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines/-/tree/10.1.1)     | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_IAL_Pipelines) |\n+| [MER_IAL_Pipelines](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines)         | [10.1.2](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines/-/tree/10.1.2)     | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_IAL_Pipelines) |\n+| [MER_ProcessingUtils](https://gitlab.euclid-sgs.uk/PF-MER/MER_ProcessingUtils)     | [10.1.2](https://gitlab.euclid-sgs.uk/PF-MER/MER_ProcessingUtils/-/tree/10.1.2)   | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_ProcessingUtils) |\n \n \n # 4. Main Changes in this Release <a name=\"changes_and_fixed_issues\"></a>\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines.git into develop",
                            "Martin Kuemmel",
                            "2023-08-07T16:44:19.000+02:00",
                            "f682ab8d13a80df068a83b12cfb85e8fd31a3159"
                        ],
                        [
                            "@@ -40,6 +40,10 @@ The release 10.1.2 of the MER PF has been developed for the Performance Verifica\n \n | RD | Title / Author | Document reference | Doc. Release |\n | -----------   | ----------- | ----------- |----------- |\n+| [RSD](https://euclid.roe.ac.uk/dmsf/files/16098/view) | Requirements Specification Document | EUCL-OAR-RS-8-002 | 1.1 |\n+| [STS](https://euclid.roe.ac.uk/dmsf/files/16218/view) | Validation Plan & Software Tests Specifications| EUCL-OAR-PL-8-002 | 1.74 |\n+| [SDD](https://euclid.roe.ac.uk/dmsf/files/3922/view) | Software Design Document| EUCL-OTS-DDD-8-003 | 1.71 |\n+| [STR](https://euclid.roe.ac.uk/dmsf/files/19746/view) | Software Test Report| EUCL-OTS-TR-8-002 | 1.0 |\n | [SUM](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines/-/tree/release-10.1/doc/user_manual) | Software User Manual MER Pipeline | EUCL-OTS-MA-8-001 | 5.0 |\n \n \n",
                            "Added links to reference documents",
                            "Martin Kuemmel",
                            "2023-08-07T16:44:06.000+02:00",
                            "64bd86870db14b362be21640b207d32640b3b879"
                        ],
                        [
                            "@@ -3,7 +3,7 @@\n | Title      | Euclid SGS MER PF Software Release Note |\n | PF Release | 10.1.2                                  |\n | Date:      | 07/08/2023                              |\n-| Doc. Issue | 10.1.2                                  |\n+| Doc. Issue | 1.0                                     |\n | Reference: | EUCL-???                                |\n | Custodian: | J. Gracia Carpio                        |\n \n@@ -52,7 +52,7 @@ The PF User Manual [SUM] describes the principal software parts of the system, i\n | Envt                   | Version                                                                       |\n |------------------------|-------------------------------------------------------------------------------|\n | EDEN                   | 3.1                                                                           |\n-| Data Model             | 9.2.1                                                                         |\n+| Data Model             | 9.2.0                                                                         |\n | PF IAL Pipelines conf. | [10.1.2](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines/-/tree/10.1.2) |\n \n \n@@ -75,8 +75,8 @@ The PF User Manual [SUM] describes the principal software parts of the system, i\n | [MER_CatalogAssembly](https://gitlab.euclid-sgs.uk/PF-MER/MER_CatalogAssembly)     | [10.1.1](https://gitlab.euclid-sgs.uk/PF-MER/MER_CatalogAssembly/-/tree/10.1.1)   | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_CatalogAssembly) |\n | [MER_Validation](https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation)               | [10.1.0](https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation/-/tree/10.1.0)        | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_Validation) |\n | [MER_Pipeline](https://gitlab.euclid-sgs.uk/PF-MER/MER_Pipeline)                   | [10.1.0](https://gitlab.euclid-sgs.uk/PF-MER/MER_Pipeline/-/tree/10.1.0)          | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_Pipeline) |\n-| [MER_ProcessingUtils](https://gitlab.euclid-sgs.uk/PF-MER/MER_ProcessingUtils)     | [10.1.1](https://gitlab.euclid-sgs.uk/PF-MER/MER_ProcessingUtils/-/tree/10.1.1)   | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_ProcessingUtils) |\n-| [MER_IAL_Pipelines](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines)         | [10.1.1](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines/-/tree/10.1.1)     | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_IAL_Pipelines) |\n+| [MER_IAL_Pipelines](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines)         | [10.1.2](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines/-/tree/10.1.2)     | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_IAL_Pipelines) |\n+| [MER_ProcessingUtils](https://gitlab.euclid-sgs.uk/PF-MER/MER_ProcessingUtils)     | [10.1.2](https://gitlab.euclid-sgs.uk/PF-MER/MER_ProcessingUtils/-/tree/10.1.2)   | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_ProcessingUtils) |\n \n \n # 4. Main Changes in this Release <a name=\"changes_and_fixed_issues\"></a>\n",
                            "Updates versions",
                            "Javier Gracia Carpio",
                            "2023-08-07T13:50:39.000+00:00",
                            "abd21ceab1ed84e018a7db3138ad8d5c452ddf06"
                        ],
                        [
                            "@@ -40,7 +40,7 @@ The release 10.1.2 of the MER PF has been developed for the Performance Verifica\n \n | RD | Title / Author | Document reference | Doc. Release |\n | -----------   | ----------- | ----------- |----------- |\n-| [SUM](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines/-/tree/release-10.1/doc/user_manual) | EucSoftware User Manual MER Pipeline | EUCL-OTS-MA-8-001 | 5.0 |\n+| [SUM](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines/-/tree/release-10.1/doc/user_manual) | Software User Manual MER Pipeline | EUCL-OTS-MA-8-001 | 5.0 |\n \n \n # 3. PF Software products <a name=\"software\"></a>\n",
                            "Updates the SUM",
                            "Javier Gracia Carpio",
                            "2023-08-07T13:24:00.000+00:00",
                            "fca8026919dd64c52dac3b0c920ffa0ba5cc04cc"
                        ],
                        [
                            "@@ -40,19 +40,14 @@ The release 10.1.2 of the MER PF has been developed for the Performance Verifica\n \n | RD | Title / Author | Document reference | Doc. Release |\n | -----------   | ----------- | ----------- |----------- |\n-| RSD | Euclid SGS MER Software Requirements Document | EUCL-OAR-RS-8-002 | |\n-| SDD | Euclid SGS MER Software Design Document | EUCL-OTS-DDD-8-003 | |\n-| [VP-STS](https://euclid.roe.ac.uk/projects/vis_pf/dmsf?folder_id=372) | Euclid SGS PF Euclid SGS PF Validation Plan and Software Tests Specifications  | EUCL-IAP-PL-8-001 |[2.6](https://euclid.roe.ac.uk/dmsf/files/4082/view) |\n-| [STP-STR](https://euclid.roe.ac.uk/projects/vis_pf/dmsf?folder_id=372) | Euclid SGS PF Software Test Plan and Test Report | EUCL-IAP-TP-8-001| [7.0.3](https://euclid.roe.ac.uk/dmsf/files/4807/view) |\n-| [SUM](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines/-/tree/release-10.1/doc/user_manual) | Euclid SGS MER PF Software User Manual | EUCL-OTS-MA-8-001 | 5.0 |\n-| [CCB]|Euclid SGS PF Configuration Control Board report   | -  | - |\n+| [SUM](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines/-/tree/release-10.1/doc/user_manual) | EucSoftware User Manual MER Pipeline | EUCL-OTS-MA-8-001 | 5.0 |\n \n \n # 3. PF Software products <a name=\"software\"></a>\n \n ## 3.1 PF Environment configuration <a name=\"envt\"></a>\n \n-The PF User Manual [RD5] describes the principal software parts of the system, including other software, such as operating systems, utilities, other supporting systems, and other facilities, equipment or resources.\n+The PF User Manual [SUM] describes the principal software parts of the system, including other software, such as operating systems, utilities, other supporting systems, and other facilities, equipment or resources.\n \n | Envt                   | Version                                                                       |\n |------------------------|-------------------------------------------------------------------------------|\n@@ -92,7 +87,7 @@ This release is deployed as part of the cvmfs and does fully comply with the COD\n \n ## 4.1 Functional changes <a name=\"changes\"></a>\n \n-This is the first oficial release of the MER pipeline for the PV phase.\n+This is the first official release of the MER pipeline for the PV phase.\n \n \n ## 4.2 Bugs fixed  <a name=\"fixed_issues\"></a>\n@@ -111,4 +106,4 @@ Bug reports and software change/addition requests should be submitted through th\n \n | Issue | Title |\n | ----- | ----- |\n-| [#23342](hhttps://euclid.roe.ac.uk/issues/23342) | MER mosaicing fails due to disk space limitations |\n+| [#23342](https://euclid.roe.ac.uk/issues/23342) | MER mosaicing fails due to disk space limitations |\n",
                            "Fixes some typos and removes unused doc references",
                            "Javier Gracia Carpio",
                            "2023-08-07T10:33:20.000+00:00",
                            "dac64c9cbc4bd5f8ddd77d3c23f56ef17d5ef5c1"
                        ],
                        [
                            "@@ -0,0 +1,114 @@\n+|            | **Document Identification**             |\n+|------------|-----------------------------------------|\n+| Title      | Euclid SGS MER PF Software Release Note |\n+| PF Release | 10.1.2                                  |\n+| Date:      | 07/08/2023                              |\n+| Doc. Issue | 10.1.2                                  |\n+| Reference: | EUCL-???                                |\n+| Custodian: | J. Gracia Carpio                        |\n+\n+# Table of Contents\n+\n+1. [Purpose and Scope](#purpose_and_scope)\n+    * [1.1 Scope of this PF Software](#scope)\n+    * [1.2 Purpose of the PF](#purpose)\n+2. [PF Documents](#documentation)\n+3. [PF Software products](#software)\n+    * [3.1 PF Environment configuration](#envt)\n+    * [3.2 PF software products configuration](#products)\n+ 4. [Changes Major Release](#changes_and_fixed_issues)\n+    * [4.1 Functional changes in this release](#changes)\n+    * [4.2 Issues fixed](#fixed_issues)\n+5. [Patch releases](#patches)\n+6. [Known issues](#known_issues)\n+\n+# 1. Purpose and Scope <a name=\"purpose_and_scope\"></a>\n+\n+## 1.1 Scope of this PF Software Release Note <a name=\"scope\"></a>\n+\n+The objective of the **S**oftware **R**elease **N**ote (SRN) is to provide the configuration status of the software configuration item.\n+It controls its evolution during the programme or project life cycle.\n+\n+## 1.2 Purpose of this PF Release <a name=\"purpose\"></a>\n+\n+The MER processing function is part of the Euclid SGS data processing software and is intended to be executed automatically inside the Euclid SGS infrastructure.\n+\n+The release 10.1.2 of the MER PF has been developed for the Performance Verification phase which will start in mid August 2023.\n+\n+# 2. PF Documents <a name=\"documentation\"></a>\n+\n+\n+| RD | Title / Author | Document reference | Doc. Release |\n+| -----------   | ----------- | ----------- |----------- |\n+| RSD | Euclid SGS MER Software Requirements Document | EUCL-OAR-RS-8-002 | |\n+| SDD | Euclid SGS MER Software Design Document | EUCL-OTS-DDD-8-003 | |\n+| [VP-STS](https://euclid.roe.ac.uk/projects/vis_pf/dmsf?folder_id=372) | Euclid SGS PF Euclid SGS PF Validation Plan and Software Tests Specifications  | EUCL-IAP-PL-8-001 |[2.6](https://euclid.roe.ac.uk/dmsf/files/4082/view) |\n+| [STP-STR](https://euclid.roe.ac.uk/projects/vis_pf/dmsf?folder_id=372) | Euclid SGS PF Software Test Plan and Test Report | EUCL-IAP-TP-8-001| [7.0.3](https://euclid.roe.ac.uk/dmsf/files/4807/view) |\n+| [SUM](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines/-/tree/release-10.1/doc/user_manual) | Euclid SGS MER PF Software User Manual | EUCL-OTS-MA-8-001 | 5.0 |\n+| [CCB]|Euclid SGS PF Configuration Control Board report   | -  | - |\n+\n+\n+# 3. PF Software products <a name=\"software\"></a>\n+\n+## 3.1 PF Environment configuration <a name=\"envt\"></a>\n+\n+The PF User Manual [RD5] describes the principal software parts of the system, including other software, such as operating systems, utilities, other supporting systems, and other facilities, equipment or resources.\n+\n+| Envt                   | Version                                                                       |\n+|------------------------|-------------------------------------------------------------------------------|\n+| EDEN                   | 3.1                                                                           |\n+| Data Model             | 9.2.1                                                                         |\n+| PF IAL Pipelines conf. | [10.1.2](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines/-/tree/10.1.2) |\n+\n+\n+## 3.2 PF software products configuration <a name=\"products\"></a>\n+\n+\n+| Gitlab project | Gitlab tag | SonarQube analysis |\n+| -------------- | ---------- | ------------------ |\n+| [MER_DataModelUtils](https://gitlab.euclid-sgs.uk/PF-MER/MER_DataModelUtils)       | [10.1.0](https://gitlab.euclid-sgs.uk/PF-MER/MER_DataModelUtils/-/tree/10.1.0)    | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_DataModelUtils) |\n+| [MER_DA](https://gitlab.euclid-sgs.uk/PF-MER/MER_DA)                               | [10.1.0](https://gitlab.euclid-sgs.uk/PF-MER/MER_DA/-/tree/10.1.0)                | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_DA) |\n+| [MER_PsfMosaic](https://gitlab.euclid-sgs.uk/PF-MER/MER_PsfMosaic)                 | [10.1.0](https://gitlab.euclid-sgs.uk/PF-MER/MER_PsfMosaic/-/tree/10.1.0)         | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_PsfMosaic) |\n+| [MER_Mosaicing](https://gitlab.euclid-sgs.uk/PF-MER/MER_Mosaicing)                 | [10.1.0](https://gitlab.euclid-sgs.uk/PF-MER/MER_Mosaicing/-/tree/10.1.0)         | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_Mosaicing) |\n+| [MER_Background](https://gitlab.euclid-sgs.uk/PF-MER/MER_Background)               | [10.1.0](https://gitlab.euclid-sgs.uk/PF-MER/MER_Background/-/tree/10.1.0)        | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_Background) |\n+| [MER_Detection](https://gitlab.euclid-sgs.uk/PF-MER/MER_Detection)                 | [10.1.0](https://gitlab.euclid-sgs.uk/PF-MER/MER_Detection/-/tree/10.1.0)         | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_Detection) |\n+| [MER_Deblending](https://gitlab.euclid-sgs.uk/PF-MER/MER_Deblending)               | [10.1.0](https://gitlab.euclid-sgs.uk/PF-MER/MER_Deblending/-/tree/10.1.0)        | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_Deblending) |\n+| [MER_Classification](https://gitlab.euclid-sgs.uk/PF-MER/MER_Classification)       | [10.1.0](https://gitlab.euclid-sgs.uk/PF-MER/MER_Classification/-/tree/10.1.0)    | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_Classification) |\n+| [MER_Morphology](https://gitlab.euclid-sgs.uk/PF-MER/MER_Morphology)               | [10.1.0](https://gitlab.euclid-sgs.uk/PF-MER/MER_Morphology/-/tree/10.1.0)        | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_Morphology) |\n+| [MER_PSFHomogenization](https://gitlab.euclid-sgs.uk/PF-MER/MER_PSFHomogenization) | [10.1.0](https://gitlab.euclid-sgs.uk/PF-MER/MER_PSFHomogenization/-/tree/10.1.0) | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_PSFHomogenization) |\n+| [MER_Photometry](https://gitlab.euclid-sgs.uk/PF-MER/MER_Photometry)               | [10.1.0](https://gitlab.euclid-sgs.uk/PF-MER/MER_Photometry/-/tree/10.1.0)        | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_Photometry) |\n+| [MER_CatalogAssembly](https://gitlab.euclid-sgs.uk/PF-MER/MER_CatalogAssembly)     | [10.1.1](https://gitlab.euclid-sgs.uk/PF-MER/MER_CatalogAssembly/-/tree/10.1.1)   | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_CatalogAssembly) |\n+| [MER_Validation](https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation)               | [10.1.0](https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation/-/tree/10.1.0)        | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_Validation) |\n+| [MER_Pipeline](https://gitlab.euclid-sgs.uk/PF-MER/MER_Pipeline)                   | [10.1.0](https://gitlab.euclid-sgs.uk/PF-MER/MER_Pipeline/-/tree/10.1.0)          | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_Pipeline) |\n+| [MER_ProcessingUtils](https://gitlab.euclid-sgs.uk/PF-MER/MER_ProcessingUtils)     | [10.1.1](https://gitlab.euclid-sgs.uk/PF-MER/MER_ProcessingUtils/-/tree/10.1.1)   | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_ProcessingUtils) |\n+| [MER_IAL_Pipelines](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines)         | [10.1.1](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines/-/tree/10.1.1)     | [release-10.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-10.1&id=MER_IAL_Pipelines) |\n+\n+\n+# 4. Main Changes in this Release <a name=\"changes_and_fixed_issues\"></a>\n+\n+This release of the MER PF is issued for the purpose of usual progress development in the context of the Euclid SGS. It has a particular emphasis with the preparation of the forthcoming Performance and Verification Phase processing.\n+\n+This release is deployed as part of the cvmfs and does fully comply with the CODEEN standards.\n+\n+## 4.1 Functional changes <a name=\"changes\"></a>\n+\n+This is the first oficial release of the MER pipeline for the PV phase.\n+\n+\n+## 4.2 Bugs fixed  <a name=\"fixed_issues\"></a>\n+\n+There are no fixed issues, since this is the first MER pipeline official release. \n+\n+\n+# 5. Patch releases <a name=\"patches\"></a>\n+\n+No patches yet.\n+\n+\n+# 6. Known issues <a name=\"known_issues\"></a>\n+\n+Bug reports and software change/addition requests should be submitted through the Euclid Redmine tool at https://euclid.roe.ac.uk/projects/mer_pf/issues.\n+\n+| Issue | Title |\n+| ----- | ----- |\n+| [#23342](hhttps://euclid.roe.ac.uk/issues/23342) | MER mosaicing fails due to disk space limitations |\n",
                            "Adds first version of the MER release not",
                            "Javier Gracia Carpio",
                            "2023-08-07T10:24:35.000+00:00",
                            "7b1c778bbab3ab69033ef0477a5d96a91590cefc"
                        ]
                    ],
                    "doc/user_manual/chap4.md": [
                        [
                            "@@ -52,8 +52,18 @@ PF `MER` is made of the following pipelines, gathered as following in these grou\n * Group `Analysis`:\n   * `MER_AnalyseTile`\n   * `MER_AnalyseTileVisOnly`\n-* Group `WIDE_ONTHEFLY`:\n-  * `MER_ProcessTile`\n-  * `MER_ProcessTileVisOnly`\n * Group `Morpho`:\n   * `MER_ProcessTileMorpho`\n+\n+\n+## PF input products\n+\n+Most of the MER pipelines require as input a MER configuration set product of type `DpdMerConfigurationSet`.\n+Depending on the tile use case, a different ProductId should be used:\n+\n+* EUC_MER_CONFIGURATION-SET_20230807, for WIDE tiles.\n+* EUC_MER_CONFIGURATION-SET_20230807_DEEP, for DEEP tiles.\n+\n+In addition to the MER configuration file, the MER_ProcessTile and MER_ProcessTileVisOnly\n+pipelines require as input a MER DQC static flag limits product of type DpdMerDqcStaticFlagLimits. The ProductId\n+to use is EUC_MER_DQC-STATIC-FLAG-LIMITS_20230807.\n",
                            "Adds MER input products information",
                            "Javier Gracia Carpio",
                            "2023-08-07T14:46:40.000+00:00",
                            "93aee00f65beee909785e3680f7d4cc2777f84d7"
                        ],
                        [
                            "@@ -17,13 +17,13 @@ The version of MER Pipeline to which this document refers does not depend on ext\n `MER` Pipeline depends on some Euclid compliant projects developed outside MER-PF:\n \n *\t`Elements` version 6.2.1\n-*\t`ST_DataModelTools` version 9.2.0\n-*\t`SourceXtractorPlusPlus` version 0.2\n-*\t`CT_Swarp_cpp` version 10.1\n-* `CP_PositionCrossMatch` version 2.1\n+*\t`ST_DataModelTools` version 9.2.1\n+*\t`SourceXtractorPlusPlus` version 0.19.4\n+*\t`CT_Swarp_cpp` version 10.1.0\n+* `CP_PositionCrossMatch` version 2.1.0\n *\t`EL_Utils` version 1.4.1\n-*\t`EL_Background` version 10.1\n-*\t`LE3_GALEXT_ED` version 10.1\n+*\t`EL_Background` version 10.1.0\n+*\t`LE3_GALEXT_ED` version 10.1.0\n \n We leave the description of these projects to their respective reference.\n \n@@ -33,9 +33,9 @@ The SGS document [RD7] describes through the principal software parts of the sys\n \n |   |   |\n |---|---|\n-| **PF Release:**  | `10.1` |\n+| **PF Release:**  | `10.1.2` |\n | **EDEN:** | `3.1` |\n-| **Data Models:** | `9.2` |\n+| **Data Models:** | `9.2.0` |\n \n These elements (related to the PF software) are identified **with their versions** in the **PF Release Note** [RD8].\n \n@@ -57,5 +57,3 @@ PF `MER` is made of the following pipelines, gathered as following in these grou\n   * `MER_ProcessTileVisOnly`\n * Group `Morpho`:\n   * `MER_ProcessTileMorpho`\n-* Group `Validate`:\n-  * `MER_ValidateTile`\n\\ No newline at end of file\n",
                            "More small version changes",
                            "Javier Gracia Carpio",
                            "2023-08-07T13:30:46.000+00:00",
                            "fe47336de236acc56c4f3ec5cbc2ea429a9b881b"
                        ],
                        [
                            "@@ -16,13 +16,14 @@ The `MER` PF software can be executed:\n The version of MER Pipeline to which this document refers does not depend on external software tools.\n `MER` Pipeline depends on some Euclid compliant projects developed outside MER-PF:\n \n-*\t`Elements` version 6.0.1\n-*\t`ST_DataModelTools` version 9.0.2\n-*\t`SourceXtractorPlusPlus` version 0.18.0\n-*\t`CT_Swarp_cpp` version 9.0\n-*\t`EL_Utils` version 1.2.2\n-*\t`EL_Background` version 9.0\n-*\t`LE3_GALEXT_ED` version 9.0\n+*\t`Elements` version 6.2.1\n+*\t`ST_DataModelTools` version 9.2.0\n+*\t`SourceXtractorPlusPlus` version 0.2\n+*\t`CT_Swarp_cpp` version 10.1\n+* `CP_PositionCrossMatch` version 2.1\n+*\t`EL_Utils` version 1.4.1\n+*\t`EL_Background` version 10.1\n+*\t`LE3_GALEXT_ED` version 10.1\n \n We leave the description of these projects to their respective reference.\n \n@@ -32,9 +33,9 @@ The SGS document [RD7] describes through the principal software parts of the sys\n \n |   |   |\n |---|---|\n-| **PF Release:**  | `9.0` |\n-| **EDEN:** | `3.0` |\n-| **Data Models:** | `9.0.2` |\n+| **PF Release:**  | `10.1` |\n+| **EDEN:** | `3.1` |\n+| **Data Models:** | `9.2` |\n \n These elements (related to the PF software) are identified **with their versions** in the **PF Release Note** [RD8].\n \n@@ -50,4 +51,11 @@ PF `MER` is made of the following pipelines, gathered as following in these grou\n   * `MER_ProcessTileVisOnly`\n * Group `Analysis`:\n   * `MER_AnalyseTile`\n-  * `MER_AnalyseTileVisOnly`\n\\ No newline at end of file\n+  * `MER_AnalyseTileVisOnly`\n+* Group `WIDE_ONTHEFLY`:\n+  * `MER_ProcessTile`\n+  * `MER_ProcessTileVisOnly`\n+* Group `Morpho`:\n+  * `MER_ProcessTileMorpho`\n+* Group `Validate`:\n+  * `MER_ValidateTile`\n\\ No newline at end of file\n",
                            "SUM update",
                            "Erik Romelli",
                            "2023-06-28T12:01:15.000+02:00",
                            "14e1cf60d97acdf4d0f5a0fce884848152ab2906"
                        ]
                    ],
                    "doc/user_manual/chap1.md": [
                        [
                            "@@ -6,7 +6,7 @@\n \n This document provides generic installation and usage instructions for the MER Pipeline.\n The SGS Procedures Handbook will cover specific instructions and procedures on how to use MER Pipeline and the tools in the operational environment. \n-This issue of the SUM is applicable for MER Pipeline release 10.1.\n+This issue of the SUM is applicable for MER Pipeline release 10.1.2.\n \n ## Purpose of the PF\n \n",
                            "More small version changes",
                            "Javier Gracia Carpio",
                            "2023-08-07T13:30:46.000+00:00",
                            "fe47336de236acc56c4f3ec5cbc2ea429a9b881b"
                        ],
                        [
                            "@@ -6,7 +6,7 @@\n \n This document provides generic installation and usage instructions for the MER Pipeline.\n The SGS Procedures Handbook will cover specific instructions and procedures on how to use MER Pipeline and the tools in the operational environment. \n-This issue of the SUM is applicable for MER Pipeline release 9.0.\n+This issue of the SUM is applicable for MER Pipeline release 10.1.\n \n ## Purpose of the PF\n \n",
                            "SUM update",
                            "Erik Romelli",
                            "2023-06-28T12:01:15.000+02:00",
                            "14e1cf60d97acdf4d0f5a0fce884848152ab2906"
                        ]
                    ],
                    "doc/user_manual/chap9-Validate.md": [
                        [
                            "@@ -1,129 +0,0 @@\n-\\newpage\n-\n-# Group `Validate`\n-\n-## Pipelines and dependencies\n-\n-The group `Validate` is made of the following pipelines:\n-\n-* Group `Validate`:\n-  * `MER_ValidateTile`\n-\n-The pipelines of the group `Validate` depend on the respective processing pipelines.\n-\n-```mermaid\n-%%{init: { \"flowchart\": { \"curve\": \"monotoneX\" } } }%%\n-flowchart LR\n-    proc(MER_ProcessingTile)\n-    pipeline(MER_ValidateTile)\n-\n-    proc ==>|DpdMerFinalCatalog<br>1..1| pipeline\n-    proc ==>|DpdMerSegmentationMap<br>1..1| pipeline\n-    proc ==>|DpdMerBksMosaic<br>1..N| pipeline\n-    proc ==>|DpdMerDetectionMosaic<br>1..2| pipeline\n-```\n-\n-## Pipeline `MER_ValidateTile`\n-\n-### Pipeline Description\n-\n-The related GitLab projects are following [RD7]:\n-\n-* [`MER_IAL_Pipelines`](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines)\n-* [`MER_Validation`](https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation)\n-\n-### Pipeline ports with inputs/outputs\n-\n-The following diagram represents the ports of `MER_ValidateTile`. For each port, the product type, port name and cardinality are provided. The thick arrow is for the key input port. Optional ports are represented by dotted arrows.\n-\n-```mermaid\n-%%{init: { \"flowchart\": { \"curve\": \"monotoneX\" } } }%%\n-flowchart LR\n-    pipeline(MER_AnalysisTile)\n-\n-    cat(DpdMerFinalCatalog)\n-    bgkmos(DpdMerBksMosaic)\n-    detmos(DpdMerDetectionMosaic)\n-    seg(DpdMerSegmentationMap)\n-    mdb(DpdMdbDataBase)\n-    conf(DpdMerConfigurationSet)\n-    tile(DpdMerTile)\n-    val(DpdMerValidationRequirements)\n-\n-    val_res(DpdMerValidationResult)\n-\n-    tu_star(DpdMerTrueUniverseStarCatalog)\n-    tu_gal(DpdMerTrueUniverseGalaxyCatalog)\n-\n-    val ==> pipeline\n-    cat ==>|EUC_MER_FINAL-CAT<br>1..1| pipeline\n-    seg ==>|EUC_MER_FINAL-SEGMAP<br>1..1| pipeline\n-    bgkmos ==>|EUC_MER_BGSUB-MOSAIC<br>1..N| pipeline\n-    detmos ==>|EUC_MER_BGSUB-MOSAIC<br>1..2| pipeline\n-    tu_star ==>|TU_star_catalog<br>1..1| pipeline\n-    tu_gal ==>|TU_galaxy_catalog<br>1..1| pipeline\n-\n-    conf ==>|EUC_MER_CONF-FILE-MOSAICS| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-BACKGROUND| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-DETECTION| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-DEBLENDING| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-PHOTOMETRY| pipeline\n-    conf ==>|EUC_MER_CONF-FILE-SPURIOUS| pipeline\n-\n-    tile ==> pipeline \n-\n-    pipeline ==>|EUC_MER_VALIDATION_RESULTS<br>1..1| val_res\n-```\n-\n-**Ports description:**\n-\n-* Input:\n-  * `validation_requirements`: MER validation requirements.\n-  * `all_mosaics`: Background-subtracted mosaics.\n-  * `vis_detection_mosaic`: Mosaic used to perform the object detection on VIS.\n-  * `nir_detection_mosaic`: Mosaic used to perform the object detection on NIR.\n-  * `final_segmentation_map`: Map showing the connected pixels of the objects detected on the corresponding detection mosaic.\n-  * `final_catalog`: Final merged catalog with photometric and morphological information.\n-  * `tile`: Tile definition.\n-  * `configuration_set`: List configuration files.\n-  * `tu_star_catalog`: True Universe star catalog.\n-  * `tu_galaxy_catalog`: True Universe galaxy catalog..\n-\n-* Output:\n-  * `validation_result`: Analysis report.\n-\n-\n-### Processing triggering assumptions\n-\n-* `MER_ValidateTile` triggered at Tile scale.\n-* `MER_ValidateTile` needs a completed `MER_ProcessTile` on the same tile.\n-\n-| Scale(s) | Periodicity | Input DataProduct | Information for creating the pipeline definition |\n-| -------| ----------- | ----------- |  --------------- |\n-| Tile | As soon as a completed `MER_ProcessTile` is available | See ports description |  |\n-\n-### Operational constraints\n-\n-`MER_ValidateTile` requires a completed `MER_ProcessTile`.\n-\n-### Hardware configuration and related performances\n-\n-The \"Execution Context\" of the `MER_ValidateTile` is always:\n-\n-* Nominal\n-\n-| Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n-| -------------------------- | ----- | ------------------------------ | ----- | ------- | ------- | ------- |\n-| MER_Validation   | 10.0 | MER_Validation  | 1 | 8.0 | 1.0 | <1 |\n-\n-### Normal termination\n-\n-MER Pipeline is managed by the official EDEN pipeline runner. The standard output of the EDEN pipeline runner is expected if MER Pipeline runs through all the PEs. \n-\n-### Error condition\n-\n-The runtime errors related to `MER_ValidateTile` are listed below:\n-\n-| Software Executable | Message | Operator Instruction |\n-| ---------------------- | ----------------------------- |  ----------------------------- |\n-\n",
                            "Updates the SUM",
                            "Javier Gracia Carpio",
                            "2023-08-07T13:24:00.000+00:00",
                            "fca8026919dd64c52dac3b0c920ffa0ba5cc04cc"
                        ],
                        [
                            "@@ -114,7 +114,7 @@ The \"Execution Context\" of the `MER_ValidateTile` is always:\n \n | Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n | -------------------------- | ----- | ------------------------------ | ----- | ------- | ------- | ------- |\n-| MER_Validation   | 10.0 | MER_Validation  | 1 | 16.0 | 2.0 | <1 |\n+| MER_Validation   | 10.0 | MER_Validation  | 1 | 8.0 | 1.0 | <1 |\n \n ### Normal termination\n \n",
                            "SUM update",
                            "Erik Romelli",
                            "2023-06-28T12:02:58.000+02:00",
                            "d43c0f8a6651b76163fb9481c86bc232f76715bc"
                        ],
                        [
                            "@@ -0,0 +1,129 @@\n+\\newpage\n+\n+# Group `Validate`\n+\n+## Pipelines and dependencies\n+\n+The group `Validate` is made of the following pipelines:\n+\n+* Group `Validate`:\n+  * `MER_ValidateTile`\n+\n+The pipelines of the group `Validate` depend on the respective processing pipelines.\n+\n+```mermaid\n+%%{init: { \"flowchart\": { \"curve\": \"monotoneX\" } } }%%\n+flowchart LR\n+    proc(MER_ProcessingTile)\n+    pipeline(MER_ValidateTile)\n+\n+    proc ==>|DpdMerFinalCatalog<br>1..1| pipeline\n+    proc ==>|DpdMerSegmentationMap<br>1..1| pipeline\n+    proc ==>|DpdMerBksMosaic<br>1..N| pipeline\n+    proc ==>|DpdMerDetectionMosaic<br>1..2| pipeline\n+```\n+\n+## Pipeline `MER_ValidateTile`\n+\n+### Pipeline Description\n+\n+The related GitLab projects are following [RD7]:\n+\n+* [`MER_IAL_Pipelines`](https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines)\n+* [`MER_Validation`](https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation)\n+\n+### Pipeline ports with inputs/outputs\n+\n+The following diagram represents the ports of `MER_ValidateTile`. For each port, the product type, port name and cardinality are provided. The thick arrow is for the key input port. Optional ports are represented by dotted arrows.\n+\n+```mermaid\n+%%{init: { \"flowchart\": { \"curve\": \"monotoneX\" } } }%%\n+flowchart LR\n+    pipeline(MER_AnalysisTile)\n+\n+    cat(DpdMerFinalCatalog)\n+    bgkmos(DpdMerBksMosaic)\n+    detmos(DpdMerDetectionMosaic)\n+    seg(DpdMerSegmentationMap)\n+    mdb(DpdMdbDataBase)\n+    conf(DpdMerConfigurationSet)\n+    tile(DpdMerTile)\n+    val(DpdMerValidationRequirements)\n+\n+    val_res(DpdMerValidationResult)\n+\n+    tu_star(DpdMerTrueUniverseStarCatalog)\n+    tu_gal(DpdMerTrueUniverseGalaxyCatalog)\n+\n+    val ==> pipeline\n+    cat ==>|EUC_MER_FINAL-CAT<br>1..1| pipeline\n+    seg ==>|EUC_MER_FINAL-SEGMAP<br>1..1| pipeline\n+    bgkmos ==>|EUC_MER_BGSUB-MOSAIC<br>1..N| pipeline\n+    detmos ==>|EUC_MER_BGSUB-MOSAIC<br>1..2| pipeline\n+    tu_star ==>|TU_star_catalog<br>1..1| pipeline\n+    tu_gal ==>|TU_galaxy_catalog<br>1..1| pipeline\n+\n+    conf ==>|EUC_MER_CONF-FILE-MOSAICS| pipeline\n+    conf ==>|EUC_MER_CONF-FILE-BACKGROUND| pipeline\n+    conf ==>|EUC_MER_CONF-FILE-DETECTION| pipeline\n+    conf ==>|EUC_MER_CONF-FILE-DEBLENDING| pipeline\n+    conf ==>|EUC_MER_CONF-FILE-PHOTOMETRY| pipeline\n+    conf ==>|EUC_MER_CONF-FILE-SPURIOUS| pipeline\n+\n+    tile ==> pipeline \n+\n+    pipeline ==>|EUC_MER_VALIDATION_RESULTS<br>1..1| val_res\n+```\n+\n+**Ports description:**\n+\n+* Input:\n+  * `validation_requirements`: MER validation requirements.\n+  * `all_mosaics`: Background-subtracted mosaics.\n+  * `vis_detection_mosaic`: Mosaic used to perform the object detection on VIS.\n+  * `nir_detection_mosaic`: Mosaic used to perform the object detection on NIR.\n+  * `final_segmentation_map`: Map showing the connected pixels of the objects detected on the corresponding detection mosaic.\n+  * `final_catalog`: Final merged catalog with photometric and morphological information.\n+  * `tile`: Tile definition.\n+  * `configuration_set`: List configuration files.\n+  * `tu_star_catalog`: True Universe star catalog.\n+  * `tu_galaxy_catalog`: True Universe galaxy catalog..\n+\n+* Output:\n+  * `validation_result`: Analysis report.\n+\n+\n+### Processing triggering assumptions\n+\n+* `MER_ValidateTile` triggered at Tile scale.\n+* `MER_ValidateTile` needs a completed `MER_ProcessTile` on the same tile.\n+\n+| Scale(s) | Periodicity | Input DataProduct | Information for creating the pipeline definition |\n+| -------| ----------- | ----------- |  --------------- |\n+| Tile | As soon as a completed `MER_ProcessTile` is available | See ports description |  |\n+\n+### Operational constraints\n+\n+`MER_ValidateTile` requires a completed `MER_ProcessTile`.\n+\n+### Hardware configuration and related performances\n+\n+The \"Execution Context\" of the `MER_ValidateTile` is always:\n+\n+* Nominal\n+\n+| Processing Element (PE)| PE Version | Executable name | Cores | RAM (GB) | Walltime (hours) | Disk space (GB) |\n+| -------------------------- | ----- | ------------------------------ | ----- | ------- | ------- | ------- |\n+| MER_Validation   | 10.0 | MER_Validation  | 1 | 16.0 | 2.0 | <1 |\n+\n+### Normal termination\n+\n+MER Pipeline is managed by the official EDEN pipeline runner. The standard output of the EDEN pipeline runner is expected if MER Pipeline runs through all the PEs. \n+\n+### Error condition\n+\n+The runtime errors related to `MER_ValidateTile` are listed below:\n+\n+| Software Executable | Message | Operator Instruction |\n+| ---------------------- | ----------------------------- |  ----------------------------- |\n+\n",
                            "SUM update",
                            "Erik Romelli",
                            "2023-06-28T12:01:15.000+02:00",
                            "14e1cf60d97acdf4d0f5a0fce884848152ab2906"
                        ]
                    ],
                    "doc/user_manual/manifest": [
                        [
                            "@@ -9,4 +9,3 @@ chap5-WIDE.md # Pipeline group 1\n chap6-DEEP.md # Pipeline group 2\n chap7-Analysis.md # Pipeline group 3\n chap8-Morpho.md # Pipeline group 4\n-chap9-Validate.md # Pipeline group 5\n",
                            "Updates the SUM",
                            "Javier Gracia Carpio",
                            "2023-08-07T13:24:00.000+00:00",
                            "fca8026919dd64c52dac3b0c920ffa0ba5cc04cc"
                        ],
                        [
                            "@@ -8,3 +8,5 @@ chap4.md # PF Operations Environment\n chap5-WIDE.md # Pipeline group 1\n chap6-DEEP.md # Pipeline group 2\n chap7-Analysis.md # Pipeline group 3\n+chap8-Morpho.md # Pipeline group 4\n+chap9-Validate.md # Pipeline group 5\n",
                            "SUM update",
                            "Erik Romelli",
                            "2023-06-28T12:01:15.000+02:00",
                            "14e1cf60d97acdf4d0f5a0fce884848152ab2906"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_AnalyseTile_Pipeline/PipDef_MER_GaiaAnalyseTile.xml": [
                        [
                            "@@ -0,0 +1,64 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<tsk:PipelineDef xmlns:tsk=\"http://euclid.esa.org/schema/interfaces/sys/tsk\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://euclid.esa.org/schema/interfaces/sys/tsk\">\n+    <EdenVersion>Eden-3.1-dev</EdenVersion>\n+    <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n+    <TargetSDC>ALLSDC</TargetSDC>\n+    <Id>PipDef_MER_GAIA_ANALYSE_TILE_DEV_10.2_2023-07-04</Id>\n+    <PipelineVersion>10.2</PipelineVersion>\n+    <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n+    <PipelineContext>PRODUCTION</PipelineContext>\n+    <PipelineScriptPath>PipScript_MER_GaiaAnalyseTile.py</PipelineScriptPath>\n+    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.2/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_AnalyseTile_Pipeline/</PipelineRootPath>\n+    <InputDataSet>\n+        <KeyProductInputDataPlan>\n+            <InputPortName>final_catalog</InputPortName>\n+            <DataProductType>DpdMerFinalCatalog</DataProductType>\n+            <InputQuerySpecPlan>final_catalog.Header.PPOId == \"UNKNOWN\"</InputQuerySpecPlan>\n+            <InputQuerySpecPlan>(final_catalog.Header.ManualValidationStatus != \"INVALID\") &amp; (final_catalog.Header.DataSetRelease == \"UNKNOWN\") &amp; (final_catalog.Data.TileIndex == \"UNKNOWN\")</InputQuerySpecPlan>\n+            <InputQuerySpecPlan>(final_catalog.Header.ManualValidationStatus != \"INVALID\") &amp; (final_catalog.Header.DataSetRelease == \"UNKNOWN\")</InputQuerySpecPlan>\n+            <InputQuerySpecPlan>(final_catalog.Header.ManualValidationStatus != \"INVALID\") &amp; (final_catalog.Header.DataSetRelease == \"UNKNOWN\") &amp; (final_catalog.Data.SpatialCoverage.Polygon INTERSECT(\"UNKNOWN\",\"UNKNOWN\") 'POLYGON(\"UNKNOWN\")')</InputQuerySpecPlan>\n+            <Cardinality>\n+                <Optionality>MANDATORY</Optionality>\n+                <Min>1</Min>\n+                <Max>1</Max>\n+            </Cardinality>\n+        </KeyProductInputDataPlan>\n+        <InputDataPlan>\n+            <InputPortName>gaia_cutout</InputPortName>\n+            <DataProductType>DpdExtGaiaCutout</DataProductType>\n+            <InputQuerySpecPlan>(gaia_cutout.Header.ManualValidationStatus != \"INVALID\") &amp; (gaia_cutout.Header.CreationDate BETWEEN \"UNKNOWN\" AND \"UNKNOWN\")</InputQuerySpecPlan>\n+            <InputQuerySpecPlan>(gaia_cutout.Header.ManualValidationStatus != \"INVALID\") &amp; (gaia_cutout.Header.DataSetRelease == \"UNKNOWN\")</InputQuerySpecPlan>\n+            <Cardinality>\n+                <Optionality>OPTIONAL</Optionality>\n+                <Min>1</Min>\n+                <Max>1</Max>\n+            </Cardinality>\n+        </InputDataPlan>\n+        <InputDataPlan>\n+            <InputPortName>configuration_set</InputPortName>\n+            <DataProductType>DpdMerConfigurationSet</DataProductType>\n+            <InputQuerySpecPlan>configuration_set.Header.ProductId == \"UNKNOWN\"</InputQuerySpecPlan>\n+            <Cardinality>\n+                <Optionality>MANDATORY</Optionality>\n+                <Min>1</Min>\n+                <Max>1</Max>\n+            </Cardinality>\n+        </InputDataPlan>\n+        <Dependencies>\n+            <LinkedBy refPort=\"final_catalog\">\n+                <Query>final_catalog.Data.TileIndex == gaia_cutouts.Data.TileIndex</Query>\n+            </LinkedBy>\n+        </Dependencies>\n+    </InputDataSet>\n+    <OutputDataSet>\n+        <OutputDataProduct>\n+            <OutputPortName>analysis_result</OutputPortName>\n+            <DataProductType>DpdMerAnalysisResult</DataProductType>\n+            <Cardinality>\n+                <Optionality>MANDATORY</Optionality>\n+                <Min>1</Min>\n+                <Max>1</Max>\n+            </Cardinality>            \n+        </OutputDataProduct>\n+    </OutputDataSet>\n+</tsk:PipelineDef>\n",
                            "Adds first version of the analysis pipeline using Gaia data",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:31:19.000+00:00",
                            "e10713efbf6f3da22ca2f4dee7a20017a1255d11"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_AnalyseTile_Pipeline/PipScript_MER_GaiaAnalyseTile.py": [
                        [
                            "@@ -0,0 +1,39 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+MER analysis pipeline script file for real data\n+\n+\"\"\"\n+\n+from euclidwf.framework.workflow_dsl import pipeline\n+\n+from PkgDef_MER_GaiaAnalyseTile import *\n+\n+@pipeline(outputs=(\"analysis_result\"))\n+def mer_pipeline(final_catalog, gaia_cutout, configuration_set):\n+    \"\"\"\n+    Main analysis pipeline for the MER PF\n+    \"\"\"\n+    analysis_result = MER_AstrometryValidation(\n+        mer_catalog=final_catalog,\n+        gaia_cutout=gaia_cutout,\n+        configuration_set=configuration_set\n+    )\n+\n+    return analysis_result\n",
                            "Adds first version of the analysis pipeline using Gaia data",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:31:19.000+00:00",
                            "e10713efbf6f3da22ca2f4dee7a20017a1255d11"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_AnalyseTile_Pipeline/PkgDef_MER_GaiaAnalyseTile.py": [
                        [
                            "@@ -0,0 +1,38 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+MER package definition file\n+\n+\"\"\"\n+\n+from euclidwf.framework.taskdefs import (Executable, Input, Output,\n+                                         ComputingResources)\n+\n+\n+ENV_VARIABLES = {\n+    \"MPLCONFIGDIR\": \"/dev/null\"\n+}\n+\n+MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_AstrometryValidationPrg\",\n+                                   inputs=[Input(\"mer_catalog\"),\n+                                           Input(\"gaia_cutout\"),\n+                                           Input(\"configuration_set\")],\n+                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n",
                            "Adds first version of the analysis pipeline using Gaia data",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:31:19.000+00:00",
                            "e10713efbf6f3da22ca2f4dee7a20017a1255d11"
                        ]
                    ],
                    "CMakeLists.txt": [
                        [
                            "@@ -12,4 +12,4 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_IAL_Pipelines 10.1 USE Elements 6.2.1 ST_DataModel 9.2.0)\n+elements_project(MER_IAL_Pipelines 10.2 USE Elements 6.2.1 ST_DataModel 9.2.0)\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -12,4 +12,4 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_IAL_Pipelines 10.0 USE Elements 6.1.1 ST_DataModel 9.1.5)\n+elements_project(MER_IAL_Pipelines 10.1 USE Elements 6.2.1 ST_DataModel 9.2.0)\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_AnalyseTile_Pipeline/PipDef_MER_AnalyseTile.xml": [
                        [
                            "@@ -3,12 +3,12 @@\n     <EdenVersion>Eden-3.1-dev</EdenVersion>\n     <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_ANALYSE_TILE_DEV_10.1_2023-06-23</Id>\n-    <PipelineVersion>10.1</PipelineVersion>\n+    <Id>PipDef_MER_ANALYSE_TILE_DEV_10.2_2023-07-03</Id>\n+    <PipelineVersion>10.2</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n     <PipelineScriptPath>PipScript_MER_AnalyseTile.py</PipelineScriptPath>\n-    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.1/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_AnalyseTile_Pipeline/</PipelineRootPath>\n+    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.2/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_AnalyseTile_Pipeline/</PipelineRootPath>\n     <InputDataSet>\n         <KeyProductInputDataPlan>\n             <InputPortName>final_catalog</InputPortName>\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -1,14 +1,14 @@\n <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n <tsk:PipelineDef xmlns:tsk=\"http://euclid.esa.org/schema/interfaces/sys/tsk\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://euclid.esa.org/schema/interfaces/sys/tsk\">\n-    <EdenVersion>Eden-3.0-dev</EdenVersion>\n-    <CommonDataModelVersion>9.1.5</CommonDataModelVersion>\n+    <EdenVersion>Eden-3.1-dev</EdenVersion>\n+    <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_ANALYSE_TILE_DEV_10.0_2023-03-07</Id>\n-    <PipelineVersion>10.0</PipelineVersion>\n+    <Id>PipDef_MER_ANALYSE_TILE_DEV_10.1_2023-06-23</Id>\n+    <PipelineVersion>10.1</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n     <PipelineScriptPath>PipScript_MER_AnalyseTile.py</PipelineScriptPath>\n-    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid/MER_IAL_Pipelines/10.0/InstallArea/x86_64-conda_cos6-gcc93-o2g/auxdir/MER_AnalyseTile_Pipeline/</PipelineRootPath>\n+    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.1/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_AnalyseTile_Pipeline/</PipelineRootPath>\n     <InputDataSet>\n         <KeyProductInputDataPlan>\n             <InputPortName>final_catalog</InputPortName>\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_AnalyseTile_Pipeline/PipDef_MER_AnalyseTile_VISONLY.xml": [
                        [
                            "@@ -3,12 +3,12 @@\n     <EdenVersion>Eden-3.1-dev</EdenVersion>\n     <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_ANALYSE_TILE_VISONLY_DEV_10.1_2023-06-23</Id>\n-    <PipelineVersion>10.1</PipelineVersion>\n+    <Id>PipDef_MER_ANALYSE_TILE_VISONLY_DEV_10.2_2023-07-03</Id>\n+    <PipelineVersion>10.2</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n     <PipelineScriptPath>PipScript_MER_AnalyseTileVisOnly.py</PipelineScriptPath>\n-    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.1/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_AnalyseTile_Pipeline/</PipelineRootPath>\n+    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.2/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_AnalyseTile_Pipeline/</PipelineRootPath>\n     <InputDataSet>\n         <KeyProductInputDataPlan>\n             <InputPortName>final_catalog</InputPortName>\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -1,14 +1,14 @@\n <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n <tsk:PipelineDef xmlns:tsk=\"http://euclid.esa.org/schema/interfaces/sys/tsk\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://euclid.esa.org/schema/interfaces/sys/tsk\">\n-    <EdenVersion>Eden-3.0-dev</EdenVersion>\n-    <CommonDataModelVersion>9.1.5</CommonDataModelVersion>\n+    <EdenVersion>Eden-3.1-dev</EdenVersion>\n+    <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_ANALYSE_TILE_VISONLY_DEV_10.0_2023-03-07</Id>\n-    <PipelineVersion>10.0</PipelineVersion>\n+    <Id>PipDef_MER_ANALYSE_TILE_VISONLY_DEV_10.1_2023-06-23</Id>\n+    <PipelineVersion>10.1</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n     <PipelineScriptPath>PipScript_MER_AnalyseTileVisOnly.py</PipelineScriptPath>\n-    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid/MER_IAL_Pipelines/10.0/InstallArea/x86_64-conda_cos6-gcc93-o2g/auxdir/MER_AnalyseTile_Pipeline/</PipelineRootPath>\n+    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.1/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_AnalyseTile_Pipeline/</PipelineRootPath>\n     <InputDataSet>\n         <KeyProductInputDataPlan>\n             <InputPortName>final_catalog</InputPortName>\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_ProcessTileMorpho_Pipeline/PipDef_MER_ProcessTileMorpho.xml": [
                        [
                            "@@ -3,12 +3,12 @@\n     <EdenVersion>Eden-3.1-dev</EdenVersion>\n     <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_PROCESS_TILE_MORPHO_DEV_10.1_2023-06-23</Id>\n-    <PipelineVersion>10.1</PipelineVersion>\n+    <Id>PipDef_MER_PROCESS_TILE_MORPHO_DEV_10.2_2023-07-03</Id>\n+    <PipelineVersion>10.2</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n     <PipelineScriptPath>PipScript_MER_ProcessTileMorpho.py</PipelineScriptPath>\n-    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.1/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_ProcessTileMorpho_Pipeline/</PipelineRootPath>\n+    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.2/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_ProcessTileMorpho_Pipeline/</PipelineRootPath>\n     <InputDataSet>\n         <KeyProductInputDataPlan>\n             <InputPortName>final_catalog</InputPortName>\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -1,14 +1,14 @@\n <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n <tsk:PipelineDef xmlns:tsk=\"http://euclid.esa.org/schema/interfaces/sys/tsk\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://euclid.esa.org/schema/interfaces/sys/tsk\">\n-    <EdenVersion>Eden-3.0-dev</EdenVersion>\n-    <CommonDataModelVersion>9.1.5</CommonDataModelVersion>\n+    <EdenVersion>Eden-3.1-dev</EdenVersion>\n+    <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_PROCESS_TILE_MORPHO_DEV_10.0_2023-05-03</Id>\n-    <PipelineVersion>10.0</PipelineVersion>\n+    <Id>PipDef_MER_PROCESS_TILE_MORPHO_DEV_10.1_2023-06-23</Id>\n+    <PipelineVersion>10.1</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n     <PipelineScriptPath>PipScript_MER_ProcessTileMorpho.py</PipelineScriptPath>\n-    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid/MER_IAL_Pipelines/10.0/InstallArea/x86_64-conda_cos6-gcc93-o2g/auxdir/MER_ProcessTileMorpho_Pipeline/</PipelineRootPath>\n+    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.1/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_ProcessTileMorpho_Pipeline/</PipelineRootPath>\n     <InputDataSet>\n         <KeyProductInputDataPlan>\n             <InputPortName>final_catalog</InputPortName>\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_ProcessTile_Pipeline/PipDef_MER_ProcessTile_DEEP.xml": [
                        [
                            "@@ -3,12 +3,12 @@\n     <EdenVersion>Eden-3.1-dev</EdenVersion>\n     <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_PROCESS_TILE_DEEP_DEV_10.1_2023-06-23</Id>\n-    <PipelineVersion>10.1</PipelineVersion>\n+    <Id>PipDef_MER_PROCESS_TILE_DEEP_DEV_10.2_2023-07-03</Id>\n+    <PipelineVersion>10.2</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n     <PipelineScriptPath>PipScript_MER_ProcessTile.py</PipelineScriptPath>\n-    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.1/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_ProcessTile_Pipeline/</PipelineRootPath>\n+    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.2/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_ProcessTile_Pipeline/</PipelineRootPath>\n     <InputDataSet>\n         <KeyProductInputDataPlan>\n             <InputPortName>tile</InputPortName>\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -1,14 +1,14 @@\n <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n <tsk:PipelineDef xmlns:tsk=\"http://euclid.esa.org/schema/interfaces/sys/tsk\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://euclid.esa.org/schema/interfaces/sys/tsk\">\n-    <EdenVersion>Eden-3.0-dev</EdenVersion>\n-    <CommonDataModelVersion>9.1.5</CommonDataModelVersion>\n+    <EdenVersion>Eden-3.1-dev</EdenVersion>\n+    <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_PROCESS_TILE_DEEP_DEV_10.0_2023-03-07</Id>\n-    <PipelineVersion>10.0</PipelineVersion>\n+    <Id>PipDef_MER_PROCESS_TILE_DEEP_DEV_10.1_2023-06-23</Id>\n+    <PipelineVersion>10.1</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n     <PipelineScriptPath>PipScript_MER_ProcessTile.py</PipelineScriptPath>\n-    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid/MER_IAL_Pipelines/10.0/InstallArea/x86_64-conda_cos6-gcc93-o2g/auxdir/MER_ProcessTile_Pipeline/</PipelineRootPath>\n+    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.1/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_ProcessTile_Pipeline/</PipelineRootPath>\n     <InputDataSet>\n         <KeyProductInputDataPlan>\n             <InputPortName>tile</InputPortName>\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_ProcessTile_Pipeline/PipDef_MER_ProcessTile_VISONLY.xml": [
                        [
                            "@@ -3,12 +3,12 @@\n     <EdenVersion>Eden-3.1-dev</EdenVersion>\n     <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_PROCESS_TILE_VISONLY_DEV_10.1_2023-06-23</Id>\n-    <PipelineVersion>10.1</PipelineVersion>\n+    <Id>PipDef_MER_PROCESS_TILE_VISONLY_DEV_10.2_2023-07-03</Id>\n+    <PipelineVersion>10.2</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n     <PipelineScriptPath>PipScript_MER_ProcessTileVisOnly.py</PipelineScriptPath>\n-    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.1/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_ProcessTile_Pipeline/</PipelineRootPath>\n+    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.2/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_ProcessTile_Pipeline/</PipelineRootPath>\n     <InputDataSet>\n         <KeyProductInputDataPlan>\n             <InputPortName>tile</InputPortName>\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -1,14 +1,14 @@\n <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n <tsk:PipelineDef xmlns:tsk=\"http://euclid.esa.org/schema/interfaces/sys/tsk\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://euclid.esa.org/schema/interfaces/sys/tsk\">\n-    <EdenVersion>Eden-3.0-dev</EdenVersion>\n-    <CommonDataModelVersion>9.1.5</CommonDataModelVersion>\n+    <EdenVersion>Eden-3.1-dev</EdenVersion>\n+    <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_PROCESS_TILE_VISONLY_DEV_10.0_2023-03-07</Id>\n-    <PipelineVersion>10.0</PipelineVersion>\n+    <Id>PipDef_MER_PROCESS_TILE_VISONLY_DEV_10.1_2023-06-23</Id>\n+    <PipelineVersion>10.1</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n     <PipelineScriptPath>PipScript_MER_ProcessTileVisOnly.py</PipelineScriptPath>\n-    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid/MER_IAL_Pipelines/10.0/InstallArea/x86_64-conda_cos6-gcc93-o2g/auxdir/MER_ProcessTile_Pipeline/</PipelineRootPath>\n+    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.1/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_ProcessTile_Pipeline/</PipelineRootPath>\n     <InputDataSet>\n         <KeyProductInputDataPlan>\n             <InputPortName>tile</InputPortName>\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_ProcessTile_Pipeline/PipDef_MER_ProcessTile_WIDE.xml": [
                        [
                            "@@ -3,12 +3,12 @@\n     <EdenVersion>Eden-3.1-dev</EdenVersion>\n     <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_PROCESS_TILE_WIDE_DEV_10.1_2023-06-23</Id>\n-    <PipelineVersion>10.1</PipelineVersion>\n+    <Id>PipDef_MER_PROCESS_TILE_WIDE_DEV_10.2_2023-07-03</Id>\n+    <PipelineVersion>10.2</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n     <PipelineScriptPath>PipScript_MER_ProcessTile.py</PipelineScriptPath>\n-    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.1/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_ProcessTile_Pipeline/</PipelineRootPath>\n+    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.2/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_ProcessTile_Pipeline/</PipelineRootPath>\n     <InputDataSet>\n         <KeyProductInputDataPlan>\n             <InputPortName>tile</InputPortName>\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -1,14 +1,14 @@\n <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n <tsk:PipelineDef xmlns:tsk=\"http://euclid.esa.org/schema/interfaces/sys/tsk\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://euclid.esa.org/schema/interfaces/sys/tsk\">\n-    <EdenVersion>Eden-3.0-dev</EdenVersion>\n-    <CommonDataModelVersion>9.1.5</CommonDataModelVersion>\n+    <EdenVersion>Eden-3.1-dev</EdenVersion>\n+    <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_PROCESS_TILE_WIDE_DEV_10.0_2023-03-07</Id>\n-    <PipelineVersion>10.0</PipelineVersion>\n+    <Id>PipDef_MER_PROCESS_TILE_WIDE_DEV_10.1_2023-06-23</Id>\n+    <PipelineVersion>10.1</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n     <PipelineScriptPath>PipScript_MER_ProcessTile.py</PipelineScriptPath>\n-    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid/MER_IAL_Pipelines/10.0/InstallArea/x86_64-conda_cos6-gcc93-o2g/auxdir/MER_ProcessTile_Pipeline/</PipelineRootPath>\n+    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.1/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_ProcessTile_Pipeline/</PipelineRootPath>\n     <InputDataSet>\n         <KeyProductInputDataPlan>\n             <InputPortName>tile</InputPortName>\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_ProcessTile_Pipeline/PipDef_MER_ProcessTile_WIDE_ONTHEFLY.xml": [
                        [
                            "@@ -3,12 +3,12 @@\n     <EdenVersion>Eden-3.1-dev</EdenVersion>\n     <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_PROCESS_TILE_WIDE_ONTHEFLY_DEV_10.1_2023-06-23</Id>\n-    <PipelineVersion>10.1</PipelineVersion>\n+    <Id>PipDef_MER_PROCESS_TILE_WIDE_ONTHEFLY_DEV_10.2_2023-07-03</Id>\n+    <PipelineVersion>10.2</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n     <PipelineScriptPath>PipScript_MER_ProcessTile.py</PipelineScriptPath>\n-    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.1/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_ProcessTile_Pipeline/</PipelineRootPath>\n+    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.2/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_ProcessTile_Pipeline/</PipelineRootPath>\n     <InputDataSet>\n         <KeyProductInputDataPlan>\n             <InputPortName>tile</InputPortName>\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -1,14 +1,14 @@\n <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n <tsk:PipelineDef xmlns:tsk=\"http://euclid.esa.org/schema/interfaces/sys/tsk\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://euclid.esa.org/schema/interfaces/sys/tsk\">\n-    <EdenVersion>Eden-3.0-dev</EdenVersion>\n-    <CommonDataModelVersion>9.1.5</CommonDataModelVersion>\n+    <EdenVersion>Eden-3.1-dev</EdenVersion>\n+    <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_PROCESS_TILE_WIDE_ONTHEFLY_DEV_10.0_2023-03-07</Id>\n-    <PipelineVersion>10.0</PipelineVersion>\n+    <Id>PipDef_MER_PROCESS_TILE_WIDE_ONTHEFLY_DEV_10.1_2023-06-23</Id>\n+    <PipelineVersion>10.1</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n     <PipelineScriptPath>PipScript_MER_ProcessTile.py</PipelineScriptPath>\n-    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid/MER_IAL_Pipelines/10.0/InstallArea/x86_64-conda_cos6-gcc93-o2g/auxdir/MER_ProcessTile_Pipeline/</PipelineRootPath>\n+    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.1/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_ProcessTile_Pipeline/</PipelineRootPath>\n     <InputDataSet>\n         <KeyProductInputDataPlan>\n             <InputPortName>tile</InputPortName>\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_ValidateTile_Pipeline/PipDef_MER_ValidateTile.xml": [
                        [
                            "@@ -3,12 +3,12 @@\n     <EdenVersion>Eden-3.1-dev</EdenVersion>\n     <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_VALIDATE_TILE_DEV_10.1_2023-06-23</Id>\n-    <PipelineVersion>10.1</PipelineVersion>\n+    <Id>PipDef_MER_VALIDATE_TILE_DEV_10.2_2023-07-03</Id>\n+    <PipelineVersion>10.2</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n     <PipelineScriptPath>PipScript_MER_ValidateTile.py</PipelineScriptPath>\n-    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.1/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_ValidateTile_Pipeline/</PipelineRootPath>\n+    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.2/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_ValidateTile_Pipeline/</PipelineRootPath>\n     <InputDataSet>\n         <KeyProductInputDataPlan>\n             <InputPortName>final_catalog</InputPortName>\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -1,14 +1,14 @@\n <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n <tsk:PipelineDef xmlns:tsk=\"http://euclid.esa.org/schema/interfaces/sys/tsk\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://euclid.esa.org/schema/interfaces/sys/tsk\">\n-    <EdenVersion>Eden-3.0-dev</EdenVersion>\n-    <CommonDataModelVersion>9.1.4</CommonDataModelVersion>\n+    <EdenVersion>Eden-3.1-dev</EdenVersion>\n+    <CommonDataModelVersion>9.2.0</CommonDataModelVersion>\n     <TargetSDC>ALLSDC</TargetSDC>\n-    <Id>PipDef_MER_VALIDATE_TILE_DEV_10.0_2023-03-07</Id>\n-    <PipelineVersion>10.0</PipelineVersion>\n+    <Id>PipDef_MER_VALIDATE_TILE_DEV_10.1_2023-06-23</Id>\n+    <PipelineVersion>10.1</PipelineVersion>\n     <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag>\n     <PipelineContext>PRODUCTION</PipelineContext>\n     <PipelineScriptPath>PipScript_MER_ValidateTile.py</PipelineScriptPath>\n-    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/CentOS7/EDEN-3.0/opt/euclid/MER_IAL_Pipelines/10.0/InstallArea/x86_64-conda_cos6-gcc93-o2g/auxdir/MER_ValidateTile_Pipeline/</PipelineRootPath>\n+    <PipelineRootPath>/cvmfs/euclid-dev.in2p3.fr/EDEN-3.1/opt/euclid/MER_IAL_Pipelines/10.1/InstallArea/x86_64-conda_ry9-gcc11-o2g/auxdir/MER_ValidateTile_Pipeline/</PipelineRootPath>\n     <InputDataSet>\n         <KeyProductInputDataPlan>\n             <InputPortName>final_catalog</InputPortName>\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_ValidateTile_Pipeline/PkgDef_MER_ValidateTile.py": [
                        [
                            "@@ -24,7 +24,7 @@ MER package definition file\n from euclidwf.framework.taskdefs import (Executable, Input, Output,\n                                          ComputingResources)\n \n-MER_Validation = Executable(command=\"E-Run MER_Validation 10.1 MER_Validation\",\n+MER_Validation = Executable(command=\"E-Run MER_Validation 10.2 MER_Validation\",\n                             inputs=[Input(\"validation_requirements\"),\n                                     Input(\"final_catalog\"),\n                                     Input(\"all_mosaics\", content_type=\"listfile\"),\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -24,7 +24,7 @@ MER package definition file\n from euclidwf.framework.taskdefs import (Executable, Input, Output,\n                                          ComputingResources)\n \n-MER_Validation = Executable(command=\"E-Run MER_Validation 10.0 MER_Validation\",\n+MER_Validation = Executable(command=\"E-Run MER_Validation 10.1 MER_Validation\",\n                             inputs=[Input(\"validation_requirements\"),\n                                     Input(\"final_catalog\"),\n                                     Input(\"all_mosaics\", content_type=\"listfile\"),\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    ".jenkinsFile": [
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\n-@Library('integration-library@release-9') _\n-pipelineElements(artifactId:\"MER_IAL_Pipelines\", component:'eden.3.0')\n+@Library(value='integration-library@release-10') _\n+pipelineElements(name:\"MER_IAL_Pipelines\", component:'eden.3.1')\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "Makefile": [
                        [
                            "@@ -44,169 +44,19 @@\n #\n ################################################################################\n \n-# settings\n-CMAKE := cmake\n-CTEST := ctest\n-NINJA := $(shell which ninja-build 2> /dev/null)\n-ifeq ($(NINJA),)\n-  NINJA := $(shell which ninja 2> /dev/null)\n-endif\n-\n-# Looking for the Custom make library\n-\n-CUSTOM_MAKE_LIB := Custom.mk\n-\n-ifneq ($(wildcard $(CURDIR)/make/$(CUSTOM_MAKE_LIB)),)\n-  CUSTOM_MAKE_LIB_FILE := $(CURDIR)/make/$(CUSTOM_MAKE_LIB)\n-else\n-  ifneq ($(CMAKE_PREFIX_PATH),)\n-    PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    CUSTOM_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(CUSTOM_MAKE_LIB) $(dir)/../make/$(CUSTOM_MAKE_LIB)))\n-  endif\n-  CUSTOM_MAKE_LIB_LIST += /usr/share/Elements/make/$(CUSTOM_MAKE_LIB)\n-  CUSTOM_MAKE_LIB_FILE := $(firstword $(CUSTOM_MAKE_LIB_LIST))\n-endif\n-\n-# Looking for the ToolChain\n-\n-TOOLCHAIN_NAME := ElementsToolChain.cmake\n+ELEMENTS_MAKE_LIB := Elements.mk\n \n-ifneq ($(wildcard $(CURDIR)/cmake/$(TOOLCHAIN_NAME)),)\n-  TOOLCHAIN_FILE := $(CURDIR)/cmake/$(TOOLCHAIN_NAME)\n+ifneq ($(wildcard $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)),)\n+  ELEMENTS_MAKE_LIB_FILE := $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)\n else\n   ifneq ($(CMAKE_PREFIX_PATH),)\n     PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    TOOLCHAIN_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/lib*/cmake/ElementsProject/$(TOOLCHAIN_NAME) $(dir)/$(TOOLCHAIN_NAME)))\n-    TOOLCHAIN_FILE := $(firstword $(TOOLCHAIN_LIST))\n+    ELEMENTS_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(ELEMENTS_MAKE_LIB) $(dir)/../make/$(ELEMENTS_MAKE_LIB)))\n   endif\n+  ELEMENTS_MAKE_LIB_LIST += /usr/share/Elements/make/$(ELEMENTS_MAKE_LIB)\n+  ELEMENTS_MAKE_LIB_FILE := $(firstword $(ELEMENTS_MAKE_LIB_LIST))\n endif\n \n-override ALL_CMAKEFLAGS := -Wno-dev --no-warn-unused-cli\n-\n-ifneq ($(TOOLCHAIN_FILE),)\n-  # A toolchain has been found. Lets use it.\n-  override ALL_CMAKEFLAGS += -DCMAKE_TOOLCHAIN_FILE=$(TOOLCHAIN_FILE)\n-endif\n-\n-\n-BUILD_PREFIX_NAME := build\n-\n-override ALL_CMAKEFLAGS += -DUSE_LOCAL_INSTALLAREA=ON -DBUILD_PREFIX_NAME:STRING=$(BUILD_PREFIX_NAME)\n-override ALL_CMAKEFLAGS += -DUSE_VERSIONED_LIBRARIES=OFF\n-\n-ifndef BINARY_TAG\n-  ifdef CMAKECONFIG\n-    BINARY_TAG := ${CMAKECONFIG}\n-  else\n-    ifdef CMTCONFIG\n-      BINARY_TAG := ${CMTCONFIG}\n-    endif\n-  endif\n-endif\n-\n-ifdef BINARY_TAG\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME).$(BINARY_TAG)\n-else\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME)\n-endif\n-BUILDDIR := $(CURDIR)/$(BUILD_SUBDIR)\n-\n-# build tool\n-\n-ifneq ($(USE_NINJA),)\n-  # enable Ninja\n-  override ALL_CMAKEFLAGS += -GNinja\n-  BUILD_CONF_FILE := build.ninja\n-  BUILDFLAGS := $(NINJAFLAGS)\n-  ifneq ($(VERBOSE),)\n-    BUILDFLAGS := -v $(BUILDFLAGS)\n-  endif\n-else\n-  BUILD_CONF_FILE := Makefile\n-endif\n-BUILD_CMD := $(CMAKE) --build $(BUILD_SUBDIR) --target\n-\n-\n-# Use environment variable for extra flags\n-\n-# Replace the \":\" from eclipse variable list to spaces  \n-ifneq ($(EXPAND_FLAGS),)\n-  CMAKEFLAGS := $(subst :-, -,$(CMAKEFLAGS))\n-endif\n-\n-ifneq ($(CMAKEFLAGS),)\n-  override ALL_CMAKEFLAGS += $(CMAKEFLAGS)\n-endif\n-\n-# default target\n-all:\n-\n-# deep clean\n-purge:\n-\t$(RM) -r $(BUILDDIR) $(CURDIR)/InstallArea/$(BINARY_TAG)\n-\tfind $(CURDIR) \"(\" -name \"InstallArea\" -prune -o -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# Remove all the possible directories and the whole InstallArea as well\n-mrproper:\n-\t$(RM) -r $(CURDIR)/build $(CURDIR)/build.* $(CURDIR)/InstallArea\n-\tfind $(CURDIR) \"(\" -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# delegate any target to the build directory (except 'purge')\n-ifneq ($(MAKECMDGOALS),purge)\n-ifneq ($(MAKECMDGOALS),mrproper)\n-%: $(BUILDDIR)/$(BUILD_CONF_FILE) FORCE\n-\t+$(BUILD_CMD) $* -- $(BUILDFLAGS)\n-endif\n-endif\n-\n-# aliases\n-.PHONY: configure tests FORCE\n-ifneq ($(wildcard $(BUILDDIR)/$(BUILD_CONF_FILE)),)\n-configure: rebuild_cache\n-else\n-configure: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-endif\n-\t@ # do not delegate further\n-\n-\n-# This wrapping around the test target is used to ensure the generation of\n-# the XML output from ctest.\n-test: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-\n-# This target ensures that the \"all\" target is called before\n-# running the tests (unlike the \"test\" default target of CMake)\n-tests: all\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-ifeq ($(VERBOSE),)\n-# less verbose install\n-# (emulate the default CMake install target)\n-install: all\n-\tcd $(BUILDDIR) && $(CMAKE) -P cmake_install.cmake | grep -v \"^-- Up-to-date:\"\n-endif\n-\n-# import the library to look for a custom Makefile\n--include $(CUSTOM_MAKE_LIB_FILE)\n-\n-# ensure that the target are always passed to the CMake Makefile\n-FORCE: ;\n-\n-# Makefiles are used as implicit targets in make, but we should not consider\n-# them for delegation.\n-$(MAKEFILE_LIST): ;\n-\n-\n-# trigger CMake configuration\n-$(BUILDDIR)/$(BUILD_CONF_FILE): | $(BUILDDIR)\n-\tcd $(BUILDDIR) && $(CMAKE) $(ALL_CMAKEFLAGS) $(CURDIR)\n+$(info Using the $(ELEMENTS_MAKE_LIB_FILE) make library)\n+include $(ELEMENTS_MAKE_LIB_FILE)\n \n-$(BUILDDIR):\n-\tmkdir -p $(BUILDDIR)\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ]
                },
                "selected_modifications": {
                    "MER_IAL_Pipelines/auxdir/MER_ProcessTile_Pipeline/PkgDef_MER_ProcessTile.py": [
                        [
                            "@@ -62,9 +62,7 @@ MER_Background = Executable(command=\"E-Run MER_Background 10.2 MER_BackgroundPrg\n MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.2 MER_VisDetectionPrg\",\n                               inputs=[Input(\"mosaic\"),\n                                       Input(\"configuration\"),\n-                                      Input(\"flag_limits\"),\n-                                      Input(\"nir_mosaics\", content_type=\"listfile\"),\n-                                      Input(\"ext_mosaics\", content_type=\"listfile\")],\n+                                      Input(\"flag_limits\")],\n                               outputs=[Output(\"detection_mosaic\", mime_type=\"xml\"),\n                                        Output(\"segmentation_map\", mime_type=\"xml\"),\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n@@ -74,9 +72,7 @@ MER_NirDetection = Executable(command=\"E-Run MER_Detection 10.2 MER_NirDetection\n                               inputs=[Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                       Input(\"tile\"),\n                                       Input(\"configuration\"),\n-                                      Input(\"flag_limits\"),\n-                                      Input(\"vis_mosaic\"),\n-                                      Input(\"ext_mosaics\", content_type=\"listfile\")],\n+                                      Input(\"flag_limits\")],\n                               outputs=[Output(\"detection_mosaic\", mime_type=\"xml\"),\n                                        Output(\"segmentation_map\", mime_type=\"xml\"),\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n",
                            "Merge branch 'feature/slim_detection' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T14:07:39.000+00:00",
                            "83523e87084abc2c20a56604754a0f138bbe0467"
                        ],
                        [
                            "@@ -56,9 +56,7 @@ MER_Background = Executable(command=\"E-Run MER_Background 10.2 MER_BackgroundPrg\n MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.2 MER_VisDetectionPrg\",\n                               inputs=[Input(\"mosaic\"),\n                                       Input(\"configuration\"),\n-                                      Input(\"flag_limits\"),\n-                                      Input(\"nir_mosaics\", content_type=\"listfile\"),\n-                                      Input(\"ext_mosaics\", content_type=\"listfile\")],\n+                                      Input(\"flag_limits\")],\n                               outputs=[Output(\"detection_mosaic\", mime_type=\"xml\"),\n                                        Output(\"segmentation_map\", mime_type=\"xml\"),\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n@@ -68,9 +66,7 @@ MER_NirDetection = Executable(command=\"E-Run MER_Detection 10.2 MER_NirDetection\n                               inputs=[Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                       Input(\"tile\"),\n                                       Input(\"configuration\"),\n-                                      Input(\"flag_limits\"),\n-                                      Input(\"vis_mosaic\"),\n-                                      Input(\"ext_mosaics\", content_type=\"listfile\")],\n+                                      Input(\"flag_limits\")],\n                               outputs=[Output(\"detection_mosaic\", mime_type=\"xml\"),\n                                        Output(\"segmentation_map\", mime_type=\"xml\"),\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n",
                            "Detection now *without* the model fitting interface.",
                            "Martin Kuemmel",
                            "2023-08-16T15:59:45.000+02:00",
                            "27cff94a74e37a58c7ac2be5e9d40888e25fb37d"
                        ],
                        [
                            "@@ -25,7 +25,13 @@ from euclidwf.framework.taskdefs import (Executable, Input, Output,\n \n \n ENV_VARIABLES = {\n-    \"MPLCONFIGDIR\": \"/dev/null\"\n+    \"MPLCONFIGDIR\": \"/dev/null\",\n+    \"MKL_NUM_THREADS\": \"1\",\n+    \"NUMEXPR_NUM_THREADS\": \"1\",\n+    \"OMP_NUM_THREADS\": \"1\",\n+    \"OPENBLAS_NUM_THREADS\": \"1\", \n+    \"VECLIB_MAXIMUM_THREADS\": \"1\", \n+    \"NTHREADS\":  \"1\" \n }\n \n MER_Initialize = Executable(command=\"E-Run MER_Pipeline 10.2 MER_Initialize\",\n",
                            "Pass the same environment variables in all package defs",
                            "Javier Gracia Carpio",
                            "2023-08-16T13:20:46.000+00:00",
                            "09023779349a879cd1ad6aa851e1d12e5edea37e"
                        ],
                        [
                            "@@ -28,7 +28,7 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n-MER_Initialize = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Initialize\",\n+MER_Initialize = Executable(command=\"E-Run MER_Pipeline 10.2 MER_Initialize\",\n                             inputs=[Input(\"vis_calibrated_frames\", content_type=\"listfile\"),\n                                     Input(\"nir_calibrated_frames\", content_type=\"listfile\"),\n                                     Input(\"ext_stacks\", content_type=\"listfile\")],\n@@ -37,7 +37,7 @@ MER_Initialize = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Initialize\",\n                                      Output(\"ext_image_lists\", content_type=\"listfile\", mime_type=\"json\")],\n                             resources=ComputingResources(cores=1, ram=1.0, walltime=0.3))\n \n-MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Mosaicing\",\n+MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.2 MER_Mosaicing\",\n                            inputs=[Input(\"image_list\", content_type=\"listfile\"),\n                                    Input(\"tile\"),\n                                    Input(\"configuration\"),\n@@ -46,14 +46,14 @@ MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Mosaicing\",\n                            outputs=[Output(\"mosaic\", mime_type=\"xml\")],\n                            resources=ComputingResources(cores=2, ram=6.0, walltime=6.0, tmpsize=999))\n \n-MER_Background = Executable(command=\"E-Run MER_Background 10.1 MER_BackgroundPrg\",\n+MER_Background = Executable(command=\"E-Run MER_Background 10.2 MER_BackgroundPrg\",\n                             inputs=[Input(\"mosaic\"),\n                                     Input(\"configuration\"),\n                                     Input(\"flag_limits\")],\n                             outputs=[Output(\"background_subtracted_mosaic\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=8.0, walltime=4.0))\n \n-MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.1 MER_VisDetectionPrg\",\n+MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.2 MER_VisDetectionPrg\",\n                               inputs=[Input(\"mosaic\"),\n                                       Input(\"configuration\"),\n                                       Input(\"flag_limits\"),\n@@ -64,7 +64,7 @@ MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.1 MER_VisDetection\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=4, ram=20.0, walltime=6.0))\n \n-MER_NirDetection = Executable(command=\"E-Run MER_Detection 10.1 MER_NirDetectionPrg\",\n+MER_NirDetection = Executable(command=\"E-Run MER_Detection 10.2 MER_NirDetectionPrg\",\n                               inputs=[Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                       Input(\"tile\"),\n                                       Input(\"configuration\"),\n@@ -76,7 +76,7 @@ MER_NirDetection = Executable(command=\"E-Run MER_Detection 10.1 MER_NirDetection\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=4, ram=20.0, walltime=6.0))\n \n-MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.1 MER_Deblending\",\n+MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.2 MER_Deblending\",\n                             inputs=[Input(\"input_mosaic\"),\n                                     Input(\"detection_segmap\"),\n                                     Input(\"configuration\"),\n@@ -86,7 +86,7 @@ MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.1 MER_Deblending\",\n                                      Output(\"to_aphot_catalog\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=22.0, walltime=14.0))\n \n-MER_MBCombine = Executable(command=\"E-Run MER_Detection 10.1 MER_MBCombinePrg\",\n+MER_MBCombine = Executable(command=\"E-Run MER_Detection 10.2 MER_MBCombinePrg\",\n                            inputs=[Input(\"visSegmentMap\"),\n                                    Input(\"visDetectionCatalog\"),\n                                    Input(\"nirSegmentMap\"),\n@@ -98,7 +98,7 @@ MER_MBCombine = Executable(command=\"E-Run MER_Detection 10.1 MER_MBCombinePrg\",\n                                     Output(\"combinedDetectionCat\", mime_type=\"xml\")],\n                            resources=ComputingResources(cores=1, ram=8.0, walltime=0.5))\n \n-MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.1 MER_CatalogPsfCalculation\",\n+MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.2 MER_CatalogPsfCalculation\",\n                            inputs=[Input(\"image_list\", content_type=\"listfile\"),\n                                    Input(\"mosaic\"),\n                                    Input(\"catalog\"),\n@@ -107,20 +107,20 @@ MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Cata\n                            outputs=[Output(\"output_mosaic\", mime_type=\"xml\")],\n                            resources=ComputingResources(cores=2, ram=6.0, walltime=4.0, tmpsize=999))\n \n-MER_PsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.1 MER_PsfExtraction\",\n+MER_PsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.2 MER_PsfExtraction\",\n                                inputs=[Input(\"mosaic\"),\n                                        Input(\"catalog\")],\n                                outputs=[Output(\"psf_stamp_collection\", mime_type=\"xml\")],\n                                resources=ComputingResources(cores=1, ram=3.0, walltime=1.0))\n \n-MER_LowResPsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.1 MER_LowResPsfExtraction\",\n+MER_LowResPsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.2 MER_LowResPsfExtraction\",\n                                      inputs=[Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                              Input(\"ext_mosaics\", content_type=\"listfile\"),\n                                              Input(\"catalog\")],\n                                      outputs=[Output(\"psf_stamp_collection\", mime_type=\"xml\")],\n                                      resources=ComputingResources(cores=1, ram=14.0, walltime=3.0))\n \n-MER_MosaicSelection = Executable(command=\"E-Run MER_Pipeline 10.1 MER_MosaicSelection\",\n+MER_MosaicSelection = Executable(command=\"E-Run MER_Pipeline 10.2 MER_MosaicSelection\",\n                                  inputs=[Input(\"vis_mosaic\"),\n                                          Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                          Input(\"ext_mosaics\", content_type=\"listfile\")],\n@@ -128,7 +128,7 @@ MER_MosaicSelection = Executable(command=\"E-Run MER_Pipeline 10.1 MER_MosaicSele\n                                           Output(\"nir_and_ext_mosaics\", content_type=\"listfile\", mime_type=\"json\")],\n                                  resources=ComputingResources(cores=1, ram=1.0, walltime=0.3))\n \n-MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.1 MER_Morphology\",\n+MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.2 MER_Morphology\",\n                             inputs=[Input(\"input_mosaic\"),\n                                     Input(\"input_segmap\"),\n                                     Input(\"input_catalog\"),\n@@ -136,19 +136,19 @@ MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.1 MER_Morphology\",\n                             outputs=[Output(\"morph_catalog\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=10.0, walltime=2.0))\n \n-MER_NirCatalogMerging = Executable(command=\"E-Run MER_Pipeline 10.1 MER_NirCatalogMerging\",\n+MER_NirCatalogMerging = Executable(command=\"E-Run MER_Pipeline 10.2 MER_NirCatalogMerging\",\n                                    inputs=[Input(\"catalogs\", content_type=\"listfile\")],\n                                    outputs=[Output(\"nir_merged_catalog\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=1.0, walltime=0.3))\n \n-MER_KernelAPhot = Executable(command=\"E-Run MER_Pipeline 10.1 MER_KernelAPhot\",\n+MER_KernelAPhot = Executable(command=\"E-Run MER_Pipeline 10.2 MER_KernelAPhot\",\n                              inputs=[Input(\"mosaic_input\"),\n                                      Input(\"low_resolution_psf\"),\n                                      Input(\"catalog\")],\n                              outputs=[Output(\"transformation_kernel\", mime_type=\"xml\")],\n                              resources=ComputingResources(cores=1, ram=16.0, walltime=3.0))\n \n-MER_KernelAPhotNIRStack = Executable(command=\"E-Run MER_Pipeline 10.1 MER_KernelAPhotNIRStack\",\n+MER_KernelAPhotNIRStack = Executable(command=\"E-Run MER_Pipeline 10.2 MER_KernelAPhotNIRStack\",\n                                      inputs=[Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                              Input(\"low_resolution_psf\"),\n                                              Input(\"catalog\"),\n@@ -156,7 +156,7 @@ MER_KernelAPhotNIRStack = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Kernel\n                                      outputs=[Output(\"transformation_kernel\", mime_type=\"xml\")],\n                                      resources=ComputingResources(cores=1, ram=16.0, walltime=3.0))\n \n-MER_KernelTPhot = Executable(command=\"E-Run MER_Pipeline 10.1 MER_KernelTPhot\",\n+MER_KernelTPhot = Executable(command=\"E-Run MER_Pipeline 10.2 MER_KernelTPhot\",\n                              inputs=[Input(\"vis_mosaic\"),\n                                      Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                      Input(\"mosaic_target\"),\n@@ -165,7 +165,7 @@ MER_KernelTPhot = Executable(command=\"E-Run MER_Pipeline 10.1 MER_KernelTPhot\",\n                              outputs=[Output(\"transformation_kernel\", mime_type=\"xml\")],\n                              resources=ComputingResources(cores=1, ram=12.0, walltime=3.0))\n \n-MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotMorphology\",\n+MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.2 MER_APhotMorphology\",\n                                    inputs=[Input(\"configuration\"),\n                                            Input(\"input_image\"),\n                                            Input(\"input_catalog\"),\n@@ -173,7 +173,7 @@ MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotM\n                                    outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=10.0, walltime=1.0))\n \n-MER_Photometry_FilterTransmission = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotTrasmission\",\n+MER_Photometry_FilterTransmission = Executable(command=\"E-Run MER_Photometry 10.2 MER_APhotTrasmission\",\n                                                inputs=[Input(\"input_image\"),\n                                                        Input(\"configuration\"),\n                                                        Input(\"input_catalog\"),\n@@ -181,7 +181,7 @@ MER_Photometry_FilterTransmission = Executable(command=\"E-Run MER_Photometry 10.\n                                                outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                                resources=ComputingResources(cores=1, ram=10.0, walltime=1.0))\n \n-MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotDetection\",\n+MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.2 MER_APhotDetection\",\n                                 inputs=[Input(\"configuration\"),\n                                         Input(\"input_image\"),\n                                         Input(\"nir_input_image\"),\n@@ -192,7 +192,7 @@ MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotDete\n                                 outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                 resources=ComputingResources(cores=1, ram=12.0, walltime=1.0))\n \n-MER_Photometry_A = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotCircular\",\n+MER_Photometry_A = Executable(command=\"E-Run MER_Photometry 10.2 MER_APhotCircular\",\n                               inputs=[Input(\"configuration\"),\n                                       Input(\"input_image\"),\n                                       Input(\"input_catalog\"),\n@@ -201,7 +201,7 @@ MER_Photometry_A = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotCircul\n                               outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=1, ram=12.0, walltime=2.0))\n \n-MER_Photometry_T = Executable(command=\"E-Run MER_Photometry 10.1 MER_TPhotProgram\",\n+MER_Photometry_T = Executable(command=\"E-Run MER_Photometry 10.2 MER_TPhotProgram\",\n                               inputs=[Input(\"configuration\"),\n                                       Input(\"vis_image\"),\n                                       Input(\"nir_image\"),\n@@ -214,7 +214,7 @@ MER_Photometry_T = Executable(command=\"E-Run MER_Photometry 10.1 MER_TPhotProgra\n                                        Output(\"stats_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=1, ram=36.0, walltime=14.0))\n \n-MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.1 MER_PsfFitting\",\n+MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.2 MER_PsfFitting\",\n                                        inputs=[Input(\"configuration\"),\n                                                Input(\"vis_image\"),\n                                                Input(\"input_catalog\"),\n@@ -223,7 +223,7 @@ MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.1 MER_Ps\n                                        outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                        resources=ComputingResources(cores=1, ram=16.0, walltime=12.0))\n \n-MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.1 MER_CatalogAssembly\",\n+MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.2 MER_CatalogAssembly\",\n                          inputs=[Input(\"vis_mosaic\"),\n                                  Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                  Input(\"gaia_cutouts\", content_type=\"listfile\"),\n@@ -246,13 +246,13 @@ MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.1 MER_CatalogAsse\n                                   Output(\"final_segmap\", mime_type=\"xml\")],\n                          resources=ComputingResources(cores=1, ram=22.0, walltime=1.0))\n \n-MER_QuickAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_QuickAnalysis\",\n+MER_QuickAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_QuickAnalysis\",\n                                inputs=[Input(\"final_catalog\")],\n                                outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                resources=ComputingResources(cores=1, ram=2.0, walltime=1.0),\n                                env_variables=ENV_VARIABLES)\n \n-MER_Compression = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Compression\",\n+MER_Compression = Executable(command=\"E-Run MER_Pipeline 10.2 MER_Compression\",\n                          inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                  Input(\"vis_detection_mosaic\"),\n                                  Input(\"nir_detection_mosaic\"),\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -28,7 +28,7 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n-MER_Initialize = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Initialize\",\n+MER_Initialize = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Initialize\",\n                             inputs=[Input(\"vis_calibrated_frames\", content_type=\"listfile\"),\n                                     Input(\"nir_calibrated_frames\", content_type=\"listfile\"),\n                                     Input(\"ext_stacks\", content_type=\"listfile\")],\n@@ -37,7 +37,7 @@ MER_Initialize = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Initialize\",\n                                      Output(\"ext_image_lists\", content_type=\"listfile\", mime_type=\"json\")],\n                             resources=ComputingResources(cores=1, ram=1.0, walltime=0.3))\n \n-MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Mosaicing\",\n+MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Mosaicing\",\n                            inputs=[Input(\"image_list\", content_type=\"listfile\"),\n                                    Input(\"tile\"),\n                                    Input(\"configuration\"),\n@@ -46,14 +46,14 @@ MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Mosaicing\",\n                            outputs=[Output(\"mosaic\", mime_type=\"xml\")],\n                            resources=ComputingResources(cores=2, ram=6.0, walltime=6.0, tmpsize=999))\n \n-MER_Background = Executable(command=\"E-Run MER_Background 10.0 MER_BackgroundPrg\",\n+MER_Background = Executable(command=\"E-Run MER_Background 10.1 MER_BackgroundPrg\",\n                             inputs=[Input(\"mosaic\"),\n                                     Input(\"configuration\"),\n                                     Input(\"flag_limits\")],\n                             outputs=[Output(\"background_subtracted_mosaic\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=8.0, walltime=4.0))\n \n-MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.0 MER_VisDetectionPrg\",\n+MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.1 MER_VisDetectionPrg\",\n                               inputs=[Input(\"mosaic\"),\n                                       Input(\"configuration\"),\n                                       Input(\"flag_limits\"),\n@@ -64,7 +64,7 @@ MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.0 MER_VisDetection\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=4, ram=20.0, walltime=6.0))\n \n-MER_NirDetection = Executable(command=\"E-Run MER_Detection 10.0 MER_NirDetectionPrg\",\n+MER_NirDetection = Executable(command=\"E-Run MER_Detection 10.1 MER_NirDetectionPrg\",\n                               inputs=[Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                       Input(\"tile\"),\n                                       Input(\"configuration\"),\n@@ -76,7 +76,7 @@ MER_NirDetection = Executable(command=\"E-Run MER_Detection 10.0 MER_NirDetection\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=4, ram=20.0, walltime=6.0))\n \n-MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.0 MER_Deblending\",\n+MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.1 MER_Deblending\",\n                             inputs=[Input(\"input_mosaic\"),\n                                     Input(\"detection_segmap\"),\n                                     Input(\"configuration\"),\n@@ -86,7 +86,7 @@ MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.0 MER_Deblending\",\n                                      Output(\"to_aphot_catalog\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=22.0, walltime=14.0))\n \n-MER_MBCombine = Executable(command=\"E-Run MER_Detection 10.0 MER_MBCombinePrg\",\n+MER_MBCombine = Executable(command=\"E-Run MER_Detection 10.1 MER_MBCombinePrg\",\n                            inputs=[Input(\"visSegmentMap\"),\n                                    Input(\"visDetectionCatalog\"),\n                                    Input(\"nirSegmentMap\"),\n@@ -98,7 +98,7 @@ MER_MBCombine = Executable(command=\"E-Run MER_Detection 10.0 MER_MBCombinePrg\",\n                                     Output(\"combinedDetectionCat\", mime_type=\"xml\")],\n                            resources=ComputingResources(cores=1, ram=8.0, walltime=0.5))\n \n-MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.0 MER_CatalogPsfCalculation\",\n+MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.1 MER_CatalogPsfCalculation\",\n                            inputs=[Input(\"image_list\", content_type=\"listfile\"),\n                                    Input(\"mosaic\"),\n                                    Input(\"catalog\"),\n@@ -107,20 +107,20 @@ MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Cata\n                            outputs=[Output(\"output_mosaic\", mime_type=\"xml\")],\n                            resources=ComputingResources(cores=2, ram=6.0, walltime=4.0, tmpsize=999))\n \n-MER_PsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.0 MER_PsfExtraction\",\n+MER_PsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.1 MER_PsfExtraction\",\n                                inputs=[Input(\"mosaic\"),\n                                        Input(\"catalog\")],\n                                outputs=[Output(\"psf_stamp_collection\", mime_type=\"xml\")],\n                                resources=ComputingResources(cores=1, ram=3.0, walltime=1.0))\n \n-MER_LowResPsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.0 MER_LowResPsfExtraction\",\n+MER_LowResPsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.1 MER_LowResPsfExtraction\",\n                                      inputs=[Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                              Input(\"ext_mosaics\", content_type=\"listfile\"),\n                                              Input(\"catalog\")],\n                                      outputs=[Output(\"psf_stamp_collection\", mime_type=\"xml\")],\n                                      resources=ComputingResources(cores=1, ram=14.0, walltime=3.0))\n \n-MER_MosaicSelection = Executable(command=\"E-Run MER_Pipeline 10.0 MER_MosaicSelection\",\n+MER_MosaicSelection = Executable(command=\"E-Run MER_Pipeline 10.1 MER_MosaicSelection\",\n                                  inputs=[Input(\"vis_mosaic\"),\n                                          Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                          Input(\"ext_mosaics\", content_type=\"listfile\")],\n@@ -128,7 +128,7 @@ MER_MosaicSelection = Executable(command=\"E-Run MER_Pipeline 10.0 MER_MosaicSele\n                                           Output(\"nir_and_ext_mosaics\", content_type=\"listfile\", mime_type=\"json\")],\n                                  resources=ComputingResources(cores=1, ram=1.0, walltime=0.3))\n \n-MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.0 MER_Morphology\",\n+MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.1 MER_Morphology\",\n                             inputs=[Input(\"input_mosaic\"),\n                                     Input(\"input_segmap\"),\n                                     Input(\"input_catalog\"),\n@@ -136,19 +136,19 @@ MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.0 MER_Morphology\",\n                             outputs=[Output(\"morph_catalog\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=10.0, walltime=2.0))\n \n-MER_NirCatalogMerging = Executable(command=\"E-Run MER_Pipeline 10.0 MER_NirCatalogMerging\",\n+MER_NirCatalogMerging = Executable(command=\"E-Run MER_Pipeline 10.1 MER_NirCatalogMerging\",\n                                    inputs=[Input(\"catalogs\", content_type=\"listfile\")],\n                                    outputs=[Output(\"nir_merged_catalog\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=1.0, walltime=0.3))\n \n-MER_KernelAPhot = Executable(command=\"E-Run MER_Pipeline 10.0 MER_KernelAPhot\",\n+MER_KernelAPhot = Executable(command=\"E-Run MER_Pipeline 10.1 MER_KernelAPhot\",\n                              inputs=[Input(\"mosaic_input\"),\n                                      Input(\"low_resolution_psf\"),\n                                      Input(\"catalog\")],\n                              outputs=[Output(\"transformation_kernel\", mime_type=\"xml\")],\n                              resources=ComputingResources(cores=1, ram=16.0, walltime=3.0))\n \n-MER_KernelAPhotNIRStack = Executable(command=\"E-Run MER_Pipeline 10.0 MER_KernelAPhotNIRStack\",\n+MER_KernelAPhotNIRStack = Executable(command=\"E-Run MER_Pipeline 10.1 MER_KernelAPhotNIRStack\",\n                                      inputs=[Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                              Input(\"low_resolution_psf\"),\n                                              Input(\"catalog\"),\n@@ -156,7 +156,7 @@ MER_KernelAPhotNIRStack = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Kernel\n                                      outputs=[Output(\"transformation_kernel\", mime_type=\"xml\")],\n                                      resources=ComputingResources(cores=1, ram=16.0, walltime=3.0))\n \n-MER_KernelTPhot = Executable(command=\"E-Run MER_Pipeline 10.0 MER_KernelTPhot\",\n+MER_KernelTPhot = Executable(command=\"E-Run MER_Pipeline 10.1 MER_KernelTPhot\",\n                              inputs=[Input(\"vis_mosaic\"),\n                                      Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                      Input(\"mosaic_target\"),\n@@ -165,7 +165,7 @@ MER_KernelTPhot = Executable(command=\"E-Run MER_Pipeline 10.0 MER_KernelTPhot\",\n                              outputs=[Output(\"transformation_kernel\", mime_type=\"xml\")],\n                              resources=ComputingResources(cores=1, ram=12.0, walltime=3.0))\n \n-MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotMorphology\",\n+MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotMorphology\",\n                                    inputs=[Input(\"configuration\"),\n                                            Input(\"input_image\"),\n                                            Input(\"input_catalog\"),\n@@ -173,7 +173,7 @@ MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotM\n                                    outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=10.0, walltime=1.0))\n \n-MER_Photometry_FilterTransmission = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotTrasmission\",\n+MER_Photometry_FilterTransmission = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotTrasmission\",\n                                                inputs=[Input(\"input_image\"),\n                                                        Input(\"configuration\"),\n                                                        Input(\"input_catalog\"),\n@@ -181,7 +181,7 @@ MER_Photometry_FilterTransmission = Executable(command=\"E-Run MER_Photometry 10.\n                                                outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                                resources=ComputingResources(cores=1, ram=10.0, walltime=1.0))\n \n-MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotDetection\",\n+MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotDetection\",\n                                 inputs=[Input(\"configuration\"),\n                                         Input(\"input_image\"),\n                                         Input(\"nir_input_image\"),\n@@ -192,7 +192,7 @@ MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotDete\n                                 outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                 resources=ComputingResources(cores=1, ram=12.0, walltime=1.0))\n \n-MER_Photometry_A = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotCircular\",\n+MER_Photometry_A = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotCircular\",\n                               inputs=[Input(\"configuration\"),\n                                       Input(\"input_image\"),\n                                       Input(\"input_catalog\"),\n@@ -201,7 +201,7 @@ MER_Photometry_A = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotCircul\n                               outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=1, ram=12.0, walltime=2.0))\n \n-MER_Photometry_T = Executable(command=\"E-Run MER_Photometry 10.0 MER_TPhotProgram\",\n+MER_Photometry_T = Executable(command=\"E-Run MER_Photometry 10.1 MER_TPhotProgram\",\n                               inputs=[Input(\"configuration\"),\n                                       Input(\"vis_image\"),\n                                       Input(\"nir_image\"),\n@@ -214,7 +214,7 @@ MER_Photometry_T = Executable(command=\"E-Run MER_Photometry 10.0 MER_TPhotProgra\n                                        Output(\"stats_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=1, ram=36.0, walltime=14.0))\n \n-MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.0 MER_PsfFitting\",\n+MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.1 MER_PsfFitting\",\n                                        inputs=[Input(\"configuration\"),\n                                                Input(\"vis_image\"),\n                                                Input(\"input_catalog\"),\n@@ -223,7 +223,7 @@ MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.0 MER_Ps\n                                        outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                        resources=ComputingResources(cores=1, ram=16.0, walltime=12.0))\n \n-MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.0 MER_CatalogAssembly\",\n+MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.1 MER_CatalogAssembly\",\n                          inputs=[Input(\"vis_mosaic\"),\n                                  Input(\"nir_mosaics\", content_type=\"listfile\"),\n                                  Input(\"gaia_cutouts\", content_type=\"listfile\"),\n@@ -246,13 +246,13 @@ MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.0 MER_CatalogAsse\n                                   Output(\"final_segmap\", mime_type=\"xml\")],\n                          resources=ComputingResources(cores=1, ram=22.0, walltime=1.0))\n \n-MER_QuickAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_QuickAnalysis\",\n+MER_QuickAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_QuickAnalysis\",\n                                inputs=[Input(\"final_catalog\")],\n                                outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                resources=ComputingResources(cores=1, ram=2.0, walltime=1.0),\n                                env_variables=ENV_VARIABLES)\n \n-MER_Compression = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Compression\",\n+MER_Compression = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Compression\",\n                          inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                  Input(\"vis_detection_mosaic\"),\n                                  Input(\"nir_detection_mosaic\"),\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_AnalyseTile_Pipeline/PkgDef_MER_AnalyseTile.py": [
                        [
                            "@@ -26,7 +26,13 @@ from euclidwf.framework.taskdefs import (Executable, Input, Output,\n \n \n ENV_VARIABLES = {\n-    \"MPLCONFIGDIR\": \"/dev/null\"\n+    \"MPLCONFIGDIR\": \"/dev/null\",\n+    \"MKL_NUM_THREADS\": \"1\",\n+    \"NUMEXPR_NUM_THREADS\": \"1\",\n+    \"OMP_NUM_THREADS\": \"1\",\n+    \"OPENBLAS_NUM_THREADS\": \"1\", \n+    \"VECLIB_MAXIMUM_THREADS\": \"1\", \n+    \"NTHREADS\":  \"1\" \n }\n \n MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_MosaicingValidation\",\n",
                            "Pass the same environment variables in all package defs",
                            "Javier Gracia Carpio",
                            "2023-08-16T13:20:46.000+00:00",
                            "09023779349a879cd1ad6aa851e1d12e5edea37e"
                        ],
                        [
                            "@@ -29,34 +29,34 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n-MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MosaicingValidation\",\n+MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_MosaicingValidation\",\n                                    inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                            Input(\"segmap\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=16.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_PsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PsfAnalysis\",\n+MER_PsfAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_PsfAnalysis\",\n                              inputs=[Input(\"mosaics\", content_type=\"listfile\")],\n                              outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                              resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                              env_variables=ENV_VARIABLES)\n \n-MER_MerStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MerStarPsfAnalysis\",\n+MER_MerStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_MerStarPsfAnalysis\",\n                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                             Input(\"final_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_TuStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_TuStarPsfAnalysis\",\n+MER_TuStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_TuStarPsfAnalysis\",\n                                    inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                            Input(\"tu_star_catalog\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_BackgroundValidationPrg\",\n+MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_BackgroundValidationPrg\",\n                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                             Input(\"final_catalog\"),\n                                             Input(\"final_segmap\")],\n@@ -64,7 +64,7 @@ MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_Backg\n                                     resources=ComputingResources(cores=1, ram=26.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_DetectionValidationPrg\",\n+MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_DetectionValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"tile_file\"),\n                                            Input(\"tu_stars\"),\n@@ -73,7 +73,7 @@ MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_Detect\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_CrossmatchAnalysis\",\n+MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_CrossmatchAnalysis\",\n                                     inputs=[Input(\"final_catalog\"),\n                                             Input(\"vis_detection_mosaic\"),\n                                             Input(\"nir_detection_mosaic\"),\n@@ -85,19 +85,19 @@ MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_Cross\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_MorphologyAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MorphologyValidationPrg\",\n+MER_MorphologyAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_MorphologyValidationPrg\",\n                                     inputs=[Input(\"matched_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_PhotometryAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PhotometryAnalysis\",\n+MER_PhotometryAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_PhotometryAnalysis\",\n                                     inputs=[Input(\"crossmatched_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PhotometryPlotCheck\",\n+MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_PhotometryPlotCheck\",\n                                          inputs=[Input(\"final_catalog\"),\n                                                  Input(\"TU_gal_catalog\"),\n                                                  Input(\"TU_star_catalog\")],\n@@ -105,7 +105,7 @@ MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_\n                                          resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                          env_variables=ENV_VARIABLES)\n \n-MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_ClassificationValidationPrg\",\n+MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_ClassificationValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"tile_file\"),\n                                            Input(\"tu_stars\"),\n@@ -115,13 +115,13 @@ MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_C\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_FinalCatalogAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_CheckFinalCat\",\n+MER_FinalCatalogAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_CheckFinalCat\",\n                                    inputs=[Input(\"final_cat\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_MergeAnalysisResults = Executable(command=\"E-Run MER_Validation 10.1 MER_MergeAnalysisResults\",\n+MER_MergeAnalysisResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeAnalysisResults\",\n                                       inputs=[Input(\"mosaicing_analysis_result\"),\n                                               Input(\"psf_analysis_result\"),\n                                               Input(\"mer_star_psf_analysis_result\"),\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -29,34 +29,34 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n-MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_MosaicingValidation\",\n+MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MosaicingValidation\",\n                                    inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                            Input(\"segmap\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=16.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_PsfAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_PsfAnalysis\",\n+MER_PsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PsfAnalysis\",\n                              inputs=[Input(\"mosaics\", content_type=\"listfile\")],\n                              outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                              resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                              env_variables=ENV_VARIABLES)\n \n-MER_MerStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_MerStarPsfAnalysis\",\n+MER_MerStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MerStarPsfAnalysis\",\n                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                             Input(\"final_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_TuStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_TuStarPsfAnalysis\",\n+MER_TuStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_TuStarPsfAnalysis\",\n                                    inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                            Input(\"tu_star_catalog\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_BackgroundValidationPrg\",\n+MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_BackgroundValidationPrg\",\n                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                             Input(\"final_catalog\"),\n                                             Input(\"final_segmap\")],\n@@ -64,7 +64,7 @@ MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_Backg\n                                     resources=ComputingResources(cores=1, ram=26.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_DetectionValidationPrg\",\n+MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_DetectionValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"tile_file\"),\n                                            Input(\"tu_stars\"),\n@@ -73,7 +73,7 @@ MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_Detect\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_CrossmatchAnalysis\",\n+MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_CrossmatchAnalysis\",\n                                     inputs=[Input(\"final_catalog\"),\n                                             Input(\"vis_detection_mosaic\"),\n                                             Input(\"nir_detection_mosaic\"),\n@@ -85,19 +85,19 @@ MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_Cross\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_MorphologyAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_MorphologyValidationPrg\",\n+MER_MorphologyAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MorphologyValidationPrg\",\n                                     inputs=[Input(\"matched_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_PhotometryAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_PhotometryAnalysis\",\n+MER_PhotometryAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PhotometryAnalysis\",\n                                     inputs=[Input(\"crossmatched_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_PhotometryPlotCheck\",\n+MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PhotometryPlotCheck\",\n                                          inputs=[Input(\"final_catalog\"),\n                                                  Input(\"TU_gal_catalog\"),\n                                                  Input(\"TU_star_catalog\")],\n@@ -105,7 +105,7 @@ MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_\n                                          resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                          env_variables=ENV_VARIABLES)\n \n-MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_ClassificationValidationPrg\",\n+MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_ClassificationValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"tile_file\"),\n                                            Input(\"tu_stars\"),\n@@ -115,13 +115,13 @@ MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_C\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_FinalCatalogAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_CheckFinalCat\",\n+MER_FinalCatalogAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_CheckFinalCat\",\n                                    inputs=[Input(\"final_cat\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_MergeAnalysisResults = Executable(command=\"E-Run MER_Validation 10.0 MER_MergeAnalysisResults\",\n+MER_MergeAnalysisResults = Executable(command=\"E-Run MER_Validation 10.1 MER_MergeAnalysisResults\",\n                                       inputs=[Input(\"mosaicing_analysis_result\"),\n                                               Input(\"psf_analysis_result\"),\n                                               Input(\"mer_star_psf_analysis_result\"),\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_AnalyseTile_Pipeline/PkgDef_MER_AnalyseTileGaia.py": [
                        [
                            "@@ -26,7 +26,13 @@ from euclidwf.framework.taskdefs import (Executable, Input, Output,\n \n \n ENV_VARIABLES = {\n-    \"MPLCONFIGDIR\": \"/dev/null\"\n+    \"MPLCONFIGDIR\": \"/dev/null\",\n+    \"MKL_NUM_THREADS\": \"1\",\n+    \"NUMEXPR_NUM_THREADS\": \"1\",\n+    \"OMP_NUM_THREADS\": \"1\",\n+    \"OPENBLAS_NUM_THREADS\": \"1\", \n+    \"VECLIB_MAXIMUM_THREADS\": \"1\", \n+    \"NTHREADS\":  \"1\" \n }\n \n MER_PhotometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_PhotometryValidationPrg\",\n",
                            "Pass the same environment variables in all package defs",
                            "Javier Gracia Carpio",
                            "2023-08-16T13:20:46.000+00:00",
                            "09023779349a879cd1ad6aa851e1d12e5edea37e"
                        ],
                        [
                            "@@ -97,7 +97,9 @@ MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_M\n                                            Input(\"classification_result\"),\n                                            Input(\"psf_result\"),\n                                            Input(\"mer_star_psf_result\"),\n-                                           Input(\"gaia_psf_result\")],\n+                                           Input(\"gaia_psf_result\"),\n+                                           Input(\"mosaicing_result\"),\n+                                           Input(\"background_result\")],\n                                    outputs=[Output(\"merged_analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n",
                            "Adds missing inputs",
                            "Javier Gracia Carpio",
                            "2023-08-16T12:56:11.000+00:00",
                            "c76466bc4cc840bafe6e0071f42dc10566f84dcd"
                        ],
                        [
                            "@@ -85,7 +85,7 @@ MER_GaiaPsfValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_GaiaPs\n MER_MosaicingValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_MosaicingValidationPrg\",\n                                      inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                              Input(\"segmap\")],\n-                                     outputs=[Ouput(\"mosaicing_result\", mime_type=\"xml\"),\n+                                     outputs=[Output(\"mosaicing_result\", mime_type=\"xml\"),\n                                               Output(\"background_result\", mime_type=\"xml\")],\n                                      resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                      env_variables=ENV_VARIABLES)\n",
                            "Fixes typo in package def",
                            "Javier Gracia Carpio",
                            "2023-08-16T12:36:42.000+00:00",
                            "4227e74f1138bb64d7cbc7231babb41b0cf4f2b3"
                        ],
                        [
                            "@@ -82,6 +82,14 @@ MER_GaiaPsfValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_GaiaPs\n                                    resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n+MER_MosaicingValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_MosaicingValidationPrg\",\n+                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n+                                             Input(\"segmap\")],\n+                                     outputs=[Ouput(\"mosaicing_result\", mime_type=\"xml\"),\n+                                              Output(\"background_result\", mime_type=\"xml\")],\n+                                     resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n+                                     env_variables=ENV_VARIABLES)\n+\n MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeValidationResults\",\n                                    inputs=[Input(\"astrometry_result\"),\n                                            Input(\"detection_result\"),\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T11:47:15.000+00:00",
                            "9d681bfaa9e90d2e3d8279e2616d18ef13eef190"
                        ],
                        [
                            "@@ -82,6 +82,14 @@ MER_GaiaPsfValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_GaiaPs\n                                    resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n+MER_MosaicingValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_MosaicingValidationPrg\",\n+                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n+                                             Input(\"segmap\")],\n+                                     outputs=[Ouput(\"mosaicing_result\", mime_type=\"xml\"),\n+                                              Output(\"background_result\", mime_type=\"xml\")],\n+                                     resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n+                                     env_variables=ENV_VARIABLES)\n+\n MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeValidationResults\",\n                                    inputs=[Input(\"astrometry_result\"),\n                                            Input(\"detection_result\"),\n",
                            "add MosaicingValidationPrg to the AnalyseTileGaia pipeline",
                            "yfang",
                            "2023-08-14T18:25:53.000+02:00",
                            "3a7b450e921778912f6ffc79366157ad2c0b1184"
                        ],
                        [
                            "@@ -54,7 +54,7 @@ MER_DetectionValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_DetV\n                                      resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                      env_variables=ENV_VARIABLES)\n \n-MER_ClassificationValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_ClassificationValidationPrg\",\n+MER_ClassificationValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_ClassificationValidationGaiaPrg\",\n                                           inputs=[Input(\"final_catalog\"),\n                                                   Input(\"gaia_cutout\"),\n                                                   Input(\"configuration_set\")],\n",
                            "Use new executable name",
                            "Javier Gracia Carpio",
                            "2023-08-10T20:02:51.000+00:00",
                            "94379932bc4284c0e7098d45b67788bd36dc7a92"
                        ],
                        [
                            "@@ -54,6 +54,14 @@ MER_DetectionValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_DetV\n                                      resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                      env_variables=ENV_VARIABLES)\n \n+MER_ClassificationValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_ClassificationValidationPrg\",\n+                                          inputs=[Input(\"final_catalog\"),\n+                                                  Input(\"gaia_cutout\"),\n+                                                  Input(\"configuration_set\")],\n+                                          outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                          resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                          env_variables=ENV_VARIABLES)\n+\n MER_PsfValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_PsfAnalysis\",\n                                inputs=[Input(\"mosaics\", content_type=\"listfile\")],\n                                outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n@@ -78,6 +86,7 @@ MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_M\n                                    inputs=[Input(\"astrometry_result\"),\n                                            Input(\"detection_result\"),\n                                            Input(\"photometry_result\"),\n+                                           Input(\"classification_result\"),\n                                            Input(\"psf_result\"),\n                                            Input(\"mer_star_psf_result\"),\n                                            Input(\"gaia_psf_result\")],\n",
                            "Adds the classification step",
                            "Javier Gracia Carpio",
                            "2023-08-10T19:42:23.000+00:00",
                            "62735fd620a56e5e537f75a5cdabcaaa17a9bee5"
                        ],
                        [
                            "@@ -67,12 +67,20 @@ MER_MerStarPsfValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_Mer\n                                       resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                       env_variables=ENV_VARIABLES)\n \n+MER_GaiaPsfValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_GaiaPsfAnalysis\",\n+                                   inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n+                                           Input(\"gaia_cutout\")],\n+                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n+\n MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeValidationResults\",\n                                    inputs=[Input(\"astrometry_result\"),\n                                            Input(\"detection_result\"),\n                                            Input(\"photometry_result\"),\n                                            Input(\"psf_result\"),\n-                                           Input(\"mer_star_psf_result\")],\n+                                           Input(\"mer_star_psf_result\"),\n+                                           Input(\"gaia_psf_result\")],\n                                    outputs=[Output(\"merged_analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n",
                            "Adds Gaia PSF validation step",
                            "Javier Gracia Carpio",
                            "2023-08-10T16:23:09.000+00:00",
                            "77feb68869a4a208c50a97b3d3e80dd84b14afc7"
                        ],
                        [
                            "@@ -29,44 +29,50 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n-MER_DetValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_DetValidationPrg\",\n-                               inputs=[Input(\"final_catalog\"),\n-                                       Input(\"gaia_cutout\"),\n-                                       Input(\"tile_file\"),\n-                                       Input(\"configuration_set\")],\n-                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n-                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n-                                   env_variables=ENV_VARIABLES)\n+MER_PhotometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_PhotometryValidationPrg\",\n+                                      inputs=[Input(\"final_catalog\"),\n+                                              Input(\"gaia_cutout\"),\n+                                              Input(\"configuration_set\")],\n+                                      outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                      resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                      env_variables=ENV_VARIABLES)\n \n MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_AstrometryValidationPrg\",\n-                                   inputs=[Input(\"final_catalog\"),\n-                                           Input(\"gaia_cutout\"),\n-                                           Input(\"configuration_set\")],\n-                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n-                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n-                                   env_variables=ENV_VARIABLES)\n+                                      inputs=[Input(\"final_catalog\"),\n+                                              Input(\"gaia_cutout\"),\n+                                              Input(\"configuration_set\")],\n+                                      outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                      resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                      env_variables=ENV_VARIABLES)\n \n MER_DetectionValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_DetValidationPrg\",\n-                                   inputs=[Input(\"final_catalog\"),\n-                                           Input(\"gaia_cutout\"),\n-                                           Input(\"tile_file\"),\n-                                           Input(\"configuration_set\")],\n-                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n-                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n-                                   env_variables=ENV_VARIABLES)\n+                                     inputs=[Input(\"final_catalog\"),\n+                                             Input(\"gaia_cutout\"),\n+                                             Input(\"tile_file\"),\n+                                             Input(\"configuration_set\")],\n+                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                     resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                     env_variables=ENV_VARIABLES)\n \n-MER_PhotometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_PhotometryValidationPrg\",\n-                                   inputs=[Input(\"final_catalog\"),\n-                                           Input(\"gaia_cutout\"),\n-                                           Input(\"configuration_set\")],\n-                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n-                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n-                                   env_variables=ENV_VARIABLES)\n+MER_PsfValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_PsfAnalysis\",\n+                               inputs=[Input(\"mosaics\", content_type=\"listfile\")],\n+                               outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                               resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n+                               env_variables=ENV_VARIABLES)\n+\n+MER_MerStarPsfValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_MerStarPsfAnalysis\",\n+                                      inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n+                                              Input(\"final_catalog\")],\n+                                      outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                      resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n+                                      env_variables=ENV_VARIABLES)\n \n MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeValidationResults\",\n                                    inputs=[Input(\"astrometry_result\"),\n                                            Input(\"detection_result\"),\n-                                           Input(\"photometry_result\")],\n+                                           Input(\"photometry_result\"),\n+                                           Input(\"psf_result\"),\n+                                           Input(\"mer_star_psf_result\")],\n                                    outputs=[Output(\"merged_analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n",
                            "Adds mosaics inputs to the gaia validation pipeline",
                            "Javier Gracia Carpio",
                            "2023-08-10T14:30:31.000+00:00",
                            "c60aef018ad53b4f543701cee1592e90c3a469e4"
                        ],
                        [
                            "@@ -29,6 +29,15 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n+MER_DetValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_DetValidationPrg\",\n+                               inputs=[Input(\"final_catalog\"),\n+                                       Input(\"gaia_cutout\"),\n+                                       Input(\"tile_file\"),\n+                                       Input(\"configuration_set\")],\n+                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n+\n MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_AstrometryValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"gaia_cutout\"),\n@@ -37,8 +46,27 @@ MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_Ast\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n+MER_DetectionValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_DetValidationPrg\",\n+                                   inputs=[Input(\"final_catalog\"),\n+                                           Input(\"gaia_cutout\"),\n+                                           Input(\"tile_file\"),\n+                                           Input(\"configuration_set\")],\n+                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n+\n+MER_PhotometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_PhotometryValidationPrg\",\n+                                   inputs=[Input(\"final_catalog\"),\n+                                           Input(\"gaia_cutout\"),\n+                                           Input(\"configuration_set\")],\n+                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n+\n MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeValidationResults\",\n-                                   inputs=[Input(\"astrometry_result\")],\n+                                   inputs=[Input(\"astrometry_result\"),\n+                                           Input(\"detection_result\"),\n+                                           Input(\"photometry_result\")],\n                                    outputs=[Output(\"merged_analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:50:41.000+00:00",
                            "b61999f44bcba73649185b197918dd343601a31d"
                        ],
                        [
                            "@@ -29,6 +29,15 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n+MER_DetValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_DetValidationPrg\",\n+                               inputs=[Input(\"final_catalog\"),\n+                                       Input(\"gaia_cutout\"),\n+                                       Input(\"tile_file\"),\n+                                       Input(\"configuration_set\")],\n+                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n+\n MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_AstrometryValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"gaia_cutout\"),\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_IAL_Pipelines into develop",
                            "yfang",
                            "2023-07-20T14:52:13.000+02:00",
                            "435e24aa5c3078f91782c91fe687450349b25e0f"
                        ],
                        [
                            "@@ -37,8 +37,27 @@ MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_Ast\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n+MER_DetectionValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_DetValidationPrg\",\n+                                   inputs=[Input(\"final_catalog\"),\n+                                           Input(\"gaia_cutout\"),\n+                                           Input(\"tile_file\"),\n+                                           Input(\"configuration_set\")],\n+                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n+\n+MER_PhotometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_PhotometryValidationPrg\",\n+                                   inputs=[Input(\"final_catalog\"),\n+                                           Input(\"gaia_cutout\"),\n+                                           Input(\"configuration_set\")],\n+                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n+\n MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeValidationResults\",\n-                                   inputs=[Input(\"astrometry_result\")],\n+                                   inputs=[Input(\"astrometry_result\"),\n+                                           Input(\"detection_result\"),\n+                                           Input(\"photometry_result\")],\n                                    outputs=[Output(\"merged_analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n",
                            "add photometry validation to pipeline",
                            "yfang",
                            "2023-07-20T14:50:03.000+02:00",
                            "55942f26187474b2de694e8eb9d05be36f7cf234"
                        ],
                        [
                            "@@ -29,6 +29,15 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n+MER_DetValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_DetValidationPrg\",\n+                               inputs=[Input(\"final_catalog\"),\n+                                       Input(\"gaia_cutout\"),\n+                                       Input(\"tile_file\"),\n+                                       Input(\"configuration_set\")],\n+                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n+\n MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_AstrometryValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"gaia_cutout\"),\n@@ -38,7 +47,8 @@ MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_Ast\n                                    env_variables=ENV_VARIABLES)\n \n MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeValidationResults\",\n-                                   inputs=[Input(\"astrometry_result\")],\n+                                   inputs=[Input(\"detection_result\"),\n+                                           Input(\"astrometry_result\")],\n                                    outputs=[Output(\"merged_analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n",
                            "Integrated the detection validation.",
                            "Martin Kuemmel",
                            "2023-07-20T14:41:54.000+02:00",
                            "96efffdda590a304b80cedb01061dc4f62f37b50"
                        ],
                        [
                            "@@ -30,9 +30,15 @@ ENV_VARIABLES = {\n }\n \n MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_AstrometryValidationPrg\",\n-                                   inputs=[Input(\"mer_catalog\"),\n+                                   inputs=[Input(\"final_catalog\"),\n                                            Input(\"gaia_cutout\"),\n                                            Input(\"configuration_set\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n+\n+MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeValidationResults\",\n+                                   inputs=[Input(\"astrometry_result\")],\n+                                   outputs=[Output(\"merged_analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n",
                            "Merge branch 'feature/gaia_index' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T21:40:49.000+00:00",
                            "b5c7c0d135177fbca99d1a973a2207fc5ee7d6dc"
                        ],
                        [
                            "@@ -30,9 +30,15 @@ ENV_VARIABLES = {\n }\n \n MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_AstrometryValidationPrg\",\n-                                   inputs=[Input(\"mer_catalog\"),\n+                                   inputs=[Input(\"final_catalog\"),\n                                            Input(\"gaia_cutout\"),\n                                            Input(\"configuration_set\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n+\n+MER_MergeValidationResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeValidationResults\",\n+                                   inputs=[Input(\"astrometry_result\")],\n+                                   outputs=[Output(\"merged_analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n",
                            "Added the index to the GAIA validation",
                            "Martin Kuemmel",
                            "2023-07-04T23:18:12.000+02:00",
                            "53c7a3a924b3acb720ccc5a2d7137737ed711069"
                        ],
                        [
                            "",
                            "Use better names",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:36:54.000+00:00",
                            "a9ff684e194f0bbf670427c515527a348a9b7da3"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_AnalyseTile_Pipeline/PkgDef_MER_AnalyseTileVisOnly.py": [
                        [
                            "@@ -26,7 +26,13 @@ from euclidwf.framework.taskdefs import (Executable, Input, Output,\n \n \n ENV_VARIABLES = {\n-    \"MPLCONFIGDIR\": \"/dev/null\"\n+    \"MPLCONFIGDIR\": \"/dev/null\",\n+    \"MKL_NUM_THREADS\": \"1\",\n+    \"NUMEXPR_NUM_THREADS\": \"1\",\n+    \"OMP_NUM_THREADS\": \"1\",\n+    \"OPENBLAS_NUM_THREADS\": \"1\", \n+    \"VECLIB_MAXIMUM_THREADS\": \"1\", \n+    \"NTHREADS\":  \"1\" \n }\n \n MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_MosaicingValidation\",\n",
                            "Pass the same environment variables in all package defs",
                            "Javier Gracia Carpio",
                            "2023-08-16T13:20:46.000+00:00",
                            "09023779349a879cd1ad6aa851e1d12e5edea37e"
                        ],
                        [
                            "@@ -29,34 +29,34 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n-MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MosaicingValidation\",\n+MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_MosaicingValidation\",\n                                    inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                            Input(\"segmap\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=16.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_PsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PsfAnalysis\",\n+MER_PsfAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_PsfAnalysis\",\n                              inputs=[Input(\"mosaics\", content_type=\"listfile\")],\n                              outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                              resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                              env_variables=ENV_VARIABLES)\n \n-MER_MerStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MerStarPsfAnalysis\",\n+MER_MerStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_MerStarPsfAnalysis\",\n                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                             Input(\"final_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_TuStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_TuStarPsfAnalysis\",\n+MER_TuStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_TuStarPsfAnalysis\",\n                                    inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                            Input(\"tu_star_catalog\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_BackgroundValidationPrg\",\n+MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_BackgroundValidationPrg\",\n                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                             Input(\"final_catalog\"),\n                                             Input(\"final_segmap\")],\n@@ -64,7 +64,7 @@ MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_Backg\n                                     resources=ComputingResources(cores=1, ram=26.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_DetectionValidationPrg\",\n+MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_DetectionValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"tile_file\"),\n                                            Input(\"tu_stars\"),\n@@ -73,7 +73,7 @@ MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_Detect\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_CrossmatchAnalysis\",\n+MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_CrossmatchAnalysis\",\n                                     inputs=[Input(\"final_catalog\"),\n                                             Input(\"vis_detection_mosaic\"),\n                                             Input(\"tu_star_catalog\"),\n@@ -84,19 +84,19 @@ MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_Cross\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_MorphologyAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MorphologyValidationPrg\",\n+MER_MorphologyAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_MorphologyValidationPrg\",\n                                     inputs=[Input(\"matched_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_PhotometryAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PhotometryAnalysis\",\n+MER_PhotometryAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_PhotometryAnalysis\",\n                                     inputs=[Input(\"crossmatched_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PhotometryPlotCheck\",\n+MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_PhotometryPlotCheck\",\n                                          inputs=[Input(\"final_catalog\"),\n                                                  Input(\"TU_gal_catalog\"),\n                                                  Input(\"TU_star_catalog\")],\n@@ -104,7 +104,7 @@ MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_\n                                          resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                          env_variables=ENV_VARIABLES)\n \n-MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_ClassificationValidationPrg\",\n+MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_ClassificationValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"tile_file\"),\n                                            Input(\"tu_stars\"),\n@@ -114,13 +114,13 @@ MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_C\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_FinalCatalogAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_CheckFinalCat\",\n+MER_FinalCatalogAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_CheckFinalCat\",\n                                    inputs=[Input(\"final_cat\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_MergeAnalysisResults = Executable(command=\"E-Run MER_Validation 10.1 MER_MergeAnalysisResults\",\n+MER_MergeAnalysisResults = Executable(command=\"E-Run MER_Validation 10.2 MER_MergeAnalysisResults\",\n                                       inputs=[Input(\"mosaicing_analysis_result\"),\n                                               Input(\"psf_analysis_result\"),\n                                               Input(\"mer_star_psf_analysis_result\"),\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -29,34 +29,34 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n-MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_MosaicingValidation\",\n+MER_MosaicingAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MosaicingValidation\",\n                                    inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                            Input(\"segmap\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=16.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_PsfAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_PsfAnalysis\",\n+MER_PsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PsfAnalysis\",\n                              inputs=[Input(\"mosaics\", content_type=\"listfile\")],\n                              outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                              resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                              env_variables=ENV_VARIABLES)\n \n-MER_MerStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_MerStarPsfAnalysis\",\n+MER_MerStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MerStarPsfAnalysis\",\n                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                             Input(\"final_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_TuStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_TuStarPsfAnalysis\",\n+MER_TuStarPsfAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_TuStarPsfAnalysis\",\n                                    inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                            Input(\"tu_star_catalog\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=12.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_BackgroundValidationPrg\",\n+MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_BackgroundValidationPrg\",\n                                     inputs=[Input(\"mosaics\", content_type=\"listfile\"),\n                                             Input(\"final_catalog\"),\n                                             Input(\"final_segmap\")],\n@@ -64,7 +64,7 @@ MER_BackgroundAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_Backg\n                                     resources=ComputingResources(cores=1, ram=26.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_DetectionValidationPrg\",\n+MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_DetectionValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"tile_file\"),\n                                            Input(\"tu_stars\"),\n@@ -73,7 +73,7 @@ MER_DetectionAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_Detect\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_CrossmatchAnalysis\",\n+MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_CrossmatchAnalysis\",\n                                     inputs=[Input(\"final_catalog\"),\n                                             Input(\"vis_detection_mosaic\"),\n                                             Input(\"tu_star_catalog\"),\n@@ -84,19 +84,19 @@ MER_CrossmatchAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_Cross\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_MorphologyAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_MorphologyValidationPrg\",\n+MER_MorphologyAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_MorphologyValidationPrg\",\n                                     inputs=[Input(\"matched_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_PhotometryAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_PhotometryAnalysis\",\n+MER_PhotometryAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PhotometryAnalysis\",\n                                     inputs=[Input(\"crossmatched_catalog\")],\n                                     outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                     resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                     env_variables=ENV_VARIABLES)\n \n-MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_PhotometryPlotCheck\",\n+MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_PhotometryPlotCheck\",\n                                          inputs=[Input(\"final_catalog\"),\n                                                  Input(\"TU_gal_catalog\"),\n                                                  Input(\"TU_star_catalog\")],\n@@ -104,7 +104,7 @@ MER_PhotometryPlotsAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_\n                                          resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                          env_variables=ENV_VARIABLES)\n \n-MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_ClassificationValidationPrg\",\n+MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_ClassificationValidationPrg\",\n                                    inputs=[Input(\"final_catalog\"),\n                                            Input(\"tile_file\"),\n                                            Input(\"tu_stars\"),\n@@ -114,13 +114,13 @@ MER_ClassificationAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_C\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_FinalCatalogAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_CheckFinalCat\",\n+MER_FinalCatalogAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_CheckFinalCat\",\n                                    inputs=[Input(\"final_cat\")],\n                                    outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=2.0, walltime=2.0),\n                                    env_variables=ENV_VARIABLES)\n \n-MER_MergeAnalysisResults = Executable(command=\"E-Run MER_Validation 10.0 MER_MergeAnalysisResults\",\n+MER_MergeAnalysisResults = Executable(command=\"E-Run MER_Validation 10.1 MER_MergeAnalysisResults\",\n                                       inputs=[Input(\"mosaicing_analysis_result\"),\n                                               Input(\"psf_analysis_result\"),\n                                               Input(\"mer_star_psf_analysis_result\"),\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_ProcessTileMorpho_Pipeline/PkgDef_MER_ProcessTileMorpho.py": [
                        [
                            "@@ -25,12 +25,13 @@ from euclidwf.framework.taskdefs import (Executable, Input, Output,\n \n \n ENV_VARIABLES = {\n-        \"MKL_NUM_THREADS\": \"1\",\n-        \"NUMEXPR_NUM_THREADS\": \"1\",\n-        \"OMP_NUM_THREADS\": \"1\",\n-        \"OPENBLAS_NUM_THREADS\": \"1\", \n-        \"VECLIB_MAXIMUM_THREADS\": \"1\", \n-        \"NTHREADS\":  \"1\" \n+    \"MPLCONFIGDIR\": \"/dev/null\",\n+    \"MKL_NUM_THREADS\": \"1\",\n+    \"NUMEXPR_NUM_THREADS\": \"1\",\n+    \"OMP_NUM_THREADS\": \"1\",\n+    \"OPENBLAS_NUM_THREADS\": \"1\", \n+    \"VECLIB_MAXIMUM_THREADS\": \"1\", \n+    \"NTHREADS\":  \"1\" \n }\n \n MER_MorphoPatch = Executable(command=\"E-Run MER_Pipeline 10.2 MER_MorphoPatch\",\n",
                            "Pass the same environment variables in all package defs",
                            "Javier Gracia Carpio",
                            "2023-08-16T13:20:46.000+00:00",
                            "09023779349a879cd1ad6aa851e1d12e5edea37e"
                        ],
                        [
                            "@@ -33,7 +33,7 @@ ENV_VARIABLES = {\n         \"NTHREADS\":  \"1\" \n }\n \n-MER_MorphoPatch = Executable(command=\"E-Run MER_Pipeline 10.1 MER_MorphoPatch\",\n+MER_MorphoPatch = Executable(command=\"E-Run MER_Pipeline 10.2 MER_MorphoPatch\",\n                                  inputs=[Input(\"final_catalog\"),\n                                          Input(\"vis_detection_mosaic\"),\n                                          Input(\"measurement_mosaics\", content_type=\"listfile\")],\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -33,7 +33,7 @@ ENV_VARIABLES = {\n         \"NTHREADS\":  \"1\" \n }\n \n-MER_MorphoPatch = Executable(command=\"E-Run MER_Pipeline 10.0 MER_MorphoPatch\",\n+MER_MorphoPatch = Executable(command=\"E-Run MER_Pipeline 10.1 MER_MorphoPatch\",\n                                  inputs=[Input(\"final_catalog\"),\n                                          Input(\"vis_detection_mosaic\"),\n                                          Input(\"measurement_mosaics\", content_type=\"listfile\")],\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_ProcessTile_Pipeline/PkgDef_MER_ProcessTileVisOnly.py": [
                        [
                            "@@ -25,7 +25,13 @@ from euclidwf.framework.taskdefs import (Executable, Input, Output,\n \n \n ENV_VARIABLES = {\n-    \"MPLCONFIGDIR\": \"/dev/null\"\n+    \"MPLCONFIGDIR\": \"/dev/null\",\n+    \"MKL_NUM_THREADS\": \"1\",\n+    \"NUMEXPR_NUM_THREADS\": \"1\",\n+    \"OMP_NUM_THREADS\": \"1\",\n+    \"OPENBLAS_NUM_THREADS\": \"1\", \n+    \"VECLIB_MAXIMUM_THREADS\": \"1\", \n+    \"NTHREADS\":  \"1\" \n }\n \n MER_InitializeVisOnly = Executable(command=\"E-Run MER_Pipeline 10.2 MER_InitializeVisOnly\",\n",
                            "Pass the same environment variables in all package defs",
                            "Javier Gracia Carpio",
                            "2023-08-16T13:20:46.000+00:00",
                            "09023779349a879cd1ad6aa851e1d12e5edea37e"
                        ],
                        [
                            "@@ -28,12 +28,12 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n-MER_InitializeVisOnly = Executable(command=\"E-Run MER_Pipeline 10.1 MER_InitializeVisOnly\",\n+MER_InitializeVisOnly = Executable(command=\"E-Run MER_Pipeline 10.2 MER_InitializeVisOnly\",\n                                    inputs=[Input(\"vis_calibrated_frames\", content_type=\"listfile\")],\n                                    outputs=[Output(\"vis_image_list\", content_type=\"listfile\", mime_type=\"json\")],\n                                    resources=ComputingResources(cores=1, ram=1.0, walltime=0.3))\n \n-MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Mosaicing\",\n+MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.2 MER_Mosaicing\",\n                            inputs=[Input(\"image_list\", content_type=\"listfile\"),\n                                    Input(\"tile\"),\n                                    Input(\"configuration\"),\n@@ -42,14 +42,14 @@ MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Mosaicing\",\n                            outputs=[Output(\"mosaic\", mime_type=\"xml\")],\n                            resources=ComputingResources(cores=2, ram=6.0, walltime=6.0, tmpsize=999))\n \n-MER_Background = Executable(command=\"E-Run MER_Background 10.1 MER_BackgroundPrg\",\n+MER_Background = Executable(command=\"E-Run MER_Background 10.2 MER_BackgroundPrg\",\n                             inputs=[Input(\"mosaic\"),\n                                     Input(\"configuration\"),\n                                     Input(\"flag_limits\")],\n                             outputs=[Output(\"background_subtracted_mosaic\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=8.0, walltime=4.0))\n \n-MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.1 MER_VisDetectionPrg\",\n+MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.2 MER_VisDetectionPrg\",\n                               inputs=[Input(\"mosaic\"),\n                                       Input(\"configuration\"),\n                                       Input(\"flag_limits\")],\n@@ -58,7 +58,7 @@ MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.1 MER_VisDetection\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=4, ram=14.0, walltime=6.0))\n \n-MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.1 MER_Deblending\",\n+MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.2 MER_Deblending\",\n                             inputs=[Input(\"input_mosaic\"),\n                                     Input(\"detection_segmap\"),\n                                     Input(\"configuration\"),\n@@ -68,7 +68,7 @@ MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.1 MER_Deblending\",\n                                      Output(\"to_aphot_catalog\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=22.0, walltime=14.0))\n \n-MER_MBCombineNone = Executable(command=\"E-Run MER_Detection 10.1 MER_MBCombineNonePrg\",\n+MER_MBCombineNone = Executable(command=\"E-Run MER_Detection 10.2 MER_MBCombineNonePrg\",\n                                   inputs=[Input(\"visSegmentMap\"),\n                                           Input(\"visDetectionCatalog\"),\n                                           Input(\"configuration\"),\n@@ -77,7 +77,7 @@ MER_MBCombineNone = Executable(command=\"E-Run MER_Detection 10.1 MER_MBCombineNo\n                                            Output(\"combinedDetectionCat\", mime_type=\"xml\")],\n                                   resources=ComputingResources(cores=1, ram=4.0, walltime=0.5))\n \n-MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.1 MER_CatalogPsfCalculation\",\n+MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.2 MER_CatalogPsfCalculation\",\n                                        inputs=[Input(\"image_list\", content_type=\"listfile\"),\n                                                Input(\"mosaic\"),\n                                                Input(\"catalog\"),\n@@ -86,13 +86,13 @@ MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Cata\n                                        outputs=[Output(\"output_mosaic\", mime_type=\"xml\")],\n                                        resources=ComputingResources(cores=2, ram=6.0, walltime=4.0, tmpsize=999))\n \n-MER_PsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.1 MER_PsfExtraction\",\n+MER_PsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.2 MER_PsfExtraction\",\n                                inputs=[Input(\"mosaic\"),\n                                        Input(\"catalog\")],\n                                outputs=[Output(\"psf_stamp_collection\", mime_type=\"xml\")],\n                                resources=ComputingResources(cores=1, ram=3.0, walltime=1.0))\n \n-MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotMorphology\",\n+MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.2 MER_APhotMorphology\",\n                                    inputs=[Input(\"configuration\"),\n                                            Input(\"input_image\"),\n                                            Input(\"input_catalog\"),\n@@ -100,7 +100,7 @@ MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotM\n                                    outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=10.0, walltime=1.0))\n \n-MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.1 MER_Morphology\",\n+MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.2 MER_Morphology\",\n                             inputs=[Input(\"input_mosaic\"),\n                                     Input(\"input_segmap\"),\n                                     Input(\"input_catalog\"),\n@@ -108,7 +108,7 @@ MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.1 MER_Morphology\",\n                             outputs=[Output(\"morph_catalog\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=10.0, walltime=2.0))\n \n-MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotDetectionVisOnly\",\n+MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.2 MER_APhotDetectionVisOnly\",\n                                 inputs=[Input(\"configuration\"),\n                                         Input(\"input_image\"),\n                                         Input(\"input_catalog\"),\n@@ -117,7 +117,7 @@ MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotDete\n                                          Output(\"aphot_catalogs\", content_type=\"listfile\", mime_type=\"json\")],\n                                 resources=ComputingResources(cores=1, ram=12.0, walltime=1.0))\n \n-MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.1 MER_PsfFitting\",\n+MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.2 MER_PsfFitting\",\n                                        inputs=[Input(\"configuration\"),\n                                                Input(\"vis_image\"),\n                                                Input(\"input_catalog\"),\n@@ -126,7 +126,7 @@ MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.1 MER_Ps\n                                        outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                        resources=ComputingResources(cores=1, ram=16.0, walltime=12.0))\n \n-MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.1 MER_CatalogAssembly\",\n+MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.2 MER_CatalogAssembly\",\n                          inputs=[Input(\"vis_mosaic\"),\n                                  Input(\"gaia_cutouts\", content_type=\"listfile\"),\n                                  Input(\"photA_list\", content_type=\"listfile\"),\n@@ -143,13 +143,13 @@ MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.1 MER_CatalogAsse\n                                   Output(\"final_segmap\", mime_type=\"xml\")],\n                          resources=ComputingResources(cores=1, ram=22.0, walltime=1.0))\n \n-MER_QuickAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_QuickAnalysis\",\n+MER_QuickAnalysis = Executable(command=\"E-Run MER_Validation 10.2 MER_QuickAnalysis\",\n                                inputs=[Input(\"final_catalog\")],\n                                outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                resources=ComputingResources(cores=1, ram=2.0, walltime=1.0),\n                                env_variables=ENV_VARIABLES)\n \n-MER_Compression = Executable(command=\"E-Run MER_Pipeline 10.1 MER_CompressionVisOnly\",\n+MER_Compression = Executable(command=\"E-Run MER_Pipeline 10.2 MER_CompressionVisOnly\",\n                          inputs=[Input(\"vis_mosaic\"),\n                                  Input(\"vis_detection_mosaic\"),\n                                  Input(\"segmentation_map\"),\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -28,12 +28,12 @@ ENV_VARIABLES = {\n     \"MPLCONFIGDIR\": \"/dev/null\"\n }\n \n-MER_InitializeVisOnly = Executable(command=\"E-Run MER_Pipeline 10.0 MER_InitializeVisOnly\",\n+MER_InitializeVisOnly = Executable(command=\"E-Run MER_Pipeline 10.1 MER_InitializeVisOnly\",\n                                    inputs=[Input(\"vis_calibrated_frames\", content_type=\"listfile\")],\n                                    outputs=[Output(\"vis_image_list\", content_type=\"listfile\", mime_type=\"json\")],\n                                    resources=ComputingResources(cores=1, ram=1.0, walltime=0.3))\n \n-MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Mosaicing\",\n+MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.1 MER_Mosaicing\",\n                            inputs=[Input(\"image_list\", content_type=\"listfile\"),\n                                    Input(\"tile\"),\n                                    Input(\"configuration\"),\n@@ -42,14 +42,14 @@ MER_Mosaicing = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Mosaicing\",\n                            outputs=[Output(\"mosaic\", mime_type=\"xml\")],\n                            resources=ComputingResources(cores=2, ram=6.0, walltime=6.0, tmpsize=999))\n \n-MER_Background = Executable(command=\"E-Run MER_Background 10.0 MER_BackgroundPrg\",\n+MER_Background = Executable(command=\"E-Run MER_Background 10.1 MER_BackgroundPrg\",\n                             inputs=[Input(\"mosaic\"),\n                                     Input(\"configuration\"),\n                                     Input(\"flag_limits\")],\n                             outputs=[Output(\"background_subtracted_mosaic\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=8.0, walltime=4.0))\n \n-MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.0 MER_VisDetectionPrg\",\n+MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.1 MER_VisDetectionPrg\",\n                               inputs=[Input(\"mosaic\"),\n                                       Input(\"configuration\"),\n                                       Input(\"flag_limits\")],\n@@ -58,7 +58,7 @@ MER_VisDetection = Executable(command=\"E-Run MER_Detection 10.0 MER_VisDetection\n                                        Output(\"object_catalog\", mime_type=\"xml\")],\n                               resources=ComputingResources(cores=4, ram=14.0, walltime=6.0))\n \n-MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.0 MER_Deblending\",\n+MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.1 MER_Deblending\",\n                             inputs=[Input(\"input_mosaic\"),\n                                     Input(\"detection_segmap\"),\n                                     Input(\"configuration\"),\n@@ -68,7 +68,7 @@ MER_Deblending = Executable(command=\"E-Run MER_Deblending 10.0 MER_Deblending\",\n                                      Output(\"to_aphot_catalog\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=22.0, walltime=14.0))\n \n-MER_MBCombineNone = Executable(command=\"E-Run MER_Detection 10.0 MER_MBCombineNonePrg\",\n+MER_MBCombineNone = Executable(command=\"E-Run MER_Detection 10.1 MER_MBCombineNonePrg\",\n                                   inputs=[Input(\"visSegmentMap\"),\n                                           Input(\"visDetectionCatalog\"),\n                                           Input(\"configuration\"),\n@@ -77,7 +77,7 @@ MER_MBCombineNone = Executable(command=\"E-Run MER_Detection 10.0 MER_MBCombineNo\n                                            Output(\"combinedDetectionCat\", mime_type=\"xml\")],\n                                   resources=ComputingResources(cores=1, ram=4.0, walltime=0.5))\n \n-MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.0 MER_CatalogPsfCalculation\",\n+MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.1 MER_CatalogPsfCalculation\",\n                                        inputs=[Input(\"image_list\", content_type=\"listfile\"),\n                                                Input(\"mosaic\"),\n                                                Input(\"catalog\"),\n@@ -86,13 +86,13 @@ MER_CatalogPsfCalculation = Executable(command=\"E-Run MER_Pipeline 10.0 MER_Cata\n                                        outputs=[Output(\"output_mosaic\", mime_type=\"xml\")],\n                                        resources=ComputingResources(cores=2, ram=6.0, walltime=4.0, tmpsize=999))\n \n-MER_PsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.0 MER_PsfExtraction\",\n+MER_PsfExtraction = Executable(command=\"E-Run MER_Pipeline 10.1 MER_PsfExtraction\",\n                                inputs=[Input(\"mosaic\"),\n                                        Input(\"catalog\")],\n                                outputs=[Output(\"psf_stamp_collection\", mime_type=\"xml\")],\n                                resources=ComputingResources(cores=1, ram=3.0, walltime=1.0))\n \n-MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotMorphology\",\n+MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotMorphology\",\n                                    inputs=[Input(\"configuration\"),\n                                            Input(\"input_image\"),\n                                            Input(\"input_catalog\"),\n@@ -100,7 +100,7 @@ MER_Photometry_Morpho = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotM\n                                    outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                    resources=ComputingResources(cores=1, ram=10.0, walltime=1.0))\n \n-MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.0 MER_Morphology\",\n+MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.1 MER_Morphology\",\n                             inputs=[Input(\"input_mosaic\"),\n                                     Input(\"input_segmap\"),\n                                     Input(\"input_catalog\"),\n@@ -108,7 +108,7 @@ MER_Morphology = Executable(command=\"E-Run MER_Morphology 10.0 MER_Morphology\",\n                             outputs=[Output(\"morph_catalog\", mime_type=\"xml\")],\n                             resources=ComputingResources(cores=1, ram=10.0, walltime=2.0))\n \n-MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotDetectionVisOnly\",\n+MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.1 MER_APhotDetectionVisOnly\",\n                                 inputs=[Input(\"configuration\"),\n                                         Input(\"input_image\"),\n                                         Input(\"input_catalog\"),\n@@ -117,7 +117,7 @@ MER_Photometry_Det = Executable(command=\"E-Run MER_Photometry 10.0 MER_APhotDete\n                                          Output(\"aphot_catalogs\", content_type=\"listfile\", mime_type=\"json\")],\n                                 resources=ComputingResources(cores=1, ram=12.0, walltime=1.0))\n \n-MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.0 MER_PsfFitting\",\n+MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.1 MER_PsfFitting\",\n                                        inputs=[Input(\"configuration\"),\n                                                Input(\"vis_image\"),\n                                                Input(\"input_catalog\"),\n@@ -126,7 +126,7 @@ MER_Photometry_PsfFitting = Executable(command=\"E-Run MER_Photometry 10.0 MER_Ps\n                                        outputs=[Output(\"final_catalog\", mime_type=\"xml\")],\n                                        resources=ComputingResources(cores=1, ram=16.0, walltime=12.0))\n \n-MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.0 MER_CatalogAssembly\",\n+MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.1 MER_CatalogAssembly\",\n                          inputs=[Input(\"vis_mosaic\"),\n                                  Input(\"gaia_cutouts\", content_type=\"listfile\"),\n                                  Input(\"photA_list\", content_type=\"listfile\"),\n@@ -143,13 +143,13 @@ MER_Catalog = Executable(command=\"E-Run MER_CatalogAssembly 10.0 MER_CatalogAsse\n                                   Output(\"final_segmap\", mime_type=\"xml\")],\n                          resources=ComputingResources(cores=1, ram=22.0, walltime=1.0))\n \n-MER_QuickAnalysis = Executable(command=\"E-Run MER_Validation 10.0 MER_QuickAnalysis\",\n+MER_QuickAnalysis = Executable(command=\"E-Run MER_Validation 10.1 MER_QuickAnalysis\",\n                                inputs=[Input(\"final_catalog\")],\n                                outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n                                resources=ComputingResources(cores=1, ram=2.0, walltime=1.0),\n                                env_variables=ENV_VARIABLES)\n \n-MER_Compression = Executable(command=\"E-Run MER_Pipeline 10.0 MER_CompressionVisOnly\",\n+MER_Compression = Executable(command=\"E-Run MER_Pipeline 10.1 MER_CompressionVisOnly\",\n                          inputs=[Input(\"vis_mosaic\"),\n                                  Input(\"vis_detection_mosaic\"),\n                                  Input(\"segmentation_map\"),\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_AnalyseTile_Pipeline/PkgDef_MER_GaiaAnalyseTile.py": [
                        [
                            "@@ -0,0 +1,38 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+MER package definition file\n+\n+\"\"\"\n+\n+from euclidwf.framework.taskdefs import (Executable, Input, Output,\n+                                         ComputingResources)\n+\n+\n+ENV_VARIABLES = {\n+    \"MPLCONFIGDIR\": \"/dev/null\"\n+}\n+\n+MER_AstrometryValidation = Executable(command=\"E-Run MER_Validation 10.2 MER_AstrometryValidationPrg\",\n+                                   inputs=[Input(\"mer_catalog\"),\n+                                           Input(\"gaia_cutout\"),\n+                                           Input(\"configuration_set\")],\n+                                   outputs=[Output(\"analysis_result\", mime_type=\"xml\")],\n+                                   resources=ComputingResources(cores=1, ram=3.0, walltime=2.0),\n+                                   env_variables=ENV_VARIABLES)\n",
                            "Adds first version of the analysis pipeline using Gaia data",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:31:19.000+00:00",
                            "e10713efbf6f3da22ca2f4dee7a20017a1255d11"
                        ]
                    ],
                    "MER_IAL_Pipelines/auxdir/MER_ValidateTile_Pipeline/PkgDef_MER_ValidateTile.py": [
                        [
                            "@@ -24,7 +24,7 @@ MER package definition file\n from euclidwf.framework.taskdefs import (Executable, Input, Output,\n                                          ComputingResources)\n \n-MER_Validation = Executable(command=\"E-Run MER_Validation 10.1 MER_Validation\",\n+MER_Validation = Executable(command=\"E-Run MER_Validation 10.2 MER_Validation\",\n                             inputs=[Input(\"validation_requirements\"),\n                                     Input(\"final_catalog\"),\n                                     Input(\"all_mosaics\", content_type=\"listfile\"),\n",
                            "Updates all versions",
                            "Javier Gracia Carpio",
                            "2023-07-03T16:24:59.000+00:00",
                            "55a04b4570f77f8454b242be76255a9e3d177fd0"
                        ],
                        [
                            "@@ -24,7 +24,7 @@ MER package definition file\n from euclidwf.framework.taskdefs import (Executable, Input, Output,\n                                          ComputingResources)\n \n-MER_Validation = Executable(command=\"E-Run MER_Validation 10.0 MER_Validation\",\n+MER_Validation = Executable(command=\"E-Run MER_Validation 10.1 MER_Validation\",\n                             inputs=[Input(\"validation_requirements\"),\n                                     Input(\"final_catalog\"),\n                                     Input(\"all_mosaics\", content_type=\"listfile\"),\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:26:43.000+00:00",
                            "cb40061c3d993e4a19908e39b52142623053cf92"
                        ]
                    ]
                },
                "count_selected_modifications": "8",
                "tags_in_period": [
                    {
                        "name": "9.1.1",
                        "created_at": "2023-03-08T15:04:03.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.0",
                        "created_at": "2023-07-03T16:17:44.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.1",
                        "created_at": "2023-07-28T14:38:08.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.2",
                        "created_at": "2023-08-11T13:07:37.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.3",
                        "created_at": "2023-08-14T14:17:43.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    }
                ]
            },
            "PF-MER/MER_Morphology": {
                "start date": "2023-06-09 09:00",
                "end date": "2023-08-23 15:00",
                "start tag": "> 9.1.0",
                "end tag": "> 10.1.1",
                "count_files_modified": "3",
                "modifications_by_file": {
                    "CMakeLists.txt": [
                        [
                            "@@ -12,4 +12,4 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_Morphology 10.1 USE Elements 6.2.1 MER_DataModelUtils 10.1 MER_Deblending 10.1)\n+elements_project(MER_Morphology 10.2 USE Elements 6.2.1 MER_DataModelUtils 10.2 MER_Deblending 10.2)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-07-03T13:02:22.000+00:00",
                            "aba3d06768f7eb9ea7d2a01efd2607a29f9a0367"
                        ],
                        [
                            "@@ -12,4 +12,4 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_Morphology 10.0 USE Elements 6.1.1 MER_DataModelUtils 10.0 MER_Deblending 10.0)\n+elements_project(MER_Morphology 10.1 USE Elements 6.2.1 MER_DataModelUtils 10.1 MER_Deblending 10.1)\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:43:38.000+00:00",
                            "94838755ea47bf85bef47bbb6c6144bbf76aa795"
                        ]
                    ],
                    ".jenkinsFile": [
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\n-@Library('integration-library@release-9') _\n-pipelineElements(artifactId:\"MER_Morphology\", component:'eden.3.0')\n+@Library(value='integration-library@release-10') _\n+pipelineElements(name:\"MER_Morphology\", component:'eden.3.1')\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:43:38.000+00:00",
                            "94838755ea47bf85bef47bbb6c6144bbf76aa795"
                        ]
                    ],
                    "Makefile": [
                        [
                            "@@ -44,169 +44,19 @@\n #\n ################################################################################\n \n-# settings\n-CMAKE := cmake\n-CTEST := ctest\n-NINJA := $(shell which ninja-build 2> /dev/null)\n-ifeq ($(NINJA),)\n-  NINJA := $(shell which ninja 2> /dev/null)\n-endif\n-\n-# Looking for the Custom make library\n-\n-CUSTOM_MAKE_LIB := Custom.mk\n-\n-ifneq ($(wildcard $(CURDIR)/make/$(CUSTOM_MAKE_LIB)),)\n-  CUSTOM_MAKE_LIB_FILE := $(CURDIR)/make/$(CUSTOM_MAKE_LIB)\n-else\n-  ifneq ($(CMAKE_PREFIX_PATH),)\n-    PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    CUSTOM_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(CUSTOM_MAKE_LIB) $(dir)/../make/$(CUSTOM_MAKE_LIB)))\n-  endif\n-  CUSTOM_MAKE_LIB_LIST += /usr/share/Elements/make/$(CUSTOM_MAKE_LIB)\n-  CUSTOM_MAKE_LIB_FILE := $(firstword $(CUSTOM_MAKE_LIB_LIST))\n-endif\n-\n-# Looking for the ToolChain\n-\n-TOOLCHAIN_NAME := ElementsToolChain.cmake\n+ELEMENTS_MAKE_LIB := Elements.mk\n \n-ifneq ($(wildcard $(CURDIR)/cmake/$(TOOLCHAIN_NAME)),)\n-  TOOLCHAIN_FILE := $(CURDIR)/cmake/$(TOOLCHAIN_NAME)\n+ifneq ($(wildcard $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)),)\n+  ELEMENTS_MAKE_LIB_FILE := $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)\n else\n   ifneq ($(CMAKE_PREFIX_PATH),)\n     PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    TOOLCHAIN_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/lib*/cmake/ElementsProject/$(TOOLCHAIN_NAME) $(dir)/$(TOOLCHAIN_NAME)))\n-    TOOLCHAIN_FILE := $(firstword $(TOOLCHAIN_LIST))\n+    ELEMENTS_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(ELEMENTS_MAKE_LIB) $(dir)/../make/$(ELEMENTS_MAKE_LIB)))\n   endif\n+  ELEMENTS_MAKE_LIB_LIST += /usr/share/Elements/make/$(ELEMENTS_MAKE_LIB)\n+  ELEMENTS_MAKE_LIB_FILE := $(firstword $(ELEMENTS_MAKE_LIB_LIST))\n endif\n \n-override ALL_CMAKEFLAGS := -Wno-dev --no-warn-unused-cli\n-\n-ifneq ($(TOOLCHAIN_FILE),)\n-  # A toolchain has been found. Lets use it.\n-  override ALL_CMAKEFLAGS += -DCMAKE_TOOLCHAIN_FILE=$(TOOLCHAIN_FILE)\n-endif\n-\n-\n-BUILD_PREFIX_NAME := build\n-\n-override ALL_CMAKEFLAGS += -DUSE_LOCAL_INSTALLAREA=ON -DBUILD_PREFIX_NAME:STRING=$(BUILD_PREFIX_NAME)\n-override ALL_CMAKEFLAGS += -DUSE_VERSIONED_LIBRARIES=OFF\n-\n-ifndef BINARY_TAG\n-  ifdef CMAKECONFIG\n-    BINARY_TAG := ${CMAKECONFIG}\n-  else\n-    ifdef CMTCONFIG\n-      BINARY_TAG := ${CMTCONFIG}\n-    endif\n-  endif\n-endif\n-\n-ifdef BINARY_TAG\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME).$(BINARY_TAG)\n-else\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME)\n-endif\n-BUILDDIR := $(CURDIR)/$(BUILD_SUBDIR)\n-\n-# build tool\n-\n-ifneq ($(USE_NINJA),)\n-  # enable Ninja\n-  override ALL_CMAKEFLAGS += -GNinja\n-  BUILD_CONF_FILE := build.ninja\n-  BUILDFLAGS := $(NINJAFLAGS)\n-  ifneq ($(VERBOSE),)\n-    BUILDFLAGS := -v $(BUILDFLAGS)\n-  endif\n-else\n-  BUILD_CONF_FILE := Makefile\n-endif\n-BUILD_CMD := $(CMAKE) --build $(BUILD_SUBDIR) --target\n-\n-\n-# Use environment variable for extra flags\n-\n-# Replace the \":\" from eclipse variable list to spaces  \n-ifneq ($(EXPAND_FLAGS),)\n-  CMAKEFLAGS := $(subst :-, -,$(CMAKEFLAGS))\n-endif\n-\n-ifneq ($(CMAKEFLAGS),)\n-  override ALL_CMAKEFLAGS += $(CMAKEFLAGS)\n-endif\n-\n-# default target\n-all:\n-\n-# deep clean\n-purge:\n-\t$(RM) -r $(BUILDDIR) $(CURDIR)/InstallArea/$(BINARY_TAG)\n-\tfind $(CURDIR) \"(\" -name \"InstallArea\" -prune -o -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# Remove all the possible directories and the whole InstallArea as well\n-mrproper:\n-\t$(RM) -r $(CURDIR)/build $(CURDIR)/build.* $(CURDIR)/InstallArea\n-\tfind $(CURDIR) \"(\" -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# delegate any target to the build directory (except 'purge')\n-ifneq ($(MAKECMDGOALS),purge)\n-ifneq ($(MAKECMDGOALS),mrproper)\n-%: $(BUILDDIR)/$(BUILD_CONF_FILE) FORCE\n-\t+$(BUILD_CMD) $* -- $(BUILDFLAGS)\n-endif\n-endif\n-\n-# aliases\n-.PHONY: configure tests FORCE\n-ifneq ($(wildcard $(BUILDDIR)/$(BUILD_CONF_FILE)),)\n-configure: rebuild_cache\n-else\n-configure: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-endif\n-\t@ # do not delegate further\n-\n-\n-# This wrapping around the test target is used to ensure the generation of\n-# the XML output from ctest.\n-test: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-\n-# This target ensures that the \"all\" target is called before\n-# running the tests (unlike the \"test\" default target of CMake)\n-tests: all\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-ifeq ($(VERBOSE),)\n-# less verbose install\n-# (emulate the default CMake install target)\n-install: all\n-\tcd $(BUILDDIR) && $(CMAKE) -P cmake_install.cmake | grep -v \"^-- Up-to-date:\"\n-endif\n-\n-# import the library to look for a custom Makefile\n--include $(CUSTOM_MAKE_LIB_FILE)\n-\n-# ensure that the target are always passed to the CMake Makefile\n-FORCE: ;\n-\n-# Makefiles are used as implicit targets in make, but we should not consider\n-# them for delegation.\n-$(MAKEFILE_LIST): ;\n-\n-\n-# trigger CMake configuration\n-$(BUILDDIR)/$(BUILD_CONF_FILE): | $(BUILDDIR)\n-\tcd $(BUILDDIR) && $(CMAKE) $(ALL_CMAKEFLAGS) $(CURDIR)\n+$(info Using the $(ELEMENTS_MAKE_LIB_FILE) make library)\n+include $(ELEMENTS_MAKE_LIB_FILE)\n \n-$(BUILDDIR):\n-\tmkdir -p $(BUILDDIR)\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:43:38.000+00:00",
                            "94838755ea47bf85bef47bbb6c6144bbf76aa795"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "9.1.0",
                        "created_at": "2023-03-06T16:04:55.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.0",
                        "created_at": "2023-07-03T13:01:52.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.1",
                        "created_at": "2023-08-14T12:41:58.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    }
                ]
            },
            "PF-MER/MER_Deblending": {
                "start date": "2023-06-09 09:00",
                "end date": "2023-08-23 15:00",
                "start tag": "> 9.1.0",
                "end tag": "> 10.1.1",
                "count_files_modified": "3",
                "modifications_by_file": {
                    "CMakeLists.txt": [
                        [
                            "@@ -12,6 +12,6 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_Deblending 10.1 USE Elements 6.2.1\n-                                        MER_DataModelUtils 10.1)\n+elements_project(MER_Deblending 10.2 USE Elements 6.2.1\n+                                        MER_DataModelUtils 10.2)\n \n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-07-03T12:36:04.000+00:00",
                            "7f3e95092eba83d2ae18c3b1be25a1423d1e41bf"
                        ],
                        [
                            "@@ -12,6 +12,6 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_Deblending 10.0 USE Elements 6.1.1\n-                                        MER_DataModelUtils 10.0)\n+elements_project(MER_Deblending 10.1 USE Elements 6.2.1\n+                                        MER_DataModelUtils 10.1)\n \n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:39:09.000+00:00",
                            "911693b86c9c8f694111a409163ed6b46040bf70"
                        ]
                    ],
                    ".jenkinsFile": [
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\n-@Library('integration-library@release-9') _\n-pipelineElements(artifactId:\"MER_Deblending\", component:'eden.3.0')\n+@Library(value='integration-library@release-10') _\n+pipelineElements(name:\"MER_Deblending\", component:'eden.3.1')\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:39:09.000+00:00",
                            "911693b86c9c8f694111a409163ed6b46040bf70"
                        ]
                    ],
                    "Makefile": [
                        [
                            "@@ -44,170 +44,19 @@\n #\n ################################################################################\n \n-# settings\n-CMAKE := cmake\n-CTEST := ctest\n-NINJA := $(shell which ninja-build 2> /dev/null)\n-ifeq ($(NINJA),)\n-  NINJA := $(shell which ninja 2> /dev/null)\n-endif\n-\n-# Looking for the Custom make library\n-\n-CUSTOM_MAKE_LIB := Custom.mk\n-\n-ifneq ($(wildcard $(CURDIR)/make/$(CUSTOM_MAKE_LIB)),)\n-  CUSTOM_MAKE_LIB_FILE := $(CURDIR)/make/$(CUSTOM_MAKE_LIB)\n-else\n-  ifneq ($(CMAKE_PREFIX_PATH),)\n-    PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    CUSTOM_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(CUSTOM_MAKE_LIB) $(dir)/../make/$(CUSTOM_MAKE_LIB)))\n-  endif\n-  CUSTOM_MAKE_LIB_LIST += /usr/share/Elements/make/$(CUSTOM_MAKE_LIB)\n-  CUSTOM_MAKE_LIB_FILE := $(firstword $(CUSTOM_MAKE_LIB_LIST))\n-endif\n-\n-# Looking for the ToolChain\n-\n-TOOLCHAIN_NAME := ElementsToolChain.cmake\n+ELEMENTS_MAKE_LIB := Elements.mk\n \n-ifneq ($(wildcard $(CURDIR)/cmake/$(TOOLCHAIN_NAME)),)\n-  TOOLCHAIN_FILE := $(CURDIR)/cmake/$(TOOLCHAIN_NAME)\n+ifneq ($(wildcard $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)),)\n+  ELEMENTS_MAKE_LIB_FILE := $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)\n else\n   ifneq ($(CMAKE_PREFIX_PATH),)\n     PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    TOOLCHAIN_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/lib*/cmake/ElementsProject/$(TOOLCHAIN_NAME) $(dir)/$(TOOLCHAIN_NAME)))\n-    TOOLCHAIN_FILE := $(firstword $(TOOLCHAIN_LIST))\n-  endif\n-endif\n-\n-override ALL_CMAKEFLAGS := -Wno-dev --no-warn-unused-cli\n-\n-ifneq ($(TOOLCHAIN_FILE),)\n-  # A toolchain has been found. Lets use it.\n-  override ALL_CMAKEFLAGS += -DCMAKE_TOOLCHAIN_FILE=$(TOOLCHAIN_FILE)\n-endif\n-\n-\n-BUILD_PREFIX_NAME := build\n-\n-override ALL_CMAKEFLAGS += -DUSE_LOCAL_INSTALLAREA=ON -DBUILD_PREFIX_NAME:STRING=$(BUILD_PREFIX_NAME)\n-override ALL_CMAKEFLAGS += -DUSE_VERSIONED_LIBRARIES=OFF\n-\n-ifndef BINARY_TAG\n-  ifdef CMAKECONFIG\n-    BINARY_TAG := ${CMAKECONFIG}\n-  else\n-    ifdef CMTCONFIG\n-      BINARY_TAG := ${CMTCONFIG}\n-    endif\n-  endif\n-endif\n-\n-ifdef BINARY_TAG\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME).$(BINARY_TAG)\n-else\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME)\n-endif\n-BUILDDIR := $(CURDIR)/$(BUILD_SUBDIR)\n-\n-# build tool\n-\n-ifneq ($(USE_NINJA),)\n-  # enable Ninja\n-  override ALL_CMAKEFLAGS += -GNinja\n-  BUILD_CONF_FILE := build.ninja\n-  BUILDFLAGS := $(NINJAFLAGS)\n-  ifneq ($(VERBOSE),)\n-    BUILDFLAGS := -v $(BUILDFLAGS)\n+    ELEMENTS_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(ELEMENTS_MAKE_LIB) $(dir)/../make/$(ELEMENTS_MAKE_LIB)))\n   endif\n-else\n-  BUILD_CONF_FILE := Makefile\n-endif\n-BUILD_CMD := $(CMAKE) --build $(BUILD_SUBDIR) --target\n-\n-\n-# Use environment variable for extra flags\n-\n-# Replace the \":\" from eclipse variable list to spaces  \n-ifneq ($(EXPAND_FLAGS),)\n-  CMAKEFLAGS := $(subst :-, -,$(CMAKEFLAGS))\n-endif\n-\n-ifneq ($(CMAKEFLAGS),)\n-  override ALL_CMAKEFLAGS += $(CMAKEFLAGS)\n+  ELEMENTS_MAKE_LIB_LIST += /usr/share/Elements/make/$(ELEMENTS_MAKE_LIB)\n+  ELEMENTS_MAKE_LIB_FILE := $(firstword $(ELEMENTS_MAKE_LIB_LIST))\n endif\n \n-# default target\n-all:\n-\n-# deep clean\n-purge:\n-\t$(RM) -r $(BUILDDIR) $(CURDIR)/InstallArea/$(BINARY_TAG)\n-\tfind $(CURDIR) \"(\" -name \"InstallArea\" -prune -o -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# Remove all the possible directories and the whole InstallArea as well\n-mrproper:\n-\t$(RM) -r $(CURDIR)/build $(CURDIR)/build.* $(CURDIR)/InstallArea\n-\tfind $(CURDIR) \"(\" -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# delegate any target to the build directory (except 'purge')\n-ifneq ($(MAKECMDGOALS),purge)\n-ifneq ($(MAKECMDGOALS),mrproper)\n-%: $(BUILDDIR)/$(BUILD_CONF_FILE) FORCE\n-\t+$(BUILD_CMD) $* -- $(BUILDFLAGS)\n-endif\n-endif\n-\n-# aliases\n-.PHONY: configure tests FORCE\n-ifneq ($(wildcard $(BUILDDIR)/$(BUILD_CONF_FILE)),)\n-configure: rebuild_cache\n-else\n-configure: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-endif\n-\t@ # do not delegate further\n-\n-\n-# This wrapping around the test target is used to ensure the generation of\n-# the XML output from ctest.\n-test: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-\n-# This target ensures that the \"all\" target is called before\n-# running the tests (unlike the \"test\" default target of CMake)\n-tests: all\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-ifeq ($(VERBOSE),)\n-# less verbose install\n-# (emulate the default CMake install target)\n-install: all\n-\tcd $(BUILDDIR) && $(CMAKE) -P cmake_install.cmake | grep -v \"^-- Up-to-date:\"\n-endif\n-\n-# import the library to look for a custom Makefile\n--include $(CUSTOM_MAKE_LIB_FILE)\n-\n-# ensure that the target are always passed to the CMake Makefile\n-FORCE: ;\n-\n-# Makefiles are used as implicit targets in make, but we should not consider\n-# them for delegation.\n-$(MAKEFILE_LIST): ;\n-\n-\n-# trigger CMake configuration\n-$(BUILDDIR)/$(BUILD_CONF_FILE): | $(BUILDDIR)\n-\tcd $(BUILDDIR) && $(CMAKE) $(ALL_CMAKEFLAGS) $(CURDIR)\n-\n-$(BUILDDIR):\n-\tmkdir -p $(BUILDDIR)\n+$(info Using the $(ELEMENTS_MAKE_LIB_FILE) make library)\n+include $(ELEMENTS_MAKE_LIB_FILE)\n \n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-23T09:39:09.000+00:00",
                            "911693b86c9c8f694111a409163ed6b46040bf70"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "9.1.0",
                        "created_at": "2023-03-06T15:17:15.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.0",
                        "created_at": "2023-07-03T12:35:35.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.1",
                        "created_at": "2023-08-14T12:07:22.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    }
                ]
            },
            "PF-MER/MER_SExtractorPP": {
                "start date": "2023-06-09 09:00",
                "end date": "2023-08-23 15:00",
                "start tag": "> v0.2.1",
                "end tag": "> v0.2.1",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "v0.2.1",
                        "created_at": "2019-05-09T19:31:59.000+02:00",
                        "author_name": "Samuele Galeotta"
                    }
                ]
            },
            "PF-MER/MER_PsfMosaic": {
                "start date": "2023-06-09 09:00",
                "end date": "2023-08-23 15:00",
                "start tag": "> 9.1.0",
                "end tag": "> 10.1.0",
                "count_files_modified": "6",
                "modifications_by_file": {
                    "MER_PsfMosaic/python/MER_PsfMosaic/BasePsf.py": [
                        [
                            "@@ -43,7 +43,7 @@ class BasePsf(object):\n     \"\"\"The precision in the ratio between the stamp pixel size and the PSF pixel\n     size.\"\"\"\n \n-    MAXIMUM_STAMP_SIZE = 26 / 3600\n+    MAXIMUM_STAMP_SIZE = 5 / 3600\n     \"\"\"The maximum allowed stamp size in degrees.\"\"\"\n \n     UNIMPLEMENTED_MESSAGE = \"This method should be implemented in a subclass\"\n",
                            "Changes the maximum stamp size to 5 arcseconds",
                            "Javier Gracia Carpio",
                            "2023-08-23T12:27:14.000+00:00",
                            "a5f765d6031e230ff25b8e87aa97489df4999f22"
                        ]
                    ],
                    "CMakeLists.txt": [
                        [
                            "@@ -12,4 +12,4 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_PsfMosaic 10.2 USE Elements 6.2.1 EL_PSFExModel 10.3)\n+elements_project(MER_PsfMosaic 10.2 USE Elements 6.2.1 EL_PSFExModel 10.3 MER_DA 10.2)\n",
                            "Merge branch 'feature/lowdisk' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-17T08:35:01.000+00:00",
                            "72e01d39141963b922d141a2966806939c73ee0a"
                        ],
                        [
                            "@@ -12,4 +12,4 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_PsfMosaic 10.2 USE Elements 6.2.1 EL_PSFExModel 10.2)\n+elements_project(MER_PsfMosaic 10.2 USE Elements 6.2.1 EL_PSFExModel 10.3)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-07-03T14:52:11.000+00:00",
                            "7c0f241ae986a1780aba0000b7cef29a7627f877"
                        ],
                        [
                            "@@ -12,4 +12,4 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_PsfMosaic 10.1 USE Elements 6.2.1 EL_PSFExModel 10.2)\n+elements_project(MER_PsfMosaic 10.2 USE Elements 6.2.1 EL_PSFExModel 10.2)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-07-03T13:30:09.000+00:00",
                            "89f524403ba90a9911195b3ebcfad452199d7784"
                        ],
                        [
                            "@@ -12,4 +12,4 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_PsfMosaic 10.0 USE Elements 6.1.1 EL_PSFExModel 10.1)\n+elements_project(MER_PsfMosaic 10.1 USE Elements 6.2.1 EL_PSFExModel 10.2)\n",
                            "Made all necessary changes for eden-3.1",
                            "Martin Kuemmel",
                            "2023-06-24T10:00:54.000+02:00",
                            "7f41d0f39172a7f85fe24b69b7d7f33b99c9e0cc"
                        ]
                    ],
                    "MER_PsfMosaic/python/MER_PsfMosaic/PsfCombiner.py": [
                        [
                            "@@ -22,6 +22,7 @@ File: python/MER_PsfMosaic/PsfCombiner.py\n Created on: 05/29/18\n Author: Javier Gracia Carpio (jgracia@mpe.mpg.de)\n \"\"\"\n+import os.path\n \n import numpy as np\n from astropy.io import fits\n@@ -29,6 +30,7 @@ from astropy.io import fits\n from MER_PsfMosaic.BasePsf import BasePsf\n from MER_PsfMosaic.EuclidWcs import EuclidWcs\n \n+from MER_DA.MER_FitsToCards import MER_FitsToCards\n \n class PsfCombiner(object):\n     \"\"\"A utility class for the MER Mosaic PSF calculation.\n@@ -225,8 +227,15 @@ class PsfCombiner(object):\n             An astropy HDU list with the PSF image.\n \n         \"\"\"\n-        # Get the input image data and the header information\n-        data, header = fits.getdata(image_file_name, ext=extension, header=True)\n+        if os.path.isfile(image_file_name):\n+            # Get the input image data and the header information\n+            data, header = fits.getdata(image_file_name, ext=extension, header=True)\n+        else:\n+            card_file_name = os.path.splitext(image_file_name)[0]+'.cards'\n+            if os.path.isfile(card_file_name):\n+                data, header = MER_FitsToCards.card_file_to_fits(card_file_name)\n+            else:\n+                raise Exception('File: %s and its card file: %s do not exist!' % (image_file_name, card_file_name))\n \n         # Calculate the input image WCS\n         wcs = EuclidWcs(header)\n",
                            "Merge branch 'feature/lowdisk' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-17T08:35:01.000+00:00",
                            "72e01d39141963b922d141a2966806939c73ee0a"
                        ]
                    ],
                    ".jenkinsFile": [
                        [
                            "@@ -1,6 +1,3 @@\n-\n-\n-\n #!groovy\n-@Library('integration-library@release-10') _\n+@Library(value='integration-library@release-10') _\n pipelineElements(name:\"MER_PsfMosaic\", component:'eden.3.1')\n",
                            "Fixes jenkins file",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:19:12.000+00:00",
                            "0abfd3412064570b8716d61fea67ca196cdbb22b"
                        ],
                        [
                            "@@ -1,3 +1,6 @@\n+\n+\n+\n #!groovy\n-@Library('integration-library@release-9') _\n-pipelineElements(artifactId:\"MER_PsfMosaic\", component:'eden.3.0')\n+@Library('integration-library@release-10') _\n+pipelineElements(name:\"MER_PsfMosaic\", component:'eden.3.1')\n",
                            "Made all necessary changes for eden-3.1",
                            "Martin Kuemmel",
                            "2023-06-24T10:00:54.000+02:00",
                            "7f41d0f39172a7f85fe24b69b7d7f33b99c9e0cc"
                        ]
                    ],
                    "MER_PsfMosaic/python/MER_PsfMosaic/PsfExModelPsf.py": [
                        [
                            "@@ -31,7 +31,6 @@ from MER_PsfMosaic.ArrayUtils import ArrayUtils\n from MER_PsfMosaic.EuclidPsfStamp import EuclidPsfStamp\n from MER_PsfMosaic.BasePsf import BasePsf\n from PSFExModelModuleBinding import floatArray\n-#from PSFExModelModuleBinding import floatArray_frompointer\n from PSFExModelModuleBinding import PsfExMasking\n \n \n",
                            "Small changes",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:13:16.000+00:00",
                            "418ef59004c89405d449985d5094af7bf522c374"
                        ],
                        [
                            "@@ -31,7 +31,7 @@ from MER_PsfMosaic.ArrayUtils import ArrayUtils\n from MER_PsfMosaic.EuclidPsfStamp import EuclidPsfStamp\n from MER_PsfMosaic.BasePsf import BasePsf\n from PSFExModelModuleBinding import floatArray\n-from PSFExModelModuleBinding import floatArray_frompointer\n+#from PSFExModelModuleBinding import floatArray_frompointer\n from PSFExModelModuleBinding import PsfExMasking\n \n \n@@ -233,7 +233,7 @@ class PsfExModelPsf(BasePsf):\n         array_size = self._npix_x * self._npix_y\n         values = floatArray(array_size)\n         self._psf_model.getPsfDataAt(\n-            float(xy_coord[0]), float(xy_coord[1]), floatArray_frompointer(values))\n+            float(xy_coord[0]), float(xy_coord[1]), floatArray.frompointer(values))\n \n         # Return the result as a numpy array\n         return np.array([values[i] for i in range(array_size)]).reshape(\n",
                            "Made all necessary changes for eden-3.1",
                            "Martin Kuemmel",
                            "2023-06-24T10:00:54.000+02:00",
                            "7f41d0f39172a7f85fe24b69b7d7f33b99c9e0cc"
                        ]
                    ],
                    "Makefile": [
                        [
                            "@@ -44,169 +44,19 @@\n #\n ################################################################################\n \n-# settings\n-CMAKE := cmake\n-CTEST := ctest\n-NINJA := $(shell which ninja-build 2> /dev/null)\n-ifeq ($(NINJA),)\n-  NINJA := $(shell which ninja 2> /dev/null)\n-endif\n-\n-# Looking for the Custom make library\n-\n-CUSTOM_MAKE_LIB := Custom.mk\n-\n-ifneq ($(wildcard $(CURDIR)/make/$(CUSTOM_MAKE_LIB)),)\n-  CUSTOM_MAKE_LIB_FILE := $(CURDIR)/make/$(CUSTOM_MAKE_LIB)\n-else\n-  ifneq ($(CMAKE_PREFIX_PATH),)\n-    PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    CUSTOM_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(CUSTOM_MAKE_LIB) $(dir)/../make/$(CUSTOM_MAKE_LIB)))\n-  endif\n-  CUSTOM_MAKE_LIB_LIST += /usr/share/Elements/make/$(CUSTOM_MAKE_LIB)\n-  CUSTOM_MAKE_LIB_FILE := $(firstword $(CUSTOM_MAKE_LIB_LIST))\n-endif\n-\n-# Looking for the ToolChain\n-\n-TOOLCHAIN_NAME := ElementsToolChain.cmake\n+ELEMENTS_MAKE_LIB := Elements.mk\n \n-ifneq ($(wildcard $(CURDIR)/cmake/$(TOOLCHAIN_NAME)),)\n-  TOOLCHAIN_FILE := $(CURDIR)/cmake/$(TOOLCHAIN_NAME)\n+ifneq ($(wildcard $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)),)\n+  ELEMENTS_MAKE_LIB_FILE := $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)\n else\n   ifneq ($(CMAKE_PREFIX_PATH),)\n     PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    TOOLCHAIN_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/lib*/cmake/ElementsProject/$(TOOLCHAIN_NAME) $(dir)/$(TOOLCHAIN_NAME)))\n-    TOOLCHAIN_FILE := $(firstword $(TOOLCHAIN_LIST))\n+    ELEMENTS_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(ELEMENTS_MAKE_LIB) $(dir)/../make/$(ELEMENTS_MAKE_LIB)))\n   endif\n+  ELEMENTS_MAKE_LIB_LIST += /usr/share/Elements/make/$(ELEMENTS_MAKE_LIB)\n+  ELEMENTS_MAKE_LIB_FILE := $(firstword $(ELEMENTS_MAKE_LIB_LIST))\n endif\n \n-override ALL_CMAKEFLAGS := -Wno-dev --no-warn-unused-cli\n-\n-ifneq ($(TOOLCHAIN_FILE),)\n-  # A toolchain has been found. Lets use it.\n-  override ALL_CMAKEFLAGS += -DCMAKE_TOOLCHAIN_FILE=$(TOOLCHAIN_FILE)\n-endif\n-\n-\n-BUILD_PREFIX_NAME := build\n-\n-override ALL_CMAKEFLAGS += -DUSE_LOCAL_INSTALLAREA=ON -DBUILD_PREFIX_NAME:STRING=$(BUILD_PREFIX_NAME)\n-override ALL_CMAKEFLAGS += -DUSE_VERSIONED_LIBRARIES=OFF\n-\n-ifndef BINARY_TAG\n-  ifdef CMAKECONFIG\n-    BINARY_TAG := ${CMAKECONFIG}\n-  else\n-    ifdef CMTCONFIG\n-      BINARY_TAG := ${CMTCONFIG}\n-    endif\n-  endif\n-endif\n-\n-ifdef BINARY_TAG\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME).$(BINARY_TAG)\n-else\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME)\n-endif\n-BUILDDIR := $(CURDIR)/$(BUILD_SUBDIR)\n-\n-# build tool\n-\n-ifneq ($(USE_NINJA),)\n-  # enable Ninja\n-  override ALL_CMAKEFLAGS += -GNinja\n-  BUILD_CONF_FILE := build.ninja\n-  BUILDFLAGS := $(NINJAFLAGS)\n-  ifneq ($(VERBOSE),)\n-    BUILDFLAGS := -v $(BUILDFLAGS)\n-  endif\n-else\n-  BUILD_CONF_FILE := Makefile\n-endif\n-BUILD_CMD := $(CMAKE) --build $(BUILD_SUBDIR) --target\n-\n-\n-# Use environment variable for extra flags\n-\n-# Replace the \":\" from eclipse variable list to spaces  \n-ifneq ($(EXPAND_FLAGS),)\n-  CMAKEFLAGS := $(subst :-, -,$(CMAKEFLAGS))\n-endif\n-\n-ifneq ($(CMAKEFLAGS),)\n-  override ALL_CMAKEFLAGS += $(CMAKEFLAGS)\n-endif\n-\n-# default target\n-all:\n-\n-# deep clean\n-purge:\n-\t$(RM) -r $(BUILDDIR) $(CURDIR)/InstallArea/$(BINARY_TAG)\n-\tfind $(CURDIR) \"(\" -name \"InstallArea\" -prune -o -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# Remove all the possible directories and the whole InstallArea as well\n-mrproper:\n-\t$(RM) -r $(CURDIR)/build $(CURDIR)/build.* $(CURDIR)/InstallArea\n-\tfind $(CURDIR) \"(\" -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# delegate any target to the build directory (except 'purge')\n-ifneq ($(MAKECMDGOALS),purge)\n-ifneq ($(MAKECMDGOALS),mrproper)\n-%: $(BUILDDIR)/$(BUILD_CONF_FILE) FORCE\n-\t+$(BUILD_CMD) $* -- $(BUILDFLAGS)\n-endif\n-endif\n-\n-# aliases\n-.PHONY: configure tests FORCE\n-ifneq ($(wildcard $(BUILDDIR)/$(BUILD_CONF_FILE)),)\n-configure: rebuild_cache\n-else\n-configure: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-endif\n-\t@ # do not delegate further\n-\n-\n-# This wrapping around the test target is used to ensure the generation of\n-# the XML output from ctest.\n-test: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-\n-# This target ensures that the \"all\" target is called before\n-# running the tests (unlike the \"test\" default target of CMake)\n-tests: all\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-ifeq ($(VERBOSE),)\n-# less verbose install\n-# (emulate the default CMake install target)\n-install: all\n-\tcd $(BUILDDIR) && $(CMAKE) -P cmake_install.cmake | grep -v \"^-- Up-to-date:\"\n-endif\n-\n-# import the library to look for a custom Makefile\n--include $(CUSTOM_MAKE_LIB_FILE)\n-\n-# ensure that the target are always passed to the CMake Makefile\n-FORCE: ;\n-\n-# Makefiles are used as implicit targets in make, but we should not consider\n-# them for delegation.\n-$(MAKEFILE_LIST): ;\n-\n-\n-# trigger CMake configuration\n-$(BUILDDIR)/$(BUILD_CONF_FILE): | $(BUILDDIR)\n-\tcd $(BUILDDIR) && $(CMAKE) $(ALL_CMAKEFLAGS) $(CURDIR)\n+$(info Using the $(ELEMENTS_MAKE_LIB_FILE) make library)\n+include $(ELEMENTS_MAKE_LIB_FILE)\n \n-$(BUILDDIR):\n-\tmkdir -p $(BUILDDIR)\n",
                            "Small changes",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:13:16.000+00:00",
                            "418ef59004c89405d449985d5094af7bf522c374"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "9.1.0",
                        "created_at": "2023-03-06T14:36:10.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.0",
                        "created_at": "2023-07-03T13:28:50.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    }
                ]
            },
            "PF-MER/MER_DA": {
                "start date": "2023-06-09 09:00",
                "end date": "2023-08-23 15:00",
                "start tag": "> 9.1.0",
                "end tag": "> 10.1.1",
                "count_files_modified": "14",
                "modifications_by_file": {
                    "CMakeLists.txt": [
                        [
                            "@@ -12,4 +12,4 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_DA 10.2 USE Elements 6.2.1 MER_DataModelUtils 10.2)\n+elements_project(MER_DA 10.2 USE Elements 6.2.1 MER_DataModelUtils 10.2 EL_Utils 1.5.1)\n",
                            "add proper motion correction to CrossMatchModule",
                            "yfang",
                            "2023-08-23T13:57:26.000+02:00",
                            "7914af5e171751b05cec5ecb23bc2ac47321c49b"
                        ],
                        [
                            "@@ -12,4 +12,4 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_DA 10.1 USE Elements 6.2.1 MER_DataModelUtils 10.1)\n+elements_project(MER_DA 10.2 USE Elements 6.2.1 MER_DataModelUtils 10.2)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-07-03T11:57:18.000+00:00",
                            "0252281189eb934cd76f2241d17bac0579e71f95"
                        ],
                        [
                            "@@ -12,4 +12,4 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_DA 10.0 USE Elements 6.1.1 MER_DataModelUtils 10.0)\n+elements_project(MER_DA 10.1 USE Elements 6.2.1 MER_DataModelUtils 10.1)\n",
                            "Updates to new DM and Eden 3.1",
                            "Javier Gracia Carpio",
                            "2023-06-22T09:30:49.000+00:00",
                            "f3934f92e484cf286ae3a6197c398509ffd0b6ed"
                        ]
                    ],
                    "MER_DA/python/MER_DA/MER_CrossMatchModule.py": [
                        [
                            "@@ -30,9 +30,14 @@ import astropy.units as u\n import matplotlib.pyplot as plt\n from astropy.coordinates import SkyCoord\n from astropy.io import fits\n+from astropy.time import Time\n # from astropy.io import ascii\n from sklearn.neighbors import BallTree\n \n+from EL_NullValue import NullValueDefinition\n+# from MER_DA.MER_ProperMotionModule import ProperMotionCorrection\n+from EL_GaiaUtils.ProperMotion import ProperMotionCorrection\n+\n # def convert_catalog(catname):\n #     text_file = ascii.read(catname)\n #     text_file.write('test_ascii_to_fits.fits', overwrite=True)\n@@ -40,7 +45,7 @@ from sklearn.neighbors import BallTree\n def MER_position_crossmatch(catname_1=None, ext_num_1=1, ra_name_1='ra', dec_name_1='dec', col_list_1=[],\n                            catname_2=None, ext_num_2=1, ra_name_2='ra', dec_name_2='dec', id_col_name_2=None, col_list_2=[],\n                            max_separation=1.0, other_thresholds=[], weights=[],\n-                           output_path=None, matched_id_outputname='MATCH_ID', matched_quality_outputname=\"MATCH_DIST\", logger=None):\n+                           output_path=None, matched_id_outputname='MATCH_ID', matched_quality_outputname=\"MATCH_DIST\", pmcorr_2=True, epoch_1=2023.12, logger=None):\n     \"\"\"Function which does everything\n     \"\"\"\n     if logger is not None:\n@@ -59,7 +64,9 @@ def MER_position_crossmatch(catname_1=None, ext_num_1=1, ra_name_1='ra', dec_nam\n                                                              ra_name_2,\n                                                              dec_name_2,\n                                                              id_col_name=id_col_name_2,\n-                                                             col_list=col_list_2)\n+                                                             col_list=col_list_2,\n+                                                             pmcorr=pmcorr_2,\n+                                                             epoch=epoch_1)\n \n     # col_lists2 = [gaia_g_flux_to_mag(col) for col in col_lists2]\n     if logger is not None:\n@@ -88,7 +95,7 @@ def MER_position_crossmatch(catname_1=None, ext_num_1=1, ra_name_1='ra', dec_nam\n     return None\n     \n \n-def MER_read_catalog(catname, ext_num=1, ra_name='ra', dec_name='dec', id_col_name=None, col_list=[]):\n+def MER_read_catalog(catname, ext_num=1, ra_name='ra', dec_name='dec', id_col_name=None, col_list=[], pmcorr=False, epoch=Time(\"2023.915\", format='jyear')):\n     \"\"\"Read data from a FITS table\n     \"\"\"\n     hdu = fits.open(catname)\n@@ -97,6 +104,10 @@ def MER_read_catalog(catname, ext_num=1, ra_name='ra', dec_name='dec', id_col_na\n     ra = data[ra_name]\n     dec = data[dec_name]\n     col_other = []\n+    if pmcorr:\n+        pm = ProperMotionCorrection(epoch=epoch)\n+        pmra, pmdec = data['PMRA'], data['PMDEC']\n+        ra, dec = pm.get_positions(ra, dec, pmra, pmdec)\n     if len(col_list) > 0:\n         for col in col_list:\n             col_other.append(data[col])\n@@ -164,8 +175,10 @@ def MER_match_catalogs_sky(ra1, dec1, ra2, dec2, id_col_cat2, max_dist=0.6, unit\n     matching_quality = []\n     for i in range(len(idx1)):\n         if len(idx1[i]) == 0:\n-            matching_id.append(-1)\n-            matching_quality.append(1e10)\n+            # matching_id.append(-1)\n+            # matching_quality.append(1e10)\n+            matching_id.append(NullValueDefinition().LONG_LONG)\n+            matching_quality.append(NullValueDefinition().FLOAT)\n             continue\n         else:\n             features_1 = [col[i] for col in col1]\n@@ -187,6 +200,8 @@ def MER_match_catalogs_sky(ra1, dec1, ra2, dec2, id_col_cat2, max_dist=0.6, unit\n                 matching_quality.append(best_matching_quality)\n                 tot_matched += 1\n             else:\n-                matching_id.append(-1)\n-                matching_quality.append(1e10)\n+                # matching_id.append(-1)\n+                # matching_quality.append(1e10)\n+                matching_id.append(NullValueDefinition().LONG_LONG)\n+                matching_quality.append(NullValueDefinition().FLOAT)\n     return matching_id, matching_quality, tot_matched\n\\ No newline at end of file\n",
                            "add proper motion correction to CrossMatchModule",
                            "yfang",
                            "2023-08-23T13:57:26.000+02:00",
                            "7914af5e171751b05cec5ecb23bc2ac47321c49b"
                        ]
                    ],
                    "MER_DA/python/MER_DA/MER_FileCleaner.py": [
                        [
                            "@@ -25,11 +25,13 @@\n import os\n import os.path\n \n+from MER_DA.MER_FitsToCards import MER_FitsToCards\n+\n class MER_FileCleaner(object):\n     \"\"\"The main class\n     \"\"\"\n     @staticmethod\n-    def clean_list(file_list, base_path=os.getcwd(), replace_items=None, logger=None):\n+    def clean_list(file_list, base_path=os.getcwd(), save_cards=False, replace_items=None, logger=None):\n         \"\"\"Loads a JSON file\n \n         Parameters\n@@ -48,6 +50,9 @@ class MER_FileCleaner(object):\n                 # compose the file path and delete the file\n                 act_file = os.path.join(base_path, act_item.strip())\n                 if os.path.isfile(act_file):\n+                    if save_cards:\n+                        card_file = os.path.splitext(act_item.strip())[0] + '.cards'\n+                        MER_FitsToCards.header_to_card_file(act_file, os.path.join(base_path, card_file), logger=logger)\n                     os.remove(act_file)\n                     logger.debug('# DELETED: %s'%act_file)\n \n",
                            "Merge branch 'feature/lowdisk' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-17T08:53:26.000+00:00",
                            "419cb54a8597c1a4eacfd5659b41e46baa823813"
                        ],
                        [
                            "@@ -0,0 +1,59 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+:file: python/MER_DA/MER_FileCleaner.py\n+\n+:date: 08/08/23\n+:author: mkuemmel@usm.lmu.de\n+\"\"\"\n+import os\n+import os.path\n+\n+class MER_FileCleaner(object):\n+    \"\"\"The main class\n+    \"\"\"\n+    @staticmethod\n+    def clean_list(file_list, base_path=os.getcwd(), replace_items=None, logger=None):\n+        \"\"\"Loads a JSON file\n+\n+        Parameters\n+        ----------\n+        file_list: string\n+        base_path: string\n+        logger: object, optional\n+            The logger object.\n+        \"\"\"\n+        # compose the file list path and open the list\n+        file_list_path = os.path.join(base_path, file_list)\n+        with open(file_list_path) as file_list_obj:\n+            # go over all items\n+            for act_item in file_list_obj.readlines():\n+\n+                # compose the file path and delete the file\n+                act_file = os.path.join(base_path, act_item.strip())\n+                if os.path.isfile(act_file):\n+                    os.remove(act_file)\n+                    logger.debug('# DELETED: %s'%act_file)\n+\n+                # if a replacement id given, get the replaced filename and remove it                \n+                if replace_items is not None and len(replace_items)==2:\n+                    act_file_replace = os.path.join(base_path, (act_item.strip()).replace(replace_items[0],replace_items[1]))\n+                    if os.path.isfile(act_file_replace):\n+                        os.remove(act_file_replace)\n+                        logger.debug('# DELETED: %s'%act_file_replace)\n\\ No newline at end of file\n",
                            "Merge branch 'feature/low_diskspace' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-11T12:33:50.000+00:00",
                            "84cf91a8d95a27dca6e96c05ada2f6871ff7c09d"
                        ],
                        [
                            "@@ -0,0 +1,59 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+:file: python/MER_DA/MER_FileCleaner.py\n+\n+:date: 08/08/23\n+:author: mkuemmel@usm.lmu.de\n+\"\"\"\n+import os\n+import os.path\n+\n+class MER_FileCleaner(object):\n+    \"\"\"The main class\n+    \"\"\"\n+    @staticmethod\n+    def clean_list(file_list, base_path=os.getcwd(), replace_items=None, logger=None):\n+        \"\"\"Loads a JSON file\n+\n+        Parameters\n+        ----------\n+        file_list: string\n+        base_path: string\n+        logger: object, optional\n+            The logger object.\n+        \"\"\"\n+        # compose the file list path and open the list\n+        file_list_path = os.path.join(base_path, file_list)\n+        with open(file_list_path) as file_list_obj:\n+            # go over all items\n+            for act_item in file_list_obj.readlines():\n+\n+                # compose the file path and delete the file\n+                act_file = os.path.join(base_path, act_item.strip())\n+                if os.path.isfile(act_file):\n+                    os.remove(act_file)\n+                    logger.debug('# DELETED: %s'%act_file)\n+\n+                # if a replacement id given, get the replaced filename and remove it                \n+                if replace_items is not None and len(replace_items)==2:\n+                    act_file_replace = os.path.join(base_path, (act_item.strip()).replace(replace_items[0],replace_items[1]))\n+                    if os.path.isfile(act_file_replace):\n+                        os.remove(act_file_replace)\n+                        logger.debug('# DELETED: %s'%act_file_replace)\n\\ No newline at end of file\n",
                            "Added a function to remove images in a list.",
                            "Martin Kuemmel",
                            "2023-08-10T18:47:08.000+02:00",
                            "14c5b89145562ce5bc0dada06dbcc4d3e1771cb8"
                        ]
                    ],
                    "MER_DA/python/MER_DA/MER_FitsToCards.py": [
                        [
                            "@@ -0,0 +1,70 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+:file: python/MER_DA/MER_FitsToCards.py\n+\n+:date: 08/13/23\n+:author: mkuemmel@usm.lmu.de\n+\n+\"\"\"\n+import numpy\n+from astropy.io import fits\n+\n+class MER_FitsToCards(object):\n+    \"\"\"The main class\n+    \"\"\"\n+    @staticmethod\n+    def header_to_card_file(in_fits, card_file, hdu_index=0, logger=None):\n+        \"\"\"\n+        \"\"\"\n+        with fits.open(in_fits) as img_fits, open(card_file, 'w+') as out_cards:\n+            target_header = img_fits[hdu_index].header\n+            all_cards = target_header.cards\n+            #print(all_cards)\n+            \n+            for one_card in all_cards:\n+                #print(one_card.image)\n+                out_cards.write('%s\\n' % one_card.image)\n+            if logger is not None:\n+                logger.debug('# %s[%i] --> %s' % (in_fits, hdu_index, card_file))\n+\n+    @staticmethod\n+    def card_file_to_fits(in_cards):\n+        \"\"\"\n+        \"\"\"\n+        fits_cards = []\n+        npix_x = None\n+        npix_y = None\n+        with open(in_cards) as card_file:\n+            all_card_strings = card_file.readlines()\n+            for one_card_string in all_card_strings:\n+                act_card = fits.Card.fromstring(one_card_string.strip()) \n+                if act_card.rawkeyword == 'NAXIS1':\n+                    npix_x = int(act_card.value)\n+                elif act_card.rawkeyword == 'NAXIS2':\n+                    npix_y = int(act_card.value)\n+                #act_card.verify(option='fix')\n+                fits_cards.append(act_card)\n+        if npix_x is not None and npix_y is not None:\n+            out_fits_data = numpy.zeros((npix_y, npix_x), dtype=numpy.float32)\n+        else:\n+            raise Exception('Wrong NAXIS keywords NAXIS1=%s NAXIS2=%s'%(str(npix_x), str(npix_y)))\n+        #fits.writeto(out_fits, data=out_fits_data, header=fits.Header(cards=fits_cards), overwrite=True)\n+        #print('%s --> %s' % (in_cards, out_fits))\n+        return out_fits_data, fits.Header(cards=fits_cards)\n",
                            "Merge branch 'feature/lowdisk' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-17T08:53:26.000+00:00",
                            "419cb54a8597c1a4eacfd5659b41e46baa823813"
                        ]
                    ],
                    "MER_DA/tests/python/MER_FitsToCards_test.py": [
                        [
                            "@@ -0,0 +1,38 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+:file: tests/python/MER_FitsToCards_test.py\n+\n+:date: 08/13/23\n+:author: mkuemmel@usm.lmu.de\n+\"\"\"\n+\n+import pytest\n+import MER_DA.MER_FitsToCards\n+\n+class TestMER_FitsToCards(object):\n+    \"\"\"\n+    @class TestMER_FitsToCards\n+\n+    @brief Unit Test class\n+    !!! Test class example for python             !!!\n+    !!! Please remove it and add your tests there !!!\n+    \"\"\"\n+    def testFailure(self):\n+        assert True, \"!!!! Please implement your tests !!!!\"\n",
                            "Merge branch 'feature/lowdisk' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-17T08:53:26.000+00:00",
                            "419cb54a8597c1a4eacfd5659b41e46baa823813"
                        ]
                    ],
                    "MER_DA/tests/python/MER_FileCleaner_test.py": [
                        [
                            "@@ -0,0 +1,38 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+:file: tests/python/MER_FileCleaner_test.py\n+\n+:date: 08/08/23\n+:author: mkuemmel@usm.lmu.de\n+\"\"\"\n+\n+import pytest\n+import MER_DA.MER_FileCleaner\n+\n+class TestMER_FileCleaner(object):\n+    \"\"\"\n+    @class TestMER_FileCleaner\n+\n+    @brief Unit Test class\n+    !!! Test class example for python             !!!\n+    !!! Please remove it and add your tests there !!!\n+    \"\"\"\n+    def testFailure(self):\n+        assert True, \"!!!! Please implement your tests !!!!\"\n",
                            "Merge branch 'feature/low_diskspace' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-11T12:33:50.000+00:00",
                            "84cf91a8d95a27dca6e96c05ada2f6871ff7c09d"
                        ]
                    ],
                    "MER_DA/python/MER_DA/MER_CrossMatchPrg.py": [
                        [
                            "@@ -58,9 +58,9 @@ def defineSpecificProgramOptions():\n                         help = 'the column name in catalog #2 for RA')\n     parser.add_argument('--dec_name2', type = str, required = True, default = 'DEC',\n                         help = 'the column name in catalog #2 for DEC')\n-    parser.add_argument('--matched_id_outputname', type = str, required = False, default = 'MATCHED_OBJ_ID',\n+    parser.add_argument('--matched_id_outputname', type = str, required = True,\n                         help = 'the column name in the output catalog for matched object ID')\n-    parser.add_argument('--matched_quality_outputname', type = str, required = False, default = 'MATCHED_QUALITY',\n+    parser.add_argument('--matched_quality_outputname', type = str, required = True,\n                         help = 'the column name in the output catalog for matching quality')\n     # parser.add_argument('--id_col_name1', type = str, required = False, default='ID',\n     #                     help = 'the column name in catalog #1 for ID')\n@@ -88,17 +88,6 @@ def defineSpecificProgramOptions():\n \n     return parser\n \n-def gaia_g_flux_to_mag(flux_gaia_g):\n-    mag_gaia_g = -2.5 * np.log10(flux_gaia_g) + 25.8010\n-    # print(mag_gaia_g)\n-    return mag_gaia_g\n-\n-def convert_ujy_to_mag(flux_ujy):\n-    # mag_ab = -2.5 * np.log10(flux_ujy / 1e6 / 3631.)\n-    mag_ab = -2.5 * np.log10(flux_ujy / 1e6) + 8.90\n-    print(mag_ab)\n-    return mag_ab\n-\n def mainMethod(args):\n     \"\"\"\n     @brief The \"main\" method.\n",
                            "remove column naming defaults in MER_CrossMatchPrg",
                            "yfang",
                            "2023-07-26T16:17:43.000+02:00",
                            "437e7b133e71851a55c1d5a7f3c0e3bb720acd48"
                        ]
                    ],
                    "MER_DA/python/MER_DA/MER_ClusterProjector.py": [
                        [
                            "@@ -96,6 +96,10 @@ class MER_ClusterProjector(object):\n                 all_kids = cluster_objects[parent_mask]\n                 #kids_coord1.append(numpy.sum(all_kids[COORD_1]*all_kids['FLUX_TOT'])/numpy.sum(all_kids['FLUX_TOT']))\n                 #kids_coord2.append(numpy.sum(all_kids[COORD_2]*all_kids['FLUX_TOT'])/numpy.sum(all_kids['FLUX_TOT']))\n+                act_coord1 = numpy.sum(all_kids[self._ra_column]*all_kids[self._weight_column])/numpy.sum(all_kids[self._weight_column])\n+                act_coord2 = numpy.sum(all_kids[self._dec_column]*all_kids[self._weight_column])/numpy.sum(all_kids[self._weight_column])\n+                if numpy.isnan(act_coord1) or numpy.isnan(act_coord2):\n+                    self._info('Weights: %s'%str(all_kids[self._weight_column]))\n                 kids_coord1.append(numpy.sum(all_kids[self._ra_column]*all_kids[self._weight_column])/numpy.sum(all_kids[self._weight_column]))\n                 kids_coord2.append(numpy.sum(all_kids[self._dec_column]*all_kids[self._weight_column])/numpy.sum(all_kids[self._weight_column]))\n             \n@@ -103,6 +107,9 @@ class MER_ClusterProjector(object):\n             cluster_coord1 = numpy.array(kids_coord1)[unique_parent_inv]\n             cluster_coord2 = numpy.array(kids_coord2)[unique_parent_inv]\n \n+            self._info('Number of NANs in cluster_coord1: %i' % numpy.sum(numpy.isnan(cluster_coord1)))\n+            self._info('Number of NANs in cluster_coord2: %i' % numpy.sum(numpy.isnan(cluster_coord2)))\n+\n             # write the cluster RA/Dec for all children in two new columns\n             cluster_coords_coord1 = numpy.copy(in_cat[1].data[self._ra_column])\n             cluster_coords_coord2 = numpy.copy(in_cat[1].data[self._dec_column])\n",
                            "Some smaller updates.",
                            "Martin Kuemmel",
                            "2023-06-26T10:57:16.000+02:00",
                            "04fd8d18d6a0f68a93f2e4b5f2d5a33df2d64621"
                        ]
                    ],
                    "MER_DA/python/MER_DA/MER_CreateCoverMapPrg.py": [
                        [
                            "@@ -62,6 +62,8 @@ def defineSpecificProgramOptions():\n                         required=False, default='coverage_map.fits', help='Map image name')    \n     parser.add_argument('--resolution', type=int, dest='resolution',\n                         required=False, default=10, help='Resolution of the mapped image!')\n+    parser.add_argument('--sublist_index', type=int, dest='sublist_index',\n+                        required=False, default=None, help='For NIR which sub-list to use (Y/J/H)')\n     parser.add_argument('--layers', type=int, dest='layers',\n                         required=False, default=1, help='Compute also the layer map')\n \n@@ -102,7 +104,11 @@ def mainMethod(args):\n     data_fits_file_name = mosaic.get_data()\n \n     image_fits_files = []\n-    for product_file_name in product_file_names:\n+    if args.sublist_index is not None:\n+        product_list = product_file_names[args.sublist_index]\n+    else:\n+        product_list = product_file_names\n+    for product_file_name in product_list:\n         # Load the product from the XML file\n         product = dm_utils.read_product_metadata(\n             os.path.join(args.workdir, product_file_name))\n",
                            "Some smaller updates.",
                            "Martin Kuemmel",
                            "2023-06-26T10:57:16.000+02:00",
                            "04fd8d18d6a0f68a93f2e4b5f2d5a33df2d64621"
                        ]
                    ],
                    "MER_DA/python/MER_DA/MER_HPObjectSelection.py": [
                        [
                            "@@ -140,7 +140,7 @@ class MER_HPObjectSelection(object):\n         else:\n             in_fits = fits.open(self._input_fits_path, 'readonly')\n \n-\t# Keep copy of original header\n+\t    # Keep copy of original header\n         _head = in_fits[1].header.copy()      \n    \n         # save the original data size\n",
                            "Some smaller updates.",
                            "Martin Kuemmel",
                            "2023-06-26T10:57:16.000+02:00",
                            "04fd8d18d6a0f68a93f2e4b5f2d5a33df2d64621"
                        ]
                    ],
                    "MER_DA/tests/python/MER_AddBrightStarCol_test.py": [
                        [
                            "@@ -23,7 +23,7 @@\n :author: yfang\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DA.MER_AddBrightStarCol\n \n class TestMER_AddBrightStarCol(object):\n",
                            "fixes imports",
                            "Javier Gracia Carpio",
                            "2023-06-22T09:56:28.000+00:00",
                            "444af6eee37cd33d846d38a37d625e0f00a7f2e2"
                        ]
                    ],
                    "MER_DA/tests/python/MER_ClusterProjector_test.py": [
                        [
                            "@@ -23,7 +23,7 @@\n :author: mkuemmel\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DA.MER_ClusterProjector\n \n class TestMER_ClusterProjector(object):\n",
                            "fixes imports",
                            "Javier Gracia Carpio",
                            "2023-06-22T09:56:28.000+00:00",
                            "444af6eee37cd33d846d38a37d625e0f00a7f2e2"
                        ]
                    ],
                    ".jenkinsFile": [
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\n @Library(value='integration-library@release-10') _\n-pipelineElements(artifactId:\"MER_DA\", component:'eden.3.1')\n+pipelineElements(name:\"MER_DA\", component:'eden.3.1')\n",
                            "Fixes jenkins file",
                            "Javier Gracia Carpio",
                            "2023-06-22T09:45:06.000+00:00",
                            "9f797cdf550971ee50099160b092d0f8abe6d3b9"
                        ],
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\n-@Library('integration-library@release-10') _\n+@Library(value='integration-library@release-10') _\n pipelineElements(artifactId:\"MER_DA\", component:'eden.3.1')\n",
                            "update jenkins file",
                            "Javier Gracia Carpio",
                            "2023-06-22T09:42:27.000+00:00",
                            "1d0281057ef2f5454cbfe6db0c2b32a184c1eaeb"
                        ],
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\n-@Library('integration-library@release-9') _\n-pipelineElements(artifactId:\"MER_DA\", component:'eden.3.0')\n+@Library('integration-library@release-10') _\n+pipelineElements(artifactId:\"MER_DA\", component:'eden.3.1')\n",
                            "Updates to new DM and Eden 3.1",
                            "Javier Gracia Carpio",
                            "2023-06-22T09:30:49.000+00:00",
                            "f3934f92e484cf286ae3a6197c398509ffd0b6ed"
                        ]
                    ],
                    "Makefile": [
                        [
                            "@@ -44,169 +44,19 @@\n #\n ################################################################################\n \n-# settings\n-CMAKE := cmake\n-CTEST := ctest\n-NINJA := $(shell which ninja-build 2> /dev/null)\n-ifeq ($(NINJA),)\n-  NINJA := $(shell which ninja 2> /dev/null)\n-endif\n-\n-# Looking for the Custom make library\n-\n-CUSTOM_MAKE_LIB := Custom.mk\n-\n-ifneq ($(wildcard $(CURDIR)/make/$(CUSTOM_MAKE_LIB)),)\n-  CUSTOM_MAKE_LIB_FILE := $(CURDIR)/make/$(CUSTOM_MAKE_LIB)\n-else\n-  ifneq ($(CMAKE_PREFIX_PATH),)\n-    PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    CUSTOM_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(CUSTOM_MAKE_LIB) $(dir)/../make/$(CUSTOM_MAKE_LIB)))\n-  endif\n-  CUSTOM_MAKE_LIB_LIST += /usr/share/Elements/make/$(CUSTOM_MAKE_LIB)\n-  CUSTOM_MAKE_LIB_FILE := $(firstword $(CUSTOM_MAKE_LIB_LIST))\n-endif\n-\n-# Looking for the ToolChain\n-\n-TOOLCHAIN_NAME := ElementsToolChain.cmake\n+ELEMENTS_MAKE_LIB := Elements.mk\n \n-ifneq ($(wildcard $(CURDIR)/cmake/$(TOOLCHAIN_NAME)),)\n-  TOOLCHAIN_FILE := $(CURDIR)/cmake/$(TOOLCHAIN_NAME)\n+ifneq ($(wildcard $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)),)\n+  ELEMENTS_MAKE_LIB_FILE := $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)\n else\n   ifneq ($(CMAKE_PREFIX_PATH),)\n     PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    TOOLCHAIN_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/lib*/cmake/ElementsProject/$(TOOLCHAIN_NAME) $(dir)/$(TOOLCHAIN_NAME)))\n-    TOOLCHAIN_FILE := $(firstword $(TOOLCHAIN_LIST))\n+    ELEMENTS_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(ELEMENTS_MAKE_LIB) $(dir)/../make/$(ELEMENTS_MAKE_LIB)))\n   endif\n+  ELEMENTS_MAKE_LIB_LIST += /usr/share/Elements/make/$(ELEMENTS_MAKE_LIB)\n+  ELEMENTS_MAKE_LIB_FILE := $(firstword $(ELEMENTS_MAKE_LIB_LIST))\n endif\n \n-override ALL_CMAKEFLAGS := -Wno-dev --no-warn-unused-cli\n-\n-ifneq ($(TOOLCHAIN_FILE),)\n-  # A toolchain has been found. Lets use it.\n-  override ALL_CMAKEFLAGS += -DCMAKE_TOOLCHAIN_FILE=$(TOOLCHAIN_FILE)\n-endif\n-\n-\n-BUILD_PREFIX_NAME := build\n-\n-override ALL_CMAKEFLAGS += -DUSE_LOCAL_INSTALLAREA=ON -DBUILD_PREFIX_NAME:STRING=$(BUILD_PREFIX_NAME)\n-override ALL_CMAKEFLAGS += -DUSE_VERSIONED_LIBRARIES=OFF\n-\n-ifndef BINARY_TAG\n-  ifdef CMAKECONFIG\n-    BINARY_TAG := ${CMAKECONFIG}\n-  else\n-    ifdef CMTCONFIG\n-      BINARY_TAG := ${CMTCONFIG}\n-    endif\n-  endif\n-endif\n-\n-ifdef BINARY_TAG\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME).$(BINARY_TAG)\n-else\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME)\n-endif\n-BUILDDIR := $(CURDIR)/$(BUILD_SUBDIR)\n-\n-# build tool\n-\n-ifneq ($(USE_NINJA),)\n-  # enable Ninja\n-  override ALL_CMAKEFLAGS += -GNinja\n-  BUILD_CONF_FILE := build.ninja\n-  BUILDFLAGS := $(NINJAFLAGS)\n-  ifneq ($(VERBOSE),)\n-    BUILDFLAGS := -v $(BUILDFLAGS)\n-  endif\n-else\n-  BUILD_CONF_FILE := Makefile\n-endif\n-BUILD_CMD := $(CMAKE) --build $(BUILD_SUBDIR) --target\n-\n-\n-# Use environment variable for extra flags\n-\n-# Replace the \":\" from eclipse variable list to spaces  \n-ifneq ($(EXPAND_FLAGS),)\n-  CMAKEFLAGS := $(subst :-, -,$(CMAKEFLAGS))\n-endif\n-\n-ifneq ($(CMAKEFLAGS),)\n-  override ALL_CMAKEFLAGS += $(CMAKEFLAGS)\n-endif\n-\n-# default target\n-all:\n-\n-# deep clean\n-purge:\n-\t$(RM) -r $(BUILDDIR) $(CURDIR)/InstallArea/$(BINARY_TAG)\n-\tfind $(CURDIR) \"(\" -name \"InstallArea\" -prune -o -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# Remove all the possible directories and the whole InstallArea as well\n-mrproper:\n-\t$(RM) -r $(CURDIR)/build $(CURDIR)/build.* $(CURDIR)/InstallArea\n-\tfind $(CURDIR) \"(\" -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# delegate any target to the build directory (except 'purge')\n-ifneq ($(MAKECMDGOALS),purge)\n-ifneq ($(MAKECMDGOALS),mrproper)\n-%: $(BUILDDIR)/$(BUILD_CONF_FILE) FORCE\n-\t+$(BUILD_CMD) $* -- $(BUILDFLAGS)\n-endif\n-endif\n-\n-# aliases\n-.PHONY: configure tests FORCE\n-ifneq ($(wildcard $(BUILDDIR)/$(BUILD_CONF_FILE)),)\n-configure: rebuild_cache\n-else\n-configure: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-endif\n-\t@ # do not delegate further\n-\n-\n-# This wrapping around the test target is used to ensure the generation of\n-# the XML output from ctest.\n-test: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-\n-# This target ensures that the \"all\" target is called before\n-# running the tests (unlike the \"test\" default target of CMake)\n-tests: all\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-ifeq ($(VERBOSE),)\n-# less verbose install\n-# (emulate the default CMake install target)\n-install: all\n-\tcd $(BUILDDIR) && $(CMAKE) -P cmake_install.cmake | grep -v \"^-- Up-to-date:\"\n-endif\n-\n-# import the library to look for a custom Makefile\n--include $(CUSTOM_MAKE_LIB_FILE)\n-\n-# ensure that the target are always passed to the CMake Makefile\n-FORCE: ;\n-\n-# Makefiles are used as implicit targets in make, but we should not consider\n-# them for delegation.\n-$(MAKEFILE_LIST): ;\n-\n-\n-# trigger CMake configuration\n-$(BUILDDIR)/$(BUILD_CONF_FILE): | $(BUILDDIR)\n-\tcd $(BUILDDIR) && $(CMAKE) $(ALL_CMAKEFLAGS) $(CURDIR)\n+$(info Using the $(ELEMENTS_MAKE_LIB_FILE) make library)\n+include $(ELEMENTS_MAKE_LIB_FILE)\n \n-$(BUILDDIR):\n-\tmkdir -p $(BUILDDIR)\n",
                            "Updates to new DM and Eden 3.1",
                            "Javier Gracia Carpio",
                            "2023-06-22T09:30:49.000+00:00",
                            "f3934f92e484cf286ae3a6197c398509ffd0b6ed"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "9.1.0",
                        "created_at": "2023-03-06T14:59:37.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.0",
                        "created_at": "2023-07-03T11:56:39.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.1",
                        "created_at": "2023-08-14T12:03:40.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    }
                ]
            },
            "PF-MER/MER_Detection": {
                "start date": "2023-06-09 09:00",
                "end date": "2023-08-23 15:00",
                "start tag": "> 9.1.0",
                "end tag": "> 10.1.1",
                "count_files_modified": "24",
                "modifications_by_file": {
                    "MER_DetectionPrgs/python/MER_DetectionPrgs/MER_NirDetectionPrg.py": [
                        [
                            "@@ -64,12 +64,6 @@ def defineSpecificProgramOptions():\n                         required=True, help='Step Specific Parameters')\n     parser.add_argument('--flag_limits', type=str, dest='flag_limits',\n                         required=True, help='Quality flag limits')\n-    parser.add_argument('--vis_mosaic', type=str,\n-                        dest='vis_mosaic', required=False, default=None,\n-                        help='The input VIS mosaic')\n-    parser.add_argument('--ext_mosaics', type=str, dest='ext_mosaics',\n-                        required=False, default=None,\n-                        help='Input json file with all the EXT mosaic XMLs')\n     parser.add_argument('--detection_mosaic', type=str,\n                         dest='detection_mosaic', required=True,\n                         help='The NIR detection mosaic')\n@@ -107,15 +101,6 @@ def mainMethod(args):\n         args.workdir, os.path.dirname(args.segmentation_map))\n     data_path = os.path.join(args.workdir, \"data\")\n \n-    if args.vis_mosaic is not None and args.ext_mosaics is not None:\n-        mf_image_collection = MER_MFImageCollector.MER_MFImageCollector(os.path.join(args.workdir, args.nir_mosaics), args.workdir, data_path, branch_name='nir', logger=logger)\n-        mf_image_collection.add_images(os.path.join(args.workdir, args.vis_mosaic))\n-        #mf_image_collection.add_images(os.path.join(args.workdir, args.ext_mosaics))\n-        mf_image_collection.writeto(os.path.join(args.workdir, MEF_IMAGES_FILE))\n-    else:\n-        mf_image_collection=None\n-\n-\n     # Add some extra functionality to the data product bindings\n     mer_utils.init()\n \n@@ -219,8 +204,6 @@ def mainMethod(args):\n         psf_file_name, zero_point, detect_config_file_path, args.workdir,\n         data_path, step_path, args.logdir, logger, segmentation_map_file_name,\n         catalog_file_name, psf_conv_file_name, tile_index)\n-    if mf_image_collection is not None:\n-        detector.add_python_config(MEF_IMAGES_FILE, 'nir')\n     # run the source detector\n     detector.run()\n \n",
                            "Merge branch 'feature/slim_detection' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T14:06:31.000+00:00",
                            "24a8d0dca32aef860d13e7e04399b735e74cf8a1"
                        ]
                    ],
                    "MER_DetectionPrgs/python/MER_DetectionPrgs/MER_VisDetectionPrg.py": [
                        [
                            "@@ -59,12 +59,6 @@ def defineSpecificProgramOptions():\n                         required=True, help='Step Specific Parameters')\n     parser.add_argument('--flag_limits', type=str, dest='flag_limits',\n                         required=True, help='Quality flag limits')\n-    parser.add_argument('--nir_mosaics', type=str, dest='nir_mosaics',\n-                        required=False, help='Input json file with all the NIR '\n-                        'mosaic XMLs', default=None)\n-    parser.add_argument('--ext_mosaics', type=str, dest='ext_mosaics',\n-                        required=False, help='Input json file with all the EXT'\n-                        'mosaic XMLs', default=None)\n     parser.add_argument('--detection_mosaic', type=str,\n                         dest='detection_mosaic', required=True,\n                         help='The VIS detection mosaic')\n@@ -128,25 +122,6 @@ def mainMethod(args):\n     # Get the processing mode information from the configuration set\n     processing_mode = configuration_set.get_processing_mode()\n     logger.info('# Processing mode: %s' % processing_mode)\n-    \n-    if processing_mode.find('OTHERS') > -1:\n-        mf_image_collection = MER_MFImageCollector.MER_MFImageCollector(os.path.join(args.workdir, args.mosaic), args.workdir, data_path, branch_name='vis', logger=logger)\n-        if args.nir_mosaics is not None and args.ext_mosaics is not None:\n-            mf_image_collection.add_images(os.path.join(args.workdir, args.nir_mosaics))\n-            #mf_image_collection.add_images(os.path.join(args.workdir, args.ext_mosaics))\n-        mf_image_collection.writeto(os.path.join(args.workdir, MEF_IMAGES_FILE))\n-    else:\n-        mf_image_collection = None\n-    #if args.nir_mosaics is not None and args.ext_mosaics is not None:\n-    #    mf_image_collection = MER_MFImageCollector.MER_MFImageCollector(os.path.join(args.workdir, args.mosaic), args.workdir, data_path, logger=logger)\n-    #    mf_image_collection.add_images(os.path.join(args.workdir, args.nir_mosaics))\n-    #    #mf_image_collection.add_images(os.path.join(args.workdir, args.ext_mosaics))\n-    #    mf_image_collection.writeto(os.path.join(args.workdir, MEF_IMAGES_FILE))\n-    #    #raise Exception('FINISH!')\n-    #else:\n-    #    mf_image_collection = MER_MFImageCollector.MER_MFImageCollector(os.path.join(args.workdir, args.mosaic), args.workdir, data_path, logger=logger)\n-    #    mf_image_collection.writeto(os.path.join(args.workdir, MEF_IMAGES_FILE))\n-    #    #mf_image_collection = None\n \n     # Save the original directory and move to the working directory\n     original_dir = os.getcwd()\n@@ -171,8 +146,6 @@ def mainMethod(args):\n         data_path, step_path, args.logdir, logger, segmentation_map_file_name,\n         catalog_file_name, psf_conv_file_name, tile_index)\n     # run the source detector\n-    if mf_image_collection is not None:\n-        detector.add_python_config(MEF_IMAGES_FILE, 'vis')\n     detector.run()\n \n     # create the file names for the final products\n",
                            "Merge branch 'feature/slim_detection' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T14:06:31.000+00:00",
                            "24a8d0dca32aef860d13e7e04399b735e74cf8a1"
                        ]
                    ],
                    "MER_MBandDetection/auxdir/sepp_sersic.txt": [
                        [
                            "@@ -32,7 +32,9 @@ mesgroup = MeasurementGroup(top)\n \n # set some fitting parameters\n set_engine('levmar')\n-set_max_iterations(150)\n+set_max_iterations(100)\n+use_iterative_fitting(True)\n+set_meta_iterations(4)\n \n # define the sersic parameters\n sersic_radius = FreeParameter(lambda o: o.radius, Range(lambda v, o: (.1 * v, 10*v), RangeType.EXPONENTIAL))\n",
                            "Merge branch 'feature/slim_detection' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T14:06:31.000+00:00",
                            "24a8d0dca32aef860d13e7e04399b735e74cf8a1"
                        ]
                    ],
                    "MER_MBandDetection/python/MER_MBandDetection/MER_SourceDetectorDeep.py": [
                        [
                            "@@ -19,7 +19,7 @@\n File: python/MER_MBandDetection/SourceDetector.py\n \n Created on: 05/14/18\n-Author: mkuemmel\n+Author: mkuemmel@usm.lmu.de\n \"\"\"\n \n import os\n@@ -128,15 +128,6 @@ class MER_SourceDetectorDeep(object):\n             #convolveFileIn = getAuxiliaryPath(configDict['sepp_conv'])\n             convolutionFilePath = getAuxiliaryPath(configDict['sepp_conv'])\n             self._info('Using convolution file: %s!' % convolutionFilePath)\n-            \n-            #    convolveFileIn, convolutionFilePath))\n-\n-            # copy the convolution file to the data directory\n-            #shutil.copy(convolveFileIn, convolutionFilePath)\n-\n-            # give feedback\n-            #self._info('Using file: %s as convolution file: %s!' % (\n-            #    convolveFileIn, convolutionFilePath))\n \n         else:\n             # get the path to the PSF file\n@@ -163,20 +154,7 @@ class MER_SourceDetectorDeep(object):\n     def _get_threadcount_param(self, act_prefix):\n         \"\"\"Set the thread-count parameter\n         \"\"\"\n-        if (self._primaryKey.find('other') > -1) and ('%sthread-count'%SEPPKEY_PREFIX in self._detectionConfigDict.keys()):\n-            n_threads = self._detectionConfigDict['%sthread-count'%SEPPKEY_PREFIX]\n-            self._info('Threadcount in others-mode set to: %i!'%n_threads)\n-        elif 'PIPELINE_CPU_CORES' in os.environ:\n-            # this prevents lower level libraries from\n-            # doing their own multi-threading, see:\n-            # https://github.com/xianyi/OpenBLAS/wiki/faq#multi-threaded\n-            # https://euclid.roe.ac.uk/issues/20966\n-            os.environ['MKL_NUM_THREADS'] = \"1\"\n-            os.environ['NUMEXPR_NUM_THREADS']= \"1\"\n-            os.environ['OMP_NUM_THREADS']=\"1\"\n-            os.environ['OPENBLAS_NUM_THREADS']=\"1\"\n-            os.environ['VECLIB_MAXIMUM_THREADS']=\"1\"\n-            os.environ['NTHREADS']= \"1\"\n+        if 'PIPELINE_CPU_CORES' in os.environ:\n             # this is an ial run, use the value from the environment\n             n_threads = int(os.environ['PIPELINE_CPU_CORES'])           \n             self._info('Threadcount from IAL to: %i!'%n_threads)\n@@ -194,7 +172,6 @@ class MER_SourceDetectorDeep(object):\n             del self._detectionConfigDict['%sthread-count'%SEPPKEY_PREFIX]\n \n         # return the threadcount parameter and vaoue\n-        #return ['%sthread-count' % act_prefix, '%i'%0]\n         return ['%sthread-count' % act_prefix, '%i'%n_threads]\n \n     def _getParameterSequence(self, act_prefix='--'):\n@@ -303,9 +280,6 @@ class MER_SourceDetectorDeep(object):\n         cmd = ExecuteCommand.ExecuteCommand(self._proc_stamp, comm_sequence,\n                                             logdir=self._logdir,\n                                             logger=self._logger)\n-        #if self._primaryKey.find('other') > -1:\n-        #    ret_code = cmd.run(ulimit=True)\n-        #else:\n         ret_code = cmd.run()\n \n         # evaluate the run and break if\n",
                            "Merge branch 'feature/slim_detection' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T14:06:31.000+00:00",
                            "24a8d0dca32aef860d13e7e04399b735e74cf8a1"
                        ]
                    ],
                    "CMakeLists.txt": [
                        [
                            "@@ -12,10 +12,10 @@ find_package(ElementsProject)\n # Example with dependency:\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n-elements_project(MER_Detection 10.1 USE Elements 6.2.1\n-                                       MER_DA 10.1\n-                                       MER_Mosaicing 10.1\n-                                       MER_Deblending 10.1\n-                                       MER_DataModelUtils 10.1\n-                                       MER_PsfMosaic 10.1\n+elements_project(MER_Detection 10.2 USE Elements 6.2.1\n+                                       MER_DA 10.2\n+                                       MER_Mosaicing 10.2\n+                                       MER_Deblending 10.2\n+                                       MER_DataModelUtils 10.2\n+                                       MER_PsfMosaic 10.2\n                                        SourceXtractorPlusPlus 0.2)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-07-03T17:03:33.000+00:00",
                            "dc546597f300477e3bb2cd48477aa3e090c8b67d"
                        ],
                        [
                            "@@ -12,10 +12,10 @@ find_package(ElementsProject)\n # Example with dependency:\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n-elements_project(MER_Detection 10.0 USE Elements 6.1.1\n-                                       MER_DA 10.0\n-                                       MER_Mosaicing 10.0\n-                                       MER_Deblending 10.0\n-                                       MER_DataModelUtils 10.0\n-                                       MER_PsfMosaic 10.0\n-                                       SourceXtractorPlusPlus 0.19.1)\n+elements_project(MER_Detection 10.1 USE Elements 6.2.1\n+                                       MER_DA 10.1\n+                                       MER_Mosaicing 10.1\n+                                       MER_Deblending 10.1\n+                                       MER_DataModelUtils 10.1\n+                                       MER_PsfMosaic 10.1\n+                                       SourceXtractorPlusPlus 0.2)\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:43:41.000+00:00",
                            "15c7f8b6f4547bf78f82294947a808ed2a4df6bd"
                        ]
                    ],
                    "MER_DetectionFilter/tests/python/MER_JBlankObjects_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 10/03/18\n Author: user\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DetectionFilter.MER_JBlankObjects\n \n class TestJBlankObjects(object):\n",
                            "Fixes pytest imports",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:55:15.000+00:00",
                            "7530997f48f34388a1d827375f9f646159567f31"
                        ]
                    ],
                    "MER_DetectionFilter/tests/python/MER_SegmentationFilter_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 09/25/18\n Author: user\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DetectionFilter.MER_SegmentationFilter\n \n class TestSegmentationFilter(object):\n",
                            "Fixes pytest imports",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:55:15.000+00:00",
                            "7530997f48f34388a1d827375f9f646159567f31"
                        ]
                    ],
                    "MER_DetectionUtils/tests/python/MER_CheckDetections_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 05/08/20\n Author: user\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DetectionUtils.MER_CheckDetections\n \n class TestMER_CheckDetections(object):\n",
                            "Fixes pytest imports",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:55:15.000+00:00",
                            "7530997f48f34388a1d827375f9f646159567f31"
                        ]
                    ],
                    "MER_DetectionUtils/tests/python/MER_ConversionTile_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 05/11/18\n Author: mkuemmel\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DetectionUtils.MER_ConversionTile\n \n \n",
                            "Fixes pytest imports",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:55:15.000+00:00",
                            "7530997f48f34388a1d827375f9f646159567f31"
                        ]
                    ],
                    "MER_DetectionUtils/tests/python/MER_ConvolutionUtils_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 05/14/18\n Author: mkuemmel\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DetectionUtils.MER_ConvolutionUtils\n \n \n",
                            "Fixes pytest imports",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:55:15.000+00:00",
                            "7530997f48f34388a1d827375f9f646159567f31"
                        ]
                    ],
                    "MER_DetectionUtils/tests/python/MER_ErrorTransformator_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 05/11/18\n Author: mkuemmel\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DetectionUtils.MER_ErrorTransformator\n \n \n",
                            "Fixes pytest imports",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:55:15.000+00:00",
                            "7530997f48f34388a1d827375f9f646159567f31"
                        ]
                    ],
                    "MER_DetectionUtils/tests/python/MER_MFImageCollector_test.py": [
                        [
                            "@@ -23,7 +23,7 @@\n :author: mkuemmel\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DetectionUtils.MER_MFImageCollector\n \n class TestMER_MFImageCollector(object):\n",
                            "Fixes pytest imports",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:55:15.000+00:00",
                            "7530997f48f34388a1d827375f9f646159567f31"
                        ]
                    ],
                    "MER_DetectionUtils/tests/python/MER_PSFChecker_test.py": [
                        [
                            "@@ -23,7 +23,7 @@\n :author: mkuemmel\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DetectionUtils.MER_PSFChecker\n \n class TestMER_PSFChecker(object):\n",
                            "Fixes pytest imports",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:55:15.000+00:00",
                            "7530997f48f34388a1d827375f9f646159567f31"
                        ]
                    ],
                    "MER_DetectionUtils/tests/python/MER_TileFactory_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 05/11/18\n Author: mkuemmel\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DetectionUtils.MER_TileFactory\n \n \n",
                            "Fixes pytest imports",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:55:15.000+00:00",
                            "7530997f48f34388a1d827375f9f646159567f31"
                        ]
                    ],
                    "MER_DetectionUtils/tests/python/MER_TileList_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 05/11/18\n Author: mkuemmel\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DetectionUtils.MER_TileList\n \n \n",
                            "Fixes pytest imports",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:55:15.000+00:00",
                            "7530997f48f34388a1d827375f9f646159567f31"
                        ]
                    ],
                    "MER_MBandDetection/tests/python/MER_ConvolutionFilter_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 05/14/18\n Author: mkuemmel\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_MBandDetection.MER_ConvolutionFilter\n \n \n",
                            "Fixes pytest imports",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:55:15.000+00:00",
                            "7530997f48f34388a1d827375f9f646159567f31"
                        ]
                    ],
                    "MER_MBandDetection/tests/python/MER_CorrelateSegImages_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 05/14/18\n Author: mkuemmel\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_MBandDetection.MER_CorrelateSegImages\n \n \n",
                            "Fixes pytest imports",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:55:15.000+00:00",
                            "7530997f48f34388a1d827375f9f646159567f31"
                        ]
                    ],
                    "MER_MBandDetection/tests/python/MER_IdentifyVISSources_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 05/14/18\n Author: mkuemmel\n \"\"\"\n \n-import py.test\n+import pytest\n #import MER_MBandDetection.IdentifyVISSources\n \n \n",
                            "Fixes pytest imports",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:55:15.000+00:00",
                            "7530997f48f34388a1d827375f9f646159567f31"
                        ]
                    ],
                    "MER_MBandDetection/tests/python/MER_MBCombineValidation_test.py": [
                        [
                            "@@ -23,7 +23,7 @@\n :author: mkuemmel@usm.lmu.de\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_MBandDetection.MER_MBCombineValidation\n \n class TestMER_MBCombineValidation(object):\n",
                            "Fixes pytest imports",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:55:15.000+00:00",
                            "7530997f48f34388a1d827375f9f646159567f31"
                        ]
                    ],
                    "MER_MBandDetection/tests/python/MER_NirCalibimageCombiner_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 05/14/18\n Author: mkuemmel\n \"\"\"\n \n-import py.test\n+import pytest\n from MER_MBandDetection import MER_NirCalibimageCombiner\n #import MER_MBandDetection.MER_NirCalibimageCombiner\n \n",
                            "Fixes pytest imports",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:55:15.000+00:00",
                            "7530997f48f34388a1d827375f9f646159567f31"
                        ]
                    ],
                    "MER_MBandDetection/tests/python/MER_ObjectSelection_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 05/14/18\n Author: mkuemmel\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_MBandDetection.MER_ObjectSelection\n \n \n",
                            "Fixes pytest imports",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:55:15.000+00:00",
                            "7530997f48f34388a1d827375f9f646159567f31"
                        ]
                    ],
                    "MER_MBandDetection/tests/python/MER_VISNIROverlaps_test.py": [
                        [
                            "@@ -23,7 +23,7 @@\n :author: mkuemmel\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_MBandDetection.MER_VISNIROverlaps\n \n class TestMER_VISNIROverlaps(object):\n",
                            "Fixes pytest imports",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:55:15.000+00:00",
                            "7530997f48f34388a1d827375f9f646159567f31"
                        ]
                    ],
                    ".jenkinsFile": [
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\n-@Library('integration-library@release-9') _\n-pipelineElements(artifactId:\"MER_Detection\", component:'eden.3.0')\n+@Library(value='integration-library@release-10') _\n+pipelineElements(name:\"MER_Detection\", component:'eden.3.1')\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:43:41.000+00:00",
                            "15c7f8b6f4547bf78f82294947a808ed2a4df6bd"
                        ]
                    ],
                    "Makefile": [
                        [
                            "@@ -44,169 +44,19 @@\n #\n ################################################################################\n \n-# settings\n-CMAKE := cmake\n-CTEST := ctest\n-NINJA := $(shell which ninja-build 2> /dev/null)\n-ifeq ($(NINJA),)\n-  NINJA := $(shell which ninja 2> /dev/null)\n-endif\n-\n-# Looking for the Custom make library\n-\n-CUSTOM_MAKE_LIB := Custom.mk\n-\n-ifneq ($(wildcard $(CURDIR)/make/$(CUSTOM_MAKE_LIB)),)\n-  CUSTOM_MAKE_LIB_FILE := $(CURDIR)/make/$(CUSTOM_MAKE_LIB)\n-else\n-  ifneq ($(CMAKE_PREFIX_PATH),)\n-    PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    CUSTOM_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(CUSTOM_MAKE_LIB) $(dir)/../make/$(CUSTOM_MAKE_LIB)))\n-  endif\n-  CUSTOM_MAKE_LIB_LIST += /usr/share/Elements/make/$(CUSTOM_MAKE_LIB)\n-  CUSTOM_MAKE_LIB_FILE := $(firstword $(CUSTOM_MAKE_LIB_LIST))\n-endif\n-\n-# Looking for the ToolChain\n-\n-TOOLCHAIN_NAME := ElementsToolChain.cmake\n+ELEMENTS_MAKE_LIB := Elements.mk\n \n-ifneq ($(wildcard $(CURDIR)/cmake/$(TOOLCHAIN_NAME)),)\n-  TOOLCHAIN_FILE := $(CURDIR)/cmake/$(TOOLCHAIN_NAME)\n+ifneq ($(wildcard $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)),)\n+  ELEMENTS_MAKE_LIB_FILE := $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)\n else\n   ifneq ($(CMAKE_PREFIX_PATH),)\n     PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    TOOLCHAIN_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/lib*/cmake/ElementsProject/$(TOOLCHAIN_NAME) $(dir)/$(TOOLCHAIN_NAME)))\n-    TOOLCHAIN_FILE := $(firstword $(TOOLCHAIN_LIST))\n+    ELEMENTS_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(ELEMENTS_MAKE_LIB) $(dir)/../make/$(ELEMENTS_MAKE_LIB)))\n   endif\n+  ELEMENTS_MAKE_LIB_LIST += /usr/share/Elements/make/$(ELEMENTS_MAKE_LIB)\n+  ELEMENTS_MAKE_LIB_FILE := $(firstword $(ELEMENTS_MAKE_LIB_LIST))\n endif\n \n-override ALL_CMAKEFLAGS := -Wno-dev --no-warn-unused-cli\n-\n-ifneq ($(TOOLCHAIN_FILE),)\n-  # A toolchain has been found. Lets use it.\n-  override ALL_CMAKEFLAGS += -DCMAKE_TOOLCHAIN_FILE=$(TOOLCHAIN_FILE)\n-endif\n-\n-\n-BUILD_PREFIX_NAME := build\n-\n-override ALL_CMAKEFLAGS += -DUSE_LOCAL_INSTALLAREA=ON -DBUILD_PREFIX_NAME:STRING=$(BUILD_PREFIX_NAME)\n-override ALL_CMAKEFLAGS += -DUSE_VERSIONED_LIBRARIES=OFF\n-\n-ifndef BINARY_TAG\n-  ifdef CMAKECONFIG\n-    BINARY_TAG := ${CMAKECONFIG}\n-  else\n-    ifdef CMTCONFIG\n-      BINARY_TAG := ${CMTCONFIG}\n-    endif\n-  endif\n-endif\n-\n-ifdef BINARY_TAG\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME).$(BINARY_TAG)\n-else\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME)\n-endif\n-BUILDDIR := $(CURDIR)/$(BUILD_SUBDIR)\n-\n-# build tool\n-\n-ifneq ($(USE_NINJA),)\n-  # enable Ninja\n-  override ALL_CMAKEFLAGS += -GNinja\n-  BUILD_CONF_FILE := build.ninja\n-  BUILDFLAGS := $(NINJAFLAGS)\n-  ifneq ($(VERBOSE),)\n-    BUILDFLAGS := -v $(BUILDFLAGS)\n-  endif\n-else\n-  BUILD_CONF_FILE := Makefile\n-endif\n-BUILD_CMD := $(CMAKE) --build $(BUILD_SUBDIR) --target\n-\n-\n-# Use environment variable for extra flags\n-\n-# Replace the \":\" from eclipse variable list to spaces  \n-ifneq ($(EXPAND_FLAGS),)\n-  CMAKEFLAGS := $(subst :-, -,$(CMAKEFLAGS))\n-endif\n-\n-ifneq ($(CMAKEFLAGS),)\n-  override ALL_CMAKEFLAGS += $(CMAKEFLAGS)\n-endif\n-\n-# default target\n-all:\n-\n-# deep clean\n-purge:\n-\t$(RM) -r $(BUILDDIR) $(CURDIR)/InstallArea/$(BINARY_TAG)\n-\tfind $(CURDIR) \"(\" -name \"InstallArea\" -prune -o -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# Remove all the possible directories and the whole InstallArea as well\n-mrproper:\n-\t$(RM) -r $(CURDIR)/build $(CURDIR)/build.* $(CURDIR)/InstallArea\n-\tfind $(CURDIR) \"(\" -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# delegate any target to the build directory (except 'purge')\n-ifneq ($(MAKECMDGOALS),purge)\n-ifneq ($(MAKECMDGOALS),mrproper)\n-%: $(BUILDDIR)/$(BUILD_CONF_FILE) FORCE\n-\t+$(BUILD_CMD) $* -- $(BUILDFLAGS)\n-endif\n-endif\n-\n-# aliases\n-.PHONY: configure tests FORCE\n-ifneq ($(wildcard $(BUILDDIR)/$(BUILD_CONF_FILE)),)\n-configure: rebuild_cache\n-else\n-configure: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-endif\n-\t@ # do not delegate further\n-\n-\n-# This wrapping around the test target is used to ensure the generation of\n-# the XML output from ctest.\n-test: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-\n-# This target ensures that the \"all\" target is called before\n-# running the tests (unlike the \"test\" default target of CMake)\n-tests: all\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-ifeq ($(VERBOSE),)\n-# less verbose install\n-# (emulate the default CMake install target)\n-install: all\n-\tcd $(BUILDDIR) && $(CMAKE) -P cmake_install.cmake | grep -v \"^-- Up-to-date:\"\n-endif\n-\n-# import the library to look for a custom Makefile\n--include $(CUSTOM_MAKE_LIB_FILE)\n-\n-# ensure that the target are always passed to the CMake Makefile\n-FORCE: ;\n-\n-# Makefiles are used as implicit targets in make, but we should not consider\n-# them for delegation.\n-$(MAKEFILE_LIST): ;\n-\n-\n-# trigger CMake configuration\n-$(BUILDDIR)/$(BUILD_CONF_FILE): | $(BUILDDIR)\n-\tcd $(BUILDDIR) && $(CMAKE) $(ALL_CMAKEFLAGS) $(CURDIR)\n+$(info Using the $(ELEMENTS_MAKE_LIB_FILE) make library)\n+include $(ELEMENTS_MAKE_LIB_FILE)\n \n-$(BUILDDIR):\n-\tmkdir -p $(BUILDDIR)\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:43:41.000+00:00",
                            "15c7f8b6f4547bf78f82294947a808ed2a4df6bd"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "9.1.0",
                        "created_at": "2023-03-07T14:47:47.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.0",
                        "created_at": "2023-07-04T09:54:30.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.1",
                        "created_at": "2023-08-14T12:45:20.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    }
                ]
            },
            "PF-MER/MER_Mosaicing": {
                "start date": "2023-06-09 09:00",
                "end date": "2023-08-23 15:00",
                "start tag": "> 9.1.0",
                "end tag": "> 10.1.1",
                "count_files_modified": "8",
                "modifications_by_file": {
                    "MER_SingCombine/python/MER_SingCombine/EuclidSingleImageList.py": [
                        [
                            "@@ -25,6 +25,8 @@ Author: mkuemmel\n \n import os.path\n \n+#from MER_DA.MER_FitsToCards import MER_FitsToCards\n+\n from MER_DataModelUtils.FileNaming import mer_filename\n from MER_PsfMosaic.NirPsf import NirPsf\n from MER_PsfMosaic.PsfCombiner import PsfCombiner\n@@ -208,7 +210,7 @@ class EuclidSingleImageList():\n             output_path = os.path.dirname(psf_list_file_name)\n         if flag_list_file_name is not None:\n             flag_list_file = open(flag_list_file_name, \"w\")\n-            output_path = os.path.dirname(psf_list_file_name)\n+            output_path = os.path.dirname(flag_list_file_name)\n \n         # Loop over all the single images\n         counter = 0\n@@ -349,8 +351,10 @@ class EuclidSingleImageList():\n                 radec_coords, psf, os.path.join(input_path, image_file_name))\n \n             # if requested remove the base image\n-            if purge and os.path.isfile(os.path.join(input_path, image_file_name)):\n-                os.remove(os.path.join(input_path, image_file_name))\n+            #if purge and os.path.isfile(os.path.join(input_path, image_file_name)):\n+            #    card_file_name = os.path.splitext(image_file_name)[0] + '.card'\n+            #    MER_FitsToCards.header_to_card_file(os.path.join(input_path, image_file_name), os.path.join(input_path, card_file_name))\n+            #    os.remove(os.path.join(input_path, image_file_name))\n \n             # Define the output fits file name\n             psf_image_file_name = mer_filename(\n",
                            "Merge branch 'feature/lowdisk' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-17T08:35:48.000+00:00",
                            "beb6df8ebced5b7d1af2ff519738586dc13e98dc"
                        ],
                        [
                            "@@ -165,13 +165,17 @@ class EuclidSingleImageList():\n \n         return single_images\n \n-    def write_data(self, image_list_file_name, weight_list_file_name,\n-                   psf_list_file_name, flag_list_file_name, polygon):\n+    def write_data(self, polygon, image_list_file_name=None, weight_list_file_name=None,\n+                   psf_list_file_name=None, flag_list_file_name=None):\n         \"\"\"Writes in fits files the background subtracted image, the weight,\n         the PSF and the flag of each detector in every single image.\n \n         Parameters\n         ----------\n+        polygon: object\n+            A numpy array with the polygon (RA, Dec) coordinates that describe\n+            the region that the detector image footprints should overlap in\n+            order to be saved as fits files.\n         image_list_file_name: str\n             The name of the list file that will contain the list of\n             background-subtracted image fits file names. It should include the\n@@ -185,10 +189,6 @@ class EuclidSingleImageList():\n         flag_list_file_name: str\n             The name of the list file that will contain the list of flag fits\n             file names. It should include the full path.\n-        polygon: object\n-            A numpy array with the polygon (RA, Dec) coordinates that describe\n-            the region that the detector image footprints should overlap in\n-            order to be saved as fits files.\n \n         Returns\n         -------\n@@ -196,14 +196,19 @@ class EuclidSingleImageList():\n             The number of written detectors.\n \n         \"\"\"\n-        # Get the output path where the output fits files should be saved\n-        output_path = os.path.dirname(image_list_file_name)\n-\n         # Open the list files\n-        image_list_file = open(image_list_file_name, \"w\")\n-        weight_list_file = open(weight_list_file_name, \"w\")\n-        psf_list_file = open(psf_list_file_name, \"w\")\n-        flag_list_file = open(flag_list_file_name, \"w\")\n+        if image_list_file_name is not None:\n+            image_list_file = open(image_list_file_name, \"w\")\n+            output_path = os.path.dirname(image_list_file_name)\n+        if weight_list_file_name is not None:\n+            weight_list_file = open(weight_list_file_name, \"w\")\n+            output_path = os.path.dirname(weight_list_file_name)\n+        if psf_list_file_name is not None:\n+            psf_list_file = open(psf_list_file_name, \"w\")\n+            output_path = os.path.dirname(psf_list_file_name)\n+        if flag_list_file_name is not None:\n+            flag_list_file = open(flag_list_file_name, \"w\")\n+            output_path = os.path.dirname(psf_list_file_name)\n \n         # Loop over all the single images\n         counter = 0\n@@ -222,56 +227,65 @@ class EuclidSingleImageList():\n                 if not detector.overlaps(polygon):\n                     continue\n \n-                # Define the detector output fits file names\n-                image_file_name = mer_filename(\n-                    \"SWIN\", prefix=\"SCI\", filter1=self._filter_name,\n-                    instance_id=str(counter))\n-                weight_file_name = mer_filename(\n-                    \"SWIN\", prefix=\"WHT\", filter1=self._filter_name,\n-                    instance_id=str(counter))\n-                psf_file_name = mer_filename(\n-                    \"SWIN\", prefix=\"PSF\", filter1=self._filter_name,\n-                    instance_id=str(counter))\n-                flag_file_name = mer_filename(\n-                    \"SWIN\", prefix=\"FLG\", filter1=self._filter_name,\n-                    instance_id=str(counter))\n-\n-                # Add the detector fits file names to the list files\n-                image_list_file.write('%s\\n' % image_file_name)\n-                weight_list_file.write('%s\\n' % weight_file_name)\n-                psf_list_file.write('%s\\n' % psf_file_name)\n-                flag_list_file.write('%s\\n' % flag_file_name)\n-\n-                # Add the output path to the fits file names\n-                image_file_name = os.path.join(output_path, image_file_name)\n-                weight_file_name = os.path.join(output_path, weight_file_name)\n-                psf_file_name = os.path.join(output_path, psf_file_name)\n-                flag_file_name = os.path.join(output_path, flag_file_name)\n-\n-                # Write the detector fits files\n-                detector.write_image_fits_file(\n-                    image_file_name, self._bit_mask_image)\n-                detector.write_weight_fits_file(\n-                    weight_file_name, self._bit_mask_image)\n-                detector.write_flag_fits_file(\n-                    flag_file_name, self._bit_mask_flag)\n-                detector.write_psf_fits_file(\n-                    psf_file_name, self._psfex_models, self._filter_name)\n+                # deal with the image files\n+                if image_list_file_name is not None:\n+                    # Define the detector output fits file names\n+                    image_file_name = mer_filename(\n+                        \"SWIN\", prefix=\"SCI\", filter1=self._filter_name,\n+                        instance_id=str(counter))\n+                    image_list_file.write('%s\\n' % image_file_name)\n+                    image_file_name = os.path.join(output_path, image_file_name)\n+                    detector.write_image_fits_file(\n+                        image_file_name, self._bit_mask_image)\n+\n+                # deal with the weight files\n+                if weight_list_file_name is not None:\n+                    weight_file_name = mer_filename(\n+                        \"SWIN\", prefix=\"WHT\", filter1=self._filter_name,\n+                        instance_id=str(counter))\n+                    weight_list_file.write('%s\\n' % weight_file_name)\n+                    weight_file_name = os.path.join(output_path, weight_file_name)\n+                    detector.write_weight_fits_file(\n+                        weight_file_name, self._bit_mask_image)\n+                \n+                # deal with the psf files\n+                if psf_list_file_name is not None:\n+                    psf_file_name = mer_filename(\n+                        \"SWIN\", prefix=\"PSF\", filter1=self._filter_name,\n+                        instance_id=str(counter))\n+                    psf_list_file.write('%s\\n' % psf_file_name)\n+                    psf_file_name = os.path.join(output_path, psf_file_name)\n+                    detector.write_psf_fits_file(\n+                        psf_file_name, self._psfex_models, self._filter_name)\n+                \n+                # deal with the flag files\n+                if flag_list_file_name is not None:\n+                    flag_file_name = mer_filename(\n+                        \"SWIN\", prefix=\"FLG\", filter1=self._filter_name,\n+                        instance_id=str(counter))\n+                    flag_list_file.write('%s\\n' % flag_file_name)\n+                    flag_file_name = os.path.join(output_path, flag_file_name)\n+                    detector.write_flag_fits_file(\n+                        flag_file_name, self._bit_mask_flag)\n \n                 # Increase the counter\n                 counter += 1\n \n         # Close the list files\n-        image_list_file.close()\n-        weight_list_file.close()\n-        psf_list_file.close()\n-        flag_list_file.close()\n+        if image_list_file_name is not None:\n+            image_list_file.close()\n+        if weight_list_file_name is not None:\n+            weight_list_file.close()\n+        if psf_list_file_name is not None:\n+            psf_list_file.close()\n+        if flag_list_file_name is not None:\n+            flag_list_file.close()\n \n         return counter\n \n     def write_psf_image_data(self, radec_coords, maximum_stamp_size,\n                              psf_image_list_file_name, image_list_file_name,\n-                             psf_list_file_name):\n+                             psf_list_file_name, purge=False):\n         \"\"\"Writes in fits files the PSF images of each detector in every single\n         image.\n \n@@ -334,6 +348,10 @@ class EuclidSingleImageList():\n             psf_image = PsfCombiner.create_psf_image(\n                 radec_coords, psf, os.path.join(input_path, image_file_name))\n \n+            # if requested remove the base image\n+            if purge and os.path.isfile(os.path.join(input_path, image_file_name)):\n+                os.remove(os.path.join(input_path, image_file_name))\n+\n             # Define the output fits file name\n             psf_image_file_name = mer_filename(\n                 \"PSF\", prefix=\"IMAGE\", filter1=self._filter_name,\n",
                            "Merge branch 'feature/low_diskspace' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-11T12:39:39.000+00:00",
                            "0db1052f31283821f7b53b577978eb9da0a2bad2"
                        ],
                        [
                            "@@ -165,13 +165,17 @@ class EuclidSingleImageList():\n \n         return single_images\n \n-    def write_data(self, image_list_file_name, weight_list_file_name,\n-                   psf_list_file_name, flag_list_file_name, polygon):\n+    def write_data(self, polygon, image_list_file_name=None, weight_list_file_name=None,\n+                   psf_list_file_name=None, flag_list_file_name=None):\n         \"\"\"Writes in fits files the background subtracted image, the weight,\n         the PSF and the flag of each detector in every single image.\n \n         Parameters\n         ----------\n+        polygon: object\n+            A numpy array with the polygon (RA, Dec) coordinates that describe\n+            the region that the detector image footprints should overlap in\n+            order to be saved as fits files.\n         image_list_file_name: str\n             The name of the list file that will contain the list of\n             background-subtracted image fits file names. It should include the\n@@ -185,10 +189,6 @@ class EuclidSingleImageList():\n         flag_list_file_name: str\n             The name of the list file that will contain the list of flag fits\n             file names. It should include the full path.\n-        polygon: object\n-            A numpy array with the polygon (RA, Dec) coordinates that describe\n-            the region that the detector image footprints should overlap in\n-            order to be saved as fits files.\n \n         Returns\n         -------\n@@ -196,14 +196,19 @@ class EuclidSingleImageList():\n             The number of written detectors.\n \n         \"\"\"\n-        # Get the output path where the output fits files should be saved\n-        output_path = os.path.dirname(image_list_file_name)\n-\n         # Open the list files\n-        image_list_file = open(image_list_file_name, \"w\")\n-        weight_list_file = open(weight_list_file_name, \"w\")\n-        psf_list_file = open(psf_list_file_name, \"w\")\n-        flag_list_file = open(flag_list_file_name, \"w\")\n+        if image_list_file_name is not None:\n+            image_list_file = open(image_list_file_name, \"w\")\n+            output_path = os.path.dirname(image_list_file_name)\n+        if weight_list_file_name is not None:\n+            weight_list_file = open(weight_list_file_name, \"w\")\n+            output_path = os.path.dirname(weight_list_file_name)\n+        if psf_list_file_name is not None:\n+            psf_list_file = open(psf_list_file_name, \"w\")\n+            output_path = os.path.dirname(psf_list_file_name)\n+        if flag_list_file_name is not None:\n+            flag_list_file = open(flag_list_file_name, \"w\")\n+            output_path = os.path.dirname(psf_list_file_name)\n \n         # Loop over all the single images\n         counter = 0\n@@ -222,56 +227,65 @@ class EuclidSingleImageList():\n                 if not detector.overlaps(polygon):\n                     continue\n \n-                # Define the detector output fits file names\n-                image_file_name = mer_filename(\n-                    \"SWIN\", prefix=\"SCI\", filter1=self._filter_name,\n-                    instance_id=str(counter))\n-                weight_file_name = mer_filename(\n-                    \"SWIN\", prefix=\"WHT\", filter1=self._filter_name,\n-                    instance_id=str(counter))\n-                psf_file_name = mer_filename(\n-                    \"SWIN\", prefix=\"PSF\", filter1=self._filter_name,\n-                    instance_id=str(counter))\n-                flag_file_name = mer_filename(\n-                    \"SWIN\", prefix=\"FLG\", filter1=self._filter_name,\n-                    instance_id=str(counter))\n-\n-                # Add the detector fits file names to the list files\n-                image_list_file.write('%s\\n' % image_file_name)\n-                weight_list_file.write('%s\\n' % weight_file_name)\n-                psf_list_file.write('%s\\n' % psf_file_name)\n-                flag_list_file.write('%s\\n' % flag_file_name)\n-\n-                # Add the output path to the fits file names\n-                image_file_name = os.path.join(output_path, image_file_name)\n-                weight_file_name = os.path.join(output_path, weight_file_name)\n-                psf_file_name = os.path.join(output_path, psf_file_name)\n-                flag_file_name = os.path.join(output_path, flag_file_name)\n-\n-                # Write the detector fits files\n-                detector.write_image_fits_file(\n-                    image_file_name, self._bit_mask_image)\n-                detector.write_weight_fits_file(\n-                    weight_file_name, self._bit_mask_image)\n-                detector.write_flag_fits_file(\n-                    flag_file_name, self._bit_mask_flag)\n-                detector.write_psf_fits_file(\n-                    psf_file_name, self._psfex_models, self._filter_name)\n+                # deal with the image files\n+                if image_list_file_name is not None:\n+                    # Define the detector output fits file names\n+                    image_file_name = mer_filename(\n+                        \"SWIN\", prefix=\"SCI\", filter1=self._filter_name,\n+                        instance_id=str(counter))\n+                    image_list_file.write('%s\\n' % image_file_name)\n+                    image_file_name = os.path.join(output_path, image_file_name)\n+                    detector.write_image_fits_file(\n+                        image_file_name, self._bit_mask_image)\n+\n+                # deal with the weight files\n+                if weight_list_file_name is not None:\n+                    weight_file_name = mer_filename(\n+                        \"SWIN\", prefix=\"WHT\", filter1=self._filter_name,\n+                        instance_id=str(counter))\n+                    weight_list_file.write('%s\\n' % weight_file_name)\n+                    weight_file_name = os.path.join(output_path, weight_file_name)\n+                    detector.write_weight_fits_file(\n+                        weight_file_name, self._bit_mask_image)\n+                \n+                # deal with the psf files\n+                if psf_list_file_name is not None:\n+                    psf_file_name = mer_filename(\n+                        \"SWIN\", prefix=\"PSF\", filter1=self._filter_name,\n+                        instance_id=str(counter))\n+                    psf_list_file.write('%s\\n' % psf_file_name)\n+                    psf_file_name = os.path.join(output_path, psf_file_name)\n+                    detector.write_psf_fits_file(\n+                        psf_file_name, self._psfex_models, self._filter_name)\n+                \n+                # deal with the flag files\n+                if flag_list_file_name is not None:\n+                    flag_file_name = mer_filename(\n+                        \"SWIN\", prefix=\"FLG\", filter1=self._filter_name,\n+                        instance_id=str(counter))\n+                    flag_list_file.write('%s\\n' % flag_file_name)\n+                    flag_file_name = os.path.join(output_path, flag_file_name)\n+                    detector.write_flag_fits_file(\n+                        flag_file_name, self._bit_mask_flag)\n \n                 # Increase the counter\n                 counter += 1\n \n         # Close the list files\n-        image_list_file.close()\n-        weight_list_file.close()\n-        psf_list_file.close()\n-        flag_list_file.close()\n+        if image_list_file_name is not None:\n+            image_list_file.close()\n+        if weight_list_file_name is not None:\n+            weight_list_file.close()\n+        if psf_list_file_name is not None:\n+            psf_list_file.close()\n+        if flag_list_file_name is not None:\n+            flag_list_file.close()\n \n         return counter\n \n     def write_psf_image_data(self, radec_coords, maximum_stamp_size,\n                              psf_image_list_file_name, image_list_file_name,\n-                             psf_list_file_name):\n+                             psf_list_file_name, purge=False):\n         \"\"\"Writes in fits files the PSF images of each detector in every single\n         image.\n \n@@ -334,6 +348,10 @@ class EuclidSingleImageList():\n             psf_image = PsfCombiner.create_psf_image(\n                 radec_coords, psf, os.path.join(input_path, image_file_name))\n \n+            # if requested remove the base image\n+            if purge and os.path.isfile(os.path.join(input_path, image_file_name)):\n+                os.remove(os.path.join(input_path, image_file_name))\n+\n             # Define the output fits file name\n             psf_image_file_name = mer_filename(\n                 \"PSF\", prefix=\"IMAGE\", filter1=self._filter_name,\n",
                            "That should work now...",
                            "Martin Kuemmel",
                            "2023-08-10T18:23:08.000+02:00",
                            "55d6a0a0fac378b5734172e327629d7d8f41cbc4"
                        ]
                    ],
                    "MER_SingCombine/python/MER_SingCombine/ImageCombiner.py": [
                        [
                            "@@ -922,8 +922,8 @@ class ImageCombiner():\n             # Calculate the group PSF using the rounded coordinates\n             group_psf = self._calculate_mosaic_psf(\n                 radec_coords, maximum_stamp_size, psf_list_file_name,\n-                image_list_file_name, weight_list_file_name)\n-\n+                image_list_file_name, weight_list_file_name, mopup=False)\n+                \n             # Filter empty PSF stamps\n             group_psf.filter_empty_stamps()\n \n@@ -944,7 +944,7 @@ class ImageCombiner():\n \n     def _calculate_mosaic_psf(self, radec_coords, maximum_stamp_size,\n                               psf_list_file_name, image_list_file_name,\n-                              weight_list_file_name):\n+                              weight_list_file_name, mopup=True):\n         \"\"\"Calculates the mosaic PSF using Swarp.\n \n         Parameters\n@@ -980,7 +980,7 @@ class ImageCombiner():\n         # image\n         psf_counter = self._single_image_list.write_psf_image_data(\n             radec_coords, maximum_stamp_size, psf_image_list_file_name,\n-            image_list_file_name, psf_list_file_name, purge=False)\n+            image_list_file_name, psf_list_file_name, purge=True)\n \n         # Define the Swarp PSF image and weight output file names\n         psf_image_file_name = os.path.join(\n@@ -1008,10 +1008,11 @@ class ImageCombiner():\n             # Calculate the stamps central (x, y) coordinates\n             wcs = EuclidWcs(psf_header)\n             xy_coords = wcs.calculate_pixel_coordinates(radec_coords)\n-            \n+\n             # remove the \"single epoque\" files that are no longer necessary\n             MER_FileCleaner.clean_list(psf_image_list_file_name, base_path=self._output_path, logger=self._logger)\n-            #MER_FileCleaner.clean_list(weight_list_file_name, base_path=self._output_path, logger=self._logger)\n+            if mopup:\n+                MER_FileCleaner.clean_list(weight_list_file_name, base_path=self._output_path, logger=self._logger)\n         else:\n             # Create a dummy image\n             self._create_dummy_image(psf_image_file_name)\n@@ -1174,6 +1175,8 @@ class ImageCombiner():\n             self._run_swarp(image_list_file_name, weight_list_file_name,\n                             image_file_name, weight_file_name)\n             self._logger.info('# Finished runing the first SWARP!')\n+            MER_FileCleaner.clean_list(image_list_file_name, base_path=self._output_path, save_cards=True, logger=self._logger)\n+\n         else:\n             self._create_dummy_image(image_file_name)\n             self._create_dummy_image(weight_file_name)\n@@ -1209,9 +1212,9 @@ class ImageCombiner():\n                 self._mosaic_parameters, self._tile_xml).get_external_corners()\n \n             # Write the data from all the detectors of every single image\n-            self._logger.info(\"# Processing the single images\")\n+            self._logger.info(\"# Processing the single flag images: %s\"%flag_list_file_name)\n             image_counter = self._single_image_list.write_data(\n-                tile_external_corners, flag_list_file_name)\n+                tile_external_corners, flag_list_file_name=flag_list_file_name)\n \n         # combine the flag image(s)\n         if image_counter > 0:\n@@ -1245,7 +1248,7 @@ class ImageCombiner():\n         image_list_file_name = os.path.join(self._output_path, \"sciData.lis\")\n         weight_list_file_name = os.path.join(self._output_path, \"whtData.lis\")\n         psf_list_file_name = os.path.join(self._output_path, \"psfData.lis\")\n-        flag_list_file_name = os.path.join(self._output_path, \"flgData.lis\")\n+        #flag_list_file_name = os.path.join(self._output_path, \"flgData.lis\")\n \n         # Calculate the tile external corners\n         tile_external_corners = MERTile(\n@@ -1254,8 +1257,8 @@ class ImageCombiner():\n         # Write the data from all the detectors of every single image\n         self._logger.info(\"# Processing the single images\")\n         self._single_image_list.write_data(\n-            tile_external_corners, image_list_file_name, weight_list_file_name,\n-            psf_list_file_name, flag_list_file_name)\n+            tile_external_corners, image_list_file_name=image_list_file_name,\n+            weight_list_file_name=weight_list_file_name, psf_list_file_name=psf_list_file_name)\n \n         # Generate the mosaic catalog PSF fits file\n         self._calculate_mosaic_catalog_psf(\n",
                            "Merge branch 'feature/lowdisk' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-17T08:35:48.000+00:00",
                            "beb6df8ebced5b7d1af2ff519738586dc13e98dc"
                        ],
                        [
                            "@@ -980,7 +980,7 @@ class ImageCombiner():\n         # image\n         psf_counter = self._single_image_list.write_psf_image_data(\n             radec_coords, maximum_stamp_size, psf_image_list_file_name,\n-            image_list_file_name, psf_list_file_name, purge=True)\n+            image_list_file_name, psf_list_file_name, purge=False)\n \n         # Define the Swarp PSF image and weight output file names\n         psf_image_file_name = os.path.join(\n@@ -1011,7 +1011,7 @@ class ImageCombiner():\n             \n             # remove the \"single epoque\" files that are no longer necessary\n             MER_FileCleaner.clean_list(psf_image_list_file_name, base_path=self._output_path, logger=self._logger)\n-            MER_FileCleaner.clean_list(weight_list_file_name, base_path=self._output_path, logger=self._logger)\n+            #MER_FileCleaner.clean_list(weight_list_file_name, base_path=self._output_path, logger=self._logger)\n         else:\n             # Create a dummy image\n             self._create_dummy_image(psf_image_file_name)\n",
                            "Some emergency repair",
                            "Martin Kuemmel",
                            "2023-08-12T08:39:42.000+02:00",
                            "2637bcfa2014b2e1305ef982b4bffdcc23deaea7"
                        ],
                        [
                            "@@ -34,6 +34,7 @@ from ElementsKernel.Auxiliary import getAuxiliaryPath\n \n from MER_DA.ExecuteCommand import ExecuteCommand\n from MER_DA.JSONReader import JSONReader\n+from MER_DA.MER_FileCleaner import MER_FileCleaner\n from MER_DA import CheckWCS\n from MER_DataModelUtils import DmUtils as dm_utils\n from MER_PsfMosaic.ArrayUtils import ArrayUtils\n@@ -48,7 +49,7 @@ from MER_MosaicUtils.MapConversionUtils import MapConversionUtils\n from MER_SingCombine.EuclidSingleImageList import EuclidSingleImageList\n from MER_SingCombine.ExtStackList import ExtStackList\n from MER_SingCombine.MERTile import MERTile\n-\n+from MER_SingCombine.BrightStars import BrightStars\n \n class ImageCombiner():\n     \"\"\"Class used to generate a MER mosaic from the combination of a list of\n@@ -95,6 +96,7 @@ class ImageCombiner():\n         \"\"\"\n         # Store the filter name, the output and log paths, and the logger\n         self._filter_name = filter_name\n+        self._tile_file_name = tile_file_name\n         self._output_path = output_path\n         self._log_path = log_path\n         self._logger = logger\n@@ -659,6 +661,12 @@ class ImageCombiner():\n                 \"Content of ERROR file: %s\" % command.get_error_string())\n             raise Exception(\"Exit code for command %s is %i!\" % (command_signature, exit_code))\n \n+        # remove the resampled images images and their weight images\n+        # this is not done in swarp\n+        MER_FileCleaner.clean_list(resampled_flag_list_file_name,  base_path=os.getcwd(),\n+                                   replace_items=['.resamp.fits', '.resamp.weight.fits'],\n+                                   logger=self._logger)\n+\n         # Go back to the previous directory\n         os.chdir(previous_path)\n \n@@ -972,7 +980,7 @@ class ImageCombiner():\n         # image\n         psf_counter = self._single_image_list.write_psf_image_data(\n             radec_coords, maximum_stamp_size, psf_image_list_file_name,\n-            image_list_file_name, psf_list_file_name)\n+            image_list_file_name, psf_list_file_name, purge=True)\n \n         # Define the Swarp PSF image and weight output file names\n         psf_image_file_name = os.path.join(\n@@ -1000,6 +1008,10 @@ class ImageCombiner():\n             # Calculate the stamps central (x, y) coordinates\n             wcs = EuclidWcs(psf_header)\n             xy_coords = wcs.calculate_pixel_coordinates(radec_coords)\n+            \n+            # remove the \"single epoque\" files that are no longer necessary\n+            MER_FileCleaner.clean_list(psf_image_list_file_name, base_path=self._output_path, logger=self._logger)\n+            MER_FileCleaner.clean_list(weight_list_file_name, base_path=self._output_path, logger=self._logger)\n         else:\n             # Create a dummy image\n             self._create_dummy_image(psf_image_file_name)\n@@ -1087,8 +1099,8 @@ class ImageCombiner():\n             # Write the data from all the detectors of every single image\n             self._logger.info(\"# Processing the single images\")\n             self._single_image_list.write_data(\n-                image_list_file_name, weight_list_file_name, psf_list_file_name,\n-                flag_list_file_name, tile_external_corners)\n+                tile_external_corners, image_list_file_name, weight_list_file_name,\n+                psf_list_file_name, flag_list_file_name)\n         else:\n             # Write the data from all the stacks\n             self._logger.info(\"# Processing the stacks\")\n@@ -1097,7 +1109,8 @@ class ImageCombiner():\n                 flag_list_file_name, bps_list_file_name)\n \n     def produce_mosaic(self, image_file_name, rms_file_name, flag_file_name,\n-                       psf_file_name, bps_file_name):\n+                       psf_file_name, bps_file_name,\n+                       mask_file_name=None, gaia_file_name=None, template_file_name=None):\n         \"\"\"Generates the MER mosaic from the input single images or the stacks.\n \n         Parameters\n@@ -1123,6 +1136,9 @@ class ImageCombiner():\n         flag_list_file_name = os.path.join(self._output_path, \"flgData.lis\")\n         bps_list_file_name = os.path.join(self._output_path, \"bpsData.lis\")\n \n+        # Define the Swarp weight output file name\n+        weight_file_name = os.path.join(self._output_path, \"swarp_weight_%s.fits\" % self._time_stamp)\n+\n         # Check which type of dataset should be combined\n         if self._combine_single_images:\n             # Calculate the tile external corners\n@@ -1132,8 +1148,19 @@ class ImageCombiner():\n             # Write the data from all the detectors of every single image\n             self._logger.info(\"# Processing the single images\")\n             image_counter = self._single_image_list.write_data(\n-                image_list_file_name, weight_list_file_name, psf_list_file_name,\n-                flag_list_file_name, tile_external_corners)\n+                tile_external_corners, image_list_file_name, weight_list_file_name,\n+                psf_list_file_name)\n+\n+            # if possible do the bright star masking\n+            if template_file_name is not None:\n+                self._logger.info(\"# Starting the bright star masking!\")\n+                bright_stars = BrightStars(\n+                    self._filter_name, image_list_file_name,\n+                    self._tile_file_name, gaia_file_name, template_file_name,\n+                    self._output_path, mask_file_name, self._logger)\n+                bright_stars.run()\n+            else:\n+                self._logger.info(\"# No bright star masking!\")\n         else:\n             # Write the data from all the stacks\n             self._logger.info(\"# Processing the stacks\")\n@@ -1141,28 +1168,21 @@ class ImageCombiner():\n                 image_list_file_name, weight_list_file_name,\n                 flag_list_file_name, bps_list_file_name)\n \n-        # Define the Swarp weight output file name\n-        weight_file_name = os.path.join(self._output_path, \"swarp_weight_%s.fits\" % self._time_stamp)\n-\n         self._logger.info('# Number of ccd/detector images: %i' % image_counter)\n-\n         if image_counter > 0:\n             # Run Swarp and generate the mosaic image fits file\n             self._run_swarp(image_list_file_name, weight_list_file_name,\n                             image_file_name, weight_file_name)\n-            # Calculate the flag using Swarp\n-            self._run_swarp_flag(flag_list_file_name, flag_file_name)\n+            self._logger.info('# Finished runing the first SWARP!')\n         else:\n             self._create_dummy_image(image_file_name)\n             self._create_dummy_image(weight_file_name)\n-            self._create_dummy_image(flag_file_name, int_type=True)\n+            #self._create_dummy_image(flag_file_name, int_type=True)\n \n         # Check that the mosaic image WCS information is correct\n         CheckWCS.check_image_WCS(image_file_name, logger=self._logger)\n-\n         # Generate the mosaic rms fits file\n         self._calculate_mosaic_rms(weight_file_name, rms_file_name)\n-\n         # Store the zeropoint in the image header\n         self._store_reference_zeropoint(image_file_name)\n         # Maybe store ins on more images?\n@@ -1173,14 +1193,35 @@ class ImageCombiner():\n             self._calculate_mosaic_grid_psf(\n                 psf_file_name, image_file_name, psf_list_file_name,\n                 image_list_file_name, weight_list_file_name)\n+            self._logger.info('# Finished runing the PSF SWARP!')\n+            MER_FileCleaner.clean_list(psf_list_file_name, base_path=self._output_path, logger=self._logger)\n         else:\n             # Calculate the bandpass using Swarp\n             self._run_swarp_bps(bps_list_file_name,\n                                 weight_list_file_name, bps_file_name)\n-\n             # Calculate the mosaic PSF rebinning the EXT PSF\n             self._rebin_ext_psf(psf_file_name)\n \n+        # Check which type of dataset should be combined\n+        if self._combine_single_images:\n+            # Calculate the tile external corners\n+            tile_external_corners = MERTile(\n+                self._mosaic_parameters, self._tile_xml).get_external_corners()\n+\n+            # Write the data from all the detectors of every single image\n+            self._logger.info(\"# Processing the single images\")\n+            image_counter = self._single_image_list.write_data(\n+                tile_external_corners, flag_list_file_name)\n+\n+        # combine the flag image(s)\n+        if image_counter > 0:\n+            self._run_swarp_flag(flag_list_file_name, flag_file_name)\n+            MER_FileCleaner.clean_list(flag_list_file_name, base_path=self._output_path, logger=self._logger)\n+        else:\n+            self._create_dummy_image(flag_file_name, int_type=True)\n+\n+\n+\n     def produce_mosaic_psf(self, catalog_file_name, psf_file_name):\n         \"\"\"Generates the MER mosaic PSF from the input single images or the\n         stacks and the given catalog.\n@@ -1213,8 +1254,8 @@ class ImageCombiner():\n         # Write the data from all the detectors of every single image\n         self._logger.info(\"# Processing the single images\")\n         self._single_image_list.write_data(\n-            image_list_file_name, weight_list_file_name, psf_list_file_name,\n-            flag_list_file_name, tile_external_corners)\n+            tile_external_corners, image_list_file_name, weight_list_file_name,\n+            psf_list_file_name, flag_list_file_name)\n \n         # Generate the mosaic catalog PSF fits file\n         self._calculate_mosaic_catalog_psf(\n",
                            "Merge branch 'feature/low_diskspace' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-11T12:39:39.000+00:00",
                            "0db1052f31283821f7b53b577978eb9da0a2bad2"
                        ],
                        [
                            "@@ -1110,7 +1110,7 @@ class ImageCombiner():\n \n     def produce_mosaic(self, image_file_name, rms_file_name, flag_file_name,\n                        psf_file_name, bps_file_name,\n-                       mask_file_name, gaia_file_name, template_file_name):\n+                       mask_file_name=None, gaia_file_name=None, template_file_name=None):\n         \"\"\"Generates the MER mosaic from the input single images or the stacks.\n \n         Parameters\n",
                            "Removed some unnecessary comments",
                            "Martin Kuemmel",
                            "2023-08-11T09:44:56.000+02:00",
                            "592703e07fe82c9f8b26d45da50c33a395f0af6d"
                        ],
                        [
                            "@@ -980,7 +980,7 @@ class ImageCombiner():\n         # image\n         psf_counter = self._single_image_list.write_psf_image_data(\n             radec_coords, maximum_stamp_size, psf_image_list_file_name,\n-            image_list_file_name, psf_list_file_name)\n+            image_list_file_name, psf_list_file_name, purge=True)\n \n         # Define the Swarp PSF image and weight output file names\n         psf_image_file_name = os.path.join(\n@@ -1009,8 +1009,9 @@ class ImageCombiner():\n             wcs = EuclidWcs(psf_header)\n             xy_coords = wcs.calculate_pixel_coordinates(radec_coords)\n             \n-            # remove the \"single epoque\" grid PSF files that were swarped together \n+            # remove the \"single epoque\" files that are no longer necessary\n             MER_FileCleaner.clean_list(psf_image_list_file_name, base_path=self._output_path, logger=self._logger)\n+            MER_FileCleaner.clean_list(weight_list_file_name, base_path=self._output_path, logger=self._logger)\n         else:\n             # Create a dummy image\n             self._create_dummy_image(psf_image_file_name)\n@@ -1098,8 +1099,8 @@ class ImageCombiner():\n             # Write the data from all the detectors of every single image\n             self._logger.info(\"# Processing the single images\")\n             self._single_image_list.write_data(\n-                image_list_file_name, weight_list_file_name, psf_list_file_name,\n-                flag_list_file_name, tile_external_corners)\n+                tile_external_corners, image_list_file_name, weight_list_file_name,\n+                psf_list_file_name, flag_list_file_name)\n         else:\n             # Write the data from all the stacks\n             self._logger.info(\"# Processing the stacks\")\n@@ -1135,6 +1136,9 @@ class ImageCombiner():\n         flag_list_file_name = os.path.join(self._output_path, \"flgData.lis\")\n         bps_list_file_name = os.path.join(self._output_path, \"bpsData.lis\")\n \n+        # Define the Swarp weight output file name\n+        weight_file_name = os.path.join(self._output_path, \"swarp_weight_%s.fits\" % self._time_stamp)\n+\n         # Check which type of dataset should be combined\n         if self._combine_single_images:\n             # Calculate the tile external corners\n@@ -1144,8 +1148,8 @@ class ImageCombiner():\n             # Write the data from all the detectors of every single image\n             self._logger.info(\"# Processing the single images\")\n             image_counter = self._single_image_list.write_data(\n-                image_list_file_name, weight_list_file_name, psf_list_file_name,\n-                flag_list_file_name, tile_external_corners)\n+                tile_external_corners, image_list_file_name, weight_list_file_name,\n+                psf_list_file_name)\n \n             # if possible do the bright star masking\n             if template_file_name is not None:\n@@ -1164,29 +1168,16 @@ class ImageCombiner():\n                 image_list_file_name, weight_list_file_name,\n                 flag_list_file_name, bps_list_file_name)\n \n-        # Define the Swarp weight output file name\n-        weight_file_name = os.path.join(self._output_path, \"swarp_weight_%s.fits\" % self._time_stamp)\n-\n         self._logger.info('# Number of ccd/detector images: %i' % image_counter)\n-\n         if image_counter > 0:\n             # Run Swarp and generate the mosaic image fits file\n             self._run_swarp(image_list_file_name, weight_list_file_name,\n                             image_file_name, weight_file_name)\n             self._logger.info('# Finished runing the first SWARP!')\n-            #MER_FileCleaner.clean_list(image_list_file_name, base_path=self._output_path, logger=self._logger)\n-            #MER_FileCleaner.clean_list(weight_list_file_name, base_path=self._output_path, logger=self._logger)\n-            #MER_FileCleaner.clean_list(image_list_file_name, logger=self._logger)\n-            #MER_FileCleaner.clean_list(weight_list_file_name, logger=self._logger)\n-            # Calculate the flag using Swarp\n-            self._logger.info('# Finished cleaning images')\n-            self._run_swarp_flag(flag_list_file_name, flag_file_name)\n-            self._logger.info('# Finished runing the fffflag SWARP!')\n-            MER_FileCleaner.clean_list(flag_list_file_name, base_path=self._output_path, logger=self._logger)\n         else:\n             self._create_dummy_image(image_file_name)\n             self._create_dummy_image(weight_file_name)\n-            self._create_dummy_image(flag_file_name, int_type=True)\n+            #self._create_dummy_image(flag_file_name, int_type=True)\n \n         # Check that the mosaic image WCS information is correct\n         CheckWCS.check_image_WCS(image_file_name, logger=self._logger)\n@@ -1208,10 +1199,29 @@ class ImageCombiner():\n             # Calculate the bandpass using Swarp\n             self._run_swarp_bps(bps_list_file_name,\n                                 weight_list_file_name, bps_file_name)\n-\n             # Calculate the mosaic PSF rebinning the EXT PSF\n             self._rebin_ext_psf(psf_file_name)\n \n+        # Check which type of dataset should be combined\n+        if self._combine_single_images:\n+            # Calculate the tile external corners\n+            tile_external_corners = MERTile(\n+                self._mosaic_parameters, self._tile_xml).get_external_corners()\n+\n+            # Write the data from all the detectors of every single image\n+            self._logger.info(\"# Processing the single images\")\n+            image_counter = self._single_image_list.write_data(\n+                tile_external_corners, flag_list_file_name)\n+\n+        # combine the flag image(s)\n+        if image_counter > 0:\n+            self._run_swarp_flag(flag_list_file_name, flag_file_name)\n+            MER_FileCleaner.clean_list(flag_list_file_name, base_path=self._output_path, logger=self._logger)\n+        else:\n+            self._create_dummy_image(flag_file_name, int_type=True)\n+\n+\n+\n     def produce_mosaic_psf(self, catalog_file_name, psf_file_name):\n         \"\"\"Generates the MER mosaic PSF from the input single images or the\n         stacks and the given catalog.\n@@ -1244,8 +1254,8 @@ class ImageCombiner():\n         # Write the data from all the detectors of every single image\n         self._logger.info(\"# Processing the single images\")\n         self._single_image_list.write_data(\n-            image_list_file_name, weight_list_file_name, psf_list_file_name,\n-            flag_list_file_name, tile_external_corners)\n+            tile_external_corners, image_list_file_name, weight_list_file_name,\n+            psf_list_file_name, flag_list_file_name)\n \n         # Generate the mosaic catalog PSF fits file\n         self._calculate_mosaic_catalog_psf(\n",
                            "That should work now...",
                            "Martin Kuemmel",
                            "2023-08-10T18:23:08.000+02:00",
                            "55d6a0a0fac378b5734172e327629d7d8f41cbc4"
                        ],
                        [
                            "@@ -49,7 +49,7 @@ from MER_MosaicUtils.MapConversionUtils import MapConversionUtils\n from MER_SingCombine.EuclidSingleImageList import EuclidSingleImageList\n from MER_SingCombine.ExtStackList import ExtStackList\n from MER_SingCombine.MERTile import MERTile\n-\n+from MER_SingCombine.BrightStars import BrightStars\n \n class ImageCombiner():\n     \"\"\"Class used to generate a MER mosaic from the combination of a list of\n@@ -96,6 +96,7 @@ class ImageCombiner():\n         \"\"\"\n         # Store the filter name, the output and log paths, and the logger\n         self._filter_name = filter_name\n+        self._tile_file_name = tile_file_name\n         self._output_path = output_path\n         self._log_path = log_path\n         self._logger = logger\n@@ -1107,7 +1108,8 @@ class ImageCombiner():\n                 flag_list_file_name, bps_list_file_name)\n \n     def produce_mosaic(self, image_file_name, rms_file_name, flag_file_name,\n-                       psf_file_name, bps_file_name):\n+                       psf_file_name, bps_file_name,\n+                       mask_file_name, gaia_file_name, template_file_name):\n         \"\"\"Generates the MER mosaic from the input single images or the stacks.\n \n         Parameters\n@@ -1144,6 +1146,17 @@ class ImageCombiner():\n             image_counter = self._single_image_list.write_data(\n                 image_list_file_name, weight_list_file_name, psf_list_file_name,\n                 flag_list_file_name, tile_external_corners)\n+\n+            # if possible do the bright star masking\n+            if template_file_name is not None:\n+                self._logger.info(\"# Starting the bright star masking!\")\n+                bright_stars = BrightStars(\n+                    self._filter_name, image_list_file_name,\n+                    self._tile_file_name, gaia_file_name, template_file_name,\n+                    self._output_path, mask_file_name, self._logger)\n+                bright_stars.run()\n+            else:\n+                self._logger.info(\"# No bright star masking!\")\n         else:\n             # Write the data from all the stacks\n             self._logger.info(\"# Processing the stacks\")\n",
                            "Bright star masking now inside ImageCombiner",
                            "Martin Kuemmel",
                            "2023-08-10T00:33:10.000+02:00",
                            "8560fc4805e08aa134f877417d8016416fdbd8a8"
                        ],
                        [
                            "@@ -34,6 +34,7 @@ from ElementsKernel.Auxiliary import getAuxiliaryPath\n \n from MER_DA.ExecuteCommand import ExecuteCommand\n from MER_DA.JSONReader import JSONReader\n+from MER_DA.MER_FileCleaner import MER_FileCleaner\n from MER_DA import CheckWCS\n from MER_DataModelUtils import DmUtils as dm_utils\n from MER_PsfMosaic.ArrayUtils import ArrayUtils\n@@ -659,6 +660,12 @@ class ImageCombiner():\n                 \"Content of ERROR file: %s\" % command.get_error_string())\n             raise Exception(\"Exit code for command %s is %i!\" % (command_signature, exit_code))\n \n+        # remove the resampled images images and their weight images\n+        # this is not done in swarp\n+        MER_FileCleaner.clean_list(resampled_flag_list_file_name,  base_path=os.getcwd(),\n+                                   replace_items=['.resamp.fits', '.resamp.weight.fits'],\n+                                   logger=self._logger)\n+\n         # Go back to the previous directory\n         os.chdir(previous_path)\n \n@@ -1000,6 +1007,9 @@ class ImageCombiner():\n             # Calculate the stamps central (x, y) coordinates\n             wcs = EuclidWcs(psf_header)\n             xy_coords = wcs.calculate_pixel_coordinates(radec_coords)\n+            \n+            # remove the \"single epoque\" grid PSF files that were swarped together \n+            MER_FileCleaner.clean_list(psf_image_list_file_name, base_path=self._output_path, logger=self._logger)\n         else:\n             # Create a dummy image\n             self._create_dummy_image(psf_image_file_name)\n@@ -1150,8 +1160,16 @@ class ImageCombiner():\n             # Run Swarp and generate the mosaic image fits file\n             self._run_swarp(image_list_file_name, weight_list_file_name,\n                             image_file_name, weight_file_name)\n+            self._logger.info('# Finished runing the first SWARP!')\n+            #MER_FileCleaner.clean_list(image_list_file_name, base_path=self._output_path, logger=self._logger)\n+            #MER_FileCleaner.clean_list(weight_list_file_name, base_path=self._output_path, logger=self._logger)\n+            #MER_FileCleaner.clean_list(image_list_file_name, logger=self._logger)\n+            #MER_FileCleaner.clean_list(weight_list_file_name, logger=self._logger)\n             # Calculate the flag using Swarp\n+            self._logger.info('# Finished cleaning images')\n             self._run_swarp_flag(flag_list_file_name, flag_file_name)\n+            self._logger.info('# Finished runing the fffflag SWARP!')\n+            MER_FileCleaner.clean_list(flag_list_file_name, base_path=self._output_path, logger=self._logger)\n         else:\n             self._create_dummy_image(image_file_name)\n             self._create_dummy_image(weight_file_name)\n@@ -1159,10 +1177,8 @@ class ImageCombiner():\n \n         # Check that the mosaic image WCS information is correct\n         CheckWCS.check_image_WCS(image_file_name, logger=self._logger)\n-\n         # Generate the mosaic rms fits file\n         self._calculate_mosaic_rms(weight_file_name, rms_file_name)\n-\n         # Store the zeropoint in the image header\n         self._store_reference_zeropoint(image_file_name)\n         # Maybe store ins on more images?\n@@ -1173,6 +1189,8 @@ class ImageCombiner():\n             self._calculate_mosaic_grid_psf(\n                 psf_file_name, image_file_name, psf_list_file_name,\n                 image_list_file_name, weight_list_file_name)\n+            self._logger.info('# Finished runing the PSF SWARP!')\n+            MER_FileCleaner.clean_list(psf_list_file_name, base_path=self._output_path, logger=self._logger)\n         else:\n             # Calculate the bandpass using Swarp\n             self._run_swarp_bps(bps_list_file_name,\n",
                            "Towards lower temp disk space usage",
                            "Martin Kuemmel",
                            "2023-08-09T21:49:17.000+02:00",
                            "b88210f6d45646462c9de72981ac353c963c1ced"
                        ]
                    ],
                    "MER_SingCombine/python/MER_SingCombine/BrightStars.py": [
                        [
                            "@@ -47,7 +47,7 @@ class BrightStars():\n     \"\"\"\n \n     def __init__(self, filter_name, single_images_file_name, tile_file_name,\n-                 catalog_file_name, template_file_name, workdir_path, output_path, log_path, logger):\n+                 catalog_file_name, template_file_name, workdir_path, output_path, logger):\n         \"\"\"Class constructor.\n \n         Parameters\n@@ -67,8 +67,6 @@ class BrightStars():\n         output_path: str\n             The output path where most of the files will be saved. It should\n             include the full path.\n-        log_path: str\n-            The absolute path to the log directory.\n         logger: object\n             The logger object used for printing debug information.\n \n@@ -82,7 +80,6 @@ class BrightStars():\n         self._filter_name = filter_name\n         self._workdir_path = workdir_path\n         self._output_path = output_path\n-        self._log_path = log_path\n         self._logger  = logger\n \n         self._single_images_file_name = single_images_file_name\n",
                            "Merge branch 'feature/low_diskspace' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-11T12:39:39.000+00:00",
                            "0db1052f31283821f7b53b577978eb9da0a2bad2"
                        ]
                    ],
                    "MER_SingCombine/tests/python/EuclidSingleImageList_test.py": [
                        [
                            "@@ -177,8 +177,8 @@ class TestEuclidSingleImageList(object):\n         psf_list_file_name = str(tmpdir.join(\"psfData.lis\"))\n         flag_list_file_name = str(tmpdir.join(\"flagData.lis\"))\n         single_image_list.write_data(\n-            image_list_file_name, weight_list_file_name, psf_list_file_name,\n-            flag_list_file_name, polygon)\n+            polygon, image_list_file_name, weight_list_file_name,\n+            psf_list_file_name, flag_list_file_name)\n \n         # Read the names of the data fits files\n         image_file_names = EuclidSingleImageList.get_file_names(\n",
                            "Merge branch 'feature/low_diskspace' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-11T12:39:39.000+00:00",
                            "0db1052f31283821f7b53b577978eb9da0a2bad2"
                        ]
                    ],
                    "CMakeLists.txt": [
                        [
                            "@@ -12,8 +12,8 @@ find_package(ElementsProject)\n # Example with dependency:\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n-elements_project(MER_Mosaicing 10.1 USE Elements 6.2.1\n-                                       CT_Swarp_cpp 10.1\n-                                       MER_DA 10.1\n-                                       MER_DataModelUtils 10.1\n-                                       MER_PsfMosaic 10.1)\n+elements_project(MER_Mosaicing 10.2 USE Elements 6.2.1\n+                                       CT_Swarp_cpp 10.2\n+                                       MER_DA 10.2\n+                                       MER_DataModelUtils 10.2\n+                                       MER_PsfMosaic 10.2)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-07-03T15:06:00.000+00:00",
                            "e9f21c30d3f5474a1165e67653f12923cac67711"
                        ],
                        [
                            "@@ -12,8 +12,8 @@ find_package(ElementsProject)\n # Example with dependency:\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n-elements_project(MER_Mosaicing 10.0 USE Elements 6.1.1\n-                                       CT_Swarp_cpp 10.0\n-                                       MER_DA 10.0\n-                                       MER_DataModelUtils 10.0\n-                                       MER_PsfMosaic 10.0)\n+elements_project(MER_Mosaicing 10.1 USE Elements 6.2.1\n+                                       CT_Swarp_cpp 10.1\n+                                       MER_DA 10.1\n+                                       MER_DataModelUtils 10.1\n+                                       MER_PsfMosaic 10.1)\n",
                            "Made all necessary changes for eden-3.1",
                            "Martin Kuemmel",
                            "2023-06-24T10:11:47.000+02:00",
                            "ea581c364d85cc5c9bbf1974853d7e9b09429451"
                        ]
                    ],
                    "MER_MosaicUtils/tests/python/__init__.py": [
                        [
                            "",
                            "Removes init file, since it's no longer necessary",
                            "Javier Gracia Carpio",
                            "2023-06-28T12:15:51.000+00:00",
                            "e9243eda50b44b73765e1882c819b4bce8955170"
                        ]
                    ],
                    ".jenkinsFile": [
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\n-@Library('integration-library@release-10') _\n+@Library(value='integration-library@release-10') _\n pipelineElements(name:\"MER_Mosaicing\", component:'eden.3.1')\n",
                            "Updates makefile",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:22:52.000+00:00",
                            "3d41bba72e6929d449b8081570978ba8acc77cf8"
                        ],
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\n-@Library('integration-library@release-9') _\n-pipelineElements(artifactId:\"MER_Mosaicing\", component:'eden.3.0')\n+@Library('integration-library@release-10') _\n+pipelineElements(name:\"MER_Mosaicing\", component:'eden.3.1')\n",
                            "Made all necessary changes for eden-3.1",
                            "Martin Kuemmel",
                            "2023-06-24T10:11:47.000+02:00",
                            "ea581c364d85cc5c9bbf1974853d7e9b09429451"
                        ]
                    ],
                    "Makefile": [
                        [
                            "@@ -44,169 +44,19 @@\n #\n ################################################################################\n \n-# settings\n-CMAKE := cmake\n-CTEST := ctest\n-NINJA := $(shell which ninja-build 2> /dev/null)\n-ifeq ($(NINJA),)\n-  NINJA := $(shell which ninja 2> /dev/null)\n-endif\n-\n-# Looking for the Custom make library\n-\n-CUSTOM_MAKE_LIB := Custom.mk\n-\n-ifneq ($(wildcard $(CURDIR)/make/$(CUSTOM_MAKE_LIB)),)\n-  CUSTOM_MAKE_LIB_FILE := $(CURDIR)/make/$(CUSTOM_MAKE_LIB)\n-else\n-  ifneq ($(CMAKE_PREFIX_PATH),)\n-    PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    CUSTOM_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(CUSTOM_MAKE_LIB) $(dir)/../make/$(CUSTOM_MAKE_LIB)))\n-  endif\n-  CUSTOM_MAKE_LIB_LIST += /usr/share/Elements/make/$(CUSTOM_MAKE_LIB)\n-  CUSTOM_MAKE_LIB_FILE := $(firstword $(CUSTOM_MAKE_LIB_LIST))\n-endif\n-\n-# Looking for the ToolChain\n-\n-TOOLCHAIN_NAME := ElementsToolChain.cmake\n+ELEMENTS_MAKE_LIB := Elements.mk\n \n-ifneq ($(wildcard $(CURDIR)/cmake/$(TOOLCHAIN_NAME)),)\n-  TOOLCHAIN_FILE := $(CURDIR)/cmake/$(TOOLCHAIN_NAME)\n+ifneq ($(wildcard $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)),)\n+  ELEMENTS_MAKE_LIB_FILE := $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)\n else\n   ifneq ($(CMAKE_PREFIX_PATH),)\n     PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    TOOLCHAIN_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/lib*/cmake/ElementsProject/$(TOOLCHAIN_NAME) $(dir)/$(TOOLCHAIN_NAME)))\n-    TOOLCHAIN_FILE := $(firstword $(TOOLCHAIN_LIST))\n+    ELEMENTS_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(ELEMENTS_MAKE_LIB) $(dir)/../make/$(ELEMENTS_MAKE_LIB)))\n   endif\n+  ELEMENTS_MAKE_LIB_LIST += /usr/share/Elements/make/$(ELEMENTS_MAKE_LIB)\n+  ELEMENTS_MAKE_LIB_FILE := $(firstword $(ELEMENTS_MAKE_LIB_LIST))\n endif\n \n-override ALL_CMAKEFLAGS := -Wno-dev --no-warn-unused-cli\n-\n-ifneq ($(TOOLCHAIN_FILE),)\n-  # A toolchain has been found. Lets use it.\n-  override ALL_CMAKEFLAGS += -DCMAKE_TOOLCHAIN_FILE=$(TOOLCHAIN_FILE)\n-endif\n-\n-\n-BUILD_PREFIX_NAME := build\n-\n-override ALL_CMAKEFLAGS += -DUSE_LOCAL_INSTALLAREA=ON -DBUILD_PREFIX_NAME:STRING=$(BUILD_PREFIX_NAME)\n-override ALL_CMAKEFLAGS += -DUSE_VERSIONED_LIBRARIES=OFF\n-\n-ifndef BINARY_TAG\n-  ifdef CMAKECONFIG\n-    BINARY_TAG := ${CMAKECONFIG}\n-  else\n-    ifdef CMTCONFIG\n-      BINARY_TAG := ${CMTCONFIG}\n-    endif\n-  endif\n-endif\n-\n-ifdef BINARY_TAG\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME).$(BINARY_TAG)\n-else\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME)\n-endif\n-BUILDDIR := $(CURDIR)/$(BUILD_SUBDIR)\n-\n-# build tool\n-\n-ifneq ($(USE_NINJA),)\n-  # enable Ninja\n-  override ALL_CMAKEFLAGS += -GNinja\n-  BUILD_CONF_FILE := build.ninja\n-  BUILDFLAGS := $(NINJAFLAGS)\n-  ifneq ($(VERBOSE),)\n-    BUILDFLAGS := -v $(BUILDFLAGS)\n-  endif\n-else\n-  BUILD_CONF_FILE := Makefile\n-endif\n-BUILD_CMD := $(CMAKE) --build $(BUILD_SUBDIR) --target\n-\n-\n-# Use environment variable for extra flags\n-\n-# Replace the \":\" from eclipse variable list to spaces  \n-ifneq ($(EXPAND_FLAGS),)\n-  CMAKEFLAGS := $(subst :-, -,$(CMAKEFLAGS))\n-endif\n-\n-ifneq ($(CMAKEFLAGS),)\n-  override ALL_CMAKEFLAGS += $(CMAKEFLAGS)\n-endif\n-\n-# default target\n-all:\n-\n-# deep clean\n-purge:\n-\t$(RM) -r $(BUILDDIR) $(CURDIR)/InstallArea/$(BINARY_TAG)\n-\tfind $(CURDIR) \"(\" -name \"InstallArea\" -prune -o -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# Remove all the possible directories and the whole InstallArea as well\n-mrproper:\n-\t$(RM) -r $(CURDIR)/build $(CURDIR)/build.* $(CURDIR)/InstallArea\n-\tfind $(CURDIR) \"(\" -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# delegate any target to the build directory (except 'purge')\n-ifneq ($(MAKECMDGOALS),purge)\n-ifneq ($(MAKECMDGOALS),mrproper)\n-%: $(BUILDDIR)/$(BUILD_CONF_FILE) FORCE\n-\t+$(BUILD_CMD) $* -- $(BUILDFLAGS)\n-endif\n-endif\n-\n-# aliases\n-.PHONY: configure tests FORCE\n-ifneq ($(wildcard $(BUILDDIR)/$(BUILD_CONF_FILE)),)\n-configure: rebuild_cache\n-else\n-configure: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-endif\n-\t@ # do not delegate further\n-\n-\n-# This wrapping around the test target is used to ensure the generation of\n-# the XML output from ctest.\n-test: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-\n-# This target ensures that the \"all\" target is called before\n-# running the tests (unlike the \"test\" default target of CMake)\n-tests: all\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-ifeq ($(VERBOSE),)\n-# less verbose install\n-# (emulate the default CMake install target)\n-install: all\n-\tcd $(BUILDDIR) && $(CMAKE) -P cmake_install.cmake | grep -v \"^-- Up-to-date:\"\n-endif\n-\n-# import the library to look for a custom Makefile\n--include $(CUSTOM_MAKE_LIB_FILE)\n-\n-# ensure that the target are always passed to the CMake Makefile\n-FORCE: ;\n-\n-# Makefiles are used as implicit targets in make, but we should not consider\n-# them for delegation.\n-$(MAKEFILE_LIST): ;\n-\n-\n-# trigger CMake configuration\n-$(BUILDDIR)/$(BUILD_CONF_FILE): | $(BUILDDIR)\n-\tcd $(BUILDDIR) && $(CMAKE) $(ALL_CMAKEFLAGS) $(CURDIR)\n+$(info Using the $(ELEMENTS_MAKE_LIB_FILE) make library)\n+include $(ELEMENTS_MAKE_LIB_FILE)\n \n-$(BUILDDIR):\n-\tmkdir -p $(BUILDDIR)\n",
                            "Updates makefile",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:22:52.000+00:00",
                            "3d41bba72e6929d449b8081570978ba8acc77cf8"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "9.1.0",
                        "created_at": "2023-03-07T13:31:07.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.0",
                        "created_at": "2023-07-03T15:04:14.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.1",
                        "created_at": "2023-08-14T12:29:46.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    }
                ]
            },
            "PF-MER/MER_Validation": {
                "start date": "2023-06-09 09:00",
                "end date": "2023-08-23 15:00",
                "start tag": "> 9.1.1",
                "end tag": "> 10.1.1",
                "count_files_modified": "105",
                "modifications_by_file": {
                    "MER_DetectionValidation/python/MER_DetectionValidation/MER_QuickPositionPlot.py": [
                        [
                            "@@ -104,13 +104,13 @@ class MER_QuickPositionPlot(object):\n \n         # plot the documentation\n         ax.text(1.04, 0.8, 'VIS detected (%i)'%len(ra_vis), verticalalignment='center', horizontalalignment='left',\n-                transform=ax.transAxes, color='blue', fontsize=16)\n+                transform=ax.transAxes, color='blue', fontsize=12)\n         ax.text(1.04, 0.73, 'NIR deteced (%i)'%len(ra_nir), verticalalignment='center', horizontalalignment='left',\n-                transform=ax.transAxes, color='red', fontsize=16)\n+                transform=ax.transAxes, color='red', fontsize=12)\n         ax.text(1.04, 0.67, 'Near bright stars (%i)'%len(ra_masked), verticalalignment='center', horizontalalignment='left',\n-                transform=ax.transAxes, color='orange', fontsize=16)\n+                transform=ax.transAxes, color='orange', fontsize=12)\n         ax.text(1.04, 0.60, 'Matched Gaia (%i)'%len(ra_gaia), verticalalignment='center', horizontalalignment='left',\n-                transform=ax.transAxes, color='green', fontsize=16)\n+                transform=ax.transAxes, color='green', fontsize=12)\n \n         # adjust the scale if possible\n         if len(dec_vis) > 0:\n",
                            "More robust aesthetics for the quick detection plot",
                            "Martin Kuemmel",
                            "2023-08-18T16:29:53.000+02:00",
                            "ec60df3a4d2b70c6b798fe87eacae31a6bd7d62d"
                        ],
                        [
                            "@@ -109,7 +109,7 @@ class MER_QuickPositionPlot(object):\n                 transform=ax.transAxes, color='red', fontsize=16)\n         ax.text(1.04, 0.67, 'Near bright stars (%i)'%len(ra_masked), verticalalignment='center', horizontalalignment='left',\n                 transform=ax.transAxes, color='orange', fontsize=16)\n-        ax.text(1.04, 0.60, 'Matched Gaia objects (%i)'%len(ra_gaia), verticalalignment='center', horizontalalignment='left',\n+        ax.text(1.04, 0.60, 'Matched Gaia (%i)'%len(ra_gaia), verticalalignment='center', horizontalalignment='left',\n                 transform=ax.transAxes, color='green', fontsize=16)\n \n         # adjust the scale if possible\n",
                            "Included some internal links and minor improvements",
                            "Martin Kuemmel",
                            "2023-08-16T22:47:44.000+02:00",
                            "e2fe49ac5109e9e5e2ffded6d1a58aabf6225fe5"
                        ],
                        [
                            "@@ -127,5 +127,5 @@ class MER_QuickPositionPlot(object):\n         if out_plot_name is None:\n             out_plot_name = 'position_plot.png'\n         self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n         plt.close()\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ],
                        [
                            "@@ -27,8 +27,6 @@\n import sys\n import math\n import numpy\n-import matplotlib\n-matplotlib.use('AGG')\n import matplotlib.pyplot as plt\n from astropy.io import fits\n \n@@ -129,5 +127,5 @@ class MER_QuickPositionPlot(object):\n         if out_plot_name is None:\n             out_plot_name = 'position_plot.png'\n         self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n         plt.close()\n",
                            "Removes deprecated overwrite parameter from plt.savefig method",
                            "Javier Gracia Carpio",
                            "2023-06-25T14:52:37.000+00:00",
                            "3702abd7019e03de09ccb9ab9a57f592c0b18c09"
                        ],
                        [
                            "@@ -27,6 +27,8 @@\n import sys\n import math\n import numpy\n+import matplotlib\n+matplotlib.use('AGG')\n import matplotlib.pyplot as plt\n from astropy.io import fits\n \n",
                            "Fixes small issues",
                            "Javier Gracia Carpio",
                            "2023-06-25T13:56:34.000+00:00",
                            "204ce9d35926e49c0f819fb8ff0855f445b9cdf4"
                        ]
                    ],
                    "MER_Validation/python/MER_Validation/MER_ClassificationValidationPrg.py": [
                        [
                            "@@ -296,7 +296,7 @@ def mainMethod(args):\n \n     plt.figure(figsize=(18,10))\n     plt.title(\"POINT_LIKE_FLAG and DET_QUALITY_FLAG of VIS detections in $\\mu_{max}$-Mag vs Mag\")\n-    plt.plot(mer_data['MAG_STARGAL_SEP'][~vis_det_quality_OK],mer_data['MUMAX_MINUS_MAG'][~vis_det_quality_OK],'+',color='red',\n+    plt.plot(mer_data['MAG_STARGAL_SEP'][vis_det & ~vis_det_quality_OK],mer_data['MUMAX_MINUS_MAG'][vis_det & ~vis_det_quality_OK],'+',color='red',\n              ms=4,label='DET_QUALITY_FLAG!=0')\n     plt.plot(mer_data['MAG_STARGAL_SEP'][vis_det_quality_OK],mer_data['MUMAX_MINUS_MAG'][vis_det_quality_OK],'+',color='black',\n              ms=4,label='DET_QUALITY_FLAG==0')\n@@ -305,8 +305,8 @@ def mainMethod(args):\n     plt.legend()\n     plt.xlim([13,29])\n     plt.ylim([-4,4])\n-    plt.xlabel('Mag')\n     plt.ylabel('$\\mu_{max}$ - Mag')\n+    plt.xlabel('Mag')\n     plt.savefig(plot_name)\n \n \n@@ -359,7 +359,9 @@ def mainMethod(args):\n \n     h=numpy.histogram(mer_data['MAG_STARGAL_SEP'][point_like & ~gal_and_star_in_gaia],bins=bins_plot)\n     h2=numpy.histogram(mer_data['MAG_STARGAL_SEP'][high_prob & ~gal_and_star_in_gaia],bins=bins_plot)\n-    h3=numpy.histogram(mer_data['MAG_STARGAL_SEP'][~high_prob & gal_and_star_in_gaia],bins=bins_plot)\n+    # Consider only VIS detections, although some NIR-only objects could match GAIA ones if VIS\n+    # does not cover some area of the tile:\n+    h3=numpy.histogram(mer_data['MAG_STARGAL_SEP'][~high_prob & gal_and_star_in_gaia & vis_det],bins=bins_plot)\n     plt.step(h[1][1:],100*h[0]/tot_detections[0],label='% of object with POINT_LIKE_FLAG=True\\nbut not found in GAIA DR3')\n     plt.step(h2[1][1:],100*h2[0]/tot_detections[0],label='% of object with high POINT_LIKE_PROB (>0.96)\\nbut not found in GAIA DR3')\n     plt.step(h3[1][1:],100*h3[0]/tot_detections[0],label='% of object  with unknown or low POINT_LIKE_PROB (<0.96)\\nbut found in GAIA DR3')\n",
                            "Add some test on VIS_DET to condider tiles with some NIR but no VIS overlapping in ClassificationValidation",
                            "Elie Soubrie",
                            "2023-08-18T10:54:45.000+00:00",
                            "3fde7a44ce0a9b366ea33d31e205da53bbed49a9"
                        ],
                        [
                            "@@ -407,7 +407,8 @@ def mainMethod(args):\n         os.path.join(args.workdir, \"data\", tar_file_name),\n         report_file_names + [output_json_path, results_dict['flag_and_quality_plot'], \n                              results_dict['proba_and_gaia_plot'],\n-                             results_dict['histo_pointlike_and_gaia_plot'] ])\n+                             results_dict['histo_pointlike_and_gaia_plot'],\n+                             results_dict['histo_pointlike_and_gaia_percent_plot'] ])\n \n     # Create the analysis result data product\n     if results_dict['valid']:\n",
                            "Add png plot forgotten in tar for ClassificationValidation",
                            "Elie Soubrie",
                            "2023-08-14T20:35:23.000+00:00",
                            "409b57e8b02b118cb8350d6fb7926a52219fdeeb"
                        ],
                        [
                            "@@ -181,6 +181,11 @@ def create_analysis_report(results_dict, workdir, logger, configuration_paramete\n     histo_pointlike_and_gaia_plot_section.set_figures([AnalysisFigure(results_dict['histo_pointlike_and_gaia_plot'],latex_scale=0.55)])\n     analysis_report.add_section(histo_pointlike_and_gaia_plot_section)\n \n+   # Create a new analysis section and add the \"Histogram of POINT_LIKE and GAIA in percentage\" figure\n+    histo_pointlike_and_gaia_plot_percent_section = AnalysisSection(\"POINT_LIKE and GAIA crossmatch (percentage of total VIS detection in bin)\")\n+    histo_pointlike_and_gaia_plot_percent_section.set_figures([AnalysisFigure(results_dict['histo_pointlike_and_gaia_percent_plot'],latex_scale=0.55)])\n+    analysis_report.add_section(histo_pointlike_and_gaia_plot_percent_section)\n+\n     # Add an index to the analysis report\n     analysis_report.add_index()\n \n@@ -323,12 +328,12 @@ def mainMethod(args):\n     plt.legend()\n     plt.savefig(plot_name)\n     \n-   # create the \"Histogram of POINT_LIKE and GAIA DR3 crosmmatch of VIS detections\" plot\n+   # create the \"Histogram of POINT_LIKE and GAIA DR3 crossmatch of VIS detections\" plot\n     plot_name = os.path.join(args.workdir, 'data', 'HistoPointLikeAndGaiaPlot.png')\n     results_dict['histo_pointlike_and_gaia_plot'] = plot_name\n \n     plt.figure(figsize=(15,10))\n-    plt.title(\"Histogram of POINT_LIKE and GAIA DR3 crosmmatch of VIS detections\")\n+    plt.title(\"Histogram of POINT_LIKE and GAIA DR3 crossmatch of VIS detections\")\n \n     bins_plot=[12,13,14,15,16,17,18,19,20,21,22,23,24]\n \n@@ -343,6 +348,26 @@ def mainMethod(args):\n     plt.legend()\n     plt.savefig(plot_name)\n \n+   # create the \"Histogram of POINT_LIKE and GAIA DR3 crossmatch of VIS detections (in percent)\" plot\n+    plot_name = os.path.join(args.workdir, 'data', 'PercentagePointLikeAndGaiaPlot.png')\n+    results_dict['histo_pointlike_and_gaia_percent_plot'] = plot_name\n+\n+    plt.figure(figsize=(15,10))\n+    plt.title(\"Percentage of POINT_LIKE with GAIA DR3 crossmatch of VIS detections per magnitude bin\")\n+\n+    tot_detections = numpy.histogram(mer_data['MAG_STARGAL_SEP'][vis_det],bins=bins_plot)\n+\n+    h=numpy.histogram(mer_data['MAG_STARGAL_SEP'][point_like & ~gal_and_star_in_gaia],bins=bins_plot)\n+    h2=numpy.histogram(mer_data['MAG_STARGAL_SEP'][high_prob & ~gal_and_star_in_gaia],bins=bins_plot)\n+    h3=numpy.histogram(mer_data['MAG_STARGAL_SEP'][~high_prob & gal_and_star_in_gaia],bins=bins_plot)\n+    plt.step(h[1][1:],100*h[0]/tot_detections[0],label='% of object with POINT_LIKE_FLAG=True\\nbut not found in GAIA DR3')\n+    plt.step(h2[1][1:],100*h2[0]/tot_detections[0],label='% of object with high POINT_LIKE_PROB (>0.96)\\nbut not found in GAIA DR3')\n+    plt.step(h3[1][1:],100*h3[0]/tot_detections[0],label='% of object  with unknown or low POINT_LIKE_PROB (<0.96)\\nbut found in GAIA DR3')\n+    plt.ylabel('% of total VIS detections in mag bin')\n+    plt.xlabel('mag bin')\n+    plt.legend()\n+    plt.savefig(plot_name)\n+\n     results_valid = True\n \n     bright_pointlikeflag_objects_in_gaia = point_like & gal_and_star_in_gaia & (mer_data['MAG_STARGAL_SEP']<19)\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-08-14T15:33:10.000+02:00",
                            "19828bedc5fe0a61f9f373895eace1db34a0a0eb"
                        ],
                        [
                            "@@ -181,6 +181,11 @@ def create_analysis_report(results_dict, workdir, logger, configuration_paramete\n     histo_pointlike_and_gaia_plot_section.set_figures([AnalysisFigure(results_dict['histo_pointlike_and_gaia_plot'],latex_scale=0.55)])\n     analysis_report.add_section(histo_pointlike_and_gaia_plot_section)\n \n+   # Create a new analysis section and add the \"Histogram of POINT_LIKE and GAIA in percentage\" figure\n+    histo_pointlike_and_gaia_plot_percent_section = AnalysisSection(\"POINT_LIKE and GAIA crossmatch (percentage of total VIS detection in bin)\")\n+    histo_pointlike_and_gaia_plot_percent_section.set_figures([AnalysisFigure(results_dict['histo_pointlike_and_gaia_percent_plot'],latex_scale=0.55)])\n+    analysis_report.add_section(histo_pointlike_and_gaia_plot_percent_section)\n+\n     # Add an index to the analysis report\n     analysis_report.add_index()\n \n@@ -323,12 +328,12 @@ def mainMethod(args):\n     plt.legend()\n     plt.savefig(plot_name)\n     \n-   # create the \"Histogram of POINT_LIKE and GAIA DR3 crosmmatch of VIS detections\" plot\n+   # create the \"Histogram of POINT_LIKE and GAIA DR3 crossmatch of VIS detections\" plot\n     plot_name = os.path.join(args.workdir, 'data', 'HistoPointLikeAndGaiaPlot.png')\n     results_dict['histo_pointlike_and_gaia_plot'] = plot_name\n \n     plt.figure(figsize=(15,10))\n-    plt.title(\"Histogram of POINT_LIKE and GAIA DR3 crosmmatch of VIS detections\")\n+    plt.title(\"Histogram of POINT_LIKE and GAIA DR3 crossmatch of VIS detections\")\n \n     bins_plot=[12,13,14,15,16,17,18,19,20,21,22,23,24]\n \n@@ -343,6 +348,26 @@ def mainMethod(args):\n     plt.legend()\n     plt.savefig(plot_name)\n \n+   # create the \"Histogram of POINT_LIKE and GAIA DR3 crossmatch of VIS detections (in percent)\" plot\n+    plot_name = os.path.join(args.workdir, 'data', 'PercentagePointLikeAndGaiaPlot.png')\n+    results_dict['histo_pointlike_and_gaia_percent_plot'] = plot_name\n+\n+    plt.figure(figsize=(15,10))\n+    plt.title(\"Percentage of POINT_LIKE with GAIA DR3 crossmatch of VIS detections per magnitude bin\")\n+\n+    tot_detections = numpy.histogram(mer_data['MAG_STARGAL_SEP'][vis_det],bins=bins_plot)\n+\n+    h=numpy.histogram(mer_data['MAG_STARGAL_SEP'][point_like & ~gal_and_star_in_gaia],bins=bins_plot)\n+    h2=numpy.histogram(mer_data['MAG_STARGAL_SEP'][high_prob & ~gal_and_star_in_gaia],bins=bins_plot)\n+    h3=numpy.histogram(mer_data['MAG_STARGAL_SEP'][~high_prob & gal_and_star_in_gaia],bins=bins_plot)\n+    plt.step(h[1][1:],100*h[0]/tot_detections[0],label='% of object with POINT_LIKE_FLAG=True\\nbut not found in GAIA DR3')\n+    plt.step(h2[1][1:],100*h2[0]/tot_detections[0],label='% of object with high POINT_LIKE_PROB (>0.96)\\nbut not found in GAIA DR3')\n+    plt.step(h3[1][1:],100*h3[0]/tot_detections[0],label='% of object  with unknown or low POINT_LIKE_PROB (<0.96)\\nbut found in GAIA DR3')\n+    plt.ylabel('% of total VIS detections in mag bin')\n+    plt.xlabel('mag bin')\n+    plt.legend()\n+    plt.savefig(plot_name)\n+\n     results_valid = True\n \n     bright_pointlikeflag_objects_in_gaia = point_like & gal_and_star_in_gaia & (mer_data['MAG_STARGAL_SEP']<19)\n",
                            "Adding histogram in percentage of total VIS detections in ClassificationValidationPrg",
                            "Elie Soubrie",
                            "2023-08-11T14:30:20.000+00:00",
                            "2fe7405a16fe87ed9974aa475535c4a3e07bf171"
                        ],
                        [
                            "@@ -0,0 +1,407 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+:file: python/MER_Validation/MER_ClassificationValidationPrg.py\n+\n+:date: 08/10/23\n+:author: elie.soubrie@ias.u-psud.fr\n+\n+\"\"\"\n+import time\n+import json\n+import math\n+import os.path\n+import argparse\n+import ElementsKernel.Logging as log\n+\n+import numpy\n+import matplotlib.pyplot as plt\n+\n+from astropy.io import fits\n+from astropy import units as u\n+\n+from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils import ExtDmUtils as ext_utils\n+from MER_DataModelUtils.FileNaming import mer_filename\n+\n+from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisTable import AnalysisTable\n+from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n+\n+from EL_NullValue import NullValueDefinition\n+\n+from MER_DA.MERUtilities import print_input_arguments\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"\n+    @brief Allows to define the (command line and configuration file) options\n+    specific to this program\n+\n+    @details See the Elements documentation for more details.\n+    @return An  ArgumentParser.\n+    \"\"\"\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser.add_argument('--final_catalog', dest='final_catalog', type=str, required=True,\n+                        help='XML-path to the catalog to be validated')\n+    parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n+                        help='path to the gaia cutout')\n+    parser.add_argument('--classification_json', dest='classification_json', type=str, required=False,\n+                        default='classification_validation.json', help='Json file for output, default: \"classification_validation.json\")!')\n+    parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n+                        default='./', help='Path to the working directory: \"%(default)s\"!')\n+    parser.add_argument(\"--logdir\", dest=\"logdir\", required=False, default='./',\n+                        type=str, help='The logging directory path: \"%(default)s\"!')\n+    parser.add_argument(\"--analysis_result\", dest=\"analysis_result\",\n+                        type=str, help=\"The analysis result output data \"\n+                        \"product XML file name.\")\n+    parser.add_argument(\"--configuration_set\", dest=\"configuration_set\",\n+                        type=str, help=\"The MER Configuration Set product XML \"\n+                        \"file name.\")\n+\n+    return parser\n+\n+def create_analysis_report(results_dict, workdir, logger, configuration_parameters):\n+    \"\"\"Creates an analysis report.\n+\n+    Parameters\n+    ----------\n+    results_dict: dictionary\n+        All results from the detection analysis\n+    workdir: str\n+        The complete path to the working directory.\n+    logger: object\n+        A logger instance.\n+\n+    Returns\n+    -------\n+    list\n+        A python list with the analysis report file names.\n+\n+    \"\"\"\n+    logger.info(\"# Creating the analysis report!\")\n+\n+    # Put in percent and in string the thresholds used for PASSED/FAILED tests\n+    min_ratio_pointlike = '%s' % int(100*configuration_parameters['min_ratio_bright_pointlike_in_gaia'])\n+    min_ratio_highprob = '%s' % int(100*configuration_parameters['min_ratio_bright_highprob_in_gaia'])\n+\n+    # Initialize the analysis report without filling factor\n+    analysis_report = AnalysisReport('MER classification validation')\n+\n+    # Create a new analysis section and add all validation results\n+    validation_section = AnalysisSection(\"Classification validation\")\n+    validation_table = AnalysisTable(['Validation quantity', 'Result'],\n+                                     [['All',\n+                                       '# bright POINT_LIKE flagged object found in GAIA > '+min_ratio_pointlike+'%',\n+                                       '# bright POINT_LIKE_PROB>0.96 objects found in GAIA > '+min_ratio_highprob+'%'],\n+                                      ['%s' % results_dict['valid'],\n+                                       '%s' % results_dict['some_bright_pointlikeflag_object_in_GAIA'],\n+                                       '%s' % results_dict['some_bright_highprob_object_in_GAIA'] ]])\n+    validation_section.add_table(validation_table)\n+    analysis_report.add_section(validation_section)\n+\n+    # Create a new analysis section and add the detections statistics\n+    detections_section = AnalysisSection(\"Detections\")\n+\n+    detections_table = AnalysisTable(['# of detections', 'value [\"]'],\n+                                     [['Total number',\n+                                       'NIR-only',\n+                                       'VIS',\n+                                       '.. w/ SNR>50',\n+                                       '.. and QUALITY_FLAG=0',\n+                                       'POINT_LIKE_FLAG',\n+                                       'POINT_LIKE_PROB>0.96'],\n+                                      [results_dict['n_total_detections'],\n+                                       results_dict['n_NIR_only'],\n+                                       results_dict['n_VIS_detections'],\n+                                       results_dict['n_VIS_SNR_50'],\n+                                       results_dict['n_VIS_SNR_50_quality_flag_OK'],\n+                                       results_dict['n_VIS_POINT_LIKE_FLAG'],\n+                                       results_dict['n_VIS_POINT_LIKE_PROB_0.96'] ]])\n+    detections_section.add_table(detections_table)\n+    analysis_report.add_section(detections_section)\n+\n+    # Create a new analysis section and add the detections statistics\n+    gaia_section = AnalysisSection(\"GAIA DR3 matching\")\n+\n+    gaia_table = AnalysisTable(['# of objects', 'value [\"]'],\n+                                     [['All matches',\n+                                       'POINT_LIKE_FLAG matching GAIA', \n+                                       'POINT_LIKE_PROB>0.96 matching GAIA', \n+                                       'POINT_LIKE_FLAG NOT matching GAIA', \n+                                       'POINT_LIKE_PROB>0.96 NOT matching GAIA',\n+                                       'POINT_LIKE_FLAG, mag<19 and found in GAIA',\n+                                       'POINT_LIKE_FLAG, mag<19',\n+                                       'POINT_LIKE_PROB>0.96, mag<19 and found in GAIA',\n+                                       'POINT_LIKE_PROB>0.96, mag<19' ],\n+                                      [results_dict['n_GAIA_match'],\n+                                       results_dict['n_GAIA_match_POINT_LIKE_FLAG'],\n+                                       results_dict['n_GAIA_match_POINT_LIKE_PROB_0.96'],\n+                                       results_dict['n_no_GAIA_match_POINT_LIKE_FLAG'],\n+                                       results_dict['n_no_GAIA_match_POINT_LIKE_PROB_0.96'],\n+                                       results_dict['bright_pointlikeflag_object_in_GAIA'],\n+                                       results_dict['bright_pointlikeflag_object'],\n+                                       results_dict['bright_highprob_object_in_GAIA'],\n+                                       results_dict['bright_highprob_object'] ]])\n+    gaia_section.add_table(gaia_table)\n+    analysis_report.add_section(gaia_section)\n+\n+   # Create a new analysis section and add the flag and quality figure\n+    flag_and_quality_plot_section = AnalysisSection(\"POINT_LIKE_FLAG results\")\n+    flag_and_quality_plot_section.set_figures([AnalysisFigure(results_dict['flag_and_quality_plot'],latex_scale=0.55)])\n+    analysis_report.add_section(flag_and_quality_plot_section)\n+\n+   # Create a new analysis section and add the \"POINT_LIKE_PROB and GAIA\" figure\n+    proba_and_gaia_plot_section = AnalysisSection(\"POINT_LIKE_PROB and GAIA crossmatch results\")\n+    proba_and_gaia_plot_section.set_figures([AnalysisFigure(results_dict['proba_and_gaia_plot'],latex_scale=0.55)])\n+    analysis_report.add_section(proba_and_gaia_plot_section)\n+\n+   # Create a new analysis section and add the \"Histogram of POINT_LIKE and GAIA\" figure\n+    histo_pointlike_and_gaia_plot_section = AnalysisSection(\"POINT_LIKE and GAIA crossmatch histograms\")\n+    histo_pointlike_and_gaia_plot_section.set_figures([AnalysisFigure(results_dict['histo_pointlike_and_gaia_plot'],latex_scale=0.55)])\n+    analysis_report.add_section(histo_pointlike_and_gaia_plot_section)\n+\n+    # Add an index to the analysis report\n+    analysis_report.add_index()\n+\n+    # Save the analysis report in various formats\n+    json_file_name = os.path.join(workdir, \"data\", \"classificationValidation.json\")\n+    html_file_name = os.path.join(workdir, \"data\", \"classificationValidation.html\")\n+    pdflatex_file_name = os.path.join(workdir, \"data\", \"classificationValidation.tex\")\n+    analysis_report.set_backward(\"detectionValidation.html\")\n+    analysis_report.set_forward(\"psfAnalysis.html\")\n+    analysis_report.save_as_json_file(json_file_name)\n+    analysis_report.save_as_html_file(html_file_name)\n+    analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n+\n+    return [json_file_name, html_file_name, pdflatex_file_name]\n+\n+def mainMethod(args):\n+    \"\"\"\n+    @brief The \"main\" method.\n+    \n+    @details This method is the entry point to the program. In this sense, it is\n+    similar to a main (and it is why it is called mainMethod()).\n+    \"\"\"\n+    logger = log.getLogger('MER_ClassificationValidationPrg')\n+\n+    logger.info('#')\n+    logger.info('# Entering MER_ClassificationValidationPrg mainMethod()')\n+    logger.info('#')\n+\n+    # Store the start time\n+    start_time = time.time()\n+\n+    # start the dict for the results\n+    results_dict = {}\n+\n+    # Add some extra functionality to the MER data product bindings\n+    mer_utils.init()\n+    ext_utils.init() \n+\n+    # Load the configuration parameters\n+    configuration_parameters = AnalysisUtils.get_configuration_parameters(\n+        os.path.join(args.workdir, args.configuration_set),\n+        \"classification_validation\", args.workdir)\n+\n+    # Load the MER final catalog and the Gaia cutout catalog\n+    final_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.final_catalog))\n+    gaia_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.gaia_cutout))\n+\n+    # Get the tile index, the observation ids and the processing mode\n+    tile_index = final_catalog.get_tile_index()\n+    observation_ids = final_catalog.get_observation_id_list()\n+    processing_mode = final_catalog.get_processing_mode()\n+\n+    # get all table data    \n+    mer_data = fits.getdata(os.path.join(args.workdir, 'data', final_catalog.get_data()))\n+    gaia_data = fits.getdata(os.path.join(args.workdir, 'data', gaia_catalog.get_data()))\n+    \n+    # In PV simulations, GAIA_ID is negative for Besan\u00e7on stars, and positive for GAIA\n+    # Remember that a null ID would be positive value :\n+    # >>> from EL_NullValue import NullValueDefinition\n+    # >>> NullValueDefinition().LONG_LONG\n+    # 9223372036854775807\n+\n+    gal_and_star_in_gaia = (mer_data['GAIA_ID'] != -1) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG)\n+    #gal_and_star_in_gaia = (mer_data['GAIA_ID'] > 0) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG)\n+\n+    # Objects declared \"Point-like\" by the POINT_LIKE_FLAG (which excludes objects \n+    # with a DET_QUALITY_FLAG!=0\n+    point_like = mer_data['POINT_LIKE_FLAG']==1\n+\n+    # See all \"point-like\" objects (whatever their DET_QUALITY_FLAG value)\n+    # same 0.96 threshold as defined in MDB for the flag computation\n+    high_prob = mer_data['POINT_LIKE_PROB'] > 0.96\n+\n+    # We'll not consider NIR-only objects here\n+    vis_det = mer_data['VIS_DET'] == 1\n+    vis_det_quality_OK = vis_det & (mer_data['DET_QUALITY_FLAG']==0)\n+\n+    logger.info('# No. of detections: %i' % len(mer_data))\n+    logger.info('# No. of VIS detections: %i' % vis_det.sum())\n+    logger.info('# No. of VIS detections flagged as Point-Like: %i' % point_like.sum())\n+    logger.info('# No. of VIS detections with POINT_LIKE_PROB > 0.96 : %i' % high_prob.sum())\n+\n+    results_dict['n_total_detections'] = int(len(mer_data))\n+    results_dict['n_NIR_only'] = int((~vis_det).sum())\n+    results_dict['n_VIS_detections'] = int(vis_det.sum())\n+    results_dict['n_VIS_SNR_50'] = int((vis_det & (mer_data['MAG_STARGAL_SEP']<22.75)).sum())\n+    results_dict['n_VIS_SNR_50_quality_flag_OK'] = int((vis_det_quality_OK & (mer_data['MAG_STARGAL_SEP']<22.75)).sum())\n+    results_dict['n_VIS_POINT_LIKE_FLAG'] = int(point_like.sum())\n+    results_dict['n_VIS_POINT_LIKE_PROB_0.96'] = int(high_prob.sum())\n+\n+    results_dict['n_GAIA_match'] = int(gal_and_star_in_gaia.sum())\n+    results_dict['n_GAIA_match_POINT_LIKE_FLAG'] = int((gal_and_star_in_gaia & point_like).sum())\n+    results_dict['n_GAIA_match_POINT_LIKE_PROB_0.96'] = int((gal_and_star_in_gaia & high_prob).sum())\n+    results_dict['n_no_GAIA_match_POINT_LIKE_FLAG'] = int((~gal_and_star_in_gaia & point_like).sum())\n+    results_dict['n_no_GAIA_match_POINT_LIKE_PROB_0.96'] = int((~gal_and_star_in_gaia & high_prob).sum())\n+\n+\n+    # select the GAIA ID's in the final catalog\n+    gaia_selector = gal_and_star_in_gaia\n+    logger.info('# No. of GAIA matches: %i' % len(mer_data['GAIA_ID'][gaia_selector]))\n+    results_dict['n_gaia_matches'] = len(mer_data['GAIA_ID'][gaia_selector])\n+\n+    # create the \"POINT_LIKE_FLAG and DET_QUALITY_FLAG of VIS detections\" plot\n+    plot_name = os.path.join(args.workdir, 'data', 'PointLikeFlagAndQualityPlot.png')\n+    results_dict['flag_and_quality_plot'] = plot_name\n+\n+    plt.figure(figsize=(18,10))\n+    plt.title(\"POINT_LIKE_FLAG and DET_QUALITY_FLAG of VIS detections in $\\mu_{max}$-Mag vs Mag\")\n+    plt.plot(mer_data['MAG_STARGAL_SEP'][~vis_det_quality_OK],mer_data['MUMAX_MINUS_MAG'][~vis_det_quality_OK],'+',color='red',\n+             ms=4,label='DET_QUALITY_FLAG!=0')\n+    plt.plot(mer_data['MAG_STARGAL_SEP'][vis_det_quality_OK],mer_data['MUMAX_MINUS_MAG'][vis_det_quality_OK],'+',color='black',\n+             ms=4,label='DET_QUALITY_FLAG==0')\n+    plt.plot(mer_data['MAG_STARGAL_SEP'][point_like],mer_data['MUMAX_MINUS_MAG'][point_like],'+',color='green',\n+             ms=4,label='POINT_LIKE_FLAG==1')\n+    plt.legend()\n+    plt.xlim([13,29])\n+    plt.ylim([-4,4])\n+    plt.xlabel('Mag')\n+    plt.ylabel('$\\mu_{max}$ - Mag')\n+    plt.savefig(plot_name)\n+\n+\n+    # create the \"POINT_LIKE_PROB and GAIA DR3 crosmmatch of VIS detections\" plot\n+    plot_name = os.path.join(args.workdir, 'data', 'PointLikeProbAndGaiaPlot.png')\n+    results_dict['proba_and_gaia_plot'] = plot_name\n+\n+    plt.figure(figsize=(18,10))\n+    plt.title('POINT_LIKE_PROB and GAIA DR3 crossmatch of VIS detections in $\\mu_{max}$-Mag vs Mag')\n+    plt.plot(mer_data['MAG_STARGAL_SEP'][vis_det],mer_data['MUMAX_MINUS_MAG'][vis_det],'.',ms=1,color='blue',label='VIS detections')\n+    plt.plot(mer_data['MAG_STARGAL_SEP'][high_prob & gal_and_star_in_gaia],mer_data['MUMAX_MINUS_MAG'][high_prob & gal_and_star_in_gaia],'.',\n+             ms=3,color='green',label='POINT_LIKE_PROB > 0.96 and in GAIA DR3')\n+    plt.plot(mer_data['MAG_STARGAL_SEP'][high_prob & ~gal_and_star_in_gaia],mer_data['MUMAX_MINUS_MAG'][high_prob & ~gal_and_star_in_gaia],'.',\n+             ms=3,color='red',label='POINT_LIKE_PROB > 0.96 and NOT in GAIA DR3')\n+    plt.xlim([13,29])\n+    plt.ylim([-4,4])\n+    plt.xlabel('Mag')\n+    plt.ylabel('$\\mu_{max}$ - Mag')\n+    plt.legend()\n+    plt.savefig(plot_name)\n+    \n+   # create the \"Histogram of POINT_LIKE and GAIA DR3 crosmmatch of VIS detections\" plot\n+    plot_name = os.path.join(args.workdir, 'data', 'HistoPointLikeAndGaiaPlot.png')\n+    results_dict['histo_pointlike_and_gaia_plot'] = plot_name\n+\n+    plt.figure(figsize=(15,10))\n+    plt.title(\"Histogram of POINT_LIKE and GAIA DR3 crosmmatch of VIS detections\")\n+\n+    bins_plot=[12,13,14,15,16,17,18,19,20,21,22,23,24]\n+\n+    h=numpy.histogram(mer_data['MAG_STARGAL_SEP'][point_like & ~gal_and_star_in_gaia],bins=bins_plot)\n+    h2=numpy.histogram(mer_data['MAG_STARGAL_SEP'][high_prob & ~gal_and_star_in_gaia],bins=bins_plot)\n+    h3=numpy.histogram(mer_data['MAG_STARGAL_SEP'][~high_prob & gal_and_star_in_gaia],bins=bins_plot)\n+    plt.step(h[1][1:],h[0],label='Detections with POINT_LIKE_FLAG=True\\nbut not found in GAIA DR3')\n+    plt.step(h2[1][1:],h2[0],label='Detections with high POINT_LIKE_PROB (>0.96)\\nbut not found in GAIA DR3')\n+    plt.step(h3[1][1:],h3[0],label='Detections with unknown or low POINT_LIKE_PROB (<0.96)\\nbut found in GAIA DR3')\n+    plt.ylabel('number of objects in mag bin')\n+    plt.xlabel('mag bin')\n+    plt.legend()\n+    plt.savefig(plot_name)\n+\n+    results_valid = True\n+\n+    bright_pointlikeflag_objects_in_gaia = point_like & gal_and_star_in_gaia & (mer_data['MAG_STARGAL_SEP']<19)\n+    bright_pointlikeflag_objects = point_like & (mer_data['MAG_STARGAL_SEP']<19)\n+\n+    bright_highprob_objects_in_gaia = high_prob & gal_and_star_in_gaia & (mer_data['MAG_STARGAL_SEP']<19)\n+    bright_highprob_objects = high_prob & (mer_data['MAG_STARGAL_SEP']<19)\n+\n+    results_dict['bright_pointlikeflag_object_in_GAIA'] = int(bright_pointlikeflag_objects_in_gaia.sum())\n+    results_dict['bright_pointlikeflag_object'] = int(bright_pointlikeflag_objects.sum())\n+\n+    results_dict['bright_highprob_object_in_GAIA'] = int(bright_highprob_objects_in_gaia.sum())\n+    results_dict['bright_highprob_object'] = int(bright_highprob_objects.sum())\n+\n+    min_ratio_pointlike = configuration_parameters['min_ratio_bright_pointlike_in_gaia'] # 10%\n+    results_dict['some_bright_pointlikeflag_object_in_GAIA'] = float(bright_pointlikeflag_objects_in_gaia.sum()/bright_pointlikeflag_objects.sum()) > min_ratio_pointlike\n+    results_valid = results_valid & results_dict['some_bright_pointlikeflag_object_in_GAIA']\n+    \n+    min_ratio_highprob = configuration_parameters['min_ratio_bright_highprob_in_gaia'] # 10%\n+    results_dict['some_bright_highprob_object_in_GAIA'] = float(bright_highprob_objects_in_gaia.sum()/bright_highprob_objects.sum()) >  min_ratio_highprob\n+    results_valid = results_valid & results_dict['some_bright_highprob_object_in_GAIA']\n+    \n+    results_dict['valid'] = results_valid\n+\n+    # create the hml and so on\n+    report_file_names = create_analysis_report(results_dict, args.workdir, logger, configuration_parameters)\n+\n+    # Writing to sample.json\n+    output_json_path = os.path.join(args.workdir, 'data', args.classification_json)\n+    with open(output_json_path, \"w+\") as out_json:\n+        out_json.write(json.dumps(results_dict, indent=4))\n+\n+    # Save all the analysis files into a tar file\n+    tar_file_name = mer_filename(\n+        \"VALIDATION-RESULT\", prefix=\"CLASSIFICATION\", tile_index=tile_index, ext=\"tar.gz\")\n+    AnalysisUtils.save_tar_file(\n+        os.path.join(args.workdir, \"data\", tar_file_name),\n+        report_file_names + [output_json_path, results_dict['flag_and_quality_plot'], \n+                             results_dict['proba_and_gaia_plot'],\n+                             results_dict['histo_pointlike_and_gaia_plot'] ])\n+\n+    # Create the analysis result data product\n+    if results_dict['valid']:\n+        global_result = \"PASSED\"\n+    else:\n+        global_result = \"FAILED\"\n+\n+    analysis_result = mer_utils.create_analysis_result(global_result)\n+    analysis_result.set_tile_index(tile_index)\n+    analysis_result.set_observation_id_list(observation_ids)\n+    analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_figures_tar_file(tar_file_name)\n+\n+    # Save the analysis result data product as an XML file\n+    logger.info(\"# Saving the analysis result data product\")\n+    analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n+\n+    # Print the time spent running the step\n+    logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n+    logger.info('#')\n+    logger.info('# Exiting MER_ClassificationValidationPrg mainMethod()')\n+    logger.info('#')\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-08-11T15:41:07.000+02:00",
                            "3439f2b2c5d1617a26353d57808735c69cf7a538"
                        ],
                        [
                            "@@ -49,10 +49,6 @@ from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n \n from EL_NullValue import NullValueDefinition\n \n-from MER_Utils import MER_ArrayStatistics\n-\n-from MER_Validation import MER_PhotometryValidation\n-\n from MER_DA.MERUtilities import print_input_arguments\n \n def defineSpecificProgramOptions():\n@@ -85,7 +81,7 @@ def defineSpecificProgramOptions():\n \n     return parser\n \n-def create_analysis_report(results_dict, workdir, logger):\n+def create_analysis_report(results_dict, workdir, logger, configuration_parameters):\n     \"\"\"Creates an analysis report.\n \n     Parameters\n@@ -105,6 +101,10 @@ def create_analysis_report(results_dict, workdir, logger):\n     \"\"\"\n     logger.info(\"# Creating the analysis report!\")\n \n+    # Put in percent and in string the thresholds used for PASSED/FAILED tests\n+    min_ratio_pointlike = '%s' % int(100*configuration_parameters['min_ratio_bright_pointlike_in_gaia'])\n+    min_ratio_highprob = '%s' % int(100*configuration_parameters['min_ratio_bright_highprob_in_gaia'])\n+\n     # Initialize the analysis report without filling factor\n     analysis_report = AnalysisReport('MER classification validation')\n \n@@ -112,8 +112,8 @@ def create_analysis_report(results_dict, workdir, logger):\n     validation_section = AnalysisSection(\"Classification validation\")\n     validation_table = AnalysisTable(['Validation quantity', 'Result'],\n                                      [['All',\n-                                       '# bright POINT_LIKE flagged object found in GAIA > 10%',\n-                                       '# bright POINT_LIKE_PROB>0.96 objects found in GAIA > 10%'],\n+                                       '# bright POINT_LIKE flagged object found in GAIA > '+min_ratio_pointlike+'%',\n+                                       '# bright POINT_LIKE_PROB>0.96 objects found in GAIA > '+min_ratio_highprob+'%'],\n                                       ['%s' % results_dict['valid'],\n                                        '%s' % results_dict['some_bright_pointlikeflag_object_in_GAIA'],\n                                        '%s' % results_dict['some_bright_highprob_object_in_GAIA'] ]])\n@@ -343,7 +343,6 @@ def mainMethod(args):\n     plt.legend()\n     plt.savefig(plot_name)\n \n-\n     results_valid = True\n \n     bright_pointlikeflag_objects_in_gaia = point_like & gal_and_star_in_gaia & (mer_data['MAG_STARGAL_SEP']<19)\n@@ -358,17 +357,18 @@ def mainMethod(args):\n     results_dict['bright_highprob_object_in_GAIA'] = int(bright_highprob_objects_in_gaia.sum())\n     results_dict['bright_highprob_object'] = int(bright_highprob_objects.sum())\n \n-    results_dict['some_bright_pointlikeflag_object_in_GAIA'] = float(bright_pointlikeflag_objects_in_gaia.sum()/bright_pointlikeflag_objects.sum()) > 0.10 # 10%\n+    min_ratio_pointlike = configuration_parameters['min_ratio_bright_pointlike_in_gaia'] # 10%\n+    results_dict['some_bright_pointlikeflag_object_in_GAIA'] = float(bright_pointlikeflag_objects_in_gaia.sum()/bright_pointlikeflag_objects.sum()) > min_ratio_pointlike\n     results_valid = results_valid & results_dict['some_bright_pointlikeflag_object_in_GAIA']\n     \n-    results_dict['some_bright_highprob_object_in_GAIA'] = float(bright_highprob_objects_in_gaia.sum()/bright_highprob_objects.sum()) > 0.10 # 10%\n+    min_ratio_highprob = configuration_parameters['min_ratio_bright_highprob_in_gaia'] # 10%\n+    results_dict['some_bright_highprob_object_in_GAIA'] = float(bright_highprob_objects_in_gaia.sum()/bright_highprob_objects.sum()) >  min_ratio_highprob\n     results_valid = results_valid & results_dict['some_bright_highprob_object_in_GAIA']\n     \n     results_dict['valid'] = results_valid\n \n- \n     # create the hml and so on\n-    report_file_names = create_analysis_report(results_dict, args.workdir, logger)\n+    report_file_names = create_analysis_report(results_dict, args.workdir, logger, configuration_parameters)\n \n     # Writing to sample.json\n     output_json_path = os.path.join(args.workdir, 'data', args.classification_json)\n",
                            "Adding classification validation minimum ratio thresolds in the config file",
                            "Elie Soubrie",
                            "2023-08-11T13:10:43.000+00:00",
                            "73fe5e07c8b8ce9c9b4d3cfbe6ef7e2aea4c54e1"
                        ],
                        [
                            "@@ -149,12 +149,20 @@ def create_analysis_report(results_dict, workdir, logger):\n                                        'POINT_LIKE_FLAG matching GAIA', \n                                        'POINT_LIKE_PROB>0.96 matching GAIA', \n                                        'POINT_LIKE_FLAG NOT matching GAIA', \n-                                       'POINT_LIKE_PROB>0.96 NOT matching GAIA' ],\n+                                       'POINT_LIKE_PROB>0.96 NOT matching GAIA',\n+                                       'POINT_LIKE_FLAG, mag<19 and found in GAIA',\n+                                       'POINT_LIKE_FLAG, mag<19',\n+                                       'POINT_LIKE_PROB>0.96, mag<19 and found in GAIA',\n+                                       'POINT_LIKE_PROB>0.96, mag<19' ],\n                                       [results_dict['n_GAIA_match'],\n                                        results_dict['n_GAIA_match_POINT_LIKE_FLAG'],\n                                        results_dict['n_GAIA_match_POINT_LIKE_PROB_0.96'],\n                                        results_dict['n_no_GAIA_match_POINT_LIKE_FLAG'],\n-                                       results_dict['n_no_GAIA_match_POINT_LIKE_PROB_0.96'] ]])\n+                                       results_dict['n_no_GAIA_match_POINT_LIKE_PROB_0.96'],\n+                                       results_dict['bright_pointlikeflag_object_in_GAIA'],\n+                                       results_dict['bright_pointlikeflag_object'],\n+                                       results_dict['bright_highprob_object_in_GAIA'],\n+                                       results_dict['bright_highprob_object'] ]])\n     gaia_section.add_table(gaia_table)\n     analysis_report.add_section(gaia_section)\n \n@@ -338,11 +346,17 @@ def mainMethod(args):\n \n     results_valid = True\n \n-    bright_pointlikeflag_objects_in_gaia = point_like & gal_and_star_in_gaia & (mer_data['MAG_STARGAL_SEP']>19)\n-    bright_pointlikeflag_objects = point_like & (mer_data['MAG_STARGAL_SEP']>19)\n+    bright_pointlikeflag_objects_in_gaia = point_like & gal_and_star_in_gaia & (mer_data['MAG_STARGAL_SEP']<19)\n+    bright_pointlikeflag_objects = point_like & (mer_data['MAG_STARGAL_SEP']<19)\n \n-    bright_highprob_objects_in_gaia = high_prob & gal_and_star_in_gaia & (mer_data['MAG_STARGAL_SEP']>19)\n-    bright_highprob_objects = high_prob & (mer_data['MAG_STARGAL_SEP']>19)\n+    bright_highprob_objects_in_gaia = high_prob & gal_and_star_in_gaia & (mer_data['MAG_STARGAL_SEP']<19)\n+    bright_highprob_objects = high_prob & (mer_data['MAG_STARGAL_SEP']<19)\n+\n+    results_dict['bright_pointlikeflag_object_in_GAIA'] = int(bright_pointlikeflag_objects_in_gaia.sum())\n+    results_dict['bright_pointlikeflag_object'] = int(bright_pointlikeflag_objects.sum())\n+\n+    results_dict['bright_highprob_object_in_GAIA'] = int(bright_highprob_objects_in_gaia.sum())\n+    results_dict['bright_highprob_object'] = int(bright_highprob_objects.sum())\n \n     results_dict['some_bright_pointlikeflag_object_in_GAIA'] = float(bright_pointlikeflag_objects_in_gaia.sum()/bright_pointlikeflag_objects.sum()) > 0.10 # 10%\n     results_valid = results_valid & results_dict['some_bright_pointlikeflag_object_in_GAIA']\n",
                            "Adding some info to ClassificationValidationGaiaPrg (+bug correction)",
                            "Elie Soubrie",
                            "2023-08-11T08:33:26.000+00:00",
                            "fa88bfc464522609cd485cba338b238c493debbb"
                        ],
                        [
                            "@@ -180,8 +180,8 @@ def create_analysis_report(results_dict, workdir, logger):\n     json_file_name = os.path.join(workdir, \"data\", \"classificationValidation.json\")\n     html_file_name = os.path.join(workdir, \"data\", \"classificationValidation.html\")\n     pdflatex_file_name = os.path.join(workdir, \"data\", \"classificationValidation.tex\")\n-    analysis_report.set_backward(\"photometryValidation.html\")\n-    analysis_report.set_forward(\"detectionValidation.html\")\n+    analysis_report.set_backward(\"detectionValidation.html\")\n+    analysis_report.set_forward(\"psfAnalysis.html\")\n     analysis_report.save_as_json_file(json_file_name)\n     analysis_report.save_as_html_file(html_file_name)\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n",
                            "Updates for the classification validation step",
                            "Javier Gracia Carpio",
                            "2023-08-10T19:43:44.000+00:00",
                            "08bbbf05233ab7f298b3ce157dc348546bffc8ef"
                        ],
                        [
                            "@@ -0,0 +1,393 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+:file: python/MER_Validation/MER_ClassificationValidationPrg.py\n+\n+:date: 08/10/23\n+:author: elie.soubrie@ias.u-psud.fr\n+\n+\"\"\"\n+import time\n+import json\n+import math\n+import os.path\n+import argparse\n+import ElementsKernel.Logging as log\n+\n+import numpy\n+import matplotlib.pyplot as plt\n+\n+from astropy.io import fits\n+from astropy import units as u\n+\n+from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils import ExtDmUtils as ext_utils\n+from MER_DataModelUtils.FileNaming import mer_filename\n+\n+from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisTable import AnalysisTable\n+from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n+\n+from EL_NullValue import NullValueDefinition\n+\n+from MER_Utils import MER_ArrayStatistics\n+\n+from MER_Validation import MER_PhotometryValidation\n+\n+from MER_DA.MERUtilities import print_input_arguments\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"\n+    @brief Allows to define the (command line and configuration file) options\n+    specific to this program\n+\n+    @details See the Elements documentation for more details.\n+    @return An  ArgumentParser.\n+    \"\"\"\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser.add_argument('--final_catalog', dest='final_catalog', type=str, required=True,\n+                        help='XML-path to the catalog to be validated')\n+    parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n+                        help='path to the gaia cutout')\n+    parser.add_argument('--classification_json', dest='classification_json', type=str, required=False,\n+                        default='classification_validation.json', help='Json file for output, default: \"classification_validation.json\")!')\n+    parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n+                        default='./', help='Path to the working directory: \"%(default)s\"!')\n+    parser.add_argument(\"--logdir\", dest=\"logdir\", required=False, default='./',\n+                        type=str, help='The logging directory path: \"%(default)s\"!')\n+    parser.add_argument(\"--analysis_result\", dest=\"analysis_result\",\n+                        type=str, help=\"The analysis result output data \"\n+                        \"product XML file name.\")\n+    parser.add_argument(\"--configuration_set\", dest=\"configuration_set\",\n+                        type=str, help=\"The MER Configuration Set product XML \"\n+                        \"file name.\")\n+\n+    return parser\n+\n+def create_analysis_report(results_dict, workdir, logger):\n+    \"\"\"Creates an analysis report.\n+\n+    Parameters\n+    ----------\n+    results_dict: dictionary\n+        All results from the detection analysis\n+    workdir: str\n+        The complete path to the working directory.\n+    logger: object\n+        A logger instance.\n+\n+    Returns\n+    -------\n+    list\n+        A python list with the analysis report file names.\n+\n+    \"\"\"\n+    logger.info(\"# Creating the analysis report!\")\n+\n+    # Initialize the analysis report without filling factor\n+    analysis_report = AnalysisReport('MER classification validation')\n+\n+    # Create a new analysis section and add all validation results\n+    validation_section = AnalysisSection(\"Classification validation\")\n+    validation_table = AnalysisTable(['Validation quantity', 'Result'],\n+                                     [['All',\n+                                       '# bright POINT_LIKE flagged object found in GAIA > 10%',\n+                                       '# bright POINT_LIKE_PROB>0.96 objects found in GAIA > 10%'],\n+                                      ['%s' % results_dict['valid'],\n+                                       '%s' % results_dict['some_bright_pointlikeflag_object_in_GAIA'],\n+                                       '%s' % results_dict['some_bright_highprob_object_in_GAIA'] ]])\n+    validation_section.add_table(validation_table)\n+    analysis_report.add_section(validation_section)\n+\n+    # Create a new analysis section and add the detections statistics\n+    detections_section = AnalysisSection(\"Detections\")\n+\n+    detections_table = AnalysisTable(['# of detections', 'value [\"]'],\n+                                     [['Total number',\n+                                       'NIR-only',\n+                                       'VIS',\n+                                       '.. w/ SNR>50',\n+                                       '.. and QUALITY_FLAG=0',\n+                                       'POINT_LIKE_FLAG',\n+                                       'POINT_LIKE_PROB>0.96'],\n+                                      [results_dict['n_total_detections'],\n+                                       results_dict['n_NIR_only'],\n+                                       results_dict['n_VIS_detections'],\n+                                       results_dict['n_VIS_SNR_50'],\n+                                       results_dict['n_VIS_SNR_50_quality_flag_OK'],\n+                                       results_dict['n_VIS_POINT_LIKE_FLAG'],\n+                                       results_dict['n_VIS_POINT_LIKE_PROB_0.96'] ]])\n+    detections_section.add_table(detections_table)\n+    analysis_report.add_section(detections_section)\n+\n+    # Create a new analysis section and add the detections statistics\n+    gaia_section = AnalysisSection(\"GAIA DR3 matching\")\n+\n+    gaia_table = AnalysisTable(['# of objects', 'value [\"]'],\n+                                     [['All matches',\n+                                       'POINT_LIKE_FLAG matching GAIA', \n+                                       'POINT_LIKE_PROB>0.96 matching GAIA', \n+                                       'POINT_LIKE_FLAG NOT matching GAIA', \n+                                       'POINT_LIKE_PROB>0.96 NOT matching GAIA' ],\n+                                      [results_dict['n_GAIA_match'],\n+                                       results_dict['n_GAIA_match_POINT_LIKE_FLAG'],\n+                                       results_dict['n_GAIA_match_POINT_LIKE_PROB_0.96'],\n+                                       results_dict['n_no_GAIA_match_POINT_LIKE_FLAG'],\n+                                       results_dict['n_no_GAIA_match_POINT_LIKE_PROB_0.96'] ]])\n+    gaia_section.add_table(gaia_table)\n+    analysis_report.add_section(gaia_section)\n+\n+   # Create a new analysis section and add the flag and quality figure\n+    flag_and_quality_plot_section = AnalysisSection(\"POINT_LIKE_FLAG results\")\n+    flag_and_quality_plot_section.set_figures([AnalysisFigure(results_dict['flag_and_quality_plot'],latex_scale=0.55)])\n+    analysis_report.add_section(flag_and_quality_plot_section)\n+\n+   # Create a new analysis section and add the \"POINT_LIKE_PROB and GAIA\" figure\n+    proba_and_gaia_plot_section = AnalysisSection(\"POINT_LIKE_PROB and GAIA crossmatch results\")\n+    proba_and_gaia_plot_section.set_figures([AnalysisFigure(results_dict['proba_and_gaia_plot'],latex_scale=0.55)])\n+    analysis_report.add_section(proba_and_gaia_plot_section)\n+\n+   # Create a new analysis section and add the \"Histogram of POINT_LIKE and GAIA\" figure\n+    histo_pointlike_and_gaia_plot_section = AnalysisSection(\"POINT_LIKE and GAIA crossmatch histograms\")\n+    histo_pointlike_and_gaia_plot_section.set_figures([AnalysisFigure(results_dict['histo_pointlike_and_gaia_plot'],latex_scale=0.55)])\n+    analysis_report.add_section(histo_pointlike_and_gaia_plot_section)\n+\n+    # Add an index to the analysis report\n+    analysis_report.add_index()\n+\n+    # Save the analysis report in various formats\n+    json_file_name = os.path.join(workdir, \"data\", \"classificationValidation.json\")\n+    html_file_name = os.path.join(workdir, \"data\", \"classificationValidation.html\")\n+    pdflatex_file_name = os.path.join(workdir, \"data\", \"classificationValidation.tex\")\n+    analysis_report.set_backward(\"photometryValidation.html\")\n+    analysis_report.set_forward(\"detectionValidation.html\")\n+    analysis_report.save_as_json_file(json_file_name)\n+    analysis_report.save_as_html_file(html_file_name)\n+    analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n+\n+    return [json_file_name, html_file_name, pdflatex_file_name]\n+\n+def mainMethod(args):\n+    \"\"\"\n+    @brief The \"main\" method.\n+    \n+    @details This method is the entry point to the program. In this sense, it is\n+    similar to a main (and it is why it is called mainMethod()).\n+    \"\"\"\n+    logger = log.getLogger('MER_ClassificationValidationPrg')\n+\n+    logger.info('#')\n+    logger.info('# Entering MER_ClassificationValidationPrg mainMethod()')\n+    logger.info('#')\n+\n+    # Store the start time\n+    start_time = time.time()\n+\n+    # start the dict for the results\n+    results_dict = {}\n+\n+    # Add some extra functionality to the MER data product bindings\n+    mer_utils.init()\n+    ext_utils.init() \n+\n+    # Load the configuration parameters\n+    configuration_parameters = AnalysisUtils.get_configuration_parameters(\n+        os.path.join(args.workdir, args.configuration_set),\n+        \"classification_validation\", args.workdir)\n+\n+    # Load the MER final catalog and the Gaia cutout catalog\n+    final_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.final_catalog))\n+    gaia_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.gaia_cutout))\n+\n+    # Get the tile index, the observation ids and the processing mode\n+    tile_index = final_catalog.get_tile_index()\n+    observation_ids = final_catalog.get_observation_id_list()\n+    processing_mode = final_catalog.get_processing_mode()\n+\n+    # get all table data    \n+    mer_data = fits.getdata(os.path.join(args.workdir, 'data', final_catalog.get_data()))\n+    gaia_data = fits.getdata(os.path.join(args.workdir, 'data', gaia_catalog.get_data()))\n+    \n+    # In PV simulations, GAIA_ID is negative for Besan\u00e7on stars, and positive for GAIA\n+    # Remember that a null ID would be positive value :\n+    # >>> from EL_NullValue import NullValueDefinition\n+    # >>> NullValueDefinition().LONG_LONG\n+    # 9223372036854775807\n+\n+    gal_and_star_in_gaia = (mer_data['GAIA_ID'] != -1) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG)\n+    #gal_and_star_in_gaia = (mer_data['GAIA_ID'] > 0) & (mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG)\n+\n+    # Objects declared \"Point-like\" by the POINT_LIKE_FLAG (which excludes objects \n+    # with a DET_QUALITY_FLAG!=0\n+    point_like = mer_data['POINT_LIKE_FLAG']==1\n+\n+    # See all \"point-like\" objects (whatever their DET_QUALITY_FLAG value)\n+    # same 0.96 threshold as defined in MDB for the flag computation\n+    high_prob = mer_data['POINT_LIKE_PROB'] > 0.96\n+\n+    # We'll not consider NIR-only objects here\n+    vis_det = mer_data['VIS_DET'] == 1\n+    vis_det_quality_OK = vis_det & (mer_data['DET_QUALITY_FLAG']==0)\n+\n+    logger.info('# No. of detections: %i' % len(mer_data))\n+    logger.info('# No. of VIS detections: %i' % vis_det.sum())\n+    logger.info('# No. of VIS detections flagged as Point-Like: %i' % point_like.sum())\n+    logger.info('# No. of VIS detections with POINT_LIKE_PROB > 0.96 : %i' % high_prob.sum())\n+\n+    results_dict['n_total_detections'] = int(len(mer_data))\n+    results_dict['n_NIR_only'] = int((~vis_det).sum())\n+    results_dict['n_VIS_detections'] = int(vis_det.sum())\n+    results_dict['n_VIS_SNR_50'] = int((vis_det & (mer_data['MAG_STARGAL_SEP']<22.75)).sum())\n+    results_dict['n_VIS_SNR_50_quality_flag_OK'] = int((vis_det_quality_OK & (mer_data['MAG_STARGAL_SEP']<22.75)).sum())\n+    results_dict['n_VIS_POINT_LIKE_FLAG'] = int(point_like.sum())\n+    results_dict['n_VIS_POINT_LIKE_PROB_0.96'] = int(high_prob.sum())\n+\n+    results_dict['n_GAIA_match'] = int(gal_and_star_in_gaia.sum())\n+    results_dict['n_GAIA_match_POINT_LIKE_FLAG'] = int((gal_and_star_in_gaia & point_like).sum())\n+    results_dict['n_GAIA_match_POINT_LIKE_PROB_0.96'] = int((gal_and_star_in_gaia & high_prob).sum())\n+    results_dict['n_no_GAIA_match_POINT_LIKE_FLAG'] = int((~gal_and_star_in_gaia & point_like).sum())\n+    results_dict['n_no_GAIA_match_POINT_LIKE_PROB_0.96'] = int((~gal_and_star_in_gaia & high_prob).sum())\n+\n+\n+    # select the GAIA ID's in the final catalog\n+    gaia_selector = gal_and_star_in_gaia\n+    logger.info('# No. of GAIA matches: %i' % len(mer_data['GAIA_ID'][gaia_selector]))\n+    results_dict['n_gaia_matches'] = len(mer_data['GAIA_ID'][gaia_selector])\n+\n+    # create the \"POINT_LIKE_FLAG and DET_QUALITY_FLAG of VIS detections\" plot\n+    plot_name = os.path.join(args.workdir, 'data', 'PointLikeFlagAndQualityPlot.png')\n+    results_dict['flag_and_quality_plot'] = plot_name\n+\n+    plt.figure(figsize=(18,10))\n+    plt.title(\"POINT_LIKE_FLAG and DET_QUALITY_FLAG of VIS detections in $\\mu_{max}$-Mag vs Mag\")\n+    plt.plot(mer_data['MAG_STARGAL_SEP'][~vis_det_quality_OK],mer_data['MUMAX_MINUS_MAG'][~vis_det_quality_OK],'+',color='red',\n+             ms=4,label='DET_QUALITY_FLAG!=0')\n+    plt.plot(mer_data['MAG_STARGAL_SEP'][vis_det_quality_OK],mer_data['MUMAX_MINUS_MAG'][vis_det_quality_OK],'+',color='black',\n+             ms=4,label='DET_QUALITY_FLAG==0')\n+    plt.plot(mer_data['MAG_STARGAL_SEP'][point_like],mer_data['MUMAX_MINUS_MAG'][point_like],'+',color='green',\n+             ms=4,label='POINT_LIKE_FLAG==1')\n+    plt.legend()\n+    plt.xlim([13,29])\n+    plt.ylim([-4,4])\n+    plt.xlabel('Mag')\n+    plt.ylabel('$\\mu_{max}$ - Mag')\n+    plt.savefig(plot_name)\n+\n+\n+    # create the \"POINT_LIKE_PROB and GAIA DR3 crosmmatch of VIS detections\" plot\n+    plot_name = os.path.join(args.workdir, 'data', 'PointLikeProbAndGaiaPlot.png')\n+    results_dict['proba_and_gaia_plot'] = plot_name\n+\n+    plt.figure(figsize=(18,10))\n+    plt.title('POINT_LIKE_PROB and GAIA DR3 crossmatch of VIS detections in $\\mu_{max}$-Mag vs Mag')\n+    plt.plot(mer_data['MAG_STARGAL_SEP'][vis_det],mer_data['MUMAX_MINUS_MAG'][vis_det],'.',ms=1,color='blue',label='VIS detections')\n+    plt.plot(mer_data['MAG_STARGAL_SEP'][high_prob & gal_and_star_in_gaia],mer_data['MUMAX_MINUS_MAG'][high_prob & gal_and_star_in_gaia],'.',\n+             ms=3,color='green',label='POINT_LIKE_PROB > 0.96 and in GAIA DR3')\n+    plt.plot(mer_data['MAG_STARGAL_SEP'][high_prob & ~gal_and_star_in_gaia],mer_data['MUMAX_MINUS_MAG'][high_prob & ~gal_and_star_in_gaia],'.',\n+             ms=3,color='red',label='POINT_LIKE_PROB > 0.96 and NOT in GAIA DR3')\n+    plt.xlim([13,29])\n+    plt.ylim([-4,4])\n+    plt.xlabel('Mag')\n+    plt.ylabel('$\\mu_{max}$ - Mag')\n+    plt.legend()\n+    plt.savefig(plot_name)\n+    \n+   # create the \"Histogram of POINT_LIKE and GAIA DR3 crosmmatch of VIS detections\" plot\n+    plot_name = os.path.join(args.workdir, 'data', 'HistoPointLikeAndGaiaPlot.png')\n+    results_dict['histo_pointlike_and_gaia_plot'] = plot_name\n+\n+    plt.figure(figsize=(15,10))\n+    plt.title(\"Histogram of POINT_LIKE and GAIA DR3 crosmmatch of VIS detections\")\n+\n+    bins_plot=[12,13,14,15,16,17,18,19,20,21,22,23,24]\n+\n+    h=numpy.histogram(mer_data['MAG_STARGAL_SEP'][point_like & ~gal_and_star_in_gaia],bins=bins_plot)\n+    h2=numpy.histogram(mer_data['MAG_STARGAL_SEP'][high_prob & ~gal_and_star_in_gaia],bins=bins_plot)\n+    h3=numpy.histogram(mer_data['MAG_STARGAL_SEP'][~high_prob & gal_and_star_in_gaia],bins=bins_plot)\n+    plt.step(h[1][1:],h[0],label='Detections with POINT_LIKE_FLAG=True\\nbut not found in GAIA DR3')\n+    plt.step(h2[1][1:],h2[0],label='Detections with high POINT_LIKE_PROB (>0.96)\\nbut not found in GAIA DR3')\n+    plt.step(h3[1][1:],h3[0],label='Detections with unknown or low POINT_LIKE_PROB (<0.96)\\nbut found in GAIA DR3')\n+    plt.ylabel('number of objects in mag bin')\n+    plt.xlabel('mag bin')\n+    plt.legend()\n+    plt.savefig(plot_name)\n+\n+\n+    results_valid = True\n+\n+    bright_pointlikeflag_objects_in_gaia = point_like & gal_and_star_in_gaia & (mer_data['MAG_STARGAL_SEP']>19)\n+    bright_pointlikeflag_objects = point_like & (mer_data['MAG_STARGAL_SEP']>19)\n+\n+    bright_highprob_objects_in_gaia = high_prob & gal_and_star_in_gaia & (mer_data['MAG_STARGAL_SEP']>19)\n+    bright_highprob_objects = high_prob & (mer_data['MAG_STARGAL_SEP']>19)\n+\n+    results_dict['some_bright_pointlikeflag_object_in_GAIA'] = float(bright_pointlikeflag_objects_in_gaia.sum()/bright_pointlikeflag_objects.sum()) > 0.10 # 10%\n+    results_valid = results_valid & results_dict['some_bright_pointlikeflag_object_in_GAIA']\n+    \n+    results_dict['some_bright_highprob_object_in_GAIA'] = float(bright_highprob_objects_in_gaia.sum()/bright_highprob_objects.sum()) > 0.10 # 10%\n+    results_valid = results_valid & results_dict['some_bright_highprob_object_in_GAIA']\n+    \n+    results_dict['valid'] = results_valid\n+\n+ \n+    # create the hml and so on\n+    report_file_names = create_analysis_report(results_dict, args.workdir, logger)\n+\n+    # Writing to sample.json\n+    output_json_path = os.path.join(args.workdir, 'data', args.classification_json)\n+    with open(output_json_path, \"w+\") as out_json:\n+        out_json.write(json.dumps(results_dict, indent=4))\n+\n+    # Save all the analysis files into a tar file\n+    tar_file_name = mer_filename(\n+        \"VALIDATION-RESULT\", prefix=\"CLASSIFICATION\", tile_index=tile_index, ext=\"tar.gz\")\n+    AnalysisUtils.save_tar_file(\n+        os.path.join(args.workdir, \"data\", tar_file_name),\n+        report_file_names + [output_json_path, results_dict['flag_and_quality_plot'], \n+                             results_dict['proba_and_gaia_plot'],\n+                             results_dict['histo_pointlike_and_gaia_plot'] ])\n+\n+    # Create the analysis result data product\n+    if results_dict['valid']:\n+        global_result = \"PASSED\"\n+    else:\n+        global_result = \"FAILED\"\n+\n+    analysis_result = mer_utils.create_analysis_result(global_result)\n+    analysis_result.set_tile_index(tile_index)\n+    analysis_result.set_observation_id_list(observation_ids)\n+    analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_figures_tar_file(tar_file_name)\n+\n+    # Save the analysis result data product as an XML file\n+    logger.info(\"# Saving the analysis result data product\")\n+    analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n+\n+    # Print the time spent running the step\n+    logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n+    logger.info('#')\n+    logger.info('# Exiting MER_ClassificationValidationPrg mainMethod()')\n+    logger.info('#')\n",
                            "Initial version of MER_ClassificationValidationPrg",
                            "Elie Soubrie",
                            "2023-08-10T16:48:51.000+00:00",
                            "ff63e28690f5e698fef3c70a5d366f5bcb47f784"
                        ]
                    ],
                    "MER_DetectionValidation/python/MER_DetectionValidation/MER_PositionPlot.py": [
                        [
                            "@@ -170,7 +170,7 @@ class MER_PositionPlot(object):\n                     transform=ax.transAxes, color='black', fontsize=14)\n         ax.text(1.04, 0.52, 'Near bright stars (%i)'%len(self._match_ra[mask_selector]), verticalalignment='center', horizontalalignment='left',\n                 transform=ax.transAxes, color='orange', fontsize=14)\n-        ax.text(1.04, 0.45, 'Matched Gaia sources (%i)'%len(self._match_ra[gaia_selector]), verticalalignment='center', horizontalalignment='left',\n+        ax.text(1.04, 0.45, 'Matched Gaia (%i)'%len(self._match_ra[gaia_selector]), verticalalignment='center', horizontalalignment='left',\n                 transform=ax.transAxes, color='cyan', fontsize=14)\n \n         if len(self._match_dec) > 0:\n",
                            "Included some internal links and minor improvements",
                            "Martin Kuemmel",
                            "2023-08-16T22:47:44.000+02:00",
                            "e2fe49ac5109e9e5e2ffded6d1a58aabf6225fe5"
                        ],
                        [
                            "@@ -27,6 +27,7 @@ import sys\n import math\n import numpy\n from matplotlib.ticker import FormatStrFormatter\n+from EL_NullValue import NullValueDefinition\n import matplotlib.pyplot as plt\n from astropy.io import fits\n \n@@ -137,7 +138,7 @@ class MER_PositionPlot(object):\n \n         # Select the masked or Gaia matched objects\n         mask_selector = (self._match_quality_flag & 128 == 128) | (self._match_quality_flag & 256 == 256)\n-        gaia_selector = (self._match_gaia_id != -1) & (~numpy.isnan(self._match_gaia_id))\n+        gaia_selector = (self._match_gaia_id != -1) & (self._match_gaia_id != NullValueDefinition.LONG_LONG)\n \n         # plot the data\n         if self._TU_rest_ra is not None:\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:28:10.000+00:00",
                            "e3224a51e80aec0f298e9607d359a618da467017"
                        ],
                        [
                            "@@ -27,6 +27,7 @@ import sys\n import math\n import numpy\n from matplotlib.ticker import FormatStrFormatter\n+from EL_NullValue import NullValueDefinition\n import matplotlib.pyplot as plt\n from astropy.io import fits\n \n@@ -137,7 +138,7 @@ class MER_PositionPlot(object):\n \n         # Select the masked or Gaia matched objects\n         mask_selector = (self._match_quality_flag & 128 == 128) | (self._match_quality_flag & 256 == 256)\n-        gaia_selector = (self._match_gaia_id != -1) & (~numpy.isnan(self._match_gaia_id))\n+        gaia_selector = (self._match_gaia_id != -1) & (self._match_gaia_id != NullValueDefinition.LONG_LONG)\n \n         # plot the data\n         if self._TU_rest_ra is not None:\n",
                            "Merge branch 'validation_on_observed_data' of",
                            "Martin Kuemmel",
                            "2023-07-03T17:42:01.000+02:00",
                            "37c71cc1c56f30ed72f084222ced5e0364712094"
                        ],
                        [
                            "@@ -27,6 +27,7 @@ import sys\n import math\n import numpy\n from matplotlib.ticker import FormatStrFormatter\n+from EL_NullValue import NullValueDefinition\n import matplotlib.pyplot as plt\n from astropy.io import fits\n \n@@ -137,7 +138,7 @@ class MER_PositionPlot(object):\n \n         # Select the masked or Gaia matched objects\n         mask_selector = (self._match_quality_flag & 128 == 128) | (self._match_quality_flag & 256 == 256)\n-        gaia_selector = (self._match_gaia_id != -1) & (~numpy.isnan(self._match_gaia_id))\n+        gaia_selector = (self._match_gaia_id != -1) & (self._match_gaia_id != NullValueDefinition.LONG_LONG)\n \n         # plot the data\n         if self._TU_rest_ra is not None:\n",
                            "fix the null value issue in the GAIA_ID column for the positio plot",
                            "yfang",
                            "2023-06-30T17:29:57.000+02:00",
                            "10db094458acfd9af3e8b1477a7efca2289c5b12"
                        ],
                        [
                            "@@ -188,4 +188,4 @@ class MER_PositionPlot(object):\n         if out_plot_name is None:\n             out_plot_name = 'position_plot.png'\n         self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ],
                        [
                            "@@ -137,7 +137,7 @@ class MER_PositionPlot(object):\n \n         # Select the masked or Gaia matched objects\n         mask_selector = (self._match_quality_flag & 128 == 128) | (self._match_quality_flag & 256 == 256)\n-        gaia_selector = (self._match_gaia_id != -1)\n+        gaia_selector = (self._match_gaia_id != -1) & (~numpy.isnan(self._match_gaia_id))\n \n         # plot the data\n         if self._TU_rest_ra is not None:\n",
                            "fix gaia_selector to handle NANs",
                            "yfang",
                            "2023-06-28T16:25:00.000+02:00",
                            "4081f6b38e5d1db83b22ce8cb6d4c40ef9a07a19"
                        ],
                        [
                            "@@ -137,7 +137,7 @@ class MER_PositionPlot(object):\n \n         # Select the masked or Gaia matched objects\n         mask_selector = (self._match_quality_flag & 128 == 128) | (self._match_quality_flag & 256 == 256)\n-        gaia_selector = (self._match_gaia_id != -1) & (~np.isnan(self._match_gaia_id))\n+        gaia_selector = (self._match_gaia_id != -1) & (~numpy.isnan(self._match_gaia_id))\n \n         # plot the data\n         if self._TU_rest_ra is not None:\n",
                            "use numpy instead of np",
                            "Javier Gracia Carpio",
                            "2023-06-28T14:16:37.000+00:00",
                            "16a0a46648c99b5e0035918932822d664758c402"
                        ],
                        [
                            "@@ -137,7 +137,7 @@ class MER_PositionPlot(object):\n \n         # Select the masked or Gaia matched objects\n         mask_selector = (self._match_quality_flag & 128 == 128) | (self._match_quality_flag & 256 == 256)\n-        gaia_selector = (self._match_gaia_id != -1)\n+        gaia_selector = (self._match_gaia_id != -1) & (~np.isnan(self._match_gaia_id))\n \n         # plot the data\n         if self._TU_rest_ra is not None:\n",
                            "Fixes problem with gaia ids",
                            "Javier Gracia Carpio",
                            "2023-06-28T14:10:05.000+00:00",
                            "a6c001d9017e631d3e3d6a210ba44fb07a6762dc"
                        ],
                        [
                            "@@ -188,4 +188,4 @@ class MER_PositionPlot(object):\n         if out_plot_name is None:\n             out_plot_name = 'position_plot.png'\n         self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n",
                            "Removes deprecated overwrite parameter from plt.savefig method",
                            "Javier Gracia Carpio",
                            "2023-06-25T14:52:37.000+00:00",
                            "3702abd7019e03de09ccb9ab9a57f592c0b18c09"
                        ]
                    ],
                    "MER_PsfMosaicValidation/python/MER_PsfMosaicValidation/MER_GaiaPsfAnalysis.py": [
                        [
                            "@@ -429,7 +429,7 @@ def create_analysis_report(mosaics, catalog, workdir, figsdir, logger):\n     # Add an index and the forward and backward links to the analysis report\n     analysis_report.add_index()\n     analysis_report.set_backward(\"merStarPsfAnalysis.html\")\n-    analysis_report.set_forward(\"index.html\")\n+    analysis_report.set_forward(\"mosaicingValidation.html\")\n \n     # Save the analysis report in various formats\n     json_file_name = os.path.join(workdir, \"data\", \"gaiaPsfAnalysis.json\")\n",
                            "Included some internal links and minor improvements",
                            "Martin Kuemmel",
                            "2023-08-16T22:47:44.000+02:00",
                            "e2fe49ac5109e9e5e2ffded6d1a58aabf6225fe5"
                        ],
                        [
                            "@@ -0,0 +1,514 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+File: python/MER_PsfMosaicValidation/MER_GaiaPsfAnalysis.py\n+\n+Created on: 10/08/23\n+Author: Javier Gracia Carpio (jgracia@mpe.mpg.de)\n+\"\"\"\n+\n+import os.path\n+import argparse\n+import numpy as np\n+import matplotlib.pyplot as plt\n+from astropy import stats\n+from astropy.io import fits\n+\n+import ElementsKernel.Logging as log\n+\n+from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import ExtDmUtils as ext_utils\n+from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils.FileNaming import mer_filename\n+from MER_PsfMosaic.ArrayUtils import ArrayUtils\n+from MER_PsfMosaic.PsfFactory import PsfFactory\n+\n+from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n+from MER_PsfMosaicValidation.CatalogUtils import CatalogUtils\n+\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"Defines the command line input and output parameters specific to this\n+    program.\n+\n+    Returns\n+    -------\n+    ArgumentParser\n+\n+    \"\"\"\n+    # Get the parser instance\n+    parser = argparse.ArgumentParser()\n+\n+    # Add the input parameters\n+    parser.add_argument(\"--workdir\", dest=\"workdir\",\n+                        type=str, help=\"The working directory path.\")\n+\n+    parser.add_argument(\"--logdir\", dest=\"logdir\",\n+                        type=str, help=\"The logging directory path.\")\n+\n+    parser.add_argument(\"--mosaics\", dest=\"mosaics\",\n+                        type=str, help=\"A json file with the MER \"\n+                        \"background-subtracted mosaics XML file names.\")\n+\n+    parser.add_argument(\"--gaia_cutout\", dest=\"gaia_cutout\",\n+                        type=str, help=\"The EXT gaia cutout XML file name.\")\n+\n+    # Add the output parameters\n+    parser.add_argument(\"--analysis_result\", dest=\"analysis_result\",\n+                        type=str, help=\"The analysis result output data \"\n+                        \"product XML file name.\")\n+\n+    return parser\n+\n+\n+def plot_fwhm_comparison(fwhm_values, psf_fwhm_values, title):\n+    \"\"\"Plots a comparison between the Gaia sources and PSF FWHM values.\n+\n+    Parameters\n+    ----------\n+    fwhm_values: object\n+        A numpy array with the Gaia sources FWHM values.\n+    psf_fwhm_values: object\n+        A numpy array with the PSF FWHM values at the Gaia positions.\n+    title: str\n+        The figure title.\n+\n+    \"\"\"\n+    # Exclude very extreme values\n+    fwhm_median = np.median(fwhm_values)\n+    fwhm_std = stats.mad_std(fwhm_values)\n+    psf_fwhm_median = np.median(psf_fwhm_values)\n+    psf_fwhm_std = stats.mad_std(psf_fwhm_values)\n+    cond = np.logical_and(\n+        np.abs(fwhm_values - fwhm_median) < 10 * fwhm_std,\n+        np.abs(psf_fwhm_values - psf_fwhm_median) < 10 * psf_fwhm_std)\n+    fwhm_values = fwhm_values[cond]\n+    psf_fwhm_values = psf_fwhm_values[cond]\n+\n+    # plot the FWHM values\n+    plt.scatter(\n+        fwhm_values, psf_fwhm_values, marker=\"o\", s=4.0, alpha=0.6,\n+        edgecolors=\"none\")\n+\n+    # Make sure the x and y limits are the same\n+    xlim = plt.gca().get_xlim()\n+    ylim = plt.gca().get_ylim()\n+    new_lim = [min(xlim[0], ylim[0]), max(xlim[1], ylim[1])]\n+    plt.xlim(new_lim[0], new_lim[1])\n+    plt.ylim(new_lim[0], new_lim[1])\n+\n+    # Plot the identity line\n+    plt.plot(new_lim, new_lim, \"--k\", alpha=0.5, zorder=-1)\n+\n+    # Set the title and the label information\n+    plt.title(title)\n+    plt.xlabel(\"Gaia source FWHM values (arcsec)\")\n+    plt.ylabel(\"PSF FWHM values (arcsec)\")\n+\n+\n+def plot_stamps_comparison(image_data, psf, xy_coords, rows, columns, title):\n+    \"\"\"Plots a comparison between the Gaia source stamps and the PSF stamps.\n+\n+    Parameters\n+    ----------\n+    image_data: object\n+        A numpy array with the image data.\n+    psf: object\n+        The PSF instance.\n+    xy_coords: object\n+        A numpy array with the sources (x, y) pixel coordinates to use.\n+    rows: int\n+        The number of figure rows. The total number of sources displayed\n+        will be rows * columns.\n+    columns: int, optional\n+        The number of figure columns. The total number of sources displayed\n+        will be rows * columns.\n+    title: str\n+        The figure title.\n+\n+    \"\"\"\n+    # Randomize the source coordinates\n+    xy_coords = xy_coords[np.random.permutation(len(xy_coords))]\n+\n+    # Set the figure dimensions\n+    stamp_box_size = 1.2\n+    stamp_separation = 0.02\n+    margin_left = 0.2\n+    margin_right = 0.2\n+    margin_bottom = 0.2\n+    margin_top = 0.6 + stamp_separation\n+    figure_width = (margin_left + columns * stamp_box_size + \n+                    (columns - 1) * stamp_separation + margin_right)\n+    figure_height = (margin_bottom + rows * stamp_box_size + \n+                     (rows - 1) * stamp_separation + margin_top)\n+    figure_size = (figure_width, figure_height)\n+\n+    # Initialize the figure\n+    fig, ax_list = plt.subplots(rows, columns, figsize=figure_size)\n+    fig.suptitle(title)\n+\n+    # Set the subplot layout\n+    plt.subplots_adjust(\n+        left=margin_left / figure_width,\n+        right=(figure_width - margin_right) / figure_width,\n+        bottom=margin_bottom / figure_height,\n+        top=(figure_height - margin_top) / figure_height,\n+        wspace=stamp_separation / stamp_box_size,\n+        hspace=stamp_separation / stamp_box_size)\n+\n+    # Add the source and PSF stamps to the figure\n+    psf.set_maximum_stamp_size(49)\n+    stamp_size = psf.get_stamp_size()\n+\n+    for i, ax in enumerate(ax_list.ravel()):\n+        # Remove the axis tick marks\n+        ax.axis(\"off\")\n+\n+        # Don't plot anything if there are no more sources available\n+        source_index = int(i / 2)\n+\n+        if source_index >= len(xy_coords):\n+            continue\n+\n+        # Check if we should plot the source stamp or the PSF stamp\n+        if i % 2 == 0:\n+            # Extract the source stamp from the image data\n+            source_center = xy_coords[source_index, ::-1] - 1\n+            stamp = ArrayUtils.get_region(\n+                image_data, center=source_center, size=stamp_size)\n+\n+            # Plot the source stamp\n+            ax.imshow(\n+                stamp, origin=\"lower\", interpolation=\"nearest\",\n+                vmin=min(stamp.min(), 0))\n+        else:\n+            # Get the PSF stamp at the Gaia source (x, y) coordinate\n+            stamp = psf.get_closest_stamp_at_xy(xy_coords[source_index])\n+\n+            # Plot the PSF stamp\n+            ax.imshow(\n+                stamp.get_data(), origin=\"lower\", interpolation=\"nearest\")\n+\n+        # Add the type of stamp and the source pixel coordinates\n+        pos = np.full(2, 0.95 * stamp_size)\n+        stamp_type = \"Source\" if i % 2 == 0 else \"PSF\"\n+        round_xy_coord = np.round(xy_coords[source_index])\n+        text = \"%s (%i, %i)\" % (\n+            stamp_type, round_xy_coord[0], round_xy_coord[1])\n+        bbox = dict(facecolor=\"white\", edgecolor=\"none\", alpha=0.5)\n+        ax.text(\n+            pos[0], pos[1], text, horizontalalignment=\"right\",\n+            verticalalignment=\"top\", fontsize=8, bbox=bbox)\n+\n+\n+def create_analysis_figures(mosaic, catalog, workdir, figsdir):\n+    \"\"\"Creates some analysis figures.\n+\n+    Parameters\n+    ----------\n+    mosaic: object\n+        The MER background-subtracted mosaic product.\n+    catalog: object\n+        The Gaia cutouts catalog table.\n+    workdir: str\n+        The complete path to the working directory.\n+    figsdir: str\n+        The complete path to the directory where the figures will be saved.\n+\n+    Returns\n+    -------\n+    list\n+        A python list with the analysis figures.\n+\n+    \"\"\"\n+    # Get the mosaic filter name and the image, rms and PSF fits file names\n+    filter_name = mosaic.get_filter()\n+    image_file_name = os.path.join(workdir, \"data\", mosaic.get_data())\n+    rms_file_name = os.path.join(workdir, \"data\", mosaic.get_rms())\n+    psf_file_name = os.path.join(workdir, \"data\", mosaic.get_psf_model())\n+\n+    # Load the mosaic image, rms and PSF data from the fits files\n+    image_data = fits.getdata(image_file_name, 0)\n+    rms_data = fits.getdata(rms_file_name, 0)\n+    psf = PsfFactory.get_psf(filter_name, psf_file_name)\n+\n+    # Get the WCS information from the image fits file\n+    wcs = AnalysisUtils.get_wcs(image_file_name)\n+\n+    # Calculate the sources (x, y) pixel coordinates\n+    xy_coords = CatalogUtils.calculate_pixel_coordinates(catalog, wcs)\n+\n+    # Select only the bright sources and avoid sources that might be saturated\n+    #xy_coords = xy_coords[np.logical_and(\n+    #    catalog[\"TU_FNU_VIS\"] > 1e-6, catalog[\"TU_FNU_VIS\"] < 5e-4)]\n+\n+    # Calculate the source FWHM values in arcseconds\n+    stamp_size = 29 if filter_name in AnalysisUtils.EUCLID_FILTERS else 49\n+    fwhm_values = AnalysisUtils.calculate_fwhm_values(\n+        image_data, rms_data, xy_coords, stamp_size=stamp_size)\n+    fwhm_values *= wcs.get_cdelt()[0] * 3600\n+\n+    # Select only sources with valid FWHM values\n+    valid_fwhm = np.isfinite(fwhm_values)\n+    xy_coords = xy_coords[valid_fwhm]\n+    fwhm_values = fwhm_values[valid_fwhm]\n+\n+    # Return None if there is no sources with valid FWHM values\n+    if len(fwhm_values) == 0:\n+        return None\n+\n+    # Get the PSF FWHM values at the source positions\n+    psf_fwhm_values = np.empty(len(fwhm_values))\n+\n+    for i, xy_coord in enumerate(xy_coords):\n+        psf_fwhm_values[i] = psf.get_closest_stamp_at_xy(xy_coord).get_fwhm()\n+\n+    # Sort the sources by their FWHM values\n+    sorted_indices = np.argsort(fwhm_values)\n+    median_index = int(len(fwhm_values) / 2)\n+    fwhm_median = fwhm_values[sorted_indices[median_index]]\n+\n+    # Plot a histogram of the FWHM values\n+    AnalysisUtils.plot_fwhm_hist(\n+        fwhm_values, \"Gaia source FWHM values for band %s (median = %.3f arcsec)\" % \n+        (filter_name, fwhm_median))\n+\n+    # Save the plot in a file\n+    histogram_file_name = os.path.join(\n+        figsdir, filter_name + \"_gaia_FWHM_hist.png\")\n+    AnalysisUtils.save_plot(histogram_file_name)\n+\n+    # Plot a map of the FWHM values\n+    AnalysisUtils.plot_fwhm_map(\n+        xy_coords, fwhm_values, \"Gaia source FWHM values for band %s \"\n+        \"(median = %.3f arcsec)\" % (filter_name, fwhm_median))\n+\n+    # Save the plot in a file\n+    map_file_name = os.path.join(\n+        figsdir, filter_name + \"_gaia_FWHM_map.png\")\n+    AnalysisUtils.save_plot(map_file_name)\n+\n+    # Plot the 25 sources with the smaller FHWM values\n+    AnalysisUtils.plot_sources(\n+        image_data, xy_coords[sorted_indices[:25]],\n+        \"Gaia sources with the smaller FWHM values for band %s\" % filter_name,\n+        fwhm_values=fwhm_values[sorted_indices[:25]], rows=5, columns=5,\n+        add_pixel_coordinates=True, stamp_sizes=stamp_size)\n+\n+    # Save the plot in a file\n+    sources_small_file_name = os.path.join(\n+        figsdir, filter_name + \"_gaia_small_FWHM.png\")\n+    AnalysisUtils.save_plot(sources_small_file_name)\n+\n+    # Plot the 25 sources with median FHWM values\n+    AnalysisUtils.plot_sources(\n+        image_data,\n+        xy_coords[sorted_indices[median_index - 12:median_index + 13]],\n+        \"Gaia sources with median FWHM values for band %s\" % filter_name,\n+        fwhm_values=fwhm_values[\n+            sorted_indices[median_index - 12:median_index + 13]], rows=5,\n+        columns=5, add_pixel_coordinates=True, stamp_sizes=stamp_size)\n+\n+    # Save the plot in a file\n+    sources_median_file_name = os.path.join(\n+        figsdir, filter_name + \"_gaia_median_FWHM.png\")\n+    AnalysisUtils.save_plot(sources_median_file_name)\n+\n+    # Plot the 25 sources with the larger FHWM values\n+    AnalysisUtils.plot_sources(\n+        image_data, xy_coords[sorted_indices[-25:]],\n+        \"Gaia sources with the larger FWHM values for band %s\" % filter_name,\n+        fwhm_values=fwhm_values[sorted_indices[-25:]], rows=5, columns=5,\n+        add_pixel_coordinates=True, stamp_sizes=stamp_size)\n+\n+    # Save the plot in a file\n+    sources_large_file_name = os.path.join(\n+        figsdir, filter_name + \"_gaia_large_FWHM.png\")\n+    AnalysisUtils.save_plot(sources_large_file_name)\n+\n+    # Plot a comparison of the source and PSF fwhm values\n+    plot_fwhm_comparison(\n+        fwhm_values, psf_fwhm_values,\n+        \"Gaia source FWHM values vs. PSF FWHM values for band %s\" % filter_name)\n+\n+    # Save the plot in a file\n+    fwhm_comparison_file_name = os.path.join(\n+        figsdir, filter_name + \"_gaia_FWHM_comparison.png\")\n+    AnalysisUtils.save_plot(fwhm_comparison_file_name)\n+\n+    # Plot a comparison of the source stamps and the PSF stamps\n+    plot_stamps_comparison(\n+        image_data, psf, xy_coords, 14, 10,\n+        \"Gaia source stamps vs. PSF stamps for band %s\" % filter_name)\n+\n+    # Save the plot in a file\n+    stamps_comparison_file_name = os.path.join(\n+        figsdir, filter_name + \"_gaia_stamps_comparison.png\")\n+    AnalysisUtils.save_plot(stamps_comparison_file_name)\n+\n+    # Return the list of analysis figures\n+    analysis_figures = [\n+        AnalysisFigure(histogram_file_name, latex_scale=0.55),\n+        AnalysisFigure(map_file_name, latex_scale=0.55),\n+        AnalysisFigure(sources_small_file_name, latex_scale=0.7),\n+        AnalysisFigure(sources_median_file_name, latex_scale=0.7),\n+        AnalysisFigure(sources_large_file_name, latex_scale=0.7),\n+        AnalysisFigure(fwhm_comparison_file_name, latex_scale=0.55),\n+        AnalysisFigure(stamps_comparison_file_name, latex_scale=0.5)\n+    ]\n+\n+    return analysis_figures\n+\n+\n+def create_analysis_report(mosaics, catalog, workdir, figsdir, logger):\n+    \"\"\"Creates an analysis report.\n+\n+    Parameters\n+    ----------\n+    mosaics: dict\n+        A python dictionary with the MER background-subtracted mosaic products.\n+    catalog: object\n+        The Gaia cutout catalog table.\n+    workdir: str\n+        The complete path to the working directory.\n+    figsdir: str\n+        The complete path to the directory where the figures will be saved.\n+    logger: object\n+        A logger instance.\n+\n+    Returns\n+    -------\n+    list\n+        A python list with the analysis report file names.\n+\n+    \"\"\"\n+    # Initialize the analysis report\n+    analysis_report = AnalysisReport(\n+        \"Gaia PSF analysis for tile %s\" % mosaics[\"VIS\"].get_tile_index())\n+\n+    # Loop over all possible filter names\n+    for filter_name in AnalysisUtils.ALL_FILTERS:\n+        # Move to the next filter name if there is no mosaic for that filter\n+        if filter_name not in mosaics:\n+            continue\n+\n+        # Create the analysis figures\n+        logger.info(\"# Creating analysis figures for band %s\" % filter_name)\n+        analysis_figures = create_analysis_figures(\n+            mosaics[filter_name], catalog, workdir, figsdir)\n+\n+        # Create a new analysis section\n+        section_title = filter_name.replace(\"_\", \" \")\n+        analysis_section = AnalysisSection(section_title)\n+\n+        # Add the analysis figures to the analysis section\n+        analysis_section.set_figures(analysis_figures)\n+\n+        # Add the analysis section to the analysis report\n+        analysis_report.add_section(analysis_section)\n+\n+    # Add an index and the forward and backward links to the analysis report\n+    analysis_report.add_index()\n+    analysis_report.set_backward(\"merStarPsfAnalysis.html\")\n+    analysis_report.set_forward(\"index.html\")\n+\n+    # Save the analysis report in various formats\n+    json_file_name = os.path.join(workdir, \"data\", \"gaiaPsfAnalysis.json\")\n+    html_file_name = os.path.join(workdir, \"data\", \"gaiaPsfAnalysis.html\")\n+    pdflatex_file_name = os.path.join(workdir, \"data\", \"gaiaPsfAnalysis.tex\")\n+    analysis_report.save_as_json_file(json_file_name)\n+    analysis_report.save_as_html_file(html_file_name)\n+    analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n+\n+    return [json_file_name, html_file_name, pdflatex_file_name]\n+\n+\n+def mainMethod(args):\n+    \"\"\" The \"main\" method.\n+\n+    \"\"\"\n+    # Get a logger instance\n+    logger = log.getLogger(\"MER_GaiaPsfAnalysis\")\n+\n+    logger.info(\"#\")\n+    logger.info(\"# Entering MER_GaiaPsfAnalysis mainMethod()\")\n+    logger.info(\"#\")\n+\n+    # Do not print astropy warnings\n+    AnalysisUtils.ignore_astropy_warnings()\n+\n+    # Add some extra functionality to the MER and EXT data product bindings\n+    mer_utils.init()\n+    ext_utils.init() \n+\n+    # Create the figures directory\n+    figsdir = os.path.join(args.workdir, \"data\", \"gaiaPsfFigures\")\n+    AnalysisUtils.create_directory(figsdir)\n+\n+    # Load the MER background-subtracted mosaics\n+    mosaics = AnalysisUtils.get_background_subtracted_mosaics(\n+        os.path.join(args.workdir, args.mosaics), args.workdir)\n+\n+    # Load the Gaia cutout catalog\n+    gaia_cutout = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.gaia_cutout))\n+\n+    # Read the Gaia cutout catalog table\n+    catalog = CatalogUtils.read_catalog(\n+        os.path.join(args.workdir, \"data\", gaia_cutout.get_data()))\n+\n+    # Get the tile index, the processing mode and the observation ids\n+    tile_index = mosaics[\"VIS\"].get_tile_index()\n+    processing_mode = mosaics[\"VIS\"].get_processing_mode()\n+    observation_ids = set()\n+\n+    for mosaic in mosaics.values():\n+        observation_ids.update(mosaic.get_observation_id_list())\n+\n+    # Create the analysis report\n+    logger.info(\"# Creating the Gaia PSF analysis report...\")\n+    report_file_names = create_analysis_report(\n+        mosaics, catalog, args.workdir, figsdir, logger)\n+\n+    # Save all the analysis files into a tar file\n+    tar_file_name = mer_filename(\n+        \"ANALYSIS-RESULT\", prefix=\"GAIA-PSF\", tile_index=tile_index,\n+        ext=\"tar.gz\")\n+    AnalysisUtils.save_tar_file(\n+        os.path.join(args.workdir, \"data\", tar_file_name),\n+        report_file_names + [figsdir])\n+\n+    # Create the analysis result data product\n+    global_result = \"PASSED\"\n+    analysis_result = mer_utils.create_analysis_result(global_result)\n+    analysis_result.set_tile_index(tile_index)\n+    analysis_result.set_observation_id_list(observation_ids)\n+    analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_figures_tar_file(tar_file_name)\n+\n+    # Save the analysis result data product as an XML file\n+    logger.info(\"# Saving the analysis result data product\")\n+    analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n+\n+    logger.info(\"#\")\n+    logger.info(\"# Exiting MER_GaiaPsfAnalysis mainMethod()\")\n+    logger.info(\"#\")\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-08-11T15:41:07.000+02:00",
                            "3439f2b2c5d1617a26353d57808735c69cf7a538"
                        ],
                        [
                            "@@ -426,8 +426,10 @@ def create_analysis_report(mosaics, catalog, workdir, figsdir, logger):\n         # Add the analysis section to the analysis report\n         analysis_report.add_section(analysis_section)\n \n-    # Add an index to the analysis report\n+    # Add an index and the forward and backward links to the analysis report\n     analysis_report.add_index()\n+    analysis_report.set_backward(\"merStarPsfAnalysis.html\")\n+    analysis_report.set_forward(\"index.html\")\n \n     # Save the analysis report in various formats\n     json_file_name = os.path.join(workdir, \"data\", \"gaiaPsfAnalysis.json\")\n",
                            "Updates for the classification validation step",
                            "Javier Gracia Carpio",
                            "2023-08-10T19:43:44.000+00:00",
                            "08bbbf05233ab7f298b3ce157dc348546bffc8ef"
                        ],
                        [
                            "@@ -33,6 +33,7 @@ from astropy.io import fits\n import ElementsKernel.Logging as log\n \n from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import ExtDmUtils as ext_utils\n from MER_DataModelUtils import MerDmUtils as mer_utils\n from MER_DataModelUtils.FileNaming import mer_filename\n from MER_PsfMosaic.ArrayUtils import ArrayUtils\n@@ -453,8 +454,9 @@ def mainMethod(args):\n     # Do not print astropy warnings\n     AnalysisUtils.ignore_astropy_warnings()\n \n-    # Add some extra functionality to the MER data product bindings\n+    # Add some extra functionality to the MER and EXT data product bindings\n     mer_utils.init()\n+    ext_utils.init() \n \n     # Create the figures directory\n     figsdir = os.path.join(args.workdir, \"data\", \"gaiaPsfFigures\")\n",
                            "Adds missing EXT module",
                            "Javier Gracia Carpio",
                            "2023-08-10T16:38:05.000+00:00",
                            "11c68a62b2d3df6b07d494baa1e3346b933d4317"
                        ],
                        [
                            "@@ -0,0 +1,510 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+File: python/MER_PsfMosaicValidation/MER_GaiaPsfAnalysis.py\n+\n+Created on: 10/08/23\n+Author: Javier Gracia Carpio (jgracia@mpe.mpg.de)\n+\"\"\"\n+\n+import os.path\n+import argparse\n+import numpy as np\n+import matplotlib.pyplot as plt\n+from astropy import stats\n+from astropy.io import fits\n+\n+import ElementsKernel.Logging as log\n+\n+from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils.FileNaming import mer_filename\n+from MER_PsfMosaic.ArrayUtils import ArrayUtils\n+from MER_PsfMosaic.PsfFactory import PsfFactory\n+\n+from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n+from MER_PsfMosaicValidation.CatalogUtils import CatalogUtils\n+\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"Defines the command line input and output parameters specific to this\n+    program.\n+\n+    Returns\n+    -------\n+    ArgumentParser\n+\n+    \"\"\"\n+    # Get the parser instance\n+    parser = argparse.ArgumentParser()\n+\n+    # Add the input parameters\n+    parser.add_argument(\"--workdir\", dest=\"workdir\",\n+                        type=str, help=\"The working directory path.\")\n+\n+    parser.add_argument(\"--logdir\", dest=\"logdir\",\n+                        type=str, help=\"The logging directory path.\")\n+\n+    parser.add_argument(\"--mosaics\", dest=\"mosaics\",\n+                        type=str, help=\"A json file with the MER \"\n+                        \"background-subtracted mosaics XML file names.\")\n+\n+    parser.add_argument(\"--gaia_cutout\", dest=\"gaia_cutout\",\n+                        type=str, help=\"The EXT gaia cutout XML file name.\")\n+\n+    # Add the output parameters\n+    parser.add_argument(\"--analysis_result\", dest=\"analysis_result\",\n+                        type=str, help=\"The analysis result output data \"\n+                        \"product XML file name.\")\n+\n+    return parser\n+\n+\n+def plot_fwhm_comparison(fwhm_values, psf_fwhm_values, title):\n+    \"\"\"Plots a comparison between the Gaia sources and PSF FWHM values.\n+\n+    Parameters\n+    ----------\n+    fwhm_values: object\n+        A numpy array with the Gaia sources FWHM values.\n+    psf_fwhm_values: object\n+        A numpy array with the PSF FWHM values at the Gaia positions.\n+    title: str\n+        The figure title.\n+\n+    \"\"\"\n+    # Exclude very extreme values\n+    fwhm_median = np.median(fwhm_values)\n+    fwhm_std = stats.mad_std(fwhm_values)\n+    psf_fwhm_median = np.median(psf_fwhm_values)\n+    psf_fwhm_std = stats.mad_std(psf_fwhm_values)\n+    cond = np.logical_and(\n+        np.abs(fwhm_values - fwhm_median) < 10 * fwhm_std,\n+        np.abs(psf_fwhm_values - psf_fwhm_median) < 10 * psf_fwhm_std)\n+    fwhm_values = fwhm_values[cond]\n+    psf_fwhm_values = psf_fwhm_values[cond]\n+\n+    # plot the FWHM values\n+    plt.scatter(\n+        fwhm_values, psf_fwhm_values, marker=\"o\", s=4.0, alpha=0.6,\n+        edgecolors=\"none\")\n+\n+    # Make sure the x and y limits are the same\n+    xlim = plt.gca().get_xlim()\n+    ylim = plt.gca().get_ylim()\n+    new_lim = [min(xlim[0], ylim[0]), max(xlim[1], ylim[1])]\n+    plt.xlim(new_lim[0], new_lim[1])\n+    plt.ylim(new_lim[0], new_lim[1])\n+\n+    # Plot the identity line\n+    plt.plot(new_lim, new_lim, \"--k\", alpha=0.5, zorder=-1)\n+\n+    # Set the title and the label information\n+    plt.title(title)\n+    plt.xlabel(\"Gaia source FWHM values (arcsec)\")\n+    plt.ylabel(\"PSF FWHM values (arcsec)\")\n+\n+\n+def plot_stamps_comparison(image_data, psf, xy_coords, rows, columns, title):\n+    \"\"\"Plots a comparison between the Gaia source stamps and the PSF stamps.\n+\n+    Parameters\n+    ----------\n+    image_data: object\n+        A numpy array with the image data.\n+    psf: object\n+        The PSF instance.\n+    xy_coords: object\n+        A numpy array with the sources (x, y) pixel coordinates to use.\n+    rows: int\n+        The number of figure rows. The total number of sources displayed\n+        will be rows * columns.\n+    columns: int, optional\n+        The number of figure columns. The total number of sources displayed\n+        will be rows * columns.\n+    title: str\n+        The figure title.\n+\n+    \"\"\"\n+    # Randomize the source coordinates\n+    xy_coords = xy_coords[np.random.permutation(len(xy_coords))]\n+\n+    # Set the figure dimensions\n+    stamp_box_size = 1.2\n+    stamp_separation = 0.02\n+    margin_left = 0.2\n+    margin_right = 0.2\n+    margin_bottom = 0.2\n+    margin_top = 0.6 + stamp_separation\n+    figure_width = (margin_left + columns * stamp_box_size + \n+                    (columns - 1) * stamp_separation + margin_right)\n+    figure_height = (margin_bottom + rows * stamp_box_size + \n+                     (rows - 1) * stamp_separation + margin_top)\n+    figure_size = (figure_width, figure_height)\n+\n+    # Initialize the figure\n+    fig, ax_list = plt.subplots(rows, columns, figsize=figure_size)\n+    fig.suptitle(title)\n+\n+    # Set the subplot layout\n+    plt.subplots_adjust(\n+        left=margin_left / figure_width,\n+        right=(figure_width - margin_right) / figure_width,\n+        bottom=margin_bottom / figure_height,\n+        top=(figure_height - margin_top) / figure_height,\n+        wspace=stamp_separation / stamp_box_size,\n+        hspace=stamp_separation / stamp_box_size)\n+\n+    # Add the source and PSF stamps to the figure\n+    psf.set_maximum_stamp_size(49)\n+    stamp_size = psf.get_stamp_size()\n+\n+    for i, ax in enumerate(ax_list.ravel()):\n+        # Remove the axis tick marks\n+        ax.axis(\"off\")\n+\n+        # Don't plot anything if there are no more sources available\n+        source_index = int(i / 2)\n+\n+        if source_index >= len(xy_coords):\n+            continue\n+\n+        # Check if we should plot the source stamp or the PSF stamp\n+        if i % 2 == 0:\n+            # Extract the source stamp from the image data\n+            source_center = xy_coords[source_index, ::-1] - 1\n+            stamp = ArrayUtils.get_region(\n+                image_data, center=source_center, size=stamp_size)\n+\n+            # Plot the source stamp\n+            ax.imshow(\n+                stamp, origin=\"lower\", interpolation=\"nearest\",\n+                vmin=min(stamp.min(), 0))\n+        else:\n+            # Get the PSF stamp at the Gaia source (x, y) coordinate\n+            stamp = psf.get_closest_stamp_at_xy(xy_coords[source_index])\n+\n+            # Plot the PSF stamp\n+            ax.imshow(\n+                stamp.get_data(), origin=\"lower\", interpolation=\"nearest\")\n+\n+        # Add the type of stamp and the source pixel coordinates\n+        pos = np.full(2, 0.95 * stamp_size)\n+        stamp_type = \"Source\" if i % 2 == 0 else \"PSF\"\n+        round_xy_coord = np.round(xy_coords[source_index])\n+        text = \"%s (%i, %i)\" % (\n+            stamp_type, round_xy_coord[0], round_xy_coord[1])\n+        bbox = dict(facecolor=\"white\", edgecolor=\"none\", alpha=0.5)\n+        ax.text(\n+            pos[0], pos[1], text, horizontalalignment=\"right\",\n+            verticalalignment=\"top\", fontsize=8, bbox=bbox)\n+\n+\n+def create_analysis_figures(mosaic, catalog, workdir, figsdir):\n+    \"\"\"Creates some analysis figures.\n+\n+    Parameters\n+    ----------\n+    mosaic: object\n+        The MER background-subtracted mosaic product.\n+    catalog: object\n+        The Gaia cutouts catalog table.\n+    workdir: str\n+        The complete path to the working directory.\n+    figsdir: str\n+        The complete path to the directory where the figures will be saved.\n+\n+    Returns\n+    -------\n+    list\n+        A python list with the analysis figures.\n+\n+    \"\"\"\n+    # Get the mosaic filter name and the image, rms and PSF fits file names\n+    filter_name = mosaic.get_filter()\n+    image_file_name = os.path.join(workdir, \"data\", mosaic.get_data())\n+    rms_file_name = os.path.join(workdir, \"data\", mosaic.get_rms())\n+    psf_file_name = os.path.join(workdir, \"data\", mosaic.get_psf_model())\n+\n+    # Load the mosaic image, rms and PSF data from the fits files\n+    image_data = fits.getdata(image_file_name, 0)\n+    rms_data = fits.getdata(rms_file_name, 0)\n+    psf = PsfFactory.get_psf(filter_name, psf_file_name)\n+\n+    # Get the WCS information from the image fits file\n+    wcs = AnalysisUtils.get_wcs(image_file_name)\n+\n+    # Calculate the sources (x, y) pixel coordinates\n+    xy_coords = CatalogUtils.calculate_pixel_coordinates(catalog, wcs)\n+\n+    # Select only the bright sources and avoid sources that might be saturated\n+    #xy_coords = xy_coords[np.logical_and(\n+    #    catalog[\"TU_FNU_VIS\"] > 1e-6, catalog[\"TU_FNU_VIS\"] < 5e-4)]\n+\n+    # Calculate the source FWHM values in arcseconds\n+    stamp_size = 29 if filter_name in AnalysisUtils.EUCLID_FILTERS else 49\n+    fwhm_values = AnalysisUtils.calculate_fwhm_values(\n+        image_data, rms_data, xy_coords, stamp_size=stamp_size)\n+    fwhm_values *= wcs.get_cdelt()[0] * 3600\n+\n+    # Select only sources with valid FWHM values\n+    valid_fwhm = np.isfinite(fwhm_values)\n+    xy_coords = xy_coords[valid_fwhm]\n+    fwhm_values = fwhm_values[valid_fwhm]\n+\n+    # Return None if there is no sources with valid FWHM values\n+    if len(fwhm_values) == 0:\n+        return None\n+\n+    # Get the PSF FWHM values at the source positions\n+    psf_fwhm_values = np.empty(len(fwhm_values))\n+\n+    for i, xy_coord in enumerate(xy_coords):\n+        psf_fwhm_values[i] = psf.get_closest_stamp_at_xy(xy_coord).get_fwhm()\n+\n+    # Sort the sources by their FWHM values\n+    sorted_indices = np.argsort(fwhm_values)\n+    median_index = int(len(fwhm_values) / 2)\n+    fwhm_median = fwhm_values[sorted_indices[median_index]]\n+\n+    # Plot a histogram of the FWHM values\n+    AnalysisUtils.plot_fwhm_hist(\n+        fwhm_values, \"Gaia source FWHM values for band %s (median = %.3f arcsec)\" % \n+        (filter_name, fwhm_median))\n+\n+    # Save the plot in a file\n+    histogram_file_name = os.path.join(\n+        figsdir, filter_name + \"_gaia_FWHM_hist.png\")\n+    AnalysisUtils.save_plot(histogram_file_name)\n+\n+    # Plot a map of the FWHM values\n+    AnalysisUtils.plot_fwhm_map(\n+        xy_coords, fwhm_values, \"Gaia source FWHM values for band %s \"\n+        \"(median = %.3f arcsec)\" % (filter_name, fwhm_median))\n+\n+    # Save the plot in a file\n+    map_file_name = os.path.join(\n+        figsdir, filter_name + \"_gaia_FWHM_map.png\")\n+    AnalysisUtils.save_plot(map_file_name)\n+\n+    # Plot the 25 sources with the smaller FHWM values\n+    AnalysisUtils.plot_sources(\n+        image_data, xy_coords[sorted_indices[:25]],\n+        \"Gaia sources with the smaller FWHM values for band %s\" % filter_name,\n+        fwhm_values=fwhm_values[sorted_indices[:25]], rows=5, columns=5,\n+        add_pixel_coordinates=True, stamp_sizes=stamp_size)\n+\n+    # Save the plot in a file\n+    sources_small_file_name = os.path.join(\n+        figsdir, filter_name + \"_gaia_small_FWHM.png\")\n+    AnalysisUtils.save_plot(sources_small_file_name)\n+\n+    # Plot the 25 sources with median FHWM values\n+    AnalysisUtils.plot_sources(\n+        image_data,\n+        xy_coords[sorted_indices[median_index - 12:median_index + 13]],\n+        \"Gaia sources with median FWHM values for band %s\" % filter_name,\n+        fwhm_values=fwhm_values[\n+            sorted_indices[median_index - 12:median_index + 13]], rows=5,\n+        columns=5, add_pixel_coordinates=True, stamp_sizes=stamp_size)\n+\n+    # Save the plot in a file\n+    sources_median_file_name = os.path.join(\n+        figsdir, filter_name + \"_gaia_median_FWHM.png\")\n+    AnalysisUtils.save_plot(sources_median_file_name)\n+\n+    # Plot the 25 sources with the larger FHWM values\n+    AnalysisUtils.plot_sources(\n+        image_data, xy_coords[sorted_indices[-25:]],\n+        \"Gaia sources with the larger FWHM values for band %s\" % filter_name,\n+        fwhm_values=fwhm_values[sorted_indices[-25:]], rows=5, columns=5,\n+        add_pixel_coordinates=True, stamp_sizes=stamp_size)\n+\n+    # Save the plot in a file\n+    sources_large_file_name = os.path.join(\n+        figsdir, filter_name + \"_gaia_large_FWHM.png\")\n+    AnalysisUtils.save_plot(sources_large_file_name)\n+\n+    # Plot a comparison of the source and PSF fwhm values\n+    plot_fwhm_comparison(\n+        fwhm_values, psf_fwhm_values,\n+        \"Gaia source FWHM values vs. PSF FWHM values for band %s\" % filter_name)\n+\n+    # Save the plot in a file\n+    fwhm_comparison_file_name = os.path.join(\n+        figsdir, filter_name + \"_gaia_FWHM_comparison.png\")\n+    AnalysisUtils.save_plot(fwhm_comparison_file_name)\n+\n+    # Plot a comparison of the source stamps and the PSF stamps\n+    plot_stamps_comparison(\n+        image_data, psf, xy_coords, 14, 10,\n+        \"Gaia source stamps vs. PSF stamps for band %s\" % filter_name)\n+\n+    # Save the plot in a file\n+    stamps_comparison_file_name = os.path.join(\n+        figsdir, filter_name + \"_gaia_stamps_comparison.png\")\n+    AnalysisUtils.save_plot(stamps_comparison_file_name)\n+\n+    # Return the list of analysis figures\n+    analysis_figures = [\n+        AnalysisFigure(histogram_file_name, latex_scale=0.55),\n+        AnalysisFigure(map_file_name, latex_scale=0.55),\n+        AnalysisFigure(sources_small_file_name, latex_scale=0.7),\n+        AnalysisFigure(sources_median_file_name, latex_scale=0.7),\n+        AnalysisFigure(sources_large_file_name, latex_scale=0.7),\n+        AnalysisFigure(fwhm_comparison_file_name, latex_scale=0.55),\n+        AnalysisFigure(stamps_comparison_file_name, latex_scale=0.5)\n+    ]\n+\n+    return analysis_figures\n+\n+\n+def create_analysis_report(mosaics, catalog, workdir, figsdir, logger):\n+    \"\"\"Creates an analysis report.\n+\n+    Parameters\n+    ----------\n+    mosaics: dict\n+        A python dictionary with the MER background-subtracted mosaic products.\n+    catalog: object\n+        The Gaia cutout catalog table.\n+    workdir: str\n+        The complete path to the working directory.\n+    figsdir: str\n+        The complete path to the directory where the figures will be saved.\n+    logger: object\n+        A logger instance.\n+\n+    Returns\n+    -------\n+    list\n+        A python list with the analysis report file names.\n+\n+    \"\"\"\n+    # Initialize the analysis report\n+    analysis_report = AnalysisReport(\n+        \"Gaia PSF analysis for tile %s\" % mosaics[\"VIS\"].get_tile_index())\n+\n+    # Loop over all possible filter names\n+    for filter_name in AnalysisUtils.ALL_FILTERS:\n+        # Move to the next filter name if there is no mosaic for that filter\n+        if filter_name not in mosaics:\n+            continue\n+\n+        # Create the analysis figures\n+        logger.info(\"# Creating analysis figures for band %s\" % filter_name)\n+        analysis_figures = create_analysis_figures(\n+            mosaics[filter_name], catalog, workdir, figsdir)\n+\n+        # Create a new analysis section\n+        section_title = filter_name.replace(\"_\", \" \")\n+        analysis_section = AnalysisSection(section_title)\n+\n+        # Add the analysis figures to the analysis section\n+        analysis_section.set_figures(analysis_figures)\n+\n+        # Add the analysis section to the analysis report\n+        analysis_report.add_section(analysis_section)\n+\n+    # Add an index to the analysis report\n+    analysis_report.add_index()\n+\n+    # Save the analysis report in various formats\n+    json_file_name = os.path.join(workdir, \"data\", \"gaiaPsfAnalysis.json\")\n+    html_file_name = os.path.join(workdir, \"data\", \"gaiaPsfAnalysis.html\")\n+    pdflatex_file_name = os.path.join(workdir, \"data\", \"gaiaPsfAnalysis.tex\")\n+    analysis_report.save_as_json_file(json_file_name)\n+    analysis_report.save_as_html_file(html_file_name)\n+    analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n+\n+    return [json_file_name, html_file_name, pdflatex_file_name]\n+\n+\n+def mainMethod(args):\n+    \"\"\" The \"main\" method.\n+\n+    \"\"\"\n+    # Get a logger instance\n+    logger = log.getLogger(\"MER_GaiaPsfAnalysis\")\n+\n+    logger.info(\"#\")\n+    logger.info(\"# Entering MER_GaiaPsfAnalysis mainMethod()\")\n+    logger.info(\"#\")\n+\n+    # Do not print astropy warnings\n+    AnalysisUtils.ignore_astropy_warnings()\n+\n+    # Add some extra functionality to the MER data product bindings\n+    mer_utils.init()\n+\n+    # Create the figures directory\n+    figsdir = os.path.join(args.workdir, \"data\", \"gaiaPsfFigures\")\n+    AnalysisUtils.create_directory(figsdir)\n+\n+    # Load the MER background-subtracted mosaics\n+    mosaics = AnalysisUtils.get_background_subtracted_mosaics(\n+        os.path.join(args.workdir, args.mosaics), args.workdir)\n+\n+    # Load the Gaia cutout catalog\n+    gaia_cutout = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.gaia_cutout))\n+\n+    # Read the Gaia cutout catalog table\n+    catalog = CatalogUtils.read_catalog(\n+        os.path.join(args.workdir, \"data\", gaia_cutout.get_data()))\n+\n+    # Get the tile index, the processing mode and the observation ids\n+    tile_index = mosaics[\"VIS\"].get_tile_index()\n+    processing_mode = mosaics[\"VIS\"].get_processing_mode()\n+    observation_ids = set()\n+\n+    for mosaic in mosaics.values():\n+        observation_ids.update(mosaic.get_observation_id_list())\n+\n+    # Create the analysis report\n+    logger.info(\"# Creating the Gaia PSF analysis report...\")\n+    report_file_names = create_analysis_report(\n+        mosaics, catalog, args.workdir, figsdir, logger)\n+\n+    # Save all the analysis files into a tar file\n+    tar_file_name = mer_filename(\n+        \"ANALYSIS-RESULT\", prefix=\"GAIA-PSF\", tile_index=tile_index,\n+        ext=\"tar.gz\")\n+    AnalysisUtils.save_tar_file(\n+        os.path.join(args.workdir, \"data\", tar_file_name),\n+        report_file_names + [figsdir])\n+\n+    # Create the analysis result data product\n+    global_result = \"PASSED\"\n+    analysis_result = mer_utils.create_analysis_result(global_result)\n+    analysis_result.set_tile_index(tile_index)\n+    analysis_result.set_observation_id_list(observation_ids)\n+    analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_figures_tar_file(tar_file_name)\n+\n+    # Save the analysis result data product as an XML file\n+    logger.info(\"# Saving the analysis result data product\")\n+    analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n+\n+    logger.info(\"#\")\n+    logger.info(\"# Exiting MER_GaiaPsfAnalysis mainMethod()\")\n+    logger.info(\"#\")\n",
                            "Adds the Gaia PSF validation step",
                            "Javier Gracia Carpio",
                            "2023-08-10T16:19:25.000+00:00",
                            "7c108a4a124a563b5ffeceb7d3233ae670d11007"
                        ]
                    ],
                    "MER_Validation/python/MER_Validation/MER_AstrometryValidationPrg.py": [
                        [
                            "@@ -196,7 +196,7 @@ def mainMethod(args):\n     gaia_data = fits.getdata(os.path.join(args.workdir, 'data', gaia_catalog.get_data()))\n     \n     # select the GAIA ID's in the final catalog    \n-    gaia_selector=numpy.where(numpy.logical_and(mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG, mer_data['GAIA_ID']>0),True, False)\n+    gaia_selector=numpy.where(numpy.logical_and(mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG, mer_data['GAIA_ID']!=-1),True, False)\n     logger.info('# No. of GAIA matches: %i' % len(mer_data['GAIA_ID'][gaia_selector]))\n     results_dict['n_gaia_matches'] = len(mer_data['GAIA_ID'][gaia_selector])\n \n",
                            "Included some internal links and minor improvements",
                            "Martin Kuemmel",
                            "2023-08-16T22:47:44.000+02:00",
                            "e2fe49ac5109e9e5e2ffded6d1a58aabf6225fe5"
                        ],
                        [
                            "@@ -144,7 +144,8 @@ def create_analysis_report(results_dict, workdir, logger):\n     json_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.json\")\n     html_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.html\")\n     pdflatex_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.tex\")\n-    analysis_report.set_backward(\"detectionValidation.html\")\n+    analysis_report.set_backward(\"photometryValidation.html\")\n+    analysis_report.set_forward(\"detectionValidation.html\")\n     analysis_report.save_as_json_file(json_file_name)\n     analysis_report.save_as_html_file(html_file_name)\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-27T17:00:08.000+02:00",
                            "a29716cea96bd9952a85e0d027784845fe5b7f03"
                        ],
                        [
                            "@@ -56,6 +56,7 @@ from MER_Utils import MER_ArrayStatistics\n \n from MER_Validation import MER_PhotometryValidation\n \n+from MER_DA.MERUtilities import print_input_arguments\n \n def defineSpecificProgramOptions():\n     \"\"\"\n@@ -143,7 +144,8 @@ def create_analysis_report(results_dict, workdir, logger):\n     json_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.json\")\n     html_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.html\")\n     pdflatex_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.tex\")\n-    analysis_report.set_backward('index.html')\n+    analysis_report.set_backward(\"photometryValidation.html\")\n+    analysis_report.set_forward(\"detectionValidation.html\")\n     analysis_report.save_as_json_file(json_file_name)\n     analysis_report.save_as_html_file(html_file_name)\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ],
                        [
                            "@@ -144,7 +144,8 @@ def create_analysis_report(results_dict, workdir, logger):\n     json_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.json\")\n     html_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.html\")\n     pdflatex_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.tex\")\n-    analysis_report.set_backward(\"detectionValidation.html\")\n+    analysis_report.set_backward(\"photometryValidation.html\")\n+    analysis_report.set_forward(\"detectionValidation.html\")\n     analysis_report.save_as_json_file(json_file_name)\n     analysis_report.save_as_html_file(html_file_name)\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n",
                            "Some mopping up and re-ordering",
                            "Martin Kuemmel",
                            "2023-07-21T10:47:49.000+02:00",
                            "1ff024aab348769fdd7dd60a20c39aae119902e7"
                        ],
                        [
                            "@@ -144,7 +144,7 @@ def create_analysis_report(results_dict, workdir, logger):\n     json_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.json\")\n     html_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.html\")\n     pdflatex_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.tex\")\n-    analysis_report.set_backward(os.path.join(workdir, \"data\", \"detectionValidation.html\"))\n+    analysis_report.set_backward(\"detectionValidation.html\")\n     analysis_report.save_as_json_file(json_file_name)\n     analysis_report.save_as_html_file(html_file_name)\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-18T18:37:53.000+02:00",
                            "78c5119e500255574c19c53cb5e9713d82f04f41"
                        ],
                        [
                            "@@ -144,7 +144,7 @@ def create_analysis_report(results_dict, workdir, logger):\n     json_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.json\")\n     html_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.html\")\n     pdflatex_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.tex\")\n-    analysis_report.set_backward(os.path.join(workdir, \"data\", \"detectionValidation.html\"))\n+    analysis_report.set_backward(\"detectionValidation.html\")\n     analysis_report.save_as_json_file(json_file_name)\n     analysis_report.save_as_html_file(html_file_name)\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n",
                            "Create a generic parameter for the filling factor",
                            "Martin Kuemmel",
                            "2023-07-11T16:22:45.000+02:00",
                            "ccc800212f1732126ed243791b6fafaf339c0029"
                        ],
                        [
                            "@@ -38,6 +38,7 @@ from astropy import units as u\n \n from MER_DataModelUtils import DmUtils as dm_utils\n from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils import ExtDmUtils as ext_utils\n from MER_DataModelUtils.FileNaming import mer_filename\n \n from MER_DA import MER_CrossMatchModule\n@@ -55,6 +56,7 @@ from MER_Utils import MER_ArrayStatistics\n \n from MER_Validation import MER_PhotometryValidation\n \n+from MER_DA.MERUtilities import print_input_arguments\n \n def defineSpecificProgramOptions():\n     \"\"\"\n@@ -67,11 +69,11 @@ def defineSpecificProgramOptions():\n \n     parser = argparse.ArgumentParser()\n \n-    parser.add_argument('--mer_catalog', dest='mer_catalog', type=str, required=True,\n-                        help='path to the catalog to be validated')\n+    parser.add_argument('--final_catalog', dest='final_catalog', type=str, required=True,\n+                        help='XML-path to the catalog to be validated')\n     parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n                         help='path to the gaia cutout')\n-    parser.add_argument('--output_json', dest='output_json', type=str, required=False,\n+    parser.add_argument('--astrometry_json', dest='astrometry_json', type=str, required=False,\n                         default='astrometry_validation.json', help='Json file for output, default: \"astrometry_validation.json\")!')\n     parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n                         default='./', help='Path to the working directory: \"%(default)s\"!')\n@@ -142,7 +144,7 @@ def create_analysis_report(results_dict, workdir, logger):\n     json_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.json\")\n     html_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.html\")\n     pdflatex_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.tex\")\n-    analysis_report.set_backward('index.html')\n+    analysis_report.set_backward(os.path.join(workdir, \"data\", \"detectionValidation.html\"))\n     analysis_report.save_as_json_file(json_file_name)\n     analysis_report.save_as_html_file(html_file_name)\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n@@ -170,23 +172,35 @@ def mainMethod(args):\n \n     # Add some extra functionality to the MER data product bindings\n     mer_utils.init()\n+    ext_utils.init() \n \n     # Load the configuration parameters\n     configuration_parameters = AnalysisUtils.get_configuration_parameters(\n         os.path.join(args.workdir, args.configuration_set),\n         \"astrometry_validation\", args.workdir)\n \n+    # Load the MER final catalog and the Gaia cutout catalog\n+    final_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.final_catalog))\n+    gaia_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.gaia_cutout))\n+\n+    # Get the tile index, the observation ids and the processing mode\n+    tile_index = final_catalog.get_tile_index()\n+    observation_ids = final_catalog.get_observation_id_list()\n+    processing_mode = final_catalog.get_processing_mode()\n+\n     # get all table data    \n-    gaia_data = fits.getdata(os.path.join(args.workdir, 'data', args.gaia_cutout))\n-    mer_data = fits.getdata(os.path.join(args.workdir, 'data', args.mer_catalog))\n+    mer_data = fits.getdata(os.path.join(args.workdir, 'data', final_catalog.get_data()))\n+    gaia_data = fits.getdata(os.path.join(args.workdir, 'data', gaia_catalog.get_data()))\n     \n     # select the GAIA ID's in the final catalog    \n-    gaia_selector=numpy.where(numpy.logical_and(mer_data['GAIA_OBJECT_ID'] != NullValueDefinition().LONG_LONG, mer_data['GAIA_OBJECT_ID']>0),True, False)\n+    gaia_selector=numpy.where(numpy.logical_and(mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG, mer_data['GAIA_ID']>0),True, False)\n     logger.info('# No. of GAIA matches: %i' % len(mer_data['GAIA_ID'][gaia_selector]))\n     results_dict['n_gaia_matches'] = len(mer_data['GAIA_ID'][gaia_selector])\n \n     # intersect the GAIA ID's from the final catalog with the GAIA catalog\n-    source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_OBJECT_ID'][gaia_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n+    source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_ID'][gaia_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n \n     # extract RA/Dec for GAIA sources from the final catalog \n     ra_mer = mer_data['RIGHT_ASCENSION'][gaia_selector][mer_indices]\n@@ -231,7 +245,7 @@ def mainMethod(args):\n     report_file_names = create_analysis_report(results_dict, args.workdir, logger)\n \n     # Writing to sample.json\n-    output_json_path = os.path.join(args.workdir, 'data', args.output_json)\n+    output_json_path = os.path.join(args.workdir, 'data', args.astrometry_json)\n     with open(output_json_path, \"w+\") as out_json:\n         out_json.write(json.dumps(results_dict, indent=4))\n \n@@ -239,10 +253,10 @@ def mainMethod(args):\n     #tar_file_name = mer_filename(\n     #    \"VALIDATION-RESULT\", prefix=\"ASTROMETRY\", tile_index=tile_id, ext=\"tar.gz\")\n     tar_file_name = mer_filename(\n-        \"VALIDATION-RESULT\", prefix=\"DETECTION\", tile_index=0, ext=\"tar.gz\")\n+        \"VALIDATION-RESULT\", prefix=\"DETECTION\", tile_index=tile_index, ext=\"tar.gz\")\n     AnalysisUtils.save_tar_file(\n         os.path.join(args.workdir, \"data\", tar_file_name),\n-        report_file_names + [output_json_path])\n+        report_file_names + [output_json_path, results_dict['astrometry_plot']])\n         #report_file_names + [figsdir, output_json_path])\n \n \n@@ -253,9 +267,9 @@ def mainMethod(args):\n         global_result = \"FAILED\"\n \n     analysis_result = mer_utils.create_analysis_result(global_result)\n-    #analysis_result.set_tile_index(tile_id)\n-    #analysis_result.set_observation_id_list(observation_ids)\n-    #analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_tile_index(tile_index)\n+    analysis_result.set_observation_id_list(observation_ids)\n+    analysis_result.set_processing_mode(processing_mode)\n     analysis_result.set_figures_tar_file(tar_file_name)\n \n     # Save the analysis result data product as an XML file\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-10T15:27:04.000+02:00",
                            "b4030040f2cf4ffc0140a2f4f30e0e1b83a1ff07"
                        ],
                        [
                            "@@ -56,6 +56,7 @@ from MER_Utils import MER_ArrayStatistics\n \n from MER_Validation import MER_PhotometryValidation\n \n+from MER_DA.MERUtilities import print_input_arguments\n \n def defineSpecificProgramOptions():\n     \"\"\"\n@@ -143,7 +144,7 @@ def create_analysis_report(results_dict, workdir, logger):\n     json_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.json\")\n     html_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.html\")\n     pdflatex_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.tex\")\n-    analysis_report.set_backward('index.html')\n+    analysis_report.set_backward(os.path.join(workdir, \"data\", \"detectionValidation.html\"))\n     analysis_report.save_as_json_file(json_file_name)\n     analysis_report.save_as_html_file(html_file_name)\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n",
                            "Results are displayed as intended",
                            "Martin Kuemmel",
                            "2023-07-05T17:38:13.000+02:00",
                            "88b17ad283d888d70c3cf9f6bab4ca215139258e"
                        ],
                        [
                            "@@ -266,7 +266,7 @@ def mainMethod(args):\n         global_result = \"FAILED\"\n \n     analysis_result = mer_utils.create_analysis_result(global_result)\n-    analysis_result.set_tile_index(tile_id)\n+    analysis_result.set_tile_index(tile_index)\n     analysis_result.set_observation_id_list(observation_ids)\n     analysis_result.set_processing_mode(processing_mode)\n     analysis_result.set_figures_tar_file(tar_file_name)\n",
                            "Fixes typo",
                            "Javier Gracia Carpio",
                            "2023-07-05T10:32:50.000+00:00",
                            "85e56c5f1a24dc4760e67f3d2940707d8ae1d8cd"
                        ],
                        [
                            "@@ -178,12 +178,17 @@ def mainMethod(args):\n         os.path.join(args.workdir, args.configuration_set),\n         \"astrometry_validation\", args.workdir)\n \n-    # Load the MER final catalog\n+    # Load the MER final catalog and the Gaia cutout catalog\n     final_catalog = dm_utils.read_product_metadata(\n         os.path.join(args.workdir, args.final_catalog))\n     gaia_catalog = dm_utils.read_product_metadata(\n         os.path.join(args.workdir, args.gaia_cutout))\n \n+    # Get the tile index, the observation ids and the processing mode\n+    tile_index = final_catalog.get_tile_index()\n+    observation_ids = final_catalog.get_observation_id_list()\n+    processing_mode = final_catalog.get_processing_mode()\n+\n     # get all table data    \n     mer_data = fits.getdata(os.path.join(args.workdir, 'data', final_catalog.get_data()))\n     gaia_data = fits.getdata(os.path.join(args.workdir, 'data', gaia_catalog.get_data()))\n@@ -247,7 +252,7 @@ def mainMethod(args):\n     #tar_file_name = mer_filename(\n     #    \"VALIDATION-RESULT\", prefix=\"ASTROMETRY\", tile_index=tile_id, ext=\"tar.gz\")\n     tar_file_name = mer_filename(\n-        \"VALIDATION-RESULT\", prefix=\"DETECTION\", tile_index=0, ext=\"tar.gz\")\n+        \"VALIDATION-RESULT\", prefix=\"DETECTION\", tile_index=tile_index, ext=\"tar.gz\")\n     AnalysisUtils.save_tar_file(\n         os.path.join(args.workdir, \"data\", tar_file_name),\n         report_file_names + [output_json_path, results_dict['astrometry_plot']])\n@@ -261,9 +266,9 @@ def mainMethod(args):\n         global_result = \"FAILED\"\n \n     analysis_result = mer_utils.create_analysis_result(global_result)\n-    #analysis_result.set_tile_index(tile_id)\n-    #analysis_result.set_observation_id_list(observation_ids)\n-    #analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_tile_index(tile_id)\n+    analysis_result.set_observation_id_list(observation_ids)\n+    analysis_result.set_processing_mode(processing_mode)\n     analysis_result.set_figures_tar_file(tar_file_name)\n \n     # Save the analysis result data product as an XML file\n",
                            "Some improvements for the XML information",
                            "Javier Gracia Carpio",
                            "2023-07-05T09:36:48.000+00:00",
                            "a2189f64fb4beee461d1b6a9705589ff184970c1"
                        ],
                        [
                            "@@ -68,11 +68,11 @@ def defineSpecificProgramOptions():\n \n     parser = argparse.ArgumentParser()\n \n-    parser.add_argument('--mer_catalog', dest='mer_catalog', type=str, required=True,\n-                        help='path to the catalog to be validated')\n+    parser.add_argument('--final_catalog', dest='final_catalog', type=str, required=True,\n+                        help='XML-path to the catalog to be validated')\n     parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n                         help='path to the gaia cutout')\n-    parser.add_argument('--output_json', dest='output_json', type=str, required=False,\n+    parser.add_argument('--astrometry_json', dest='astrometry_json', type=str, required=False,\n                         default='astrometry_validation.json', help='Json file for output, default: \"astrometry_validation.json\")!')\n     parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n                         default='./', help='Path to the working directory: \"%(default)s\"!')\n@@ -171,7 +171,7 @@ def mainMethod(args):\n \n     # Add some extra functionality to the MER data product bindings\n     mer_utils.init()\n-    ext_utils.init()\n+    ext_utils.init() \n \n     # Load the configuration parameters\n     configuration_parameters = AnalysisUtils.get_configuration_parameters(\n@@ -179,13 +179,13 @@ def mainMethod(args):\n         \"astrometry_validation\", args.workdir)\n \n     # Load the MER final catalog\n-    mer_catalog = dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.mer_catalog))\n+    final_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.final_catalog))\n     gaia_catalog = dm_utils.read_product_metadata(\n         os.path.join(args.workdir, args.gaia_cutout))\n \n     # get all table data    \n-    mer_data = fits.getdata(os.path.join(args.workdir, 'data', mer_catalog.get_data()))\n+    mer_data = fits.getdata(os.path.join(args.workdir, 'data', final_catalog.get_data()))\n     gaia_data = fits.getdata(os.path.join(args.workdir, 'data', gaia_catalog.get_data()))\n     \n     # select the GAIA ID's in the final catalog    \n@@ -239,7 +239,7 @@ def mainMethod(args):\n     report_file_names = create_analysis_report(results_dict, args.workdir, logger)\n \n     # Writing to sample.json\n-    output_json_path = os.path.join(args.workdir, 'data', args.output_json)\n+    output_json_path = os.path.join(args.workdir, 'data', args.astrometry_json)\n     with open(output_json_path, \"w+\") as out_json:\n         out_json.write(json.dumps(results_dict, indent=4))\n \n@@ -250,7 +250,7 @@ def mainMethod(args):\n         \"VALIDATION-RESULT\", prefix=\"DETECTION\", tile_index=0, ext=\"tar.gz\")\n     AnalysisUtils.save_tar_file(\n         os.path.join(args.workdir, \"data\", tar_file_name),\n-        report_file_names + [output_json_path])\n+        report_file_names + [output_json_path, results_dict['astrometry_plot']])\n         #report_file_names + [figsdir, output_json_path])\n \n \n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T21:40:08.000+00:00",
                            "696982ed8506ddb56f2beca6b7fe88377fa08c21"
                        ],
                        [
                            "@@ -72,7 +72,7 @@ def defineSpecificProgramOptions():\n                         help='XML-path to the catalog to be validated')\n     parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n                         help='path to the gaia cutout')\n-    parser.add_argument('--output_json', dest='output_json', type=str, required=False,\n+    parser.add_argument('--astrometry_json', dest='astrometry_json', type=str, required=False,\n                         default='astrometry_validation.json', help='Json file for output, default: \"astrometry_validation.json\")!')\n     parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n                         default='./', help='Path to the working directory: \"%(default)s\"!')\n@@ -239,7 +239,7 @@ def mainMethod(args):\n     report_file_names = create_analysis_report(results_dict, args.workdir, logger)\n \n     # Writing to sample.json\n-    output_json_path = os.path.join(args.workdir, 'data', args.output_json)\n+    output_json_path = os.path.join(args.workdir, 'data', args.astrometry_json)\n     with open(output_json_path, \"w+\") as out_json:\n         out_json.write(json.dumps(results_dict, indent=4))\n \n",
                            "Making it pipeline ready",
                            "Martin Kuemmel",
                            "2023-07-04T23:17:20.000+02:00",
                            "f918deca60ada4d351444ba20467a7703195eb00"
                        ],
                        [
                            "@@ -250,7 +250,7 @@ def mainMethod(args):\n         \"VALIDATION-RESULT\", prefix=\"DETECTION\", tile_index=0, ext=\"tar.gz\")\n     AnalysisUtils.save_tar_file(\n         os.path.join(args.workdir, \"data\", tar_file_name),\n-        report_file_names + [output_json_path])\n+        report_file_names + [output_json_path, results_dict['astrometry_plot']])\n         #report_file_names + [figsdir, output_json_path])\n \n \n",
                            "Added the plot to the tarball",
                            "Martin Kuemmel",
                            "2023-07-04T21:14:43.000+02:00",
                            "5c4888f55db223e87f92134a0deadd7728e79ee2"
                        ],
                        [
                            "@@ -181,15 +181,12 @@ def mainMethod(args):\n     # Load the MER final catalog\n     final_catalog = dm_utils.read_product_metadata(\n         os.path.join(args.workdir, args.final_catalog))\n-    final_catalog_path = os.path.join(args.workdir, \"data\", final_catalog.get_data())\n+    gaia_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.gaia_cutout))\n \n-    # load the GAIA cutout   \n-    gaia_cutout = dm_utils.read_product_metadata(os.path.join(args.workdir, args.gaia_cutout))\n-    gaia_cutout_path = os.path.join(args.workdir, 'data', gaia_cutout.get_data())\n-            \n     # get all table data    \n-    gaia_data = fits.getdata(gaia_cutout_path)\n-    mer_data = fits.getdata(final_catalog_path)\n+    mer_data = fits.getdata(os.path.join(args.workdir, 'data', final_catalog.get_data()))\n+    gaia_data = fits.getdata(os.path.join(args.workdir, 'data', gaia_catalog.get_data()))\n     \n     # select the GAIA ID's in the final catalog    \n     gaia_selector=numpy.where(numpy.logical_and(mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG, mer_data['GAIA_ID']>0),True, False)\n",
                            "Merge remote-tracking branch 'origin/develop' into",
                            "Martin Kuemmel",
                            "2023-07-04T21:06:22.000+02:00",
                            "9df9a0bbe52422666d398f4cedc0bca63a870d5c"
                        ],
                        [
                            "@@ -38,6 +38,7 @@ from astropy import units as u\n \n from MER_DataModelUtils import DmUtils as dm_utils\n from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils import ExtDmUtils as ext_utils\n from MER_DataModelUtils.FileNaming import mer_filename\n \n from MER_DA import MER_CrossMatchModule\n@@ -67,8 +68,8 @@ def defineSpecificProgramOptions():\n \n     parser = argparse.ArgumentParser()\n \n-    parser.add_argument('--mer_catalog', dest='mer_catalog', type=str, required=True,\n-                        help='path to the catalog to be validated')\n+    parser.add_argument('--final_catalog', dest='final_catalog', type=str, required=True,\n+                        help='XML-path to the catalog to be validated')\n     parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n                         help='path to the gaia cutout')\n     parser.add_argument('--output_json', dest='output_json', type=str, required=False,\n@@ -170,23 +171,33 @@ def mainMethod(args):\n \n     # Add some extra functionality to the MER data product bindings\n     mer_utils.init()\n+    ext_utils.init() \n \n     # Load the configuration parameters\n     configuration_parameters = AnalysisUtils.get_configuration_parameters(\n         os.path.join(args.workdir, args.configuration_set),\n         \"astrometry_validation\", args.workdir)\n \n+    # Load the MER final catalog\n+    final_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.final_catalog))\n+    final_catalog_path = os.path.join(args.workdir, \"data\", final_catalog.get_data())\n+\n+    # load the GAIA cutout   \n+    gaia_cutout = dm_utils.read_product_metadata(os.path.join(args.workdir, args.gaia_cutout))\n+    gaia_cutout_path = os.path.join(args.workdir, 'data', gaia_cutout.get_data())\n+            \n     # get all table data    \n-    gaia_data = fits.getdata(os.path.join(args.workdir, 'data', args.gaia_cutout))\n-    mer_data = fits.getdata(os.path.join(args.workdir, 'data', args.mer_catalog))\n+    gaia_data = fits.getdata(gaia_cutout_path)\n+    mer_data = fits.getdata(final_catalog_path)\n     \n     # select the GAIA ID's in the final catalog    \n-    gaia_selector=numpy.where(numpy.logical_and(mer_data['GAIA_OBJECT_ID'] != NullValueDefinition().LONG_LONG, mer_data['GAIA_OBJECT_ID']>0),True, False)\n+    gaia_selector=numpy.where(numpy.logical_and(mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG, mer_data['GAIA_ID']>0),True, False)\n     logger.info('# No. of GAIA matches: %i' % len(mer_data['GAIA_ID'][gaia_selector]))\n     results_dict['n_gaia_matches'] = len(mer_data['GAIA_ID'][gaia_selector])\n \n     # intersect the GAIA ID's from the final catalog with the GAIA catalog\n-    source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_OBJECT_ID'][gaia_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n+    source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_ID'][gaia_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n \n     # extract RA/Dec for GAIA sources from the final catalog \n     ra_mer = mer_data['RIGHT_ASCENSION'][gaia_selector][mer_indices]\n",
                            "Started integrating detection validation",
                            "Martin Kuemmel",
                            "2023-07-04T20:56:37.000+02:00",
                            "597608469db752cb043620ddd90606a13a97cd52"
                        ],
                        [
                            "@@ -189,12 +189,12 @@ def mainMethod(args):\n     gaia_data = fits.getdata(os.path.join(args.workdir, 'data', gaia_catalog.get_data()))\n     \n     # select the GAIA ID's in the final catalog    \n-    gaia_selector=numpy.where(numpy.logical_and(mer_data['GAIA_OBJECT_ID'] != NullValueDefinition().LONG_LONG, mer_data['GAIA_OBJECT_ID']>0),True, False)\n+    gaia_selector=numpy.where(numpy.logical_and(mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG, mer_data['GAIA_ID']>0),True, False)\n     logger.info('# No. of GAIA matches: %i' % len(mer_data['GAIA_ID'][gaia_selector]))\n     results_dict['n_gaia_matches'] = len(mer_data['GAIA_ID'][gaia_selector])\n \n     # intersect the GAIA ID's from the final catalog with the GAIA catalog\n-    source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_OBJECT_ID'][gaia_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n+    source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_ID'][gaia_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n \n     # extract RA/Dec for GAIA sources from the final catalog \n     ra_mer = mer_data['RIGHT_ASCENSION'][gaia_selector][mer_indices]\n",
                            "Fix wrong column name",
                            "Javier Gracia Carpio",
                            "2023-07-04T15:12:07.000+00:00",
                            "c654380d37d69c3418dc25c3f426bb3ae8c1b515"
                        ],
                        [
                            "@@ -38,6 +38,7 @@ from astropy import units as u\n \n from MER_DataModelUtils import DmUtils as dm_utils\n from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils import ExtDmUtils as ext_utils\n from MER_DataModelUtils.FileNaming import mer_filename\n \n from MER_DA import MER_CrossMatchModule\n@@ -170,15 +171,22 @@ def mainMethod(args):\n \n     # Add some extra functionality to the MER data product bindings\n     mer_utils.init()\n+    ext_utils.init()\n \n     # Load the configuration parameters\n     configuration_parameters = AnalysisUtils.get_configuration_parameters(\n         os.path.join(args.workdir, args.configuration_set),\n         \"astrometry_validation\", args.workdir)\n \n+    # Load the MER final catalog\n+    mer_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.mer_catalog))\n+    gaia_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.gaia_cutout))\n+\n     # get all table data    \n-    gaia_data = fits.getdata(os.path.join(args.workdir, 'data', args.gaia_cutout))\n-    mer_data = fits.getdata(os.path.join(args.workdir, 'data', args.mer_catalog))\n+    mer_data = fits.getdata(os.path.join(args.workdir, 'data', mer_catalog.get_data()))\n+    gaia_data = fits.getdata(os.path.join(args.workdir, 'data', gaia_catalog.get_data()))\n     \n     # select the GAIA ID's in the final catalog    \n     gaia_selector=numpy.where(numpy.logical_and(mer_data['GAIA_OBJECT_ID'] != NullValueDefinition().LONG_LONG, mer_data['GAIA_OBJECT_ID']>0),True, False)\n",
                            "Reads xmls instead of fits files",
                            "Javier Gracia Carpio",
                            "2023-07-04T14:46:03.000+00:00",
                            "7d0c4b642f220f9f621ca8b1214efe9a9bfee700"
                        ],
                        [
                            "@@ -0,0 +1,269 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+:file: python/MER_Validation/MER_GagaPrg.py\n+\n+:date: 06/28/23\n+:author: mkuemmel@usm.lmu.de\n+\n+\"\"\"\n+import time\n+import json\n+import math\n+import os.path\n+import argparse\n+import ElementsKernel.Logging as log\n+\n+import numpy\n+import matplotlib.pyplot as plt\n+\n+from astropy.io import fits\n+from astropy import units as u\n+\n+from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils.FileNaming import mer_filename\n+\n+from MER_DA import MER_CrossMatchModule\n+from MER_DA.MER_CrossMatchModule import MER_position_crossmatch\n+from MER_DetectionValidation import MER_AstroValidationPlots\n+from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisTable import AnalysisTable\n+from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n+\n+from EL_NullValue import NullValueDefinition\n+\n+from MER_Utils import MER_ArrayStatistics\n+\n+from MER_Validation import MER_PhotometryValidation\n+\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"\n+    @brief Allows to define the (command line and configuration file) options\n+    specific to this program\n+\n+    @details See the Elements documentation for more details.\n+    @return An  ArgumentParser.\n+    \"\"\"\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser.add_argument('--mer_catalog', dest='mer_catalog', type=str, required=True,\n+                        help='path to the catalog to be validated')\n+    parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n+                        help='path to the gaia cutout')\n+    parser.add_argument('--output_json', dest='output_json', type=str, required=False,\n+                        default='astrometry_validation.json', help='Json file for output, default: \"astrometry_validation.json\")!')\n+    parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n+                        default='./', help='Path to the working directory: \"%(default)s\"!')\n+    parser.add_argument(\"--logdir\", dest=\"logdir\", required=False, default='./',\n+                        type=str, help='The logging directory path: \"%(default)s\"!')\n+    parser.add_argument(\"--analysis_result\", dest=\"analysis_result\",\n+                        type=str, help=\"The analysis result output data \"\n+                        \"product XML file name.\")\n+    parser.add_argument(\"--configuration_set\", dest=\"configuration_set\",\n+                        type=str, help=\"The MER Configuration Set product XML \"\n+                        \"file name.\")\n+\n+    return parser\n+\n+def create_analysis_report(results_dict, workdir, logger):\n+    \"\"\"Creates an analysis report.\n+\n+    Parameters\n+    ----------\n+    results_dict: dictionary\n+        All results from the detection analysis\n+    workdir: str\n+        The complete path to the working directory.\n+    logger: object\n+        A logger instance.\n+\n+    Returns\n+    -------\n+    list\n+        A python list with the analysis report file names.\n+\n+    \"\"\"\n+    logger.info(\"# Creating the analysis report!\")\n+\n+    # Initialize the analysis report without filling factor\n+    analysis_report = AnalysisReport('MER astrometry validation')\n+\n+    # Create a new analysis section and add all validation results\n+    validation_section = AnalysisSection(\"Astrometric validation\")\n+    validation_table = AnalysisTable(['Validation quantity', 'Result'],\n+                                     [['All', 'RA median offset', 'Dec median offset', 'RA std offset', 'Dec std offset'],\n+                                      ['%s' % results_dict['valid'], '%s' % results_dict['ra_mean_valid'], '%s' % results_dict['dec_mean_valid'], '%s' % results_dict['ra_std_valid'], '%s' % results_dict['dec_std_valid']]])\n+    validation_section.add_table(validation_table)\n+    analysis_report.add_section(validation_section)\n+\n+    # Create a new analysis section and add the crossmatch statistics\n+    crossmatch_section = AnalysisSection(\"Crossmatch accuracy for GAIA stars\")\n+\n+    crossmatch_table = AnalysisTable(['Delta quantity', 'value [\"]'],\n+                                     [['# of matches', 'RA tmean', 'RA tstd', 'Dec tmean', 'Dec tstd'],\n+                                      [results_dict['n_gaia_matches'],\n+                                       '%e' % results_dict['delta_ra_stats']['tmean'],\n+                                       '%e' % results_dict['delta_ra_stats']['tstd'],\n+                                       '%e' % results_dict['delta_dec_stats']['tmean'],\n+                                       '%e' % results_dict['delta_dec_stats']['tstd']]])\n+    crossmatch_section.add_table(crossmatch_table)\n+    analysis_report.add_section(crossmatch_section)\n+\n+   # Create a new analysis section and add the crossmatch figure\n+    crossmatch_plot_section = AnalysisSection(\"Astrometry crossmatch results\")\n+    crossmatch_plot_section.set_figures([AnalysisFigure(results_dict['astrometry_plot'],latex_scale=0.55)])\n+    analysis_report.add_section(crossmatch_plot_section)\n+\n+    # Add an index to the analysis report\n+    analysis_report.add_index()\n+\n+    # Save the analysis report in various formats\n+    json_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.json\")\n+    html_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.html\")\n+    pdflatex_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.tex\")\n+    analysis_report.set_backward('index.html')\n+    analysis_report.save_as_json_file(json_file_name)\n+    analysis_report.save_as_html_file(html_file_name)\n+    analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n+\n+    return [json_file_name, html_file_name, pdflatex_file_name]\n+\n+def mainMethod(args):\n+    \"\"\"\n+    @brief The \"main\" method.\n+    \n+    @details This method is the entry point to the program. In this sense, it is\n+    similar to a main (and it is why it is called mainMethod()).\n+    \"\"\"\n+    logger = log.getLogger('MER_AstrometryValidationPrg')\n+\n+    logger.info('#')\n+    logger.info('# Entering MER_AstrometryValidationPrg mainMethod()')\n+    logger.info('#')\n+\n+    # Store the start time\n+    start_time = time.time()\n+\n+    # start the dict for the results\n+    results_dict = {}\n+\n+    # Add some extra functionality to the MER data product bindings\n+    mer_utils.init()\n+\n+    # Load the configuration parameters\n+    configuration_parameters = AnalysisUtils.get_configuration_parameters(\n+        os.path.join(args.workdir, args.configuration_set),\n+        \"astrometry_validation\", args.workdir)\n+\n+    # get all table data    \n+    gaia_data = fits.getdata(os.path.join(args.workdir, 'data', args.gaia_cutout))\n+    mer_data = fits.getdata(os.path.join(args.workdir, 'data', args.mer_catalog))\n+    \n+    # select the GAIA ID's in the final catalog    \n+    gaia_selector=numpy.where(numpy.logical_and(mer_data['GAIA_OBJECT_ID'] != NullValueDefinition().LONG_LONG, mer_data['GAIA_OBJECT_ID']>0),True, False)\n+    logger.info('# No. of GAIA matches: %i' % len(mer_data['GAIA_ID'][gaia_selector]))\n+    results_dict['n_gaia_matches'] = len(mer_data['GAIA_ID'][gaia_selector])\n+\n+    # intersect the GAIA ID's from the final catalog with the GAIA catalog\n+    source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_OBJECT_ID'][gaia_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n+\n+    # extract RA/Dec for GAIA sources from the final catalog \n+    ra_mer = mer_data['RIGHT_ASCENSION'][gaia_selector][mer_indices]\n+    dec_mer = mer_data['DECLINATION'][gaia_selector][mer_indices]\n+\n+    # extract RA/Dec from GAIA \n+    ra_gaia = gaia_data['RA'][gaia_indices]\n+    dec_gaia = gaia_data['DEC'][gaia_indices]\n+    \n+    # compute the RA and Dec differences in [\"]\n+    ra_diff = numpy.cos( numpy.radians(dec_mer) ) * (ra_mer -ra_gaia) * 3600.0\n+    dec_diff = (dec_mer-dec_gaia) * 3600.0\n+\n+    # compute the statistics for the RA/Dec differences\n+    dra_gaia_stats = MER_ArrayStatistics.MER_ArrayStatistics(ra_diff.astype(numpy.float32), logger=logger)\n+    ddec_gaia_stats = MER_ArrayStatistics.MER_ArrayStatistics(dec_diff.astype(numpy.float32), logger=logger)\n+    results_dict['delta_ra_stats'] = dra_gaia_stats.get_stats()\n+    results_dict['delta_dec_stats'] = ddec_gaia_stats.get_stats()\n+\n+    # create the offset plots\n+    plot_name = os.path.join(args.workdir, 'data', 'astrometryOffsetPlot.png')\n+    scatter_plot = MER_AstroValidationPlots.MER_AstroValidationScatterPlot(ra_diff, dec_diff, 0.3, logger)\n+    scatter_plot.generate_plot(plot_name, title='GAIA Crossmatch',\n+                               color=['red', 'm', 'g'], inset=True, \n+                               stats_info=(results_dict['delta_ra_stats']['tmean'], results_dict['delta_dec_stats']['tmean'], results_dict['delta_ra_stats']['tstd'], results_dict['delta_dec_stats']['tstd']),\n+                               size=3, alpha=0.25)\n+    results_dict['astrometry_plot'] = plot_name\n+\n+    results_valid = True\n+    results_dict['ra_mean_valid'] = math.fabs(results_dict['delta_ra_stats']['tmean']) < configuration_parameters['ra_mean_limit']\n+    results_valid = results_valid & results_dict['ra_mean_valid']\n+    results_dict['dec_mean_valid'] = math.fabs(results_dict['delta_dec_stats']['tmean']) < configuration_parameters['dec_mean_limit']\n+    results_valid = results_valid & results_dict['dec_mean_valid']\n+    results_dict['ra_std_valid'] = results_dict['delta_ra_stats']['tstd'] < configuration_parameters['ra_std_limit']\n+    results_valid = results_valid & results_dict['ra_std_valid']\n+    results_dict['dec_std_valid'] = results_dict['delta_dec_stats']['tstd'] < configuration_parameters['dec_std_limit']\n+    results_valid = results_valid & results_dict['dec_std_valid']\n+\n+    results_dict['valid'] = results_valid\n+\n+    # create the hml and so on\n+    report_file_names = create_analysis_report(results_dict, args.workdir, logger)\n+\n+    # Writing to sample.json\n+    output_json_path = os.path.join(args.workdir, 'data', args.output_json)\n+    with open(output_json_path, \"w+\") as out_json:\n+        out_json.write(json.dumps(results_dict, indent=4))\n+\n+    # Save all the analysis files into a tar file\n+    #tar_file_name = mer_filename(\n+    #    \"VALIDATION-RESULT\", prefix=\"ASTROMETRY\", tile_index=tile_id, ext=\"tar.gz\")\n+    tar_file_name = mer_filename(\n+        \"VALIDATION-RESULT\", prefix=\"DETECTION\", tile_index=0, ext=\"tar.gz\")\n+    AnalysisUtils.save_tar_file(\n+        os.path.join(args.workdir, \"data\", tar_file_name),\n+        report_file_names + [output_json_path])\n+        #report_file_names + [figsdir, output_json_path])\n+\n+\n+    # Create the analysis result data product\n+    if results_dict['valid']:\n+        global_result = \"PASSED\"\n+    else:\n+        global_result = \"FAILED\"\n+\n+    analysis_result = mer_utils.create_analysis_result(global_result)\n+    #analysis_result.set_tile_index(tile_id)\n+    #analysis_result.set_observation_id_list(observation_ids)\n+    #analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_figures_tar_file(tar_file_name)\n+\n+    # Save the analysis result data product as an XML file\n+    logger.info(\"# Saving the analysis result data product\")\n+    analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n+\n+    # Print the time spent running the step\n+    logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n+    logger.info('#')\n+    logger.info('# Exiting MER_AstrometryValidationPrg mainMethod()')\n+    logger.info('#')\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:28:10.000+00:00",
                            "e3224a51e80aec0f298e9607d359a618da467017"
                        ],
                        [
                            "@@ -38,6 +38,8 @@ from astropy import units as u\n \n from MER_DataModelUtils import DmUtils as dm_utils\n from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils.FileNaming import mer_filename\n+\n from MER_DA import MER_CrossMatchModule\n from MER_DA.MER_CrossMatchModule import MER_position_crossmatch\n from MER_DetectionValidation import MER_AstroValidationPlots\n@@ -226,12 +228,40 @@ def mainMethod(args):\n     results_dict['valid'] = results_valid\n \n     # create the hml and so on\n-    create_analysis_report(results_dict, args.workdir, logger)\n+    report_file_names = create_analysis_report(results_dict, args.workdir, logger)\n \n     # Writing to sample.json\n-    with open(os.path.join(args.workdir, 'data', args.output_json), \"w+\") as out_json:\n+    output_json_path = os.path.join(args.workdir, 'data', args.output_json)\n+    with open(output_json_path, \"w+\") as out_json:\n         out_json.write(json.dumps(results_dict, indent=4))\n \n+    # Save all the analysis files into a tar file\n+    #tar_file_name = mer_filename(\n+    #    \"VALIDATION-RESULT\", prefix=\"ASTROMETRY\", tile_index=tile_id, ext=\"tar.gz\")\n+    tar_file_name = mer_filename(\n+        \"VALIDATION-RESULT\", prefix=\"DETECTION\", tile_index=0, ext=\"tar.gz\")\n+    AnalysisUtils.save_tar_file(\n+        os.path.join(args.workdir, \"data\", tar_file_name),\n+        report_file_names + [output_json_path])\n+        #report_file_names + [figsdir, output_json_path])\n+\n+\n+    # Create the analysis result data product\n+    if results_dict['valid']:\n+        global_result = \"PASSED\"\n+    else:\n+        global_result = \"FAILED\"\n+\n+    analysis_result = mer_utils.create_analysis_result(global_result)\n+    #analysis_result.set_tile_index(tile_id)\n+    #analysis_result.set_observation_id_list(observation_ids)\n+    #analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_figures_tar_file(tar_file_name)\n+\n+    # Save the analysis result data product as an XML file\n+    logger.info(\"# Saving the analysis result data product\")\n+    analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n+\n     # Print the time spent running the step\n     logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n     logger.info('#')\n",
                            "Makes a first page.",
                            "Martin Kuemmel",
                            "2023-07-03T17:18:33.000+02:00",
                            "074876fe1564e889d6b110008f83d979769b2fc8"
                        ],
                        [
                            "@@ -24,6 +24,8 @@\n \n \"\"\"\n import time\n+import json\n+import math\n import os.path\n import argparse\n import ElementsKernel.Logging as log\n@@ -45,6 +47,8 @@ from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n from MER_PsfMosaicValidation.AnalysisTable import AnalysisTable\n from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n \n+from EL_NullValue import NullValueDefinition\n+\n from MER_Utils import MER_ArrayStatistics\n \n from MER_Validation import MER_PhotometryValidation\n@@ -99,15 +103,15 @@ def create_analysis_report(results_dict, workdir, logger):\n \n     \"\"\"\n     logger.info(\"# Creating the analysis report!\")\n-    logger.info(results_dict)\n+\n     # Initialize the analysis report without filling factor\n     analysis_report = AnalysisReport('MER astrometry validation')\n \n     # Create a new analysis section and add all validation results\n     validation_section = AnalysisSection(\"Astrometric validation\")\n     validation_table = AnalysisTable(['Validation quantity', 'Result'],\n-                                     [['All', 'RA median offset', 'Dec median offset'],\n-                                      ['%s' % results_dict['valid'], '%s' % results_dict['ra_valid'], '%s' % results_dict['dec_valid']]])\n+                                     [['All', 'RA median offset', 'Dec median offset', 'RA std offset', 'Dec std offset'],\n+                                      ['%s' % results_dict['valid'], '%s' % results_dict['ra_mean_valid'], '%s' % results_dict['dec_mean_valid'], '%s' % results_dict['ra_std_valid'], '%s' % results_dict['dec_std_valid']]])\n     validation_section.add_table(validation_table)\n     analysis_report.add_section(validation_section)\n \n@@ -115,8 +119,9 @@ def create_analysis_report(results_dict, workdir, logger):\n     crossmatch_section = AnalysisSection(\"Crossmatch accuracy for GAIA stars\")\n \n     crossmatch_table = AnalysisTable(['Delta quantity', 'value [\"]'],\n-                                     [['RA tmean', 'RA tstd', 'Dec tmean', 'Dec tstd'],\n-                                      ['%e' % results_dict['delta_ra_stats']['tmean'],\n+                                     [['# of matches', 'RA tmean', 'RA tstd', 'Dec tmean', 'Dec tstd'],\n+                                      [results_dict['n_gaia_matches'],\n+                                       '%e' % results_dict['delta_ra_stats']['tmean'],\n                                        '%e' % results_dict['delta_ra_stats']['tstd'],\n                                        '%e' % results_dict['delta_dec_stats']['tmean'],\n                                        '%e' % results_dict['delta_dec_stats']['tstd']]])\n@@ -135,6 +140,7 @@ def create_analysis_report(results_dict, workdir, logger):\n     json_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.json\")\n     html_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.html\")\n     pdflatex_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.tex\")\n+    analysis_report.set_backward('index.html')\n     analysis_report.save_as_json_file(json_file_name)\n     analysis_report.save_as_html_file(html_file_name)\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n@@ -168,54 +174,38 @@ def mainMethod(args):\n         os.path.join(args.workdir, args.configuration_set),\n         \"astrometry_validation\", args.workdir)\n \n-    #\n-    logger.info(configuration_parameters)\n-\n     # get all table data    \n     gaia_data = fits.getdata(os.path.join(args.workdir, 'data', args.gaia_cutout))\n     mer_data = fits.getdata(os.path.join(args.workdir, 'data', args.mer_catalog))\n     \n-    # select the GAIA ID's in teh final catalog    \n-    gaia_selector=numpy.where(numpy.logical_and(numpy.isfinite(mer_data['GAIA_OBJECT_ID']), mer_data['GAIA_OBJECT_ID']>0),True, False)\n-    #selector=numpy.where(mer_data['GAIA_ID']>0,True, False)\n-    #logger.info(mer_data['GAIA_ID'][gaia_selector])\n+    # select the GAIA ID's in the final catalog    \n+    gaia_selector=numpy.where(numpy.logical_and(mer_data['GAIA_OBJECT_ID'] != NullValueDefinition().LONG_LONG, mer_data['GAIA_OBJECT_ID']>0),True, False)\n     logger.info('# No. of GAIA matches: %i' % len(mer_data['GAIA_ID'][gaia_selector]))\n     results_dict['n_gaia_matches'] = len(mer_data['GAIA_ID'][gaia_selector])\n \n+    # intersect the GAIA ID's from the final catalog with the GAIA catalog\n     source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_OBJECT_ID'][gaia_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n-    #logger.info(len(source_ids))\n-    #logger.info(len(mer_indices))\n-    #logger.info(len(gaia_indices))\n \n+    # extract RA/Dec for GAIA sources from the final catalog \n     ra_mer = mer_data['RIGHT_ASCENSION'][gaia_selector][mer_indices]\n     dec_mer = mer_data['DECLINATION'][gaia_selector][mer_indices]\n \n+    # extract RA/Dec from GAIA \n     ra_gaia = gaia_data['RA'][gaia_indices]\n     dec_gaia = gaia_data['DEC'][gaia_indices]\n     \n-    #    raDiff  = np.cos( np.radians(BDec[BIdx]*u.degree) ) * ( ARa[AIdx]*u.degree - BRa[BIdx]*u.degree ).to(u.arcsec)  # in arcsecs\n-    #decDiff = ( ADec[AIdx]*u.degree - BDec[BIdx]*u.degree ).to(u.arcsec)                                            # in arcsecs\n-    #ra_diff = numpy.cos( numpy.radians(dec_mer*u.degree) ) * (ra_mer*u.degree -ra_gaia*u.degree).to(u.arcsec)\n-    #dec_diff = (dec_mer*u.degree-dec_gaia*u.degree).to(u.arcsec)\n-\n-    #ra_diff = ra_mer -ra_gaia\n-    #dec_diff = dec_mer-dec_gaia\n-    \n+    # compute the RA and Dec differences in [\"]\n     ra_diff = numpy.cos( numpy.radians(dec_mer) ) * (ra_mer -ra_gaia) * 3600.0\n     dec_diff = (dec_mer-dec_gaia) * 3600.0\n \n+    # compute the statistics for the RA/Dec differences\n     dra_gaia_stats = MER_ArrayStatistics.MER_ArrayStatistics(ra_diff.astype(numpy.float32), logger=logger)\n     ddec_gaia_stats = MER_ArrayStatistics.MER_ArrayStatistics(dec_diff.astype(numpy.float32), logger=logger)\n-\n-    #dra_gaia_statsvals = dra_gaia_stats.get_stats()\n-    #ddec_gaia_statsvals = ddec_gaia_stats.get_stats()\n     results_dict['delta_ra_stats'] = dra_gaia_stats.get_stats()\n     results_dict['delta_dec_stats'] = ddec_gaia_stats.get_stats()\n \n-    #logger.info(results_dict['delta_ra_stats'])\n-    #logger.info(results_dict['delta_dec_stats'])\n-\n-    plot_name = os.path.join(args.workdir, 'data', 'gaga.png')\n+    # create the offset plots\n+    plot_name = os.path.join(args.workdir, 'data', 'astrometryOffsetPlot.png')\n     scatter_plot = MER_AstroValidationPlots.MER_AstroValidationScatterPlot(ra_diff, dec_diff, 0.3, logger)\n     scatter_plot.generate_plot(plot_name, title='GAIA Crossmatch',\n                                color=['red', 'm', 'g'], inset=True, \n@@ -224,17 +214,26 @@ def mainMethod(args):\n     results_dict['astrometry_plot'] = plot_name\n \n     results_valid = True\n-    results_dict['ra_valid'] = results_dict['delta_ra_stats']['tmean'] < configuration_parameters['ra_mean_limit']\n-    results_valid = results_valid & results_dict['ra_valid']\n-    results_dict['dec_valid'] = results_dict['delta_dec_stats']['tmean'] < configuration_parameters['dec_mean_limit']\n-    results_valid = results_valid & results_dict['dec_valid']\n+    results_dict['ra_mean_valid'] = math.fabs(results_dict['delta_ra_stats']['tmean']) < configuration_parameters['ra_mean_limit']\n+    results_valid = results_valid & results_dict['ra_mean_valid']\n+    results_dict['dec_mean_valid'] = math.fabs(results_dict['delta_dec_stats']['tmean']) < configuration_parameters['dec_mean_limit']\n+    results_valid = results_valid & results_dict['dec_mean_valid']\n+    results_dict['ra_std_valid'] = results_dict['delta_ra_stats']['tstd'] < configuration_parameters['ra_std_limit']\n+    results_valid = results_valid & results_dict['ra_std_valid']\n+    results_dict['dec_std_valid'] = results_dict['delta_dec_stats']['tstd'] < configuration_parameters['dec_std_limit']\n+    results_valid = results_valid & results_dict['dec_std_valid']\n+\n     results_dict['valid'] = results_valid\n \n+    # create the hml and so on\n     create_analysis_report(results_dict, args.workdir, logger)\n \n+    # Writing to sample.json\n+    with open(os.path.join(args.workdir, 'data', args.output_json), \"w+\") as out_json:\n+        out_json.write(json.dumps(results_dict, indent=4))\n+\n     # Print the time spent running the step\n     logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n-\n     logger.info('#')\n     logger.info('# Exiting MER_AstrometryValidationPrg mainMethod()')\n     logger.info('#')\n",
                            "Astrometry close to ready",
                            "Martin Kuemmel",
                            "2023-07-03T11:52:26.000+02:00",
                            "948a70d638cd348e1f82b9a294f677641a50120d"
                        ],
                        [
                            "@@ -0,0 +1,240 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+:file: python/MER_Validation/MER_GagaPrg.py\n+\n+:date: 06/28/23\n+:author: mkuemmel@usm.lmu.de\n+\n+\"\"\"\n+import time\n+import os.path\n+import argparse\n+import ElementsKernel.Logging as log\n+\n+import numpy\n+import matplotlib.pyplot as plt\n+\n+from astropy.io import fits\n+from astropy import units as u\n+\n+from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DA import MER_CrossMatchModule\n+from MER_DA.MER_CrossMatchModule import MER_position_crossmatch\n+from MER_DetectionValidation import MER_AstroValidationPlots\n+from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisTable import AnalysisTable\n+from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n+\n+from MER_Utils import MER_ArrayStatistics\n+\n+from MER_Validation import MER_PhotometryValidation\n+\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"\n+    @brief Allows to define the (command line and configuration file) options\n+    specific to this program\n+\n+    @details See the Elements documentation for more details.\n+    @return An  ArgumentParser.\n+    \"\"\"\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser.add_argument('--mer_catalog', dest='mer_catalog', type=str, required=True,\n+                        help='path to the catalog to be validated')\n+    parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n+                        help='path to the gaia cutout')\n+    parser.add_argument('--output_json', dest='output_json', type=str, required=False,\n+                        default='astrometry_validation.json', help='Json file for output, default: \"astrometry_validation.json\")!')\n+    parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n+                        default='./', help='Path to the working directory: \"%(default)s\"!')\n+    parser.add_argument(\"--logdir\", dest=\"logdir\", required=False, default='./',\n+                        type=str, help='The logging directory path: \"%(default)s\"!')\n+    parser.add_argument(\"--analysis_result\", dest=\"analysis_result\",\n+                        type=str, help=\"The analysis result output data \"\n+                        \"product XML file name.\")\n+    parser.add_argument(\"--configuration_set\", dest=\"configuration_set\",\n+                        type=str, help=\"The MER Configuration Set product XML \"\n+                        \"file name.\")\n+\n+    return parser\n+\n+def create_analysis_report(results_dict, workdir, logger):\n+    \"\"\"Creates an analysis report.\n+\n+    Parameters\n+    ----------\n+    results_dict: dictionary\n+        All results from the detection analysis\n+    workdir: str\n+        The complete path to the working directory.\n+    logger: object\n+        A logger instance.\n+\n+    Returns\n+    -------\n+    list\n+        A python list with the analysis report file names.\n+\n+    \"\"\"\n+    logger.info(\"# Creating the analysis report!\")\n+    logger.info(results_dict)\n+    # Initialize the analysis report without filling factor\n+    analysis_report = AnalysisReport('MER astrometry validation')\n+\n+    # Create a new analysis section and add all validation results\n+    validation_section = AnalysisSection(\"Astrometric validation\")\n+    validation_table = AnalysisTable(['Validation quantity', 'Result'],\n+                                     [['All', 'RA median offset', 'Dec median offset'],\n+                                      ['%s' % results_dict['valid'], '%s' % results_dict['ra_valid'], '%s' % results_dict['dec_valid']]])\n+    validation_section.add_table(validation_table)\n+    analysis_report.add_section(validation_section)\n+\n+    # Create a new analysis section and add the crossmatch statistics\n+    crossmatch_section = AnalysisSection(\"Crossmatch accuracy for GAIA stars\")\n+\n+    crossmatch_table = AnalysisTable(['Delta quantity', 'value [\"]'],\n+                                     [['RA tmean', 'RA tstd', 'Dec tmean', 'Dec tstd'],\n+                                      ['%e' % results_dict['delta_ra_stats']['tmean'],\n+                                       '%e' % results_dict['delta_ra_stats']['tstd'],\n+                                       '%e' % results_dict['delta_dec_stats']['tmean'],\n+                                       '%e' % results_dict['delta_dec_stats']['tstd']]])\n+    crossmatch_section.add_table(crossmatch_table)\n+    analysis_report.add_section(crossmatch_section)\n+\n+   # Create a new analysis section and add the crossmatch figure\n+    crossmatch_plot_section = AnalysisSection(\"Astrometry crossmatch results\")\n+    crossmatch_plot_section.set_figures([AnalysisFigure(results_dict['astrometry_plot'],latex_scale=0.55)])\n+    analysis_report.add_section(crossmatch_plot_section)\n+\n+    # Add an index to the analysis report\n+    analysis_report.add_index()\n+\n+    # Save the analysis report in various formats\n+    json_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.json\")\n+    html_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.html\")\n+    pdflatex_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.tex\")\n+    analysis_report.save_as_json_file(json_file_name)\n+    analysis_report.save_as_html_file(html_file_name)\n+    analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n+\n+    return [json_file_name, html_file_name, pdflatex_file_name]\n+\n+def mainMethod(args):\n+    \"\"\"\n+    @brief The \"main\" method.\n+    \n+    @details This method is the entry point to the program. In this sense, it is\n+    similar to a main (and it is why it is called mainMethod()).\n+    \"\"\"\n+    logger = log.getLogger('MER_AstrometryValidationPrg')\n+\n+    logger.info('#')\n+    logger.info('# Entering MER_AstrometryValidationPrg mainMethod()')\n+    logger.info('#')\n+\n+    # Store the start time\n+    start_time = time.time()\n+\n+    # start the dict for the results\n+    results_dict = {}\n+\n+    # Add some extra functionality to the MER data product bindings\n+    mer_utils.init()\n+\n+    # Load the configuration parameters\n+    configuration_parameters = AnalysisUtils.get_configuration_parameters(\n+        os.path.join(args.workdir, args.configuration_set),\n+        \"astrometry_validation\", args.workdir)\n+\n+    #\n+    logger.info(configuration_parameters)\n+\n+    # get all table data    \n+    gaia_data = fits.getdata(os.path.join(args.workdir, 'data', args.gaia_cutout))\n+    mer_data = fits.getdata(os.path.join(args.workdir, 'data', args.mer_catalog))\n+    \n+    # select the GAIA ID's in teh final catalog    \n+    gaia_selector=numpy.where(numpy.logical_and(numpy.isfinite(mer_data['GAIA_OBJECT_ID']), mer_data['GAIA_OBJECT_ID']>0),True, False)\n+    #selector=numpy.where(mer_data['GAIA_ID']>0,True, False)\n+    #logger.info(mer_data['GAIA_ID'][gaia_selector])\n+    logger.info('# No. of GAIA matches: %i' % len(mer_data['GAIA_ID'][gaia_selector]))\n+    results_dict['n_gaia_matches'] = len(mer_data['GAIA_ID'][gaia_selector])\n+\n+    source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_OBJECT_ID'][gaia_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n+    #logger.info(len(source_ids))\n+    #logger.info(len(mer_indices))\n+    #logger.info(len(gaia_indices))\n+\n+    ra_mer = mer_data['RIGHT_ASCENSION'][gaia_selector][mer_indices]\n+    dec_mer = mer_data['DECLINATION'][gaia_selector][mer_indices]\n+\n+    ra_gaia = gaia_data['RA'][gaia_indices]\n+    dec_gaia = gaia_data['DEC'][gaia_indices]\n+    \n+    #    raDiff  = np.cos( np.radians(BDec[BIdx]*u.degree) ) * ( ARa[AIdx]*u.degree - BRa[BIdx]*u.degree ).to(u.arcsec)  # in arcsecs\n+    #decDiff = ( ADec[AIdx]*u.degree - BDec[BIdx]*u.degree ).to(u.arcsec)                                            # in arcsecs\n+    #ra_diff = numpy.cos( numpy.radians(dec_mer*u.degree) ) * (ra_mer*u.degree -ra_gaia*u.degree).to(u.arcsec)\n+    #dec_diff = (dec_mer*u.degree-dec_gaia*u.degree).to(u.arcsec)\n+\n+    #ra_diff = ra_mer -ra_gaia\n+    #dec_diff = dec_mer-dec_gaia\n+    \n+    ra_diff = numpy.cos( numpy.radians(dec_mer) ) * (ra_mer -ra_gaia) * 3600.0\n+    dec_diff = (dec_mer-dec_gaia) * 3600.0\n+\n+    dra_gaia_stats = MER_ArrayStatistics.MER_ArrayStatistics(ra_diff.astype(numpy.float32), logger=logger)\n+    ddec_gaia_stats = MER_ArrayStatistics.MER_ArrayStatistics(dec_diff.astype(numpy.float32), logger=logger)\n+\n+    #dra_gaia_statsvals = dra_gaia_stats.get_stats()\n+    #ddec_gaia_statsvals = ddec_gaia_stats.get_stats()\n+    results_dict['delta_ra_stats'] = dra_gaia_stats.get_stats()\n+    results_dict['delta_dec_stats'] = ddec_gaia_stats.get_stats()\n+\n+    #logger.info(results_dict['delta_ra_stats'])\n+    #logger.info(results_dict['delta_dec_stats'])\n+\n+    plot_name = os.path.join(args.workdir, 'data', 'gaga.png')\n+    scatter_plot = MER_AstroValidationPlots.MER_AstroValidationScatterPlot(ra_diff, dec_diff, 0.3, logger)\n+    scatter_plot.generate_plot(plot_name, title='GAIA Crossmatch',\n+                               color=['red', 'm', 'g'], inset=True, \n+                               stats_info=(results_dict['delta_ra_stats']['tmean'], results_dict['delta_dec_stats']['tmean'], results_dict['delta_ra_stats']['tstd'], results_dict['delta_dec_stats']['tstd']),\n+                               size=3, alpha=0.25)\n+    results_dict['astrometry_plot'] = plot_name\n+\n+    results_valid = True\n+    results_dict['ra_valid'] = results_dict['delta_ra_stats']['tmean'] < configuration_parameters['ra_mean_limit']\n+    results_valid = results_valid & results_dict['ra_valid']\n+    results_dict['dec_valid'] = results_dict['delta_dec_stats']['tmean'] < configuration_parameters['dec_mean_limit']\n+    results_valid = results_valid & results_dict['dec_valid']\n+    results_dict['valid'] = results_valid\n+\n+    create_analysis_report(results_dict, args.workdir, logger)\n+\n+    # Print the time spent running the step\n+    logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n+\n+    logger.info('#')\n+    logger.info('# Exiting MER_AstrometryValidationPrg mainMethod()')\n+    logger.info('#')\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-06-30T17:34:51.000+02:00",
                            "6d9a612f0e2d7a188f993d6b01a6edbd5ff5acae"
                        ],
                        [
                            "@@ -16,7 +16,6 @@\n # 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n #\n \n-\n \"\"\"\n :file: python/MER_Validation/MER_GagaPrg.py\n \n@@ -24,6 +23,7 @@\n :author: mkuemmel@usm.lmu.de\n \n \"\"\"\n+import time\n import os.path\n import argparse\n import ElementsKernel.Logging as log\n@@ -34,11 +34,16 @@ import matplotlib.pyplot as plt\n from astropy.io import fits\n from astropy import units as u\n \n+from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import MerDmUtils as mer_utils\n from MER_DA import MER_CrossMatchModule\n from MER_DA.MER_CrossMatchModule import MER_position_crossmatch\n+from MER_DetectionValidation import MER_AstroValidationPlots\n from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisTable import AnalysisTable\n+from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n \n from MER_Utils import MER_ArrayStatistics\n \n@@ -60,8 +65,6 @@ def defineSpecificProgramOptions():\n                         help='path to the catalog to be validated')\n     parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n                         help='path to the gaia cutout')\n-    parser.add_argument('--plot_name', dest='plot_name', type=str, required=False, default=None,\n-                        help='Name of the plot')\n     parser.add_argument('--output_json', dest='output_json', type=str, required=False,\n                         default='astrometry_validation.json', help='Json file for output, default: \"astrometry_validation.json\")!')\n     parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n@@ -71,52 +74,72 @@ def defineSpecificProgramOptions():\n     parser.add_argument(\"--analysis_result\", dest=\"analysis_result\",\n                         type=str, help=\"The analysis result output data \"\n                         \"product XML file name.\")\n+    parser.add_argument(\"--configuration_set\", dest=\"configuration_set\",\n+                        type=str, help=\"The MER Configuration Set product XML \"\n+                        \"file name.\")\n \n     return parser\n \n-def make_plot(x_diff, y_diff, out_plot_name, logger):\n-    \"\"\"\n+def create_analysis_report(results_dict, workdir, logger):\n+    \"\"\"Creates an analysis report.\n+\n+    Parameters\n+    ----------\n+    results_dict: dictionary\n+        All results from the detection analysis\n+    workdir: str\n+        The complete path to the working directory.\n+    logger: object\n+        A logger instance.\n+\n+    Returns\n+    -------\n+    list\n+        A python list with the analysis report file names.\n+\n     \"\"\"\n-    color=['r', 'b', 'r']\n-    #\n-    logger.info(\"Generating the plot file: %s\"%out_plot_name)\n-    plt.close('all')\n-    \n-    # start the plot\n-    fig=plt.figure(figsize=(12,6))\n-    ax=fig.add_subplot(121)\n-\n-    # plot the data\n-    ax.scatter(x_diff, y_diff, marker='o', c=color[0], s=2, alpha=1)\n-\n-    # set labels and title and limits\n-    ax.set_xlabel(r'$\\Delta$RA [\"]',fontsize=18)\n-    ax.set_ylabel(r'$\\Delta$Dec [\"]',fontsize=18)\n-    ax.set_title('GaGa', fontsize=20)\n-    #ax.set_xlim(-1, 1)\n-    #ax.set_ylim(-1, 1)\n-    ax.set_aspect('equal', adjustable = 'box')\n-    ax.grid(True)\n-\n-\n-    # plot the histograms\n-    ax2=fig.add_subplot(122)\n-    match_n, match_bins, match_patches = ax2.hist(x_diff, bins=41, histtype='barstacked', range=(-0.2, 0.2), facecolor=color[1], alpha=0.7, log=False)\n-    match_n, match_bins, match_patches = ax2.hist(y_diff, bins=41, histtype='barstacked', range=(-0.2, 0.2), facecolor=color[2], alpha=0.7, log=False)\n-    #match_n, match_bins, match_patches = ax2.hist(self._dist_values, bins=40, histtype='bar', range=(0.0, self._max_distance), facecolor=color, alpha=1.0, log=True)\n-    ax2.set_title(r'Distribution $\\Delta$RA/Dec', fontsize=20)\n-    ax2.text(0.8, 0.9, r'$\\Delta$RA', verticalalignment='center', horizontalalignment='left', transform=ax2.transAxes, color=color[1], fontsize=20)\n-    ax2.text(0.8, 0.8, r'$\\Delta$Dec', verticalalignment='center', horizontalalignment='left', transform=ax2.transAxes, color=color[2], fontsize=20)\n-    ax2.set_xlabel(r'$\\Delta$RA/Dec [\"]',fontsize=18)\n-    ax2.set_ylabel('N',fontsize=18)\n-    ax2.grid(True)\n-        \n-    # make the spacing\n-    plt.subplots_adjust(bottom=0.1, right=0.9, top=0.9, left=0.1, hspace=0.4)\n-\n-    logger.info('Saving Plots in : %s' % out_plot_name)\n-    plt.savefig(out_plot_name)\n-   \n+    logger.info(\"# Creating the analysis report!\")\n+    logger.info(results_dict)\n+    # Initialize the analysis report without filling factor\n+    analysis_report = AnalysisReport('MER astrometry validation')\n+\n+    # Create a new analysis section and add all validation results\n+    validation_section = AnalysisSection(\"Astrometric validation\")\n+    validation_table = AnalysisTable(['Validation quantity', 'Result'],\n+                                     [['All', 'RA median offset', 'Dec median offset'],\n+                                      ['%s' % results_dict['valid'], '%s' % results_dict['ra_valid'], '%s' % results_dict['dec_valid']]])\n+    validation_section.add_table(validation_table)\n+    analysis_report.add_section(validation_section)\n+\n+    # Create a new analysis section and add the crossmatch statistics\n+    crossmatch_section = AnalysisSection(\"Crossmatch accuracy for GAIA stars\")\n+\n+    crossmatch_table = AnalysisTable(['Delta quantity', 'value [\"]'],\n+                                     [['RA tmean', 'RA tstd', 'Dec tmean', 'Dec tstd'],\n+                                      ['%e' % results_dict['delta_ra_stats']['tmean'],\n+                                       '%e' % results_dict['delta_ra_stats']['tstd'],\n+                                       '%e' % results_dict['delta_dec_stats']['tmean'],\n+                                       '%e' % results_dict['delta_dec_stats']['tstd']]])\n+    crossmatch_section.add_table(crossmatch_table)\n+    analysis_report.add_section(crossmatch_section)\n+\n+   # Create a new analysis section and add the crossmatch figure\n+    crossmatch_plot_section = AnalysisSection(\"Astrometry crossmatch results\")\n+    crossmatch_plot_section.set_figures([AnalysisFigure(results_dict['astrometry_plot'],latex_scale=0.55)])\n+    analysis_report.add_section(crossmatch_plot_section)\n+\n+    # Add an index to the analysis report\n+    analysis_report.add_index()\n+\n+    # Save the analysis report in various formats\n+    json_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.json\")\n+    html_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.html\")\n+    pdflatex_file_name = os.path.join(workdir, \"data\", \"astrometryValidation.tex\")\n+    analysis_report.save_as_json_file(json_file_name)\n+    analysis_report.save_as_html_file(html_file_name)\n+    analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n+\n+    return [json_file_name, html_file_name, pdflatex_file_name]\n \n def mainMethod(args):\n     \"\"\"\n@@ -125,28 +148,41 @@ def mainMethod(args):\n     @details This method is the entry point to the program. In this sense, it is\n     similar to a main (and it is why it is called mainMethod()).\n     \"\"\"\n-\n-    logger = log.getLogger('MER_GagaPrg')\n+    logger = log.getLogger('MER_AstrometryValidationPrg')\n \n     logger.info('#')\n-    logger.info('# Entering MER_GagaPrg mainMethod()')\n+    logger.info('# Entering MER_AstrometryValidationPrg mainMethod()')\n     logger.info('#')\n-    \n+\n+    # Store the start time\n+    start_time = time.time()\n+\n+    # start the dict for the results\n+    results_dict = {}\n+\n+    # Add some extra functionality to the MER data product bindings\n+    mer_utils.init()\n+\n+    # Load the configuration parameters\n+    configuration_parameters = AnalysisUtils.get_configuration_parameters(\n+        os.path.join(args.workdir, args.configuration_set),\n+        \"astrometry_validation\", args.workdir)\n+\n+    #\n+    logger.info(configuration_parameters)\n+\n+    # get all table data    \n     gaia_data = fits.getdata(os.path.join(args.workdir, 'data', args.gaia_cutout))\n-    #logger.info(gaia_data['SOURCE_ID'])\n-    \n     mer_data = fits.getdata(os.path.join(args.workdir, 'data', args.mer_catalog))\n-    #logger.info(mer_data['GAIA_ID'])\n     \n-    \n-    #selector=np.where(np.logical_and(np.isfinite(mer_data['GAIA_ID']), mer_data['GAIA_ID'])>0,True, False)\n-    #selector=np.where(np.isfinite(mer_data['GAIA_ID']),True, False)\n-    gaia_selector=numpy.where(numpy.logical_and(numpy.isfinite(mer_data['GAIA_ID']), mer_data['GAIA_ID']>0),True, False)\n+    # select the GAIA ID's in teh final catalog    \n+    gaia_selector=numpy.where(numpy.logical_and(numpy.isfinite(mer_data['GAIA_OBJECT_ID']), mer_data['GAIA_OBJECT_ID']>0),True, False)\n     #selector=numpy.where(mer_data['GAIA_ID']>0,True, False)\n     #logger.info(mer_data['GAIA_ID'][gaia_selector])\n-    logger.info(len(mer_data['GAIA_ID'][gaia_selector]))\n+    logger.info('# No. of GAIA matches: %i' % len(mer_data['GAIA_ID'][gaia_selector]))\n+    results_dict['n_gaia_matches'] = len(mer_data['GAIA_ID'][gaia_selector])\n \n-    source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_ID'][gaia_selector], gaia_data['SOURCE_ID'], assume_unique=True, return_indices=True)\n+    source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_OBJECT_ID'][gaia_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n     #logger.info(len(source_ids))\n     #logger.info(len(mer_indices))\n     #logger.info(len(gaia_indices))\n@@ -168,89 +204,37 @@ def mainMethod(args):\n     ra_diff = numpy.cos( numpy.radians(dec_mer) ) * (ra_mer -ra_gaia) * 3600.0\n     dec_diff = (dec_mer-dec_gaia) * 3600.0\n \n-    if args.plot_name is not None:\n-        make_plot(ra_diff, dec_diff, args.plot_name, logger)\n-    \n-    \n-    \"\"\"\n-    logger.info(ra_diff)\n-    logger.info(dec_diff)\n-    #logger.info(gaia_data['RA'][gaia_indices])\n-    #logger.info(type(gaia_data['RA'][gaia_indices]))\n-    #logger.info(type(ra_diff.astype(numpy.float32)))\n-    #logger.info(type(ra_diff))\n-\n     dra_gaia_stats = MER_ArrayStatistics.MER_ArrayStatistics(ra_diff.astype(numpy.float32), logger=logger)\n     ddec_gaia_stats = MER_ArrayStatistics.MER_ArrayStatistics(dec_diff.astype(numpy.float32), logger=logger)\n-    #dra_gaia_stats = MER_ArrayStatistics.MER_ArrayStatistics(gaia_data['RA'][gaia_indices], logger=logger)\n-    #ddec_gaia_stats = MER_ArrayStatistics.MER_ArrayStatistics(gaia_data['DEC'][gaia_indices], logger=logger)\n-    logger.info(dra_gaia_stats.get_stats())\n-    logger.info(ddec_gaia_stats.get_stats())\n-    \"\"\"\n-    \"\"\"\n-    ra_gaia, dec_gaia, mag_g_gaia, magerr_g_gaia, mag_bp_gaia, magerr_bp_gaia, mag_rp_gaia, magerr_rp_gaia = MER_PhotometryValidation.read_gaia_catalog(catalog_path=args.gaia_cutout)\n-    ra_mer, dec_mer, mag_vis_psf, magerr_vis_psf, mer_data = MER_PhotometryValidation.read_mer_catalog(catalog_path=args.mer_catalog, \n-        flux_column=\"FLUX_DETECTION_TOTAL\", \n-        fluxerr_column=\"FLUXERR_DETECTION_TOTAL\",\n-        flag_column=\"FLAG_VIS\",\n-        flag_value=0\n-        )\n-\n-    # Cross match Gaia and MER catalog\n-    matched_idx, matched_quality, tot_matched = MER_CrossMatchModule.MER_match_catalogs_sky(ra1 = ra_mer,\n-                                                                                            dec1 = dec_mer,\n-                                                                                            ra2 = ra_gaia,\n-                                                                                            dec2 = dec_gaia,\n-                                                                                            id_col_cat2 = np.arange(len(ra_gaia)),\n-                                                                                            max_dist = 0.6,\n-                                                                                            col1 = [],\n-                                                                                            col2 = [],\n-                                                                                            thresh = [],\n-                                                                                            weights = [])\n-\n-    matched_idx = np.array(matched_idx)\n-    mer_selector = np.where(matched_idx != -1)[0]\n-    matched_idx = matched_idx[mer_selector]\n-    ra_mer_matched = ra_mer[mer_selector]\n-    dec_mer_matched = dec_mer[mer_selector]\n-\n-    ra_gaia_matched = []\n-    dec_gaia_matched = []\n-    for i in range(len(mer_selector)):\n-        ra_gaia_matched.append(ra_gaia[matched_idx[i]])\n-        dec_gaia_matched.append(dec_gaia[matched_idx[i]])\n-\n-    logger.info(len(ra_mer))\n-    logger.info(len(matched_idx))\n-\n-    #logger.info(ra_mer_matched-np.array(ra_gaia_matched))\n-    #ogger.info(len(dec_mer_matched))\n-\n-    #logger.info(ra_gaia_matched)\n-    #ogger.info(len(dec_gaia_matched))\n-    \"\"\"\n-    \"\"\"\n-    MER_position_crossmatch(catname_1 = args.mer_catalog,\n-                            ext_num_1 = 1,\n-                            ra_name_1 = \"RIGHT_ASCENSION\",\n-                            dec_name_1 = \"DECLINATION\",\n-                            col_list_1 = [],\n-                            catname_2 = args.gaia_cutout,\n-                            ext_num_2 = 1,\n-                            ra_name_2 = \"RA\",\n-                            dec_name_2= \"DEC\",\n-                            id_col_name_2=\"SOURCE_ID\",\n-                            col_list_2=[],\n-                            max_separation=0.3,\n-                            other_thresholds=[],\n-                            weights=[],\n-                            output_path = args.mer_catalog,\n-                            matched_id_outputname = \"GAIA_ID\",\n-                            matched_quality_outputname = \"GAIA_MATCH_QUALITY\",\n-                            logger=logger)\n-    \n-    \"\"\"\n+\n+    #dra_gaia_statsvals = dra_gaia_stats.get_stats()\n+    #ddec_gaia_statsvals = ddec_gaia_stats.get_stats()\n+    results_dict['delta_ra_stats'] = dra_gaia_stats.get_stats()\n+    results_dict['delta_dec_stats'] = ddec_gaia_stats.get_stats()\n+\n+    #logger.info(results_dict['delta_ra_stats'])\n+    #logger.info(results_dict['delta_dec_stats'])\n+\n+    plot_name = os.path.join(args.workdir, 'data', 'gaga.png')\n+    scatter_plot = MER_AstroValidationPlots.MER_AstroValidationScatterPlot(ra_diff, dec_diff, 0.3, logger)\n+    scatter_plot.generate_plot(plot_name, title='GAIA Crossmatch',\n+                               color=['red', 'm', 'g'], inset=True, \n+                               stats_info=(results_dict['delta_ra_stats']['tmean'], results_dict['delta_dec_stats']['tmean'], results_dict['delta_ra_stats']['tstd'], results_dict['delta_dec_stats']['tstd']),\n+                               size=3, alpha=0.25)\n+    results_dict['astrometry_plot'] = plot_name\n+\n+    results_valid = True\n+    results_dict['ra_valid'] = results_dict['delta_ra_stats']['tmean'] < configuration_parameters['ra_mean_limit']\n+    results_valid = results_valid & results_dict['ra_valid']\n+    results_dict['dec_valid'] = results_dict['delta_dec_stats']['tmean'] < configuration_parameters['dec_mean_limit']\n+    results_valid = results_valid & results_dict['dec_valid']\n+    results_dict['valid'] = results_valid\n+\n+    create_analysis_report(results_dict, args.workdir, logger)\n+\n+    # Print the time spent running the step\n+    logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n \n     logger.info('#')\n-    logger.info('# Exiting MER_GagaPrg mainMethod()')\n+    logger.info('# Exiting MER_AstrometryValidationPrg mainMethod()')\n     logger.info('#')\n",
                            "Astrometry Validation kind of works now",
                            "Martin Kuemmel",
                            "2023-06-30T17:21:02.000+02:00",
                            "86f4592b671eafc5641ccdb2329d95cb560f4578"
                        ]
                    ],
                    "MER_Validation/python/MER_Validation/MER_MosaicingValidationPrg.py": [
                        [
                            "@@ -151,6 +151,9 @@ def create_analysis_report(results_dict, tile_index, workdir, logger):\n     json_file_name_mosaicing = os.path.join(workdir, \"data\", \"mosaicingValidation.json\")\n     html_file_name_mosaicing = os.path.join(workdir, \"data\", \"mosaicingValidation.html\")\n     pdflatex_file_name_mosaicing = os.path.join(workdir, \"data\", \"mosaicingValidation.tex\")\n+    analysis_report.set_backward('gaiaPsfAnalysis.html')\n+    analysis_report.set_forward('backgroundValidation.html')\n+\n     analysis_report.save_as_json_file(json_file_name_mosaicing)\n     analysis_report.save_as_html_file(html_file_name_mosaicing)\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name_mosaicing)\n@@ -170,6 +173,7 @@ def create_analysis_report(results_dict, tile_index, workdir, logger):\n     json_file_name_bkg = os.path.join(workdir, \"data\", \"backgroundValidation.json\")\n     html_file_name_bkg = os.path.join(workdir, \"data\", \"backgroundValidation.html\")\n     pdflatex_file_name_bkg = os.path.join(workdir, \"data\", \"backgroundValidation.tex\")\n+    analysis_report.set_backward('mosaicingValidation.html')\n     analysis_report.save_as_json_file(json_file_name_bkg)\n     analysis_report.save_as_html_file(html_file_name_bkg)\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name_bkg)\n",
                            "Included some internal links and minor improvements",
                            "Martin Kuemmel",
                            "2023-08-16T22:47:44.000+02:00",
                            "e2fe49ac5109e9e5e2ffded6d1a58aabf6225fe5"
                        ],
                        [
                            "@@ -0,0 +1,603 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\n+\"\"\"\n+:file: python/MER_Validation/MER_MosaicingValidationPrg.py\n+\n+:date: 07/28/23\n+:author: yfang\n+\n+\"\"\"\n+\n+import argparse\n+import matplotlib.pyplot as plt\n+import ElementsKernel.Logging as log\n+import numpy as np\n+from astropy.io import fits\n+from astropy.stats import mad_std\n+from astropy.nddata import bitmask\n+import json\n+import os\n+import time\n+\n+from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils.FileNaming import mer_filename\n+\n+from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisTable import AnalysisTable\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n+\n+import MER_MosaicingValidation.MER_NoiseApertureUtils as MER_NoiseApertureUtils\n+import MER_MosaicingValidation.MER_NoiseRMSUtils as MER_NoiseRMSUtils\n+from MER_DA.MERUtilities import print_input_arguments\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"\n+    @brief Allows to define the (command line and configuration file) options\n+    specific to this program\n+\n+    @details See the Elements documentation for more details.\n+    @return An  ArgumentParser.\n+    \"\"\"\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser.add_argument(\"--mosaics\", dest=\"mosaics\",\n+                        type=str, help=\"A json file with the MER \"\n+                        \"background-subtracted mosaic XML file names.\")\n+    parser.add_argument(\"--segmap\", dest=\"segmap\",\n+                        type=str, help=\"A path to XML file of segmantation map \")\n+    parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n+                        default='./', help='Path to the working directory: \"%(default)s\"!')\n+    parser.add_argument(\"--logdir\", dest=\"logdir\",\n+                        type=str, help=\"The logging directory path.\")\n+\n+    parser.add_argument(\"--mosaicing_result\", dest=\"mosaicing_result\",\n+                        type=str, help=\"The mosaicing result output data \"\n+                        \"product XML file name.\")\n+    parser.add_argument(\"--background_result\", dest=\"background_result\",\n+                        type=str, help=\"The background result output data \"\n+                        \"product XML file name.\")\n+    return parser\n+\n+def create_analysis_report(results_dict, tile_index, workdir, logger):\n+    \"\"\"Creates an analysis report.\n+\n+    Parameters\n+    ----------\n+    results_dict: dictionary\n+        All results from the validation analysis\n+    tile_index: int\n+        The MER tile index.\n+    workdir: str\n+        The complete path to the working directory.\n+    logger: object\n+        A logger instance.\n+\n+    Returns\n+    -------\n+    list\n+        A python list with the analysis report file names.\n+\n+    \"\"\"\n+    logger.info(\"# Creating the analysis report!\")\n+    \n+    # Initialize the analysis report\n+    analysis_report = AnalysisReport(\"MER mosaicing validation for tile %s\" % tile_index)\n+\n+    # Create a subsection for the imag depth plot\n+    analysis_section = AnalysisSection(\"Image depth plot\")\n+    analysis_section.set_figures([AnalysisFigure(results_dict['image_depth_plot'], latex_scale=0.55)])\n+    analysis_report.add_section(analysis_section)\n+\n+    # # Create a subsection for the aperture flux histograms\n+    # analysis_section = AnalysisSection(\"Aperture flux histograms\")\n+    # analysis_section.set_figures([AnalysisFigure(results_dict['aperture_flux_hist_list'][i]) for i in range(len(results_dict['aperture_flux_hist_list']))])\n+    # analysis_report.add_section(analysis_section)\n+\n+    # Create a subsection for image holes\n+    analysis_section = AnalysisSection(\"Histogram plot for VIS and NIR image holes\")\n+    analysis_section.set_figures([AnalysisFigure(results_dict['holes_hist_plot_vis_nir'], latex_scale=0.55)])\n+    analysis_report.add_section(analysis_section)\n+\n+    analysis_section = AnalysisSection(\"Histogram plot for EXT image holes\")\n+    analysis_section.set_figures([AnalysisFigure(results_dict['holes_hist_plot_ext'], latex_scale=0.55)])\n+    analysis_report.add_section(analysis_section)\n+\n+    analysis_section = AnalysisSection(\"Statistics of holes\")\n+\n+    statistics_result_array = []\n+\n+    for filter_name in AnalysisUtils.ALL_FILTERS:\n+        if results_dict[filter_name] == {}:\n+            continue\n+        n_holes = len(results_dict[filter_name]['rms']['areas'])\n+        if n_holes > 0:\n+            max_hole = max(results_dict[filter_name]['rms']['areas'])\n+        else:\n+            max_hole = 0\n+\n+        table_row = [filter_name.replace(\"_\", \" \"), n_holes, max_hole]\n+\n+        statistics_result_array.append(table_row)\n+\n+    statistics_table = AnalysisTable(['Band', '# of holes', 'Maximum size'], list(map(list, zip(*statistics_result_array))))\n+    analysis_section.add_table(statistics_table)\n+    analysis_report.add_section(analysis_section)\n+\n+    # Add an index to the analysis report\n+    analysis_report.add_index()\n+\n+    # Save the analysis report in various formats\n+    json_file_name_mosaicing = os.path.join(workdir, \"data\", \"mosaicingValidation.json\")\n+    html_file_name_mosaicing = os.path.join(workdir, \"data\", \"mosaicingValidation.html\")\n+    pdflatex_file_name_mosaicing = os.path.join(workdir, \"data\", \"mosaicingValidation.tex\")\n+    analysis_report.save_as_json_file(json_file_name_mosaicing)\n+    analysis_report.save_as_html_file(html_file_name_mosaicing)\n+    analysis_report.save_as_pdflatex_file(pdflatex_file_name_mosaicing)\n+\n+    # Initialize the analysis report\n+    analysis_report = AnalysisReport(\"MER background validation for tile %s\" % tile_index)\n+\n+    # Create a subsection for the aperture flux histograms\n+    analysis_section = AnalysisSection(\"Aperture flux histograms\")\n+    analysis_section.set_figures([AnalysisFigure(results_dict['aperture_flux_hist_list'][i]) for i in range(len(results_dict['aperture_flux_hist_list']))])\n+    analysis_report.add_section(analysis_section)\n+\n+    # Add an index to the analysis report\n+    analysis_report.add_index()\n+\n+    # Save the analysis report in various formats\n+    json_file_name_bkg = os.path.join(workdir, \"data\", \"backgroundValidation.json\")\n+    html_file_name_bkg = os.path.join(workdir, \"data\", \"backgroundValidation.html\")\n+    pdflatex_file_name_bkg = os.path.join(workdir, \"data\", \"backgroundValidation.tex\")\n+    analysis_report.save_as_json_file(json_file_name_bkg)\n+    analysis_report.save_as_html_file(html_file_name_bkg)\n+    analysis_report.save_as_pdflatex_file(pdflatex_file_name_bkg)\n+\n+    return [json_file_name_mosaicing, html_file_name_mosaicing, pdflatex_file_name_mosaicing], [json_file_name_bkg, html_file_name_bkg, pdflatex_file_name_bkg]\n+    # return [json_file_name_mosaicing, html_file_name_mosaicing, pdflatex_file_name_mosaicing, json_file_name_bkg, html_file_name_bkg, pdflatex_file_name_bkg]\n+\n+def image_statistics(file_name, logger):\n+    \"\"\"Compute statistics for fits image.\n+\n+    Parameters\n+    ----------\n+    file_name: str\n+        The complete path to the fits file.\n+    logger: object\n+        A logger instance.\n+\n+    \"\"\"\n+    out_dict = {'image_file': file_name}\n+\n+    data = fits.getdata(file_name)\n+\n+    out_dict['N_pixels']               = np.size(data)\n+    out_dict['shape']                  = data.shape\n+    finite_mask = np.isfinite(data)\n+    out_dict['N_finite_pixels']        = len(finite_mask[finite_mask == True])\n+    out_dict['percent_finite_pixels']  = 100.*(out_dict['N_finite_pixels']/out_dict['N_pixels'])\n+\n+    if out_dict['N_finite_pixels'] != out_dict['N_pixels']:\n+        logger.warning(\"# %s pixels in %s have infinite values\\n\" % \n+                         (out_dict['N_pixels']-out_dict['N_finite_pixels'],file_name))\n+\n+    out_dict['flux_min']    = np.nanmin(data)\n+    out_dict['flux_max']    = np.nanmax(data)\n+    out_dict['flux_median'] = np.nanmedian(data)\n+    out_dict['flux_nmad']   = mad_std(data, ignore_nan=True)\n+\n+    return out_dict\n+\n+def rms_statistics(file_name, logger):\n+    \"\"\"Compute statistics for fits RMS map.\n+\n+    Parameters\n+    ----------\n+    file_name: str\n+        The complete path to the fits file.\n+    logger: object\n+        A logger instance.\n+\n+    \"\"\"\n+    out_dict = {'rms_file': file_name}\n+\n+    areas, median_rms = MER_NoiseRMSUtils.rms_holes_count(file_name)\n+\n+    out_dict['areas']      = areas\n+    if len(areas) > 0:\n+        out_dict['max_area']   = np.nanmax(areas)\n+    else:\n+        out_dict['max_area']   = 0.\n+    out_dict['median_rms'] = median_rms\n+\n+    return out_dict\n+\n+def aperture_stats_plots(results_dict, filter_name, output_path='image_depth.png'):\n+    aperture_color_list = ['b', 'cyan', 'g', 'grey', 'purple', 'r', 'orange', 'meganta', 'black']\n+    # filter_name_list = ['VIS', 'NIR_Y', 'NIR_J', 'NIR_H', 'DECAM_g', 'DECAM_r', 'DECAM_i', 'DECAM_z', 'LSST_u', 'LSST_g', 'LSST_r',\n+    #                     'LSST_i', 'LSST_z', 'OMEGACAM_u', 'OMEGACAM_g', 'OMEGACAM_r', 'OMEGACAM_i', 'MEGACAM_u', 'MEGACAM_r',\n+    #                     'JPCAM_g', 'PANSTARRS_i', 'PANSTARRS_z', 'HSCS_z']\n+    nbins = 150\n+    # for filter_name in filter_name_list:\n+        # if filter_name in results_dict:\n+    if results_dict[filter_name] != {}:\n+        fig = plt.figure(figsize=(9,6))\n+        sigma_ap_max = 0.\n+        for i in range(len(results_dict[filter_name]['aperture_list'])): \n+            sigma_ap_max = max(sigma_ap_max, results_dict[filter_name]['flux_aperture_sigma_list'][i])\n+            print(results_dict[filter_name]['flux_aperture_sigma_list'][i])\n+        # bins = np.linspace(-5.*sigma_ap_max, 5.*sigma_ap_max, nbins)\n+        bins = np.linspace(-3.*sigma_ap_max, 3.*sigma_ap_max, nbins)\n+        for i in range(len(results_dict[filter_name]['aperture_list'])):\n+            median_avg_flux = np.median(results_dict[filter_name]['flux_average_dict'][i])\n+            plt.hist(results_dict[filter_name]['flux_average_dict'][i], bins, alpha=1.0, color=aperture_color_list[i],\n+                    label='aper = %.2f pix'%(results_dict[filter_name]['aperture_list'][i]), histtype='step')\n+            plt.axvline(x=median_avg_flux, color=aperture_color_list[i],\n+                    label='median avg flux = %.5f'%(median_avg_flux))\n+            plt.axvline(x=median_avg_flux-results_dict[filter_name]['flux_aperture_sigma_list'][i], color=aperture_color_list[i], alpha=0.5, linestyle='dashed')\n+            plt.axvline(x=median_avg_flux+results_dict[filter_name]['flux_aperture_sigma_list'][i], color=aperture_color_list[i], alpha=0.5, linestyle='dashed')\n+        plt.title('Aperture flux histogram for %s'%(filter_name.replace(\"_\", \" \")))\n+        plt.grid()\n+        plt.legend()\n+        plt.xlabel('Average flux')\n+        plt.ylabel('Sample counts')\n+        plt.tight_layout()\n+        plt.savefig(output_path)\n+        plt.close(fig)\n+\n+\n+def image_depth_plot(results_dict, output_path='image_depth.png'):\n+\n+    filter_wavelength_dict = {'DECAM_g':     {'wavelength':  475.4, 'width': 130., 'marker': 'o', 'color': 'g'},\n+                              'DECAM_r':     {'wavelength':  620.4, 'width': 120., 'marker': 'o', 'color': 'r'},\n+                              'DECAM_i':     {'wavelength':  769.8, 'width': 130., 'marker': 'o', 'color': 'b'},\n+                              'DECAM_z':     {'wavelength':  966.5, 'width': 100., 'marker': 'o', 'color': 'k'},\n+                              'LSST_u':      {'wavelength':  358.0, 'width':  55., 'marker': '^', 'color': 'y'},\n+                              'LSST_g':      {'wavelength':  475.4, 'width': 130., 'marker': '^', 'color': 'g'},\n+                              'LSST_r':      {'wavelength':  620.4, 'width': 120., 'marker': '^', 'color': 'r'},\n+                              'LSST_i':      {'wavelength':  769.8, 'width': 130., 'marker': '^', 'color': 'b'},\n+                              'LSST_z':      {'wavelength':  966.5, 'width': 100., 'marker': '^', 'color': 'k'},\n+                              'NIR_Y':       {'wavelength': 1031.0, 'width': 226., 'marker': 'x', 'color': 'r'},\n+                              'NIR_J':       {'wavelength': 1248.0, 'width': 226., 'marker': 'x', 'color': 'g'},\n+                              'NIR_H':       {'wavelength': 1631.0, 'width': 628., 'marker': 'x', 'color': 'b'},\n+                              'VIS':         {'wavelength':  725.0, 'width': 350., 'marker': 's', 'color': 'k'},\n+                              'OMEGACAM_u':  {'wavelength':  358.0, 'width':  55., 'marker': '+', 'color': 'y'},\n+                              'OMEGACAM_g':  {'wavelength':  475.4, 'width': 130., 'marker': '+', 'color': 'g'},\n+                              'OMEGACAM_r':  {'wavelength':  620.4, 'width': 120., 'marker': '+', 'color': 'r'},\n+                              'OMEGACAM_i':  {'wavelength':  769.8, 'width': 130., 'marker': '+', 'color': 'b'},\n+                              'MEGACAM_u':   {'wavelength':  358.0, 'width':  55., 'marker': 'D', 'color': 'y'},\n+                              'MEGACAM_r':   {'wavelength':  620.4, 'width': 120., 'marker': 'D', 'color': 'r'},\n+                              'JPCAM_g':     {'wavelength':  475.4, 'width': 130., 'marker': 'v', 'color': 'g'},\n+                              'PANSTARRS_i': {'wavelength':  769.8, 'width': 130., 'marker': '*', 'color': 'b'},\n+                              'PANSTARRS_z': {'wavelength':  966.5, 'width': 100., 'marker': '*', 'color': 'k'},\n+                              'HSCS_z':      {'wavelength':  966.5, 'width': 100., 'marker': '>', 'color': 'k'},\n+                              'HSC_z':      {'wavelength':  966.5, 'width': 100., 'marker': '>', 'color': 'k'},\n+                              'HSC_g':      {'wavelength':  475.4, 'width': 130., 'marker': '>', 'color': 'b'},\n+                              }\n+    fig = plt.figure(figsize=(9,6))\n+\n+    for filter_name in filter_wavelength_dict:\n+        #print('filter_name:', filter_name)\n+        if filter_name in results_dict:\n+            if results_dict[filter_name] != {}:\n+\n+                # # image depth from rms map\n+                # plt.errorbar(filter_wavelength_dict[filter_name]['wavelength'],\n+                #             results_dict[filter_name]['image_depth_rms_mag'],\n+                #             xerr = filter_wavelength_dict[filter_name]['width']/2.,\n+                #             c=filter_wavelength_dict[filter_name]['color'],\n+                #             marker=filter_wavelength_dict[filter_name]['marker'],\n+                #             label=filter_name.replace(\"_\", \" \"))\n+                # image depth from rms map\n+                plt.errorbar(filter_wavelength_dict[filter_name]['wavelength'],\n+                            results_dict[filter_name]['image_mag_aperture_nmad'],\n+                            xerr = filter_wavelength_dict[filter_name]['width']/2.,\n+                            c=filter_wavelength_dict[filter_name]['color'],\n+                            marker=filter_wavelength_dict[filter_name]['marker'],\n+                            label=filter_name.replace(\"_\", \" \"))\n+\n+                plt.title('Image depth for %s\" aperture (%s\\N{greek small letter sigma})' %\n+                                                   (results_dict[filter_name]['aperture'],\n+                                                   results_dict[filter_name]['image_limit_mag_sigma_lim']))\n+    plt.legend()\n+    plt.xlabel('Wavelength [nm]')\n+    plt.ylabel('Image depth [mag]')\n+    plt.tight_layout()\n+    plt.savefig(output_path)\n+    plt.close(fig)\n+\n+def holes_hist_plot(results_dict, output_path_vis_nir='holes_hist_vis_nir.png',\n+                                  output_path_ext='holes_hist_ext.png'):\n+    plt.set_loglevel('WARNING')\n+\n+    filter_color_dict = {'DECAM_g':     'b',\n+                         'DECAM_r':     'cyan',\n+                         'DECAM_i':     'g',\n+                         'DECAM_z':     'grey',\n+                         'LSST_u':      'purple',\n+                         'LSST_g':      'b',\n+                         'LSST_r':      'cyan',\n+                         'LSST_i':      'g',\n+                         'LSST_z':      'grey',\n+                         'NIR_Y':       'r',\n+                         'NIR_J':       'orange',\n+                         'NIR_H':       'magenta',\n+                         'VIS':         'black',\n+                         'OMEGACAM_u':  'purple',\n+                         'OMEGACAM_g':  'b',\n+                         'OMEGACAM_r':  'cyan',\n+                         'OMEGACAM_i':  'g',\n+                         'MEGACAM_u':   'purple',\n+                         'MEGACAM_r':   'cyan',\n+                         'JPCAM_g':     'b',\n+                         'PANSTARRS_i': 'g',\n+                         'PANSTARRS_z': 'grey',\n+                         'HSCS_z':      'grey',\n+                         'HSC_z':       'grey',\n+                         'HSC_g':       'b'\n+                         }\n+\n+    VISNIR_filters = ['NIR_Y', 'NIR_J', 'NIR_H', 'VIS']\n+\n+    # EXT_filters    = ['DECAM_g', 'DECAM_r', 'DECAM_i', 'DECAM_z',\n+    #                   'LSST_u', 'LSST_g', 'LSST_r', 'LSST_i', 'LSST_z',\n+    #                   'OMEGACAM_u', 'OMEGACAM_g', 'OMEGACAM_r', 'OMEGACAM_i',\n+    #                   'MEGACAM_u', 'MEGACAM_r', 'JPCAM_g',\n+    #                   'PANSTARRS_i', 'PANSTARRS_z', 'HSCS_z']\n+    EXT_filters = [\n+        \"DECAM_g\", \"DECAM_r\", \"DECAM_i\", \"DECAM_z\",\n+        \"OMEGACAM_u\", \"OMEGACAM_g\", \"OMEGACAM_r\", \"OMEGACAM_i\",\n+        \"LSST_u\", \"LSST_g\", \"LSST_r\", \"LSST_i\", \"LSST_z\", \"LSST_Y\",\n+        \"MEGACAM_u\", \"MEGACAM_r\",\n+        \"JPCAM_g\",\n+        \"PANSTARRS_i\", \"PANSTARRS_z\",\n+        \"HSC_z\", \"HSC_g\"\n+    ]\n+\n+    bins = 2**(np.arange(0,23))\n+\n+    fig = plt.figure(figsize=(9,6))\n+\n+    for filter_name in AnalysisUtils.ALL_FILTERS:\n+        if results_dict[filter_name] == {}:\n+            continue\n+        if filter_name in VISNIR_filters:\n+\n+            plt.hist(results_dict[filter_name]['rms']['areas'], alpha=1.0, color=filter_color_dict[filter_name],\n+                           label=filter_name.replace(\"_\", \" \"), bins=bins, histtype='step')\n+\n+    plt.legend()\n+    plt.xscale('log')\n+    plt.yscale('log')\n+    plt.xlabel('Hole size [pixels]')\n+    plt.ylabel('N')\n+    plt.tight_layout()\n+    plt.savefig(output_path_vis_nir)\n+    plt.close(fig)\n+\n+    fig = plt.figure(figsize=(9,6))\n+\n+    for filter_name in AnalysisUtils.ALL_FILTERS:\n+        if results_dict[filter_name] == {}:\n+            continue\n+        if filter_name in EXT_filters:\n+\n+            plt.hist(results_dict[filter_name]['rms']['areas'], alpha=1.0, color=filter_color_dict[filter_name],\n+                           label=filter_name.replace(\"_\", \" \"), bins=bins, histtype='step')\n+\n+    plt.legend()\n+    plt.xscale('log')\n+    plt.yscale('log')\n+    plt.xlabel('Hole size [pixels]')\n+    plt.ylabel('N')\n+    plt.tight_layout()\n+    plt.savefig(output_path_ext)\n+    plt.close(fig)\n+\n+def get_pixel_scale(wcs):\n+    CD1_1_arcsec = np.abs(wcs['CD1_1']*3600.)\n+    CD2_2_arcsec = np.abs(wcs['CD2_2']*3600.)\n+    if (~np.isclose(CD1_1_arcsec,CD2_2_arcsec)).sum():\n+        logger.warning(\"# CD1_1 and CD2_2 have infinite values: %s and %s\\n\" % \n+                         (CD1_1_arcsec,CD2_2_arcsec))\n+    return CD1_1_arcsec\n+\n+def mainMethod(args):\n+    \"\"\"\n+    @brief The \"main\" method.\n+\n+    @details This method is the entry point to the program. In this sense, it is\n+    similar to a main (and it is why it is called mainMethod()).\n+    \"\"\"\n+\n+    logger = log.getLogger('MER_MosaicingValidationPrg')\n+\n+    logger.info('#')\n+    logger.info('# Entering MER_MosaicingValidationPrg mainMethod()')\n+    logger.info('#')\n+\n+    # Store the start time\n+    start_time = time.time()\n+\n+    # print all parameters to the screen\n+    print_input_arguments(args, logger)\n+\n+    # Do not print astropy warnings\n+    AnalysisUtils.ignore_astropy_warnings()\n+\n+    # Add some extra functionality to the MER data product bindings\n+    mer_utils.init()\n+\n+    # Create the figures directory\n+    figsdir_mosaicing = os.path.join(args.workdir, \"data\", \"mosaicingFigures\")\n+    AnalysisUtils.create_directory(figsdir_mosaicing)\n+\n+    figsdir_bkg = os.path.join(args.workdir, \"data\", \"backgroundFigures\")\n+    AnalysisUtils.create_directory(figsdir_bkg)\n+\n+    # Load the MER background-subtracted mosaics\n+    mosaics = AnalysisUtils.get_background_subtracted_mosaics(\n+        os.path.join(args.workdir, args.mosaics), args.workdir)\n+\n+    final_segmap = dm_utils.read_product_metadata(os.path.join(\n+        args.workdir, args.segmap))\n+    segmap_file_name = os.path.join(args.workdir, \"data\", final_segmap.get_data())\n+\n+    # Check that the wordir exists\n+    AnalysisUtils.check_directory_exists(args.workdir)\n+\n+    results_dict = {}\n+    aperture_arcsec = 2.\n+    results_dict['aperture_flux_hist_list'] = []\n+\n+    # Loop over all the possible filter names\n+    for filter_name in AnalysisUtils.ALL_FILTERS:\n+        # Move to the next filter name if the filter is not available\n+        if filter_name not in mosaics:\n+            results_dict[filter_name] = {}\n+            continue\n+        # Get the MER background-subtracted mosaic xmls\n+        mosaic = mosaics[filter_name]\n+        tile_index = mosaic.get_tile_index()\n+\n+        # Compare the mosaic files\n+        logger.info(\"# Validating mosaic fits files for band %s\" % filter_name)\n+        logger.info(\"#   Validating image files...\")\n+        data_file_name = os.path.join(args.workdir, \"data\", mosaic.get_data())\n+        rms_file_name = os.path.join(args.workdir, \"data\", mosaic.get_rms())\n+        \n+        wcs = mosaic.get_wcs()\n+        pix_scale = get_pixel_scale(wcs)\n+        zp = mosaic.get_zero_point()\n+\n+        # image_stat = image_statistics(data_file_name, logger)\n+        \n+        logger.info(\"#   Validating rms files...\")\n+        rms_stat = rms_statistics(rms_file_name, logger)\n+\n+        sigma_lim = 5.\n+        aperture_ap, sigma_ap, mad_ap, nmad_ap, flux_average_dict, flux_median_dict, _, _, flux_average_std, flux_average_mad = MER_NoiseApertureUtils.noise_statistics_aperture(data_file_name, segmap_file_name, \\\n+                                                       aperture_min=round(aperture_arcsec/pix_scale),\n+                                                       aperture_max=round(aperture_arcsec/pix_scale),\n+                                                       aperture_step=1,\n+                                                       Nsample=10000,\n+                                                       sigma_cl=5.,\n+                                                       logger=logger)\n+        mag_nmad = zp['value'] - 2.5*np.log10(sigma_lim*nmad_ap)\n+\n+        # aperture_ap_rms, sigma_ap_rms = MER_NoiseRMSUtils.noise_statistics_from_rms(rms_file_name,\n+        #                                                segmap_file_name,\n+        #                                                aperture_min=round(aperture_arcsec/pix_scale),\n+        #                                                aperture_max=round(aperture_arcsec/pix_scale),\n+        #                                                aperture_step=1)\n+        # image_depth_rms = zp['value'] - 2.5*np.log10(sigma_lim*sigma_ap_rms)\n+\n+        results_dict[filter_name] = {\n+                                    # 'image': image_stat,\n+                                    #  'flag': flag_stat,\n+                                     'rms': rms_stat,\n+                                    #  'flag_hist_plot': flag_hist_path,\n+                                     'image_limit_mag_sigma_lim': sigma_lim,\n+                                     'image_mag_aperture_nmad': mag_nmad[0],\n+                                     'flux_aperture_sigma_list': flux_average_std,\n+                                    #  'image_depth_rms_median': sigma_ap_rms[0],\n+                                    #  'image_depth_rms_mag': image_depth_rms[0],\n+                                     'sigma_lim': sigma_lim,\n+                                     'zp': zp['value'],\n+                                     'aperture': aperture_arcsec,\n+                                     'aperture_list': aperture_ap,\n+                                     'flux_average_dict': flux_average_dict,\n+                                     'flux_median_dict': flux_median_dict\n+                                     }\n+        aperture_flux_hist_path = os.path.join(figsdir_bkg, 'aperture_flux_hist_%s.png' % (filter_name))\n+        # aperture_flux_hist_path = os.path.join(figsdir_mosaicing, 'aperture_flux_hist_%s.png' % (filter_name))\n+        aperture_stats_plots(results_dict, filter_name, output_path=aperture_flux_hist_path)\n+        # aperture_stats_plots(results_dict, output_path=aperture_flux_hist_path)\n+        # results_dict[filter_name]['aperture_flux_hist'] = aperture_flux_hist_path\n+        results_dict['aperture_flux_hist_list'].append(aperture_flux_hist_path)\n+\n+    image_depth_plot_path = os.path.join(figsdir_mosaicing, 'image_depth_%s.png' % tile_index)\n+    image_depth_plot(results_dict, output_path=image_depth_plot_path)\n+    results_dict['image_depth_plot'] = image_depth_plot_path\n+\n+    holes_hist_path_vis_nir = os.path.join(figsdir_mosaicing, 'holes_hist_vis_nir_%s.png' % tile_index)\n+    holes_hist_path_ext     = os.path.join(figsdir_mosaicing, 'holes_hist_ext_%s.png' % tile_index)\n+    holes_hist_plot(results_dict, output_path_vis_nir=holes_hist_path_vis_nir, \n+                                  output_path_ext=holes_hist_path_ext)\n+    results_dict['holes_hist_plot_vis_nir'] = holes_hist_path_vis_nir\n+    results_dict['holes_hist_plot_ext'] = holes_hist_path_ext\n+\n+    # Create the analysis report\n+    logger.info(\"# Creating the mosaicing analysis report...\")\n+    report_file_names_mosaicing,  report_file_names_bkg = create_analysis_report(results_dict, tile_index, args.workdir, logger)\n+    # report_file_names_mosaicing = create_analysis_report(results_dict, tile_index, args.workdir, logger)\n+\n+    # Save all the analysis files into a tar file\n+    tar_file_name_mosaicing = mer_filename(\n+        \"ANALYSIS-RESULT\", prefix=\"MOSAICING\", tile_index=tile_index, ext=\"tar.gz\")\n+    AnalysisUtils.save_tar_file(os.path.join(args.workdir, \"data\", tar_file_name_mosaicing),\n+                                report_file_names_mosaicing + [figsdir_mosaicing])\n+    \n+    tar_file_name_bkg = mer_filename(\n+        \"ANALYSIS-RESULT\", prefix=\"BACKGROUND\", tile_index=tile_index, ext=\"tar.gz\")\n+    AnalysisUtils.save_tar_file(os.path.join(args.workdir, \"data\", tar_file_name_bkg),\n+                                report_file_names_bkg + [figsdir_bkg])\n+\n+    # Get the tile index, the processing mode and the observation ids\n+    tile_index      = mosaics[\"VIS\"].get_tile_index()\n+    processing_mode = mosaics[\"VIS\"].get_processing_mode()\n+    observation_ids = set()\n+\n+    for mosaic in mosaics.values():\n+        observation_ids.update(mosaic.get_observation_id_list())\n+    \n+    # Create the analysis result data product\n+    global_result = \"PASSED\"\n+    analysis_result = mer_utils.create_analysis_result(global_result)\n+    analysis_result.set_tile_index(tile_index)\n+    analysis_result.set_observation_id_list(observation_ids)\n+    analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_figures_tar_file(tar_file_name_mosaicing)\n+\n+    # Save the analysis result data product as an XML file\n+    logger.info(\"# Saving the analysis result data product\")\n+    analysis_result.save_xml(os.path.join(args.workdir, args.mosaicing_result))\n+\n+    # Create the analysis result data product\n+    global_result = \"PASSED\"\n+    analysis_result = mer_utils.create_analysis_result(global_result)\n+    analysis_result.set_tile_index(tile_index)\n+    analysis_result.set_observation_id_list(observation_ids)\n+    analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_figures_tar_file(tar_file_name_bkg)\n+\n+    # Save the analysis result data product as an XML file\n+    logger.info(\"# Saving the analysis result data product\")\n+    analysis_result.save_xml(os.path.join(args.workdir, args.background_result))\n+\n+    # Print the time spent running the step\n+    logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n+    logger.info('#')\n+    logger.info('# Exiting MER_MosaicingValidationPrg mainMethod()')\n+    logger.info('#')\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T11:46:20.000+00:00",
                            "a83f468ea9bc0e5270859fcc7d1e7f8aa8bf922f"
                        ],
                        [
                            "@@ -71,8 +71,11 @@ def defineSpecificProgramOptions():\n     parser.add_argument(\"--logdir\", dest=\"logdir\",\n                         type=str, help=\"The logging directory path.\")\n \n-    parser.add_argument(\"--analysis_result\", dest=\"analysis_result\",\n-                        type=str, help=\"The analysis result output data \"\n+    parser.add_argument(\"--mosaicing_result\", dest=\"mosaicing_result\",\n+                        type=str, help=\"The mosaicing result output data \"\n+                        \"product XML file name.\")\n+    parser.add_argument(\"--background_result\", dest=\"background_result\",\n+                        type=str, help=\"The background result output data \"\n                         \"product XML file name.\")\n     return parser\n \n@@ -153,7 +156,7 @@ def create_analysis_report(results_dict, tile_index, workdir, logger):\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name_mosaicing)\n \n     # Initialize the analysis report\n-    analysis_report = AnalysisReport(\"MER mosaicing validation for tile %s\" % tile_index)\n+    analysis_report = AnalysisReport(\"MER background validation for tile %s\" % tile_index)\n \n     # Create a subsection for the aperture flux histograms\n     analysis_section = AnalysisSection(\"Aperture flux histograms\")\n@@ -171,8 +174,8 @@ def create_analysis_report(results_dict, tile_index, workdir, logger):\n     analysis_report.save_as_html_file(html_file_name_bkg)\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name_bkg)\n \n-    return [json_file_name_mosaicing, html_file_name_mosaicing, pdflatex_file_name_mosaicing,\n-            json_file_name_bkg, html_file_name_bkg, pdflatex_file_name_bkg]\n+    return [json_file_name_mosaicing, html_file_name_mosaicing, pdflatex_file_name_mosaicing], [json_file_name_bkg, html_file_name_bkg, pdflatex_file_name_bkg]\n+    # return [json_file_name_mosaicing, html_file_name_mosaicing, pdflatex_file_name_mosaicing, json_file_name_bkg, html_file_name_bkg, pdflatex_file_name_bkg]\n \n def image_statistics(file_name, logger):\n     \"\"\"Compute statistics for fits image.\n@@ -247,10 +250,13 @@ def aperture_stats_plots(results_dict, filter_name, output_path='image_depth.png\n         # bins = np.linspace(-5.*sigma_ap_max, 5.*sigma_ap_max, nbins)\n         bins = np.linspace(-3.*sigma_ap_max, 3.*sigma_ap_max, nbins)\n         for i in range(len(results_dict[filter_name]['aperture_list'])):\n+            median_avg_flux = np.median(results_dict[filter_name]['flux_average_dict'][i])\n             plt.hist(results_dict[filter_name]['flux_average_dict'][i], bins, alpha=1.0, color=aperture_color_list[i],\n                     label='aper = %.2f pix'%(results_dict[filter_name]['aperture_list'][i]), histtype='step')\n-            plt.axvline(x=np.median(results_dict[filter_name]['flux_average_dict'][i]), color=aperture_color_list[i],\n-                    label='median avg flux = %.5f'%(np.median(results_dict[filter_name]['flux_average_dict'][i])))\n+            plt.axvline(x=median_avg_flux, color=aperture_color_list[i],\n+                    label='median avg flux = %.5f'%(median_avg_flux))\n+            plt.axvline(x=median_avg_flux-results_dict[filter_name]['flux_aperture_sigma_list'][i], color=aperture_color_list[i], alpha=0.5, linestyle='dashed')\n+            plt.axvline(x=median_avg_flux+results_dict[filter_name]['flux_aperture_sigma_list'][i], color=aperture_color_list[i], alpha=0.5, linestyle='dashed')\n         plt.title('Aperture flux histogram for %s'%(filter_name.replace(\"_\", \" \")))\n         plt.grid()\n         plt.legend()\n@@ -525,6 +531,7 @@ def mainMethod(args):\n                                      'flux_median_dict': flux_median_dict\n                                      }\n         aperture_flux_hist_path = os.path.join(figsdir_bkg, 'aperture_flux_hist_%s.png' % (filter_name))\n+        # aperture_flux_hist_path = os.path.join(figsdir_mosaicing, 'aperture_flux_hist_%s.png' % (filter_name))\n         aperture_stats_plots(results_dict, filter_name, output_path=aperture_flux_hist_path)\n         # aperture_stats_plots(results_dict, output_path=aperture_flux_hist_path)\n         # results_dict[filter_name]['aperture_flux_hist'] = aperture_flux_hist_path\n@@ -544,6 +551,7 @@ def mainMethod(args):\n     # Create the analysis report\n     logger.info(\"# Creating the mosaicing analysis report...\")\n     report_file_names_mosaicing,  report_file_names_bkg = create_analysis_report(results_dict, tile_index, args.workdir, logger)\n+    # report_file_names_mosaicing = create_analysis_report(results_dict, tile_index, args.workdir, logger)\n \n     # Save all the analysis files into a tar file\n     tar_file_name_mosaicing = mer_filename(\n@@ -552,7 +560,7 @@ def mainMethod(args):\n                                 report_file_names_mosaicing + [figsdir_mosaicing])\n     \n     tar_file_name_bkg = mer_filename(\n-        \"ANALYSIS-RESULT\", prefix=\"Background\", tile_index=tile_index, ext=\"tar.gz\")\n+        \"ANALYSIS-RESULT\", prefix=\"BACKGROUND\", tile_index=tile_index, ext=\"tar.gz\")\n     AnalysisUtils.save_tar_file(os.path.join(args.workdir, \"data\", tar_file_name_bkg),\n                                 report_file_names_bkg + [figsdir_bkg])\n \n@@ -574,7 +582,7 @@ def mainMethod(args):\n \n     # Save the analysis result data product as an XML file\n     logger.info(\"# Saving the analysis result data product\")\n-    analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n+    analysis_result.save_xml(os.path.join(args.workdir, args.mosaicing_result))\n \n     # Create the analysis result data product\n     global_result = \"PASSED\"\n@@ -586,7 +594,7 @@ def mainMethod(args):\n \n     # Save the analysis result data product as an XML file\n     logger.info(\"# Saving the analysis result data product\")\n-    analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n+    analysis_result.save_xml(os.path.join(args.workdir, args.background_result))\n \n     # Print the time spent running the step\n     logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n",
                            "updated mosaicingValidation, added mosaicing validation, background validation results to the final validation result html page",
                            "yfang",
                            "2023-08-14T18:25:04.000+02:00",
                            "39f28448cb5cf67c239c10640dcce6322725cf69"
                        ],
                        [
                            "@@ -0,0 +1,595 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\n+\"\"\"\n+:file: python/MER_Validation/MER_MosaicingValidationPrg.py\n+\n+:date: 07/28/23\n+:author: yfang\n+\n+\"\"\"\n+\n+import argparse\n+import matplotlib.pyplot as plt\n+import ElementsKernel.Logging as log\n+import numpy as np\n+from astropy.io import fits\n+from astropy.stats import mad_std\n+from astropy.nddata import bitmask\n+import json\n+import os\n+import time\n+\n+from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils.FileNaming import mer_filename\n+\n+from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisTable import AnalysisTable\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n+\n+import MER_MosaicingValidation.MER_NoiseApertureUtils as MER_NoiseApertureUtils\n+import MER_MosaicingValidation.MER_NoiseRMSUtils as MER_NoiseRMSUtils\n+from MER_DA.MERUtilities import print_input_arguments\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"\n+    @brief Allows to define the (command line and configuration file) options\n+    specific to this program\n+\n+    @details See the Elements documentation for more details.\n+    @return An  ArgumentParser.\n+    \"\"\"\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser.add_argument(\"--mosaics\", dest=\"mosaics\",\n+                        type=str, help=\"A json file with the MER \"\n+                        \"background-subtracted mosaic XML file names.\")\n+    parser.add_argument(\"--segmap\", dest=\"segmap\",\n+                        type=str, help=\"A path to XML file of segmantation map \")\n+    parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n+                        default='./', help='Path to the working directory: \"%(default)s\"!')\n+    parser.add_argument(\"--logdir\", dest=\"logdir\",\n+                        type=str, help=\"The logging directory path.\")\n+\n+    parser.add_argument(\"--analysis_result\", dest=\"analysis_result\",\n+                        type=str, help=\"The analysis result output data \"\n+                        \"product XML file name.\")\n+    return parser\n+\n+def create_analysis_report(results_dict, tile_index, workdir, logger):\n+    \"\"\"Creates an analysis report.\n+\n+    Parameters\n+    ----------\n+    results_dict: dictionary\n+        All results from the validation analysis\n+    tile_index: int\n+        The MER tile index.\n+    workdir: str\n+        The complete path to the working directory.\n+    logger: object\n+        A logger instance.\n+\n+    Returns\n+    -------\n+    list\n+        A python list with the analysis report file names.\n+\n+    \"\"\"\n+    logger.info(\"# Creating the analysis report!\")\n+    \n+    # Initialize the analysis report\n+    analysis_report = AnalysisReport(\"MER mosaicing validation for tile %s\" % tile_index)\n+\n+    # Create a subsection for the imag depth plot\n+    analysis_section = AnalysisSection(\"Image depth plot\")\n+    analysis_section.set_figures([AnalysisFigure(results_dict['image_depth_plot'], latex_scale=0.55)])\n+    analysis_report.add_section(analysis_section)\n+\n+    # # Create a subsection for the aperture flux histograms\n+    # analysis_section = AnalysisSection(\"Aperture flux histograms\")\n+    # analysis_section.set_figures([AnalysisFigure(results_dict['aperture_flux_hist_list'][i]) for i in range(len(results_dict['aperture_flux_hist_list']))])\n+    # analysis_report.add_section(analysis_section)\n+\n+    # Create a subsection for image holes\n+    analysis_section = AnalysisSection(\"Histogram plot for VIS and NIR image holes\")\n+    analysis_section.set_figures([AnalysisFigure(results_dict['holes_hist_plot_vis_nir'], latex_scale=0.55)])\n+    analysis_report.add_section(analysis_section)\n+\n+    analysis_section = AnalysisSection(\"Histogram plot for EXT image holes\")\n+    analysis_section.set_figures([AnalysisFigure(results_dict['holes_hist_plot_ext'], latex_scale=0.55)])\n+    analysis_report.add_section(analysis_section)\n+\n+    analysis_section = AnalysisSection(\"Statistics of holes\")\n+\n+    statistics_result_array = []\n+\n+    for filter_name in AnalysisUtils.ALL_FILTERS:\n+        if results_dict[filter_name] == {}:\n+            continue\n+        n_holes = len(results_dict[filter_name]['rms']['areas'])\n+        if n_holes > 0:\n+            max_hole = max(results_dict[filter_name]['rms']['areas'])\n+        else:\n+            max_hole = 0\n+\n+        table_row = [filter_name.replace(\"_\", \" \"), n_holes, max_hole]\n+\n+        statistics_result_array.append(table_row)\n+\n+    statistics_table = AnalysisTable(['Band', '# of holes', 'Maximum size'], list(map(list, zip(*statistics_result_array))))\n+    analysis_section.add_table(statistics_table)\n+    analysis_report.add_section(analysis_section)\n+\n+    # Add an index to the analysis report\n+    analysis_report.add_index()\n+\n+    # Save the analysis report in various formats\n+    json_file_name_mosaicing = os.path.join(workdir, \"data\", \"mosaicingValidation.json\")\n+    html_file_name_mosaicing = os.path.join(workdir, \"data\", \"mosaicingValidation.html\")\n+    pdflatex_file_name_mosaicing = os.path.join(workdir, \"data\", \"mosaicingValidation.tex\")\n+    analysis_report.save_as_json_file(json_file_name_mosaicing)\n+    analysis_report.save_as_html_file(html_file_name_mosaicing)\n+    analysis_report.save_as_pdflatex_file(pdflatex_file_name_mosaicing)\n+\n+    # Initialize the analysis report\n+    analysis_report = AnalysisReport(\"MER mosaicing validation for tile %s\" % tile_index)\n+\n+    # Create a subsection for the aperture flux histograms\n+    analysis_section = AnalysisSection(\"Aperture flux histograms\")\n+    analysis_section.set_figures([AnalysisFigure(results_dict['aperture_flux_hist_list'][i]) for i in range(len(results_dict['aperture_flux_hist_list']))])\n+    analysis_report.add_section(analysis_section)\n+\n+    # Add an index to the analysis report\n+    analysis_report.add_index()\n+\n+    # Save the analysis report in various formats\n+    json_file_name_bkg = os.path.join(workdir, \"data\", \"backgroundValidation.json\")\n+    html_file_name_bkg = os.path.join(workdir, \"data\", \"backgroundValidation.html\")\n+    pdflatex_file_name_bkg = os.path.join(workdir, \"data\", \"backgroundValidation.tex\")\n+    analysis_report.save_as_json_file(json_file_name_bkg)\n+    analysis_report.save_as_html_file(html_file_name_bkg)\n+    analysis_report.save_as_pdflatex_file(pdflatex_file_name_bkg)\n+\n+    return [json_file_name_mosaicing, html_file_name_mosaicing, pdflatex_file_name_mosaicing,\n+            json_file_name_bkg, html_file_name_bkg, pdflatex_file_name_bkg]\n+\n+def image_statistics(file_name, logger):\n+    \"\"\"Compute statistics for fits image.\n+\n+    Parameters\n+    ----------\n+    file_name: str\n+        The complete path to the fits file.\n+    logger: object\n+        A logger instance.\n+\n+    \"\"\"\n+    out_dict = {'image_file': file_name}\n+\n+    data = fits.getdata(file_name)\n+\n+    out_dict['N_pixels']               = np.size(data)\n+    out_dict['shape']                  = data.shape\n+    finite_mask = np.isfinite(data)\n+    out_dict['N_finite_pixels']        = len(finite_mask[finite_mask == True])\n+    out_dict['percent_finite_pixels']  = 100.*(out_dict['N_finite_pixels']/out_dict['N_pixels'])\n+\n+    if out_dict['N_finite_pixels'] != out_dict['N_pixels']:\n+        logger.warning(\"# %s pixels in %s have infinite values\\n\" % \n+                         (out_dict['N_pixels']-out_dict['N_finite_pixels'],file_name))\n+\n+    out_dict['flux_min']    = np.nanmin(data)\n+    out_dict['flux_max']    = np.nanmax(data)\n+    out_dict['flux_median'] = np.nanmedian(data)\n+    out_dict['flux_nmad']   = mad_std(data, ignore_nan=True)\n+\n+    return out_dict\n+\n+def rms_statistics(file_name, logger):\n+    \"\"\"Compute statistics for fits RMS map.\n+\n+    Parameters\n+    ----------\n+    file_name: str\n+        The complete path to the fits file.\n+    logger: object\n+        A logger instance.\n+\n+    \"\"\"\n+    out_dict = {'rms_file': file_name}\n+\n+    areas, median_rms = MER_NoiseRMSUtils.rms_holes_count(file_name)\n+\n+    out_dict['areas']      = areas\n+    if len(areas) > 0:\n+        out_dict['max_area']   = np.nanmax(areas)\n+    else:\n+        out_dict['max_area']   = 0.\n+    out_dict['median_rms'] = median_rms\n+\n+    return out_dict\n+\n+def aperture_stats_plots(results_dict, filter_name, output_path='image_depth.png'):\n+    aperture_color_list = ['b', 'cyan', 'g', 'grey', 'purple', 'r', 'orange', 'meganta', 'black']\n+    # filter_name_list = ['VIS', 'NIR_Y', 'NIR_J', 'NIR_H', 'DECAM_g', 'DECAM_r', 'DECAM_i', 'DECAM_z', 'LSST_u', 'LSST_g', 'LSST_r',\n+    #                     'LSST_i', 'LSST_z', 'OMEGACAM_u', 'OMEGACAM_g', 'OMEGACAM_r', 'OMEGACAM_i', 'MEGACAM_u', 'MEGACAM_r',\n+    #                     'JPCAM_g', 'PANSTARRS_i', 'PANSTARRS_z', 'HSCS_z']\n+    nbins = 150\n+    # for filter_name in filter_name_list:\n+        # if filter_name in results_dict:\n+    if results_dict[filter_name] != {}:\n+        fig = plt.figure(figsize=(9,6))\n+        sigma_ap_max = 0.\n+        for i in range(len(results_dict[filter_name]['aperture_list'])): \n+            sigma_ap_max = max(sigma_ap_max, results_dict[filter_name]['flux_aperture_sigma_list'][i])\n+            print(results_dict[filter_name]['flux_aperture_sigma_list'][i])\n+        # bins = np.linspace(-5.*sigma_ap_max, 5.*sigma_ap_max, nbins)\n+        bins = np.linspace(-3.*sigma_ap_max, 3.*sigma_ap_max, nbins)\n+        for i in range(len(results_dict[filter_name]['aperture_list'])):\n+            plt.hist(results_dict[filter_name]['flux_average_dict'][i], bins, alpha=1.0, color=aperture_color_list[i],\n+                    label='aper = %.2f pix'%(results_dict[filter_name]['aperture_list'][i]), histtype='step')\n+            plt.axvline(x=np.median(results_dict[filter_name]['flux_average_dict'][i]), color=aperture_color_list[i],\n+                    label='median avg flux = %.5f'%(np.median(results_dict[filter_name]['flux_average_dict'][i])))\n+        plt.title('Aperture flux histogram for %s'%(filter_name.replace(\"_\", \" \")))\n+        plt.grid()\n+        plt.legend()\n+        plt.xlabel('Average flux')\n+        plt.ylabel('Sample counts')\n+        plt.tight_layout()\n+        plt.savefig(output_path)\n+        plt.close(fig)\n+\n+\n+def image_depth_plot(results_dict, output_path='image_depth.png'):\n+\n+    filter_wavelength_dict = {'DECAM_g':     {'wavelength':  475.4, 'width': 130., 'marker': 'o', 'color': 'g'},\n+                              'DECAM_r':     {'wavelength':  620.4, 'width': 120., 'marker': 'o', 'color': 'r'},\n+                              'DECAM_i':     {'wavelength':  769.8, 'width': 130., 'marker': 'o', 'color': 'b'},\n+                              'DECAM_z':     {'wavelength':  966.5, 'width': 100., 'marker': 'o', 'color': 'k'},\n+                              'LSST_u':      {'wavelength':  358.0, 'width':  55., 'marker': '^', 'color': 'y'},\n+                              'LSST_g':      {'wavelength':  475.4, 'width': 130., 'marker': '^', 'color': 'g'},\n+                              'LSST_r':      {'wavelength':  620.4, 'width': 120., 'marker': '^', 'color': 'r'},\n+                              'LSST_i':      {'wavelength':  769.8, 'width': 130., 'marker': '^', 'color': 'b'},\n+                              'LSST_z':      {'wavelength':  966.5, 'width': 100., 'marker': '^', 'color': 'k'},\n+                              'NIR_Y':       {'wavelength': 1031.0, 'width': 226., 'marker': 'x', 'color': 'r'},\n+                              'NIR_J':       {'wavelength': 1248.0, 'width': 226., 'marker': 'x', 'color': 'g'},\n+                              'NIR_H':       {'wavelength': 1631.0, 'width': 628., 'marker': 'x', 'color': 'b'},\n+                              'VIS':         {'wavelength':  725.0, 'width': 350., 'marker': 's', 'color': 'k'},\n+                              'OMEGACAM_u':  {'wavelength':  358.0, 'width':  55., 'marker': '+', 'color': 'y'},\n+                              'OMEGACAM_g':  {'wavelength':  475.4, 'width': 130., 'marker': '+', 'color': 'g'},\n+                              'OMEGACAM_r':  {'wavelength':  620.4, 'width': 120., 'marker': '+', 'color': 'r'},\n+                              'OMEGACAM_i':  {'wavelength':  769.8, 'width': 130., 'marker': '+', 'color': 'b'},\n+                              'MEGACAM_u':   {'wavelength':  358.0, 'width':  55., 'marker': 'D', 'color': 'y'},\n+                              'MEGACAM_r':   {'wavelength':  620.4, 'width': 120., 'marker': 'D', 'color': 'r'},\n+                              'JPCAM_g':     {'wavelength':  475.4, 'width': 130., 'marker': 'v', 'color': 'g'},\n+                              'PANSTARRS_i': {'wavelength':  769.8, 'width': 130., 'marker': '*', 'color': 'b'},\n+                              'PANSTARRS_z': {'wavelength':  966.5, 'width': 100., 'marker': '*', 'color': 'k'},\n+                              'HSCS_z':      {'wavelength':  966.5, 'width': 100., 'marker': '>', 'color': 'k'},\n+                              'HSC_z':      {'wavelength':  966.5, 'width': 100., 'marker': '>', 'color': 'k'},\n+                              'HSC_g':      {'wavelength':  475.4, 'width': 130., 'marker': '>', 'color': 'b'},\n+                              }\n+    fig = plt.figure(figsize=(9,6))\n+\n+    for filter_name in filter_wavelength_dict:\n+        #print('filter_name:', filter_name)\n+        if filter_name in results_dict:\n+            if results_dict[filter_name] != {}:\n+\n+                # # image depth from rms map\n+                # plt.errorbar(filter_wavelength_dict[filter_name]['wavelength'],\n+                #             results_dict[filter_name]['image_depth_rms_mag'],\n+                #             xerr = filter_wavelength_dict[filter_name]['width']/2.,\n+                #             c=filter_wavelength_dict[filter_name]['color'],\n+                #             marker=filter_wavelength_dict[filter_name]['marker'],\n+                #             label=filter_name.replace(\"_\", \" \"))\n+                # image depth from rms map\n+                plt.errorbar(filter_wavelength_dict[filter_name]['wavelength'],\n+                            results_dict[filter_name]['image_mag_aperture_nmad'],\n+                            xerr = filter_wavelength_dict[filter_name]['width']/2.,\n+                            c=filter_wavelength_dict[filter_name]['color'],\n+                            marker=filter_wavelength_dict[filter_name]['marker'],\n+                            label=filter_name.replace(\"_\", \" \"))\n+\n+                plt.title('Image depth for %s\" aperture (%s\\N{greek small letter sigma})' %\n+                                                   (results_dict[filter_name]['aperture'],\n+                                                   results_dict[filter_name]['image_limit_mag_sigma_lim']))\n+    plt.legend()\n+    plt.xlabel('Wavelength [nm]')\n+    plt.ylabel('Image depth [mag]')\n+    plt.tight_layout()\n+    plt.savefig(output_path)\n+    plt.close(fig)\n+\n+def holes_hist_plot(results_dict, output_path_vis_nir='holes_hist_vis_nir.png',\n+                                  output_path_ext='holes_hist_ext.png'):\n+    plt.set_loglevel('WARNING')\n+\n+    filter_color_dict = {'DECAM_g':     'b',\n+                         'DECAM_r':     'cyan',\n+                         'DECAM_i':     'g',\n+                         'DECAM_z':     'grey',\n+                         'LSST_u':      'purple',\n+                         'LSST_g':      'b',\n+                         'LSST_r':      'cyan',\n+                         'LSST_i':      'g',\n+                         'LSST_z':      'grey',\n+                         'NIR_Y':       'r',\n+                         'NIR_J':       'orange',\n+                         'NIR_H':       'magenta',\n+                         'VIS':         'black',\n+                         'OMEGACAM_u':  'purple',\n+                         'OMEGACAM_g':  'b',\n+                         'OMEGACAM_r':  'cyan',\n+                         'OMEGACAM_i':  'g',\n+                         'MEGACAM_u':   'purple',\n+                         'MEGACAM_r':   'cyan',\n+                         'JPCAM_g':     'b',\n+                         'PANSTARRS_i': 'g',\n+                         'PANSTARRS_z': 'grey',\n+                         'HSCS_z':      'grey',\n+                         'HSC_z':       'grey',\n+                         'HSC_g':       'b'\n+                         }\n+\n+    VISNIR_filters = ['NIR_Y', 'NIR_J', 'NIR_H', 'VIS']\n+\n+    # EXT_filters    = ['DECAM_g', 'DECAM_r', 'DECAM_i', 'DECAM_z',\n+    #                   'LSST_u', 'LSST_g', 'LSST_r', 'LSST_i', 'LSST_z',\n+    #                   'OMEGACAM_u', 'OMEGACAM_g', 'OMEGACAM_r', 'OMEGACAM_i',\n+    #                   'MEGACAM_u', 'MEGACAM_r', 'JPCAM_g',\n+    #                   'PANSTARRS_i', 'PANSTARRS_z', 'HSCS_z']\n+    EXT_filters = [\n+        \"DECAM_g\", \"DECAM_r\", \"DECAM_i\", \"DECAM_z\",\n+        \"OMEGACAM_u\", \"OMEGACAM_g\", \"OMEGACAM_r\", \"OMEGACAM_i\",\n+        \"LSST_u\", \"LSST_g\", \"LSST_r\", \"LSST_i\", \"LSST_z\", \"LSST_Y\",\n+        \"MEGACAM_u\", \"MEGACAM_r\",\n+        \"JPCAM_g\",\n+        \"PANSTARRS_i\", \"PANSTARRS_z\",\n+        \"HSC_z\", \"HSC_g\"\n+    ]\n+\n+    bins = 2**(np.arange(0,23))\n+\n+    fig = plt.figure(figsize=(9,6))\n+\n+    for filter_name in AnalysisUtils.ALL_FILTERS:\n+        if results_dict[filter_name] == {}:\n+            continue\n+        if filter_name in VISNIR_filters:\n+\n+            plt.hist(results_dict[filter_name]['rms']['areas'], alpha=1.0, color=filter_color_dict[filter_name],\n+                           label=filter_name.replace(\"_\", \" \"), bins=bins, histtype='step')\n+\n+    plt.legend()\n+    plt.xscale('log')\n+    plt.yscale('log')\n+    plt.xlabel('Hole size [pixels]')\n+    plt.ylabel('N')\n+    plt.tight_layout()\n+    plt.savefig(output_path_vis_nir)\n+    plt.close(fig)\n+\n+    fig = plt.figure(figsize=(9,6))\n+\n+    for filter_name in AnalysisUtils.ALL_FILTERS:\n+        if results_dict[filter_name] == {}:\n+            continue\n+        if filter_name in EXT_filters:\n+\n+            plt.hist(results_dict[filter_name]['rms']['areas'], alpha=1.0, color=filter_color_dict[filter_name],\n+                           label=filter_name.replace(\"_\", \" \"), bins=bins, histtype='step')\n+\n+    plt.legend()\n+    plt.xscale('log')\n+    plt.yscale('log')\n+    plt.xlabel('Hole size [pixels]')\n+    plt.ylabel('N')\n+    plt.tight_layout()\n+    plt.savefig(output_path_ext)\n+    plt.close(fig)\n+\n+def get_pixel_scale(wcs):\n+    CD1_1_arcsec = np.abs(wcs['CD1_1']*3600.)\n+    CD2_2_arcsec = np.abs(wcs['CD2_2']*3600.)\n+    if (~np.isclose(CD1_1_arcsec,CD2_2_arcsec)).sum():\n+        logger.warning(\"# CD1_1 and CD2_2 have infinite values: %s and %s\\n\" % \n+                         (CD1_1_arcsec,CD2_2_arcsec))\n+    return CD1_1_arcsec\n+\n+def mainMethod(args):\n+    \"\"\"\n+    @brief The \"main\" method.\n+\n+    @details This method is the entry point to the program. In this sense, it is\n+    similar to a main (and it is why it is called mainMethod()).\n+    \"\"\"\n+\n+    logger = log.getLogger('MER_MosaicingValidationPrg')\n+\n+    logger.info('#')\n+    logger.info('# Entering MER_MosaicingValidationPrg mainMethod()')\n+    logger.info('#')\n+\n+    # Store the start time\n+    start_time = time.time()\n+\n+    # print all parameters to the screen\n+    print_input_arguments(args, logger)\n+\n+    # Do not print astropy warnings\n+    AnalysisUtils.ignore_astropy_warnings()\n+\n+    # Add some extra functionality to the MER data product bindings\n+    mer_utils.init()\n+\n+    # Create the figures directory\n+    figsdir_mosaicing = os.path.join(args.workdir, \"data\", \"mosaicingFigures\")\n+    AnalysisUtils.create_directory(figsdir_mosaicing)\n+\n+    figsdir_bkg = os.path.join(args.workdir, \"data\", \"backgroundFigures\")\n+    AnalysisUtils.create_directory(figsdir_bkg)\n+\n+    # Load the MER background-subtracted mosaics\n+    mosaics = AnalysisUtils.get_background_subtracted_mosaics(\n+        os.path.join(args.workdir, args.mosaics), args.workdir)\n+\n+    final_segmap = dm_utils.read_product_metadata(os.path.join(\n+        args.workdir, args.segmap))\n+    segmap_file_name = os.path.join(args.workdir, \"data\", final_segmap.get_data())\n+\n+    # Check that the wordir exists\n+    AnalysisUtils.check_directory_exists(args.workdir)\n+\n+    results_dict = {}\n+    aperture_arcsec = 2.\n+    results_dict['aperture_flux_hist_list'] = []\n+\n+    # Loop over all the possible filter names\n+    for filter_name in AnalysisUtils.ALL_FILTERS:\n+        # Move to the next filter name if the filter is not available\n+        if filter_name not in mosaics:\n+            results_dict[filter_name] = {}\n+            continue\n+        # Get the MER background-subtracted mosaic xmls\n+        mosaic = mosaics[filter_name]\n+        tile_index = mosaic.get_tile_index()\n+\n+        # Compare the mosaic files\n+        logger.info(\"# Validating mosaic fits files for band %s\" % filter_name)\n+        logger.info(\"#   Validating image files...\")\n+        data_file_name = os.path.join(args.workdir, \"data\", mosaic.get_data())\n+        rms_file_name = os.path.join(args.workdir, \"data\", mosaic.get_rms())\n+        \n+        wcs = mosaic.get_wcs()\n+        pix_scale = get_pixel_scale(wcs)\n+        zp = mosaic.get_zero_point()\n+\n+        # image_stat = image_statistics(data_file_name, logger)\n+        \n+        logger.info(\"#   Validating rms files...\")\n+        rms_stat = rms_statistics(rms_file_name, logger)\n+\n+        sigma_lim = 5.\n+        aperture_ap, sigma_ap, mad_ap, nmad_ap, flux_average_dict, flux_median_dict, _, _, flux_average_std, flux_average_mad = MER_NoiseApertureUtils.noise_statistics_aperture(data_file_name, segmap_file_name, \\\n+                                                       aperture_min=round(aperture_arcsec/pix_scale),\n+                                                       aperture_max=round(aperture_arcsec/pix_scale),\n+                                                       aperture_step=1,\n+                                                       Nsample=10000,\n+                                                       sigma_cl=5.,\n+                                                       logger=logger)\n+        mag_nmad = zp['value'] - 2.5*np.log10(sigma_lim*nmad_ap)\n+\n+        # aperture_ap_rms, sigma_ap_rms = MER_NoiseRMSUtils.noise_statistics_from_rms(rms_file_name,\n+        #                                                segmap_file_name,\n+        #                                                aperture_min=round(aperture_arcsec/pix_scale),\n+        #                                                aperture_max=round(aperture_arcsec/pix_scale),\n+        #                                                aperture_step=1)\n+        # image_depth_rms = zp['value'] - 2.5*np.log10(sigma_lim*sigma_ap_rms)\n+\n+        results_dict[filter_name] = {\n+                                    # 'image': image_stat,\n+                                    #  'flag': flag_stat,\n+                                     'rms': rms_stat,\n+                                    #  'flag_hist_plot': flag_hist_path,\n+                                     'image_limit_mag_sigma_lim': sigma_lim,\n+                                     'image_mag_aperture_nmad': mag_nmad[0],\n+                                     'flux_aperture_sigma_list': flux_average_std,\n+                                    #  'image_depth_rms_median': sigma_ap_rms[0],\n+                                    #  'image_depth_rms_mag': image_depth_rms[0],\n+                                     'sigma_lim': sigma_lim,\n+                                     'zp': zp['value'],\n+                                     'aperture': aperture_arcsec,\n+                                     'aperture_list': aperture_ap,\n+                                     'flux_average_dict': flux_average_dict,\n+                                     'flux_median_dict': flux_median_dict\n+                                     }\n+        aperture_flux_hist_path = os.path.join(figsdir_bkg, 'aperture_flux_hist_%s.png' % (filter_name))\n+        aperture_stats_plots(results_dict, filter_name, output_path=aperture_flux_hist_path)\n+        # aperture_stats_plots(results_dict, output_path=aperture_flux_hist_path)\n+        # results_dict[filter_name]['aperture_flux_hist'] = aperture_flux_hist_path\n+        results_dict['aperture_flux_hist_list'].append(aperture_flux_hist_path)\n+\n+    image_depth_plot_path = os.path.join(figsdir_mosaicing, 'image_depth_%s.png' % tile_index)\n+    image_depth_plot(results_dict, output_path=image_depth_plot_path)\n+    results_dict['image_depth_plot'] = image_depth_plot_path\n+\n+    holes_hist_path_vis_nir = os.path.join(figsdir_mosaicing, 'holes_hist_vis_nir_%s.png' % tile_index)\n+    holes_hist_path_ext     = os.path.join(figsdir_mosaicing, 'holes_hist_ext_%s.png' % tile_index)\n+    holes_hist_plot(results_dict, output_path_vis_nir=holes_hist_path_vis_nir, \n+                                  output_path_ext=holes_hist_path_ext)\n+    results_dict['holes_hist_plot_vis_nir'] = holes_hist_path_vis_nir\n+    results_dict['holes_hist_plot_ext'] = holes_hist_path_ext\n+\n+    # Create the analysis report\n+    logger.info(\"# Creating the mosaicing analysis report...\")\n+    report_file_names_mosaicing,  report_file_names_bkg = create_analysis_report(results_dict, tile_index, args.workdir, logger)\n+\n+    # Save all the analysis files into a tar file\n+    tar_file_name_mosaicing = mer_filename(\n+        \"ANALYSIS-RESULT\", prefix=\"MOSAICING\", tile_index=tile_index, ext=\"tar.gz\")\n+    AnalysisUtils.save_tar_file(os.path.join(args.workdir, \"data\", tar_file_name_mosaicing),\n+                                report_file_names_mosaicing + [figsdir_mosaicing])\n+    \n+    tar_file_name_bkg = mer_filename(\n+        \"ANALYSIS-RESULT\", prefix=\"Background\", tile_index=tile_index, ext=\"tar.gz\")\n+    AnalysisUtils.save_tar_file(os.path.join(args.workdir, \"data\", tar_file_name_bkg),\n+                                report_file_names_bkg + [figsdir_bkg])\n+\n+    # Get the tile index, the processing mode and the observation ids\n+    tile_index      = mosaics[\"VIS\"].get_tile_index()\n+    processing_mode = mosaics[\"VIS\"].get_processing_mode()\n+    observation_ids = set()\n+\n+    for mosaic in mosaics.values():\n+        observation_ids.update(mosaic.get_observation_id_list())\n+    \n+    # Create the analysis result data product\n+    global_result = \"PASSED\"\n+    analysis_result = mer_utils.create_analysis_result(global_result)\n+    analysis_result.set_tile_index(tile_index)\n+    analysis_result.set_observation_id_list(observation_ids)\n+    analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_figures_tar_file(tar_file_name_mosaicing)\n+\n+    # Save the analysis result data product as an XML file\n+    logger.info(\"# Saving the analysis result data product\")\n+    analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n+\n+    # Create the analysis result data product\n+    global_result = \"PASSED\"\n+    analysis_result = mer_utils.create_analysis_result(global_result)\n+    analysis_result.set_tile_index(tile_index)\n+    analysis_result.set_observation_id_list(observation_ids)\n+    analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_figures_tar_file(tar_file_name_bkg)\n+\n+    # Save the analysis result data product as an XML file\n+    logger.info(\"# Saving the analysis result data product\")\n+    analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n+\n+    # Print the time spent running the step\n+    logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n+    logger.info('#')\n+    logger.info('# Exiting MER_MosaicingValidationPrg mainMethod()')\n+    logger.info('#')\n",
                            "add depth validation & background validation",
                            "yfang",
                            "2023-08-11T15:40:10.000+02:00",
                            "62463cc0ce935f15628eb27c736293e7b3af7e99"
                        ]
                    ],
                    "MER_MosaicingValidation/python/MER_MosaicingValidation/MER_MosaicingValidation.py": [
                        [
                            "@@ -612,7 +612,7 @@ def mainMethod(args):\n         pix_scale = get_pixel_scale(wcs)\n \n         sigma_lim = 5.\n-        aperture_ap, sigma_ap, mad_ap, nmad_ap = MER_NoiseApertureUtils.noise_statistics_aperture(data_file_name, segmap_file_name, \\\n+        aperture_ap, sigma_ap, mad_ap, nmad_ap, _, _, _, _, _, _ = MER_NoiseApertureUtils.noise_statistics_aperture(data_file_name, segmap_file_name, \\\n                                                        aperture_min=round(aperture_arcsec/pix_scale),\n                                                        aperture_max=round(aperture_arcsec/pix_scale),\n                                                        aperture_step=1,\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T11:46:20.000+00:00",
                            "a83f468ea9bc0e5270859fcc7d1e7f8aa8bf922f"
                        ],
                        [
                            "@@ -26,7 +26,6 @@ import argparse\n import ElementsKernel.Logging as log\n import numpy as np\n from astropy.io import fits\n-from astropy.stats import median_absolute_deviation\n from astropy.stats import mad_std\n from astropy.nddata import bitmask\n import json\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ],
                        [
                            "@@ -26,7 +26,6 @@ import argparse\n import ElementsKernel.Logging as log\n import numpy as np\n from astropy.io import fits\n-from astropy.stats import median_absolute_deviation\n from astropy.stats import mad_std\n from astropy.nddata import bitmask\n import json\n",
                            "Corrects more places where median_absolute_deviation is used",
                            "Javier Gracia Carpio",
                            "2023-06-27T17:38:28.000+00:00",
                            "be62009f85707296ce7de1b4a1f7a59dfd5f4496"
                        ],
                        [
                            "@@ -15,8 +15,6 @@\n # along with this library; if not, write to the Free Software Foundation, Inc.,\n # 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n #\n-\n-\n \"\"\"\n File: python/MER_MosaicingValidation/MER_MosaicingValidation.py\n \n@@ -33,6 +31,7 @@ from astropy.stats import mad_std\n from astropy.nddata import bitmask\n import json\n import os\n+import time\n \n from MER_DataModelUtils import DmUtils as dm_utils\n from MER_DataModelUtils import MerDmUtils as mer_utils\n@@ -48,6 +47,7 @@ import matplotlib.pyplot as plt\n from . import MER_NoiseStatisticsPairwiseUtils\n from . import MER_NoiseApertureUtils\n from . import MER_NoiseRMSUtils\n+from MER_DA.MERUtilities import print_input_arguments\n \n \n def defineSpecificProgramOptions():\n@@ -548,6 +548,12 @@ def mainMethod(args):\n     logger.info('# Entering MER_MosaicingValidation mainMethod()')\n     logger.info('#')\n \n+    # Store the start time\n+    start_time = time.time()\n+\n+    # print all parameters to the screen\n+    print_input_arguments(args, logger)\n+\n     # Do not print astropy warnings\n     AnalysisUtils.ignore_astropy_warnings()\n \n@@ -611,7 +617,8 @@ def mainMethod(args):\n                                                        aperture_min=round(aperture_arcsec/pix_scale),\n                                                        aperture_max=round(aperture_arcsec/pix_scale),\n                                                        aperture_step=1,\n-                                                       Nsample=10000)\n+                                                       Nsample=10000,\n+                                                       logger=logger)\n         mag_nmad = zp['value'] - 2.5*np.log10(sigma_lim*nmad_ap)\n \n         aperture_ap_rms, sigma_ap_rms = MER_NoiseRMSUtils.noise_statistics_from_rms(rms_file_name,\n@@ -695,6 +702,8 @@ def mainMethod(args):\n     logger.info(\"# Saving the analysis result data product\")\n     analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n \n+    # Print the time spent running the step\n+    logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n     logger.info('#')\n     logger.info('# Exiting MER_MosaicingValidation mainMethod()')\n     logger.info('#')\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-06-16T14:11:46.000+02:00",
                            "504febbf2c08fe2012b74d4f6aae5c5693624ea2"
                        ]
                    ],
                    "MER_MosaicingValidation/python/MER_MosaicingValidation/MER_NoiseAperture.py": [
                        [
                            "@@ -78,7 +78,7 @@ def mainMethod(args):\n     logger.info('# Entering MER_NoiseAperture mainMethod()')\n     logger.info('#')\n \n-    aperture, sigma_ap, mad_ap, nmad_ap = MER_NoiseApertureUtils.noise_statistics_aperture(args.fitsname,\n+    aperture, sigma_ap, mad_ap, nmad_ap, _, _, _, _, _, _ = MER_NoiseApertureUtils.noise_statistics_aperture(args.fitsname,\n                                                        args.segname, \n                                                        flagname=args.flagname,\n                                                        aperture_min=args.aperture_min,\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T11:46:20.000+00:00",
                            "a83f468ea9bc0e5270859fcc7d1e7f8aa8bf922f"
                        ]
                    ],
                    "MER_MosaicingValidation/python/MER_MosaicingValidation/MER_NoiseApertureUtils.py": [
                        [
                            "@@ -50,17 +50,22 @@ def sampling(image_data, seg_data, flag_data, aperture, Nsample, logger=None):\n     wx, wy = np.where( (image_data != 0) & (seg_data == 0) & (flag_data == 0))\n     Nx, Ny = image_data.shape\n \n-    flux = np.zeros(Nsample)\n+    flux_sum = np.zeros(Nsample)\n+    flux_average = np.zeros(Nsample)\n+    flux_median = np.zeros(Nsample)\n+    x_position = np.zeros(Nsample)\n+    y_position = np.zeros(Nsample)\n+\n     if len(wx) < 1 and len(wy) < 1:\n         if logger is not None:\n             logger.warning('# There seem to be *no* valid pixels in the image!')\n-        return flux\n+        return flux_sum, flux_average, flux_median, x_position, y_position\n \n     i = 0\n     i_iter = 0\n     while i < Nsample:\n             if i_iter > 100*Nsample:\n-                #logger.warning('# Not enough background pixels for image depth analysis!')\n+                logger.warning('# Not enough background pixels for image depth analysis!')\n                 break\n             i_iter += 1\n \n@@ -94,11 +99,15 @@ def sampling(image_data, seg_data, flag_data, aperture, Nsample, logger=None):\n             #xplot.append(wy[idx]+stmpsize/2)\n             #yplot.append(wx[idx]+stmpsize/2)\n \n-            flux[i] = ratio*np.sum(img_stmp[mask])\n+            flux_sum[i] = ratio*np.sum(img_stmp[mask])\n+            flux_average[i] = np.average(img_stmp[mask])\n+            flux_median[i]  = np.median(img_stmp[mask])\n+            x_position[i] = (wx[idx]+wx[idx]+stmpsize)/2.0\n+            y_position[i] = (wy[idx]+wy[idx]+stmpsize)/2.0\n \n             i += 1\n \n-    return flux\n+    return flux_sum, flux_average, flux_median, x_position, y_position\n \n \n def noise_statistics_aperture(fitsname, segname, flagname=None, aperture_min=1, aperture_max=10, \n@@ -132,19 +141,32 @@ def noise_statistics_aperture(fitsname, segname, flagname=None, aperture_min=1,\n     sigma_output = np.zeros(len(aperture_list))\n     mad_output   = np.zeros(len(aperture_list))\n     mad_std_output = np.zeros(len(aperture_list))\n+    flux_average_dict = {}\n+    flux_median_dict = {}\n+    x_position_dict = {}\n+    y_position_dict = {}\n+    flux_average_std = {}\n+    flux_average_mad = {}\n \n     #print('# All apertures: %s!' % str(aperture_list))\n     xplot = []\n     yplot = []\n \n     for j, aperture in enumerate(aperture_list):\n-        flux = sampling(image_data, seg_data, flag_data, aperture, Nsample, logger)\n+        flux, flux_average, flux_median, x_position, y_position = sampling(image_data, seg_data, flag_data, aperture, Nsample, logger)\n \n         sigma_output[j]   = np.std(sigma_clip(flux, sigma=sigma_cl))\n         mad_output[j]     = median_absolute_deviation(flux)\n         mad_std_output[j] = mad_std(flux)\n+        \n+        flux_average_dict[j] = flux_average\n+        flux_median_dict[j] = flux_median\n+        x_position_dict[j] = x_position\n+        y_position_dict[j] = y_position\n+        flux_average_std[j] = np.std(sigma_clip(flux_average, sigma=sigma_cl))\n+        flux_average_mad[j] = median_absolute_deviation(flux_average)\n \n         #print('Sigma for aperture %i = %f, mad = %f, %f' % (aperture,sigma_output[j],mad_output[j], mad_std_output[j]) )\n \n-    return aperture_list, sigma_output, mad_output, mad_std_output\n+    return aperture_list, sigma_output, mad_output, mad_std_output, flux_average_dict, flux_median_dict, x_position_dict, y_position_dict, flux_average_std, flux_average_mad\n \n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T11:46:20.000+00:00",
                            "a83f468ea9bc0e5270859fcc7d1e7f8aa8bf922f"
                        ],
                        [
                            "@@ -29,7 +29,7 @@ import json\n import numpy as np\n from astropy.io import fits\n from astropy.stats import sigma_clip\n-from astropy.stats import median_abs_deviation\n+from astropy.stats import median_absolute_deviation\n from astropy.stats import mad_std\n \n \n@@ -141,7 +141,7 @@ def noise_statistics_aperture(fitsname, segname, flagname=None, aperture_min=1,\n         flux = sampling(image_data, seg_data, flag_data, aperture, Nsample, logger)\n \n         sigma_output[j]   = np.std(sigma_clip(flux, sigma=sigma_cl))\n-        mad_output[j]     = median_abs_deviation(flux)\n+        mad_output[j]     = median_absolute_deviation(flux)\n         mad_std_output[j] = mad_std(flux)\n \n         #print('Sigma for aperture %i = %f, mad = %f, %f' % (aperture,sigma_output[j],mad_output[j], mad_std_output[j]) )\n",
                            "Astropy uses median_absolute_deviation...",
                            "Javier Gracia Carpio",
                            "2023-06-27T17:44:46.000+00:00",
                            "783ad20b240644af8b80603986e284d53eb79b9e"
                        ],
                        [
                            "@@ -29,7 +29,7 @@ import json\n import numpy as np\n from astropy.io import fits\n from astropy.stats import sigma_clip\n-from astropy.stats import median_absolute_deviation\n+from astropy.stats import median_abs_deviation\n from astropy.stats import mad_std\n \n \n@@ -141,7 +141,7 @@ def noise_statistics_aperture(fitsname, segname, flagname=None, aperture_min=1,\n         flux = sampling(image_data, seg_data, flag_data, aperture, Nsample, logger)\n \n         sigma_output[j]   = np.std(sigma_clip(flux, sigma=sigma_cl))\n-        mad_output[j]     = median_absolute_deviation(flux)\n+        mad_output[j]     = median_abs_deviation(flux)\n         mad_std_output[j] = mad_std(flux)\n \n         #print('Sigma for aperture %i = %f, mad = %f, %f' % (aperture,sigma_output[j],mad_output[j], mad_std_output[j]) )\n",
                            "Corrects more places where median_absolute_deviation is used",
                            "Javier Gracia Carpio",
                            "2023-06-27T17:38:28.000+00:00",
                            "be62009f85707296ce7de1b4a1f7a59dfd5f4496"
                        ],
                        [
                            "@@ -46,11 +46,16 @@ def create_circular_mask(h, w, center=None, radius=None):\n     return mask\n \n \n-def sampling(image_data, seg_data, flag_data, aperture, Nsample):\n+def sampling(image_data, seg_data, flag_data, aperture, Nsample, logger=None):\n     wx, wy = np.where( (image_data != 0) & (seg_data == 0) & (flag_data == 0))\n     Nx, Ny = image_data.shape\n \n     flux = np.zeros(Nsample)\n+    if len(wx) < 1 and len(wy) < 1:\n+        if logger is not None:\n+            logger.warning('# There seem to be *no* valid pixels in the image!')\n+        return flux\n+\n     i = 0\n     i_iter = 0\n     while i < Nsample:\n@@ -97,7 +102,7 @@ def sampling(image_data, seg_data, flag_data, aperture, Nsample):\n \n \n def noise_statistics_aperture(fitsname, segname, flagname=None, aperture_min=1, aperture_max=10, \n-                     aperture_step=1, seed=None, Nsample=100, sigma_cl=10.):\n+                     aperture_step=1, seed=None, Nsample=100, sigma_cl=10., logger=None):\n     \"\"\"\n     \"\"\"\n     f     = fits.open(fitsname)\n@@ -133,7 +138,7 @@ def noise_statistics_aperture(fitsname, segname, flagname=None, aperture_min=1,\n     yplot = []\n \n     for j, aperture in enumerate(aperture_list):\n-        flux = sampling(image_data, seg_data, flag_data, aperture, Nsample)\n+        flux = sampling(image_data, seg_data, flag_data, aperture, Nsample, logger)\n \n         sigma_output[j]   = np.std(sigma_clip(flux, sigma=sigma_cl))\n         mad_output[j]     = median_absolute_deviation(flux)\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-06-16T14:11:46.000+02:00",
                            "504febbf2c08fe2012b74d4f6aae5c5693624ea2"
                        ]
                    ],
                    "MER_Validation/CMakeLists.txt": [
                        [
                            "@@ -67,6 +67,7 @@ elements_add_python_program(MER_AstrometryValidationPrg MER_Validation.MER_Astro\n elements_add_python_program(MER_ClassificationValidationGaiaPrg MER_Validation.MER_ClassificationValidationPrg)\n elements_add_python_program(MER_MergeValidationResults MER_Validation.MER_MergeValidationResults)\n elements_add_python_program(MER_DetValidationPrg MER_Validation.MER_DetValidationPrg)\n+elements_add_python_program(MER_MosaicingValidationPrg MER_Validation.MER_MosaicingValidationPrg)\n \n #===============================================================================\n # Add the elements_install_conf_files macro\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T11:46:20.000+00:00",
                            "a83f468ea9bc0e5270859fcc7d1e7f8aa8bf922f"
                        ],
                        [
                            "@@ -64,6 +64,7 @@ elements_install_aux_files()\n #===============================================================================\n elements_add_python_program(MER_PhotometryValidationPrg MER_Validation.MER_PhotometryValidationPrg)\n elements_add_python_program(MER_AstrometryValidationPrg MER_Validation.MER_AstrometryValidationPrg)\n+elements_add_python_program(MER_ClassificationValidationGaiaPrg MER_Validation.MER_ClassificationValidationPrg)\n elements_add_python_program(MER_MergeValidationResults MER_Validation.MER_MergeValidationResults)\n elements_add_python_program(MER_DetValidationPrg MER_Validation.MER_DetValidationPrg)\n elements_add_python_program(MER_MosaicingValidationPrg MER_Validation.MER_MosaicingValidationPrg)\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-08-11T15:41:07.000+02:00",
                            "3439f2b2c5d1617a26353d57808735c69cf7a538"
                        ],
                        [
                            "@@ -66,6 +66,7 @@ elements_add_python_program(MER_PhotometryValidationPrg MER_Validation.MER_Photo\n elements_add_python_program(MER_AstrometryValidationPrg MER_Validation.MER_AstrometryValidationPrg)\n elements_add_python_program(MER_MergeValidationResults MER_Validation.MER_MergeValidationResults)\n elements_add_python_program(MER_DetValidationPrg MER_Validation.MER_DetValidationPrg)\n+elements_add_python_program(MER_MosaicingValidationPrg MER_Validation.MER_MosaicingValidationPrg)\n \n #===============================================================================\n # Add the elements_install_conf_files macro\n",
                            "add depth validation & background validation",
                            "yfang",
                            "2023-08-11T15:40:10.000+02:00",
                            "62463cc0ce935f15628eb27c736293e7b3af7e99"
                        ],
                        [
                            "@@ -64,7 +64,7 @@ elements_install_aux_files()\n #===============================================================================\n elements_add_python_program(MER_PhotometryValidationPrg MER_Validation.MER_PhotometryValidationPrg)\n elements_add_python_program(MER_AstrometryValidationPrg MER_Validation.MER_AstrometryValidationPrg)\n-elements_add_python_program(MER_ClassificationValidationPrg MER_Validation.MER_ClassificationValidationPrg)\n+elements_add_python_program(MER_ClassificationValidationGaiaPrg MER_Validation.MER_ClassificationValidationPrg)\n elements_add_python_program(MER_MergeValidationResults MER_Validation.MER_MergeValidationResults)\n elements_add_python_program(MER_DetValidationPrg MER_Validation.MER_DetValidationPrg)\n \n",
                            "Use different excutable name",
                            "Javier Gracia Carpio",
                            "2023-08-10T20:02:08.000+00:00",
                            "fdd64c88ba0fab2ad0e3ae6280edaecfd4d63329"
                        ],
                        [
                            "@@ -64,6 +64,7 @@ elements_install_aux_files()\n #===============================================================================\n elements_add_python_program(MER_PhotometryValidationPrg MER_Validation.MER_PhotometryValidationPrg)\n elements_add_python_program(MER_AstrometryValidationPrg MER_Validation.MER_AstrometryValidationPrg)\n+elements_add_python_program(MER_ClassificationValidationPrg MER_Validation.MER_ClassificationValidationPrg)\n elements_add_python_program(MER_MergeValidationResults MER_Validation.MER_MergeValidationResults)\n elements_add_python_program(MER_DetValidationPrg MER_Validation.MER_DetValidationPrg)\n \n",
                            "Initial version of MER_ClassificationValidationPrg",
                            "Elie Soubrie",
                            "2023-08-10T16:48:51.000+00:00",
                            "ff63e28690f5e698fef3c70a5d366f5bcb47f784"
                        ],
                        [
                            "@@ -54,6 +54,7 @@ elements_depends_on_subdirs(ElementsKernel)\n #  elements_install_scripts()\n #===============================================================================\n elements_install_python_modules()\n+elements_install_aux_files()\n \n #===============================================================================\n # Declare the Python programs here\n@@ -61,7 +62,7 @@ elements_install_python_modules()\n # elements_add_python_program(PythonProgramExample\n #                             ElementsExamples.PythonProgramExample)\n #===============================================================================\n-elements_add_python_program(MER_ValidationPrg MER_Validation.MER_ValidationPrg)\n+elements_add_python_program(MER_PhotometryValidationPrg MER_Validation.MER_PhotometryValidationPrg)\n elements_add_python_program(MER_AstrometryValidationPrg MER_Validation.MER_AstrometryValidationPrg)\n elements_add_python_program(MER_MergeValidationResults MER_Validation.MER_MergeValidationResults)\n elements_add_python_program(MER_DetValidationPrg MER_Validation.MER_DetValidationPrg)\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ],
                        [
                            "@@ -65,6 +65,7 @@ elements_install_aux_files()\n elements_add_python_program(MER_PhotometryValidationPrg MER_Validation.MER_PhotometryValidationPrg)\n elements_add_python_program(MER_AstrometryValidationPrg MER_Validation.MER_AstrometryValidationPrg)\n elements_add_python_program(MER_MergeValidationResults MER_Validation.MER_MergeValidationResults)\n+elements_add_python_program(MER_DetValidationPrg MER_Validation.MER_DetValidationPrg)\n \n #===============================================================================\n # Add the elements_install_conf_files macro\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-10T15:27:04.000+02:00",
                            "b4030040f2cf4ffc0140a2f4f30e0e1b83a1ff07"
                        ],
                        [
                            "@@ -54,6 +54,7 @@ elements_depends_on_subdirs(ElementsKernel)\n #  elements_install_scripts()\n #===============================================================================\n elements_install_python_modules()\n+elements_install_aux_files()\n \n #===============================================================================\n # Declare the Python programs here\n@@ -61,7 +62,7 @@ elements_install_python_modules()\n # elements_add_python_program(PythonProgramExample\n #                             ElementsExamples.PythonProgramExample)\n #===============================================================================\n-elements_add_python_program(MER_ValidationPrg MER_Validation.MER_ValidationPrg)\n+elements_add_python_program(MER_PhotometryValidationPrg MER_Validation.MER_PhotometryValidationPrg)\n elements_add_python_program(MER_AstrometryValidationPrg MER_Validation.MER_AstrometryValidationPrg)\n elements_add_python_program(MER_MergeValidationResults MER_Validation.MER_MergeValidationResults)\n \n",
                            "re-organize photometry validation",
                            "yfang",
                            "2023-07-10T15:26:16.000+02:00",
                            "59dbe91c8025269aec5e6b35a0d61de128483ab7"
                        ],
                        [
                            "@@ -64,6 +64,7 @@ elements_install_python_modules()\n elements_add_python_program(MER_ValidationPrg MER_Validation.MER_ValidationPrg)\n elements_add_python_program(MER_AstrometryValidationPrg MER_Validation.MER_AstrometryValidationPrg)\n elements_add_python_program(MER_MergeValidationResults MER_Validation.MER_MergeValidationResults)\n+elements_add_python_program(MER_DetValidationPrg MER_Validation.MER_DetValidationPrg)\n \n #===============================================================================\n # Add the elements_install_conf_files macro\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T21:40:08.000+00:00",
                            "696982ed8506ddb56f2beca6b7fe88377fa08c21"
                        ],
                        [
                            "@@ -64,6 +64,7 @@ elements_install_python_modules()\n elements_add_python_program(MER_ValidationPrg MER_Validation.MER_ValidationPrg)\n elements_add_python_program(MER_AstrometryValidationPrg MER_Validation.MER_AstrometryValidationPrg)\n elements_add_python_program(MER_MergeValidationResults MER_Validation.MER_MergeValidationResults)\n+elements_add_python_program(MER_DetValidationPrg MER_Validation.MER_DetValidationPrg)\n \n #===============================================================================\n # Add the elements_install_conf_files macro\n",
                            "Started integrating detection validation",
                            "Martin Kuemmel",
                            "2023-07-04T20:56:37.000+02:00",
                            "597608469db752cb043620ddd90606a13a97cd52"
                        ],
                        [
                            "@@ -0,0 +1,73 @@\n+CMAKE_MINIMUM_REQUIRED(VERSION 2.8.12)\n+\n+#===============================================================================\n+# Load elements_subdir macro here\n+# Examples:\n+#   For declaring a project module:\n+#         elements_subdir(ElementsExamples)\n+#===============================================================================\n+elements_subdir(MER_Validation)\n+\n+#===============================================================================\n+# Load elements_depends_on_subdirs macro here\n+#   For creating a dependency onto an other accessible module\n+#         elements_depends_on_subdirs(ElementsKernel)\n+#===============================================================================\n+elements_depends_on_subdirs(ElementsKernel)\n+\n+#===============================================================================\n+# Add the find_package macro (a pure CMake command) here to locate the\n+# libraries.\n+# Examples:\n+#          find_package(CppUnit)\n+#===============================================================================\n+\n+#===============================================================================\n+# Declare the library dependencies here\n+# Example:\n+#         elements_add_library(ElementsExamples src/Lib/*.cpp\n+#                     INCLUDE_DIRS Boost ElementsKernel\n+#                     LINK_LIBRARIES Boost ElementsKernel\n+#                     PUBLIC_HEADERS ElementsExamples)\n+#===============================================================================\n+\n+#===============================================================================\n+# Declare the executables here\n+# Example:\n+# elements_add_executable(ElementsProgramExample src/Program/ProgramExample.cpp\n+#                        INCLUDE_DIRS Boost ElementsExamples\n+#                        LINK_LIBRARIES Boost ElementsExamples)\n+#===============================================================================\n+\n+#===============================================================================\n+# Declare the Boost tests here\n+# Example:\n+# elements_add_unit_test(BoostClassExample tests/src/Boost/ClassExample_test.cpp\n+#                       EXECUTABLE BoostClassExample_test\n+#                       INCLUDE_DIRS ElementsExamples\n+#                       LINK_LIBRARIES ElementsExamples TYPE Boost)\n+#===============================================================================\n+\n+#===============================================================================\n+# Use the following macro for python modules, scripts and aux files:\n+#  elements_install_python_modules()\n+#  elements_install_scripts()\n+#===============================================================================\n+elements_install_python_modules()\n+\n+#===============================================================================\n+# Declare the Python programs here\n+# Examples :\n+# elements_add_python_program(PythonProgramExample\n+#                             ElementsExamples.PythonProgramExample)\n+#===============================================================================\n+elements_add_python_program(MER_ValidationPrg MER_Validation.MER_ValidationPrg)\n+elements_add_python_program(MER_AstrometryValidationPrg MER_Validation.MER_AstrometryValidationPrg)\n+elements_add_python_program(MER_MergeValidationResults MER_Validation.MER_MergeValidationResults)\n+\n+#===============================================================================\n+# Add the elements_install_conf_files macro\n+# Examples:\n+#          elements_install_conf_files()\n+#===============================================================================\n+elements_install_conf_files()\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:28:10.000+00:00",
                            "e3224a51e80aec0f298e9607d359a618da467017"
                        ],
                        [
                            "@@ -63,6 +63,7 @@ elements_install_python_modules()\n #===============================================================================\n elements_add_python_program(MER_ValidationPrg MER_Validation.MER_ValidationPrg)\n elements_add_python_program(MER_AstrometryValidationPrg MER_Validation.MER_AstrometryValidationPrg)\n+elements_add_python_program(MER_MergeValidationResults MER_Validation.MER_MergeValidationResults)\n \n #===============================================================================\n # Add the elements_install_conf_files macro\n",
                            "Makes a first page.",
                            "Martin Kuemmel",
                            "2023-07-03T17:18:33.000+02:00",
                            "074876fe1564e889d6b110008f83d979769b2fc8"
                        ],
                        [
                            "@@ -62,6 +62,7 @@ elements_install_python_modules()\n #                             ElementsExamples.PythonProgramExample)\n #===============================================================================\n elements_add_python_program(MER_ValidationPrg MER_Validation.MER_ValidationPrg)\n+elements_add_python_program(MER_AstrometryValidationPrg MER_Validation.MER_AstrometryValidationPrg)\n \n #===============================================================================\n # Add the elements_install_conf_files macro\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-06-30T17:34:51.000+02:00",
                            "6d9a612f0e2d7a188f993d6b01a6edbd5ff5acae"
                        ],
                        [
                            "@@ -62,7 +62,7 @@ elements_install_python_modules()\n #                             ElementsExamples.PythonProgramExample)\n #===============================================================================\n elements_add_python_program(MER_ValidationPrg MER_Validation.MER_ValidationPrg)\n-elements_add_python_program(MER_GagaPrg MER_Validation.MER_GagaPrg)\n+elements_add_python_program(MER_AstrometryValidationPrg MER_Validation.MER_AstrometryValidationPrg)\n \n #===============================================================================\n # Add the elements_install_conf_files macro\n",
                            "Astrometry Validation kind of works now",
                            "Martin Kuemmel",
                            "2023-06-30T17:21:02.000+02:00",
                            "86f4592b671eafc5641ccdb2329d95cb560f4578"
                        ],
                        [
                            "@@ -62,6 +62,7 @@ elements_install_python_modules()\n #                             ElementsExamples.PythonProgramExample)\n #===============================================================================\n elements_add_python_program(MER_ValidationPrg MER_Validation.MER_ValidationPrg)\n+elements_add_python_program(MER_GagaPrg MER_Validation.MER_GagaPrg)\n \n #===============================================================================\n # Add the elements_install_conf_files macro\n",
                            "Added astrometric validation",
                            "Martin Kuemmel",
                            "2023-06-30T13:43:12.000+02:00",
                            "dd8b105bbc80fc2f67a5da64e02185d377fabfd5"
                        ],
                        [
                            "@@ -0,0 +1,71 @@\n+CMAKE_MINIMUM_REQUIRED(VERSION 2.8.12)\n+\n+#===============================================================================\n+# Load elements_subdir macro here\n+# Examples:\n+#   For declaring a project module:\n+#         elements_subdir(ElementsExamples)\n+#===============================================================================\n+elements_subdir(MER_Validation)\n+\n+#===============================================================================\n+# Load elements_depends_on_subdirs macro here\n+#   For creating a dependency onto an other accessible module\n+#         elements_depends_on_subdirs(ElementsKernel)\n+#===============================================================================\n+elements_depends_on_subdirs(ElementsKernel)\n+\n+#===============================================================================\n+# Add the find_package macro (a pure CMake command) here to locate the\n+# libraries.\n+# Examples:\n+#          find_package(CppUnit)\n+#===============================================================================\n+\n+#===============================================================================\n+# Declare the library dependencies here\n+# Example:\n+#         elements_add_library(ElementsExamples src/Lib/*.cpp\n+#                     INCLUDE_DIRS Boost ElementsKernel\n+#                     LINK_LIBRARIES Boost ElementsKernel\n+#                     PUBLIC_HEADERS ElementsExamples)\n+#===============================================================================\n+\n+#===============================================================================\n+# Declare the executables here\n+# Example:\n+# elements_add_executable(ElementsProgramExample src/Program/ProgramExample.cpp\n+#                        INCLUDE_DIRS Boost ElementsExamples\n+#                        LINK_LIBRARIES Boost ElementsExamples)\n+#===============================================================================\n+\n+#===============================================================================\n+# Declare the Boost tests here\n+# Example:\n+# elements_add_unit_test(BoostClassExample tests/src/Boost/ClassExample_test.cpp\n+#                       EXECUTABLE BoostClassExample_test\n+#                       INCLUDE_DIRS ElementsExamples\n+#                       LINK_LIBRARIES ElementsExamples TYPE Boost)\n+#===============================================================================\n+\n+#===============================================================================\n+# Use the following macro for python modules, scripts and aux files:\n+#  elements_install_python_modules()\n+#  elements_install_scripts()\n+#===============================================================================\n+elements_install_python_modules()\n+\n+#===============================================================================\n+# Declare the Python programs here\n+# Examples :\n+# elements_add_python_program(PythonProgramExample\n+#                             ElementsExamples.PythonProgramExample)\n+#===============================================================================\n+elements_add_python_program(MER_ValidationPrg MER_Validation.MER_ValidationPrg)\n+\n+#===============================================================================\n+# Add the elements_install_conf_files macro\n+# Examples:\n+#          elements_install_conf_files()\n+#===============================================================================\n+elements_install_conf_files()\n",
                            "MER_validation first commit",
                            "yfang",
                            "2023-06-16T14:07:37.000+02:00",
                            "aa8d15d7c99422f03f3b31136eb8cd04ae672e1c"
                        ]
                    ],
                    "MER_Validation/conf/MER_Validation/MER_MosaicingValidationPrg.conf": [
                        [
                            "@@ -0,0 +1 @@\n+# Write your program options here. e.g. : option = string\n\\ No newline at end of file\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T11:46:20.000+00:00",
                            "a83f468ea9bc0e5270859fcc7d1e7f8aa8bf922f"
                        ]
                    ],
                    "MER_Validation/python/MER_Validation/MER_MergeValidationResults.py": [
                        [
                            "@@ -79,6 +79,12 @@ def defineSpecificProgramOptions():\n     parser.add_argument(\"--gaia_psf_result\", dest=\"gaia_psf_result\",\n                         type=str, help=\"The Gaia PSF analysis result.\")\n \n+    parser.add_argument(\"--mosaicing_result\", dest=\"mosaicing_result\",\n+                        type=str, help=\"The Mosaicing validation result.\")\n+    \n+    parser.add_argument(\"--background_result\", dest=\"background_result\",\n+                        type=str, help=\"The Background validation result.\")\n+\n     # Add the output parameters\n     parser.add_argument(\"--merged_analysis_result\",\n                         dest=\"merged_analysis_result\", type=str,\n@@ -133,7 +139,12 @@ def create_analysis_report(reports, processing_mode, tile_index, filling_factor,\n         {\"text\": \"%s MER star PSF validation\" % reports[\"mer star psf\"].get_global_result(),\n          \"path\": \"merStarPsfAnalysis.html\"},\n         {\"text\": \"%s Gaia PSF validation\" % reports[\"gaia psf\"].get_global_result(),\n-         \"path\": \"gaiaPsfAnalysis.html\"}]\n+         \"path\": \"gaiaPsfAnalysis.html\"},\n+        {\"text\": \"%s MER Mosaicing validation\" % reports[\"mosaicing\"].get_global_result(),\n+         \"path\": \"mosaicingValidation.html\"},\n+        {\"text\": \"%s MER Background validation\" % reports[\"background\"].get_global_result(),\n+         \"path\": \"backgroundValidation.html\"}\n+         ]\n     analysis_report.set_index(reports_links)\n \n     # Set the forward link\n@@ -186,7 +197,11 @@ def mainMethod(args):\n         \"mer star psf\": dm_utils.read_product_metadata(\n             os.path.join(args.workdir, args.mer_star_psf_result)),\n         \"gaia psf\": dm_utils.read_product_metadata(\n-            os.path.join(args.workdir, args.gaia_psf_result))\n+            os.path.join(args.workdir, args.gaia_psf_result)),\n+        \"mosaicing\": dm_utils.read_product_metadata(\n+            os.path.join(args.workdir, args.mosaicing_result)),\n+        \"background\": dm_utils.read_product_metadata(\n+            os.path.join(args.workdir, args.background_result)),\n     }\n \n     # Get the figure tar file names and the global result\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T11:46:20.000+00:00",
                            "a83f468ea9bc0e5270859fcc7d1e7f8aa8bf922f"
                        ],
                        [
                            "@@ -38,6 +38,7 @@ from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n \n from MER_DA.MERUtilities import print_input_arguments\n \n+\n def defineSpecificProgramOptions():\n     \"\"\"Defines the command line input and output parameters specific to this\n     program.\n@@ -57,17 +58,26 @@ def defineSpecificProgramOptions():\n     parser.add_argument(\"--logdir\", dest=\"logdir\",\n                         type=str, help=\"The logging directory path.\")\n \n-    parser.add_argument(\"--detection_result\", dest=\"detection_result\",\n-                        default=\"detection_validation.json\", type=str,\n-                        help=\"The detection analysis result json file name.\")\n+    parser.add_argument(\"--photometry_result\", dest=\"photometry_result\",\n+                        type=str, help=\"The photometry analysis result.\")\n \n     parser.add_argument(\"--astrometry_result\", dest=\"astrometry_result\",\n-                        default=\"astrometry_validation.json\", type=str,\n-                        help=\"The mosaicing analysis result json file name.\")\n+                        type=str, help=\"The mosaicing analysis result.\")\n \n-    parser.add_argument(\"--photometry_result\", dest=\"photometry_result\",\n-                        default=\"photometry_validation.json\", type=str,\n-                        help=\"The photometry analysis result json file name.\")\n+    parser.add_argument(\"--detection_result\", dest=\"detection_result\",\n+                        type=str, help=\"The detection analysis result.\")\n+\n+    parser.add_argument(\"--classification_result\", dest=\"classification_result\",\n+                        type=str, help=\"The classification analysis result.\")\n+\n+    parser.add_argument(\"--psf_result\", dest=\"psf_result\",\n+                        type=str, help=\"The PSF analysis result.\")\n+\n+    parser.add_argument(\"--mer_star_psf_result\", dest=\"mer_star_psf_result\",\n+                        type=str, help=\"The MER star PSF analysis result.\")\n+\n+    parser.add_argument(\"--gaia_psf_result\", dest=\"gaia_psf_result\",\n+                        type=str, help=\"The Gaia PSF analysis result.\")\n \n     # Add the output parameters\n     parser.add_argument(\"--merged_analysis_result\",\n@@ -78,13 +88,22 @@ def defineSpecificProgramOptions():\n     return parser\n \n \n-def create_analysis_report(index_list, tile_index, workdir, filling_factor, processing_mode, global_result):\n+def create_analysis_report(reports, processing_mode, tile_index, filling_factor,\n+                           global_result, workdir):\n     \"\"\"Creates an analysis report.\n \n     Parameters\n     ----------\n+    reports: list\n+        The list of individual analysis reports.\n+    processing_mode: str\n+        The processing mode.\n     tile_index: int\n         The tile index.\n+    filling_factor: float\n+        The tile filling factor.\n+    global_result: str\n+        The report global result.\n     workdir: str\n         The complete path to the working directory.\n \n@@ -95,18 +114,36 @@ def create_analysis_report(index_list, tile_index, workdir, filling_factor, proc\n \n     \"\"\"\n     # Initialize the analysis report\n-    validation_report = AnalysisReport(\n-        \"%s MER validation tile: %s filling: %.1f%% mode: %s\" % (global_result, tile_index, filling_factor, processing_mode))\n-\n-    # set the leading links\n-    validation_report.set_index(index_list)\n+    analysis_report = AnalysisReport(\n+        \"%s MER validation tile: %s filling: %.1f%% mode: %s\" % (\n+            global_result, tile_index, filling_factor, processing_mode))\n+\n+    # Add the index with the links to all the analysis reports\n+    reports_links = [\n+        {\"text\": \"%s Photometry validation\" % reports[\"photometry\"].get_global_result(),\n+         \"path\": \"photometryValidation.html\"},\n+        {\"text\": \"%s Astrometry validation\" % reports[\"astrometry\"].get_global_result(),\n+         \"path\": \"astrometryValidation.html\"},\n+        {\"text\": \"%s Detection validation\" % reports[\"detection\"].get_global_result(),\n+         \"path\": \"detectionValidation.html\"},\n+        {\"text\": \"%s Classification validation\" % reports[\"classification\"].get_global_result(),\n+         \"path\": \"classificationValidation.html\"},\n+        {\"text\": \"%s PSF validation\" % reports[\"psf\"].get_global_result(),\n+         \"path\": \"psfAnalysis.html\"},\n+        {\"text\": \"%s MER star PSF validation\" % reports[\"mer star psf\"].get_global_result(),\n+         \"path\": \"merStarPsfAnalysis.html\"},\n+        {\"text\": \"%s Gaia PSF validation\" % reports[\"gaia psf\"].get_global_result(),\n+         \"path\": \"gaiaPsfAnalysis.html\"}]\n+    analysis_report.set_index(reports_links)\n+\n+    # Set the forward link\n+    analysis_report.set_forward(forward_link=\"photometryValidation.html\")\n \n     # Save the analysis report in various formats\n-    validation_report.set_forward(forward_link=\"photometryValidation.html\")\n     json_file_name = os.path.join(workdir, \"data\", \"index.json\")\n     html_file_name = os.path.join(workdir, \"data\", \"index.html\")\n-    validation_report.save_as_json_file(json_file_name)\n-    validation_report.save_as_html_file(html_file_name)\n+    analysis_report.save_as_json_file(json_file_name)\n+    analysis_report.save_as_html_file(html_file_name)\n \n     return [json_file_name, html_file_name]\n \n@@ -125,7 +162,7 @@ def mainMethod(args):\n     # Store the start time\n     start_time = time.time()\n \n-    # print all parameters to the screen\n+    # Print all parameters to the screen\n     print_input_arguments(args, logger)\n \n     # Do not print astropy warnings\n@@ -134,56 +171,47 @@ def mainMethod(args):\n     # Add some extra functionality to the MER data product bindings\n     mer_utils.init()\n \n-    # storage for the global index\n-    index_dict = {'detect': {\"text\": \"Detection validation\", \"path\": \"detectionValidation.html\"}, \n-                  'astrometry': {\"text\": \"Astrometry validation\", \"path\": \"astrometryValidation.html\"},\n-                  'photometry': {\"text\": \"Photometry validation\", \"path\": \"photometryValidation.html\"}}\n-\n     # Load the input analysis results\n-    analysis_results = []\n-    key_sequence = []\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.photometry_result)))\n-    key_sequence.append('photometry')\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.astrometry_result)))\n-    key_sequence.append('astrometry')\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.detection_result)))\n-    key_sequence.append('detect')\n+    analysis_results = {\n+        \"photometry\": dm_utils.read_product_metadata(\n+            os.path.join(args.workdir, args.photometry_result)),\n+        \"astrometry\": dm_utils.read_product_metadata(\n+            os.path.join(args.workdir, args.astrometry_result)),\n+        \"detection\": dm_utils.read_product_metadata(\n+            os.path.join(args.workdir, args.detection_result)),\n+        \"classification\": dm_utils.read_product_metadata(\n+            os.path.join(args.workdir, args.classification_result)),\n+        \"psf\": dm_utils.read_product_metadata(\n+            os.path.join(args.workdir, args.psf_result)),\n+        \"mer star psf\": dm_utils.read_product_metadata(\n+            os.path.join(args.workdir, args.mer_star_psf_result)),\n+        \"gaia psf\": dm_utils.read_product_metadata(\n+            os.path.join(args.workdir, args.gaia_psf_result))\n+    }\n \n     # Get the figure tar file names and the global result\n     figure_tar_file_names = []\n     global_result = \"PASSED\"\n \n-    index_list = []\n-    for analysis_result in zip(analysis_results, key_sequence):\n+    for analysis_result in analysis_results.values():\n         figure_tar_file_names.append(os.path.join(\n-            args.workdir, \"data\", analysis_result[0].get_figures_tar_file()))\n-        if analysis_result[0].get_global_result() == \"FAILED\":\n+            args.workdir, \"data\", analysis_result.get_figures_tar_file()))\n+\n+        if analysis_result.get_global_result() == \"FAILED\":\n             global_result = \"FAILED\"\n-        #index_list.append(index_dict[analysis_result[1]])\n-        index_list.append({'text': '%s %s'%(analysis_result[0].get_global_result(), index_dict[analysis_result[1]]['text']),\n-                           'path': index_dict[analysis_result[1]]['path']})\n-\n-    # Get the tile index, the observation ids and the processing mode\n-    tile_index = analysis_results[0].get_tile_index()\n-    observation_ids = analysis_results[0].get_observation_id_list()\n-    processing_mode = analysis_results[0].get_processing_mode()\n-\n-    # process the filling factor\n-    for act_result in analysis_results:\n-        act_filler = act_result.get_parameter(\"FILLING_FACTOR\")\n-        if act_filler is not None:\n-            filling_factor = act_filler.DoubleValue\n-            break\n-        else:\n-            filling_factor=0.0\n+\n+    # Get the tile index, the observation ids, the processing mode and the filling factor\n+    detection_result = analysis_results[\"detection\"]\n+    tile_index = detection_result.get_tile_index()\n+    observation_ids = detection_result.get_observation_id_list()\n+    processing_mode = detection_result.get_processing_mode()\n+    filling_factor = detection_result.get_parameter(\"FILLING_FACTOR\").DoubleValue\n \n     # Create the analysis report\n     logger.info(\"# Creating the merged validation report...\")\n-    report_file_names = create_analysis_report(index_list, tile_index, args.workdir, filling_factor,\n-                                               processing_mode, global_result)\n+    report_file_names = create_analysis_report(\n+        analysis_results, processing_mode, tile_index, filling_factor,\n+        global_result, args.workdir)\n \n     # Save all the analysis files into a single merged tar file\n     tar_file_name = mer_filename(\n@@ -206,6 +234,7 @@ def mainMethod(args):\n \n     # Print the time spent running the step\n     logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n+\n     logger.info(\"#\")\n     logger.info(\"# Exiting MER_MergeValidationResults mainMethod()\")\n     logger.info(\"#\")\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-08-11T15:41:07.000+02:00",
                            "3439f2b2c5d1617a26353d57808735c69cf7a538"
                        ],
                        [
                            "@@ -67,6 +67,9 @@ def defineSpecificProgramOptions():\n     parser.add_argument(\"--detection_result\", dest=\"detection_result\",\n                         type=str, help=\"The detection analysis result.\")\n \n+    parser.add_argument(\"--classification_result\", dest=\"classification_result\",\n+                        type=str, help=\"The classification analysis result.\")\n+\n     parser.add_argument(\"--psf_result\", dest=\"psf_result\",\n                         type=str, help=\"The PSF analysis result.\")\n \n@@ -123,6 +126,8 @@ def create_analysis_report(reports, processing_mode, tile_index, filling_factor,\n          \"path\": \"astrometryValidation.html\"},\n         {\"text\": \"%s Detection validation\" % reports[\"detection\"].get_global_result(),\n          \"path\": \"detectionValidation.html\"},\n+        {\"text\": \"%s Classification validation\" % reports[\"classification\"].get_global_result(),\n+         \"path\": \"classificationValidation.html\"},\n         {\"text\": \"%s PSF validation\" % reports[\"psf\"].get_global_result(),\n          \"path\": \"psfAnalysis.html\"},\n         {\"text\": \"%s MER star PSF validation\" % reports[\"mer star psf\"].get_global_result(),\n@@ -174,6 +179,8 @@ def mainMethod(args):\n             os.path.join(args.workdir, args.astrometry_result)),\n         \"detection\": dm_utils.read_product_metadata(\n             os.path.join(args.workdir, args.detection_result)),\n+        \"classification\": dm_utils.read_product_metadata(\n+            os.path.join(args.workdir, args.classification_result)),\n         \"psf\": dm_utils.read_product_metadata(\n             os.path.join(args.workdir, args.psf_result)),\n         \"mer star psf\": dm_utils.read_product_metadata(\n",
                            "Updates for the classification validation step",
                            "Javier Gracia Carpio",
                            "2023-08-10T19:43:44.000+00:00",
                            "08bbbf05233ab7f298b3ce157dc348546bffc8ef"
                        ],
                        [
                            "@@ -73,6 +73,9 @@ def defineSpecificProgramOptions():\n     parser.add_argument(\"--mer_star_psf_result\", dest=\"mer_star_psf_result\",\n                         type=str, help=\"The MER star PSF analysis result.\")\n \n+    parser.add_argument(\"--gaia_psf_result\", dest=\"gaia_psf_result\",\n+                        type=str, help=\"The Gaia PSF analysis result.\")\n+\n     # Add the output parameters\n     parser.add_argument(\"--merged_analysis_result\",\n                         dest=\"merged_analysis_result\", type=str,\n@@ -123,7 +126,9 @@ def create_analysis_report(reports, processing_mode, tile_index, filling_factor,\n         {\"text\": \"%s PSF validation\" % reports[\"psf\"].get_global_result(),\n          \"path\": \"psfAnalysis.html\"},\n         {\"text\": \"%s MER star PSF validation\" % reports[\"mer star psf\"].get_global_result(),\n-         \"path\": \"merStarPsfAnalysis.html\"}]\n+         \"path\": \"merStarPsfAnalysis.html\"},\n+        {\"text\": \"%s Gaia PSF validation\" % reports[\"gaia psf\"].get_global_result(),\n+         \"path\": \"gaiaPsfAnalysis.html\"}]\n     analysis_report.set_index(reports_links)\n \n     # Set the forward link\n@@ -172,7 +177,9 @@ def mainMethod(args):\n         \"psf\": dm_utils.read_product_metadata(\n             os.path.join(args.workdir, args.psf_result)),\n         \"mer star psf\": dm_utils.read_product_metadata(\n-            os.path.join(args.workdir, args.mer_star_psf_result))\n+            os.path.join(args.workdir, args.mer_star_psf_result)),\n+        \"gaia psf\": dm_utils.read_product_metadata(\n+            os.path.join(args.workdir, args.gaia_psf_result))\n     }\n \n     # Get the figure tar file names and the global result\n",
                            "Adds the Gaia PSF validation step",
                            "Javier Gracia Carpio",
                            "2023-08-10T16:19:25.000+00:00",
                            "7c108a4a124a563b5ffeceb7d3233ae670d11007"
                        ],
                        [
                            "@@ -127,7 +127,7 @@ def create_analysis_report(reports, processing_mode, tile_index, filling_factor,\n     analysis_report.set_index(reports_links)\n \n     # Set the forward link\n-    validation_report.set_forward(forward_link=\"photometryValidation.html\")\n+    analysis_report.set_forward(forward_link=\"photometryValidation.html\")\n \n     # Save the analysis report in various formats\n     json_file_name = os.path.join(workdir, \"data\", \"index.json\")\n",
                            "Corrects another typo...",
                            "Javier Gracia Carpio",
                            "2023-08-10T15:24:08.000+00:00",
                            "c772bbdc0a1fb768b9a23e982e3c953fca9f72c9"
                        ],
                        [
                            "@@ -122,7 +122,7 @@ def create_analysis_report(reports, processing_mode, tile_index, filling_factor,\n          \"path\": \"detectionValidation.html\"},\n         {\"text\": \"%s PSF validation\" % reports[\"psf\"].get_global_result(),\n          \"path\": \"psfAnalysis.html\"},\n-        {\"text\": \"%s MER star PSF validation\" % reports[\"mer start psf\"].get_global_result(),\n+        {\"text\": \"%s MER star PSF validation\" % reports[\"mer star psf\"].get_global_result(),\n          \"path\": \"merStarPsfAnalysis.html\"}]\n     analysis_report.set_index(reports_links)\n \n@@ -171,7 +171,7 @@ def mainMethod(args):\n             os.path.join(args.workdir, args.detection_result)),\n         \"psf\": dm_utils.read_product_metadata(\n             os.path.join(args.workdir, args.psf_result)),\n-        \"mer_star_psf\": dm_utils.read_product_metadata(\n+        \"mer star psf\": dm_utils.read_product_metadata(\n             os.path.join(args.workdir, args.mer_star_psf_result))\n     }\n \n",
                            "Corrects typo",
                            "Javier Gracia Carpio",
                            "2023-08-10T14:53:44.000+00:00",
                            "570f98bb04202fe9df0f541d149f44f4caab8bf9"
                        ],
                        [
                            "@@ -38,6 +38,7 @@ from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n \n from MER_DA.MERUtilities import print_input_arguments\n \n+\n def defineSpecificProgramOptions():\n     \"\"\"Defines the command line input and output parameters specific to this\n     program.\n@@ -57,17 +58,20 @@ def defineSpecificProgramOptions():\n     parser.add_argument(\"--logdir\", dest=\"logdir\",\n                         type=str, help=\"The logging directory path.\")\n \n-    parser.add_argument(\"--detection_result\", dest=\"detection_result\",\n-                        default=\"detection_validation.json\", type=str,\n-                        help=\"The detection analysis result json file name.\")\n+    parser.add_argument(\"--photometry_result\", dest=\"photometry_result\",\n+                        type=str, help=\"The photometry analysis result.\")\n \n     parser.add_argument(\"--astrometry_result\", dest=\"astrometry_result\",\n-                        default=\"astrometry_validation.json\", type=str,\n-                        help=\"The mosaicing analysis result json file name.\")\n+                        type=str, help=\"The mosaicing analysis result.\")\n \n-    parser.add_argument(\"--photometry_result\", dest=\"photometry_result\",\n-                        default=\"photometry_validation.json\", type=str,\n-                        help=\"The photometry analysis result json file name.\")\n+    parser.add_argument(\"--detection_result\", dest=\"detection_result\",\n+                        type=str, help=\"The detection analysis result.\")\n+\n+    parser.add_argument(\"--psf_result\", dest=\"psf_result\",\n+                        type=str, help=\"The PSF analysis result.\")\n+\n+    parser.add_argument(\"--mer_star_psf_result\", dest=\"mer_star_psf_result\",\n+                        type=str, help=\"The MER star PSF analysis result.\")\n \n     # Add the output parameters\n     parser.add_argument(\"--merged_analysis_result\",\n@@ -78,13 +82,22 @@ def defineSpecificProgramOptions():\n     return parser\n \n \n-def create_analysis_report(index_list, tile_index, workdir, filling_factor, processing_mode, global_result):\n+def create_analysis_report(reports, processing_mode, tile_index, filling_factor,\n+                           global_result, workdir):\n     \"\"\"Creates an analysis report.\n \n     Parameters\n     ----------\n+    reports: list\n+        The list of individual analysis reports.\n+    processing_mode: str\n+        The processing mode.\n     tile_index: int\n         The tile index.\n+    filling_factor: float\n+        The tile filling factor.\n+    global_result: str\n+        The report global result.\n     workdir: str\n         The complete path to the working directory.\n \n@@ -95,18 +108,32 @@ def create_analysis_report(index_list, tile_index, workdir, filling_factor, proc\n \n     \"\"\"\n     # Initialize the analysis report\n-    validation_report = AnalysisReport(\n-        \"%s MER validation tile: %s filling: %.1f%% mode: %s\" % (global_result, tile_index, filling_factor, processing_mode))\n-\n-    # set the leading links\n-    validation_report.set_index(index_list)\n+    analysis_report = AnalysisReport(\n+        \"%s MER validation tile: %s filling: %.1f%% mode: %s\" % (\n+            global_result, tile_index, filling_factor, processing_mode))\n+\n+    # Add the index with the links to all the analysis reports\n+    reports_links = [\n+        {\"text\": \"%s Photometry validation\" % reports[\"photometry\"].get_global_result(),\n+         \"path\": \"photometryValidation.html\"},\n+        {\"text\": \"%s Astrometry validation\" % reports[\"astrometry\"].get_global_result(),\n+         \"path\": \"astrometryValidation.html\"},\n+        {\"text\": \"%s Detection validation\" % reports[\"detection\"].get_global_result(),\n+         \"path\": \"detectionValidation.html\"},\n+        {\"text\": \"%s PSF validation\" % reports[\"psf\"].get_global_result(),\n+         \"path\": \"psfAnalysis.html\"},\n+        {\"text\": \"%s MER star PSF validation\" % reports[\"mer start psf\"].get_global_result(),\n+         \"path\": \"merStarPsfAnalysis.html\"}]\n+    analysis_report.set_index(reports_links)\n+\n+    # Set the forward link\n+    validation_report.set_forward(forward_link=\"photometryValidation.html\")\n \n     # Save the analysis report in various formats\n-    validation_report.set_forward(forward_link=\"photometryValidation.html\")\n     json_file_name = os.path.join(workdir, \"data\", \"index.json\")\n     html_file_name = os.path.join(workdir, \"data\", \"index.html\")\n-    validation_report.save_as_json_file(json_file_name)\n-    validation_report.save_as_html_file(html_file_name)\n+    analysis_report.save_as_json_file(json_file_name)\n+    analysis_report.save_as_html_file(html_file_name)\n \n     return [json_file_name, html_file_name]\n \n@@ -125,7 +152,7 @@ def mainMethod(args):\n     # Store the start time\n     start_time = time.time()\n \n-    # print all parameters to the screen\n+    # Print all parameters to the screen\n     print_input_arguments(args, logger)\n \n     # Do not print astropy warnings\n@@ -134,56 +161,43 @@ def mainMethod(args):\n     # Add some extra functionality to the MER data product bindings\n     mer_utils.init()\n \n-    # storage for the global index\n-    index_dict = {'detect': {\"text\": \"Detection validation\", \"path\": \"detectionValidation.html\"}, \n-                  'astrometry': {\"text\": \"Astrometry validation\", \"path\": \"astrometryValidation.html\"},\n-                  'photometry': {\"text\": \"Photometry validation\", \"path\": \"photometryValidation.html\"}}\n-\n     # Load the input analysis results\n-    analysis_results = []\n-    key_sequence = []\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.photometry_result)))\n-    key_sequence.append('photometry')\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.astrometry_result)))\n-    key_sequence.append('astrometry')\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.detection_result)))\n-    key_sequence.append('detect')\n+    analysis_results = {\n+        \"photometry\": dm_utils.read_product_metadata(\n+            os.path.join(args.workdir, args.photometry_result)),\n+        \"astrometry\": dm_utils.read_product_metadata(\n+            os.path.join(args.workdir, args.astrometry_result)),\n+        \"detection\": dm_utils.read_product_metadata(\n+            os.path.join(args.workdir, args.detection_result)),\n+        \"psf\": dm_utils.read_product_metadata(\n+            os.path.join(args.workdir, args.psf_result)),\n+        \"mer_star_psf\": dm_utils.read_product_metadata(\n+            os.path.join(args.workdir, args.mer_star_psf_result))\n+    }\n \n     # Get the figure tar file names and the global result\n     figure_tar_file_names = []\n     global_result = \"PASSED\"\n \n-    index_list = []\n-    for analysis_result in zip(analysis_results, key_sequence):\n+    for analysis_result in analysis_results.values():\n         figure_tar_file_names.append(os.path.join(\n-            args.workdir, \"data\", analysis_result[0].get_figures_tar_file()))\n-        if analysis_result[0].get_global_result() == \"FAILED\":\n+            args.workdir, \"data\", analysis_result.get_figures_tar_file()))\n+\n+        if analysis_result.get_global_result() == \"FAILED\":\n             global_result = \"FAILED\"\n-        #index_list.append(index_dict[analysis_result[1]])\n-        index_list.append({'text': '%s %s'%(analysis_result[0].get_global_result(), index_dict[analysis_result[1]]['text']),\n-                           'path': index_dict[analysis_result[1]]['path']})\n-\n-    # Get the tile index, the observation ids and the processing mode\n-    tile_index = analysis_results[0].get_tile_index()\n-    observation_ids = analysis_results[0].get_observation_id_list()\n-    processing_mode = analysis_results[0].get_processing_mode()\n-\n-    # process the filling factor\n-    for act_result in analysis_results:\n-        act_filler = act_result.get_parameter(\"FILLING_FACTOR\")\n-        if act_filler is not None:\n-            filling_factor = act_filler.DoubleValue\n-            break\n-        else:\n-            filling_factor=0.0\n+\n+    # Get the tile index, the observation ids, the processing mode and the filling factor\n+    detection_result = analysis_results[\"detection\"]\n+    tile_index = detection_result.get_tile_index()\n+    observation_ids = detection_result.get_observation_id_list()\n+    processing_mode = detection_result.get_processing_mode()\n+    filling_factor = detection_result.get_parameter(\"FILLING_FACTOR\").DoubleValue\n \n     # Create the analysis report\n     logger.info(\"# Creating the merged validation report...\")\n-    report_file_names = create_analysis_report(index_list, tile_index, args.workdir, filling_factor,\n-                                               processing_mode, global_result)\n+    report_file_names = create_analysis_report(\n+        analysis_results, processing_mode, tile_index, filling_factor,\n+        global_result, args.workdir)\n \n     # Save all the analysis files into a single merged tar file\n     tar_file_name = mer_filename(\n@@ -206,6 +220,7 @@ def mainMethod(args):\n \n     # Print the time spent running the step\n     logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n+\n     logger.info(\"#\")\n     logger.info(\"# Exiting MER_MergeValidationResults mainMethod()\")\n     logger.info(\"#\")\n",
                            "Adds the PSF validation reports + some code refactoring",
                            "Javier Gracia Carpio",
                            "2023-08-10T14:17:45.000+00:00",
                            "ad784eefa5b97030d0d46324765803dc0ceef220"
                        ],
                        [
                            "@@ -102,7 +102,7 @@ def create_analysis_report(index_list, tile_index, workdir, filling_factor, proc\n     validation_report.set_index(index_list)\n \n     # Save the analysis report in various formats\n-    validation_report.set_forward(forward_link=\"detectionValidation.html\")\n+    validation_report.set_forward(forward_link=\"photometryValidation.html\")\n     json_file_name = os.path.join(workdir, \"data\", \"index.json\")\n     html_file_name = os.path.join(workdir, \"data\", \"index.html\")\n     validation_report.save_as_json_file(json_file_name)\n@@ -143,14 +143,14 @@ def mainMethod(args):\n     analysis_results = []\n     key_sequence = []\n     analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.detection_result)))\n-    key_sequence.append('detect')\n+        os.path.join(args.workdir, args.photometry_result)))\n+    key_sequence.append('photometry')\n     analysis_results.append(dm_utils.read_product_metadata(\n         os.path.join(args.workdir, args.astrometry_result)))\n     key_sequence.append('astrometry')\n     analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.photometry_result)))\n-    key_sequence.append('photometry')\n+        os.path.join(args.workdir, args.detection_result)))\n+    key_sequence.append('detect')\n \n     # Get the figure tar file names and the global result\n     figure_tar_file_names = []\n@@ -170,7 +170,15 @@ def mainMethod(args):\n     tile_index = analysis_results[0].get_tile_index()\n     observation_ids = analysis_results[0].get_observation_id_list()\n     processing_mode = analysis_results[0].get_processing_mode()\n-    filling_factor = analysis_results[0].get_parameter(\"FILLING_FACTOR\").DoubleValue\n+\n+    # process the filling factor\n+    for act_result in analysis_results:\n+        act_filler = act_result.get_parameter(\"FILLING_FACTOR\")\n+        if act_filler is not None:\n+            filling_factor = act_filler.DoubleValue\n+            break\n+        else:\n+            filling_factor=0.0\n \n     # Create the analysis report\n     logger.info(\"# Creating the merged validation report...\")\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-27T17:00:08.000+02:00",
                            "a29716cea96bd9952a85e0d027784845fe5b7f03"
                        ],
                        [
                            "@@ -19,10 +19,10 @@\n \"\"\"\n File: python/MER_PsfMosaicValidation/MER_MergeAnalysisResults.py\n \n-Created on: 08/15/20\n-Author: Javier Gracia Carpio (jgracia@mpe.mpg.de)\n+Created on: 07/05/2023\n+Author: mkuemmel@usm.lmu.de\n \"\"\"\n-\n+import time\n import os.path\n import argparse\n \n@@ -36,6 +36,7 @@ from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n \n+from MER_DA.MERUtilities import print_input_arguments\n \n def defineSpecificProgramOptions():\n     \"\"\"Defines the command line input and output parameters specific to this\n@@ -56,14 +57,17 @@ def defineSpecificProgramOptions():\n     parser.add_argument(\"--logdir\", dest=\"logdir\",\n                         type=str, help=\"The logging directory path.\")\n \n-    #parser.add_argument(\"--mosaicing_analysis_resultastrometry_validation.json\",\n-    #                    dest=\"mosaicing_analysis_result\",\n-    #                    type=str, help=\"The mosaicing analysis result XML file \"\n-    #                    \"name.\")\n-    parser.add_argument(\"--astrometry_result\", dest=\"astrometry_validation\",\n+    parser.add_argument(\"--detection_result\", dest=\"detection_result\",\n+                        default=\"detection_validation.json\", type=str,\n+                        help=\"The detection analysis result json file name.\")\n+\n+    parser.add_argument(\"--astrometry_result\", dest=\"astrometry_result\",\n                         default=\"astrometry_validation.json\", type=str,\n                         help=\"The mosaicing analysis result json file name.\")\n \n+    parser.add_argument(\"--photometry_result\", dest=\"photometry_result\",\n+                        default=\"photometry_validation.json\", type=str,\n+                        help=\"The photometry analysis result json file name.\")\n \n     # Add the output parameters\n     parser.add_argument(\"--merged_analysis_result\",\n@@ -74,7 +78,7 @@ def defineSpecificProgramOptions():\n     return parser\n \n \n-def create_analysis_report(tile_index, workdir):\n+def create_analysis_report(index_list, tile_index, workdir, filling_factor, processing_mode, global_result):\n     \"\"\"Creates an analysis report.\n \n     Parameters\n@@ -92,16 +96,13 @@ def create_analysis_report(tile_index, workdir):\n     \"\"\"\n     # Initialize the analysis report\n     validation_report = AnalysisReport(\n-        \"MER validation report for tile %s\" % tile_index)\n+        \"%s MER validation tile: %s filling: %.1f%% mode: %s\" % (global_result, tile_index, filling_factor, processing_mode))\n \n-    # Add the index with the links to all the analysis reports\n-    reports_links = [\n-        {\"text\": \"Astrometry validation\",\n-         \"path\": \"astrometryValidation.html\"}]\n-    validation_report.set_index(reports_links)\n+    # set the leading links\n+    validation_report.set_index(index_list)\n \n     # Save the analysis report in various formats\n-    validation_report.set_forward(forward_link=\"astrometryValidation.html\")\n+    validation_report.set_forward(forward_link=\"photometryValidation.html\")\n     json_file_name = os.path.join(workdir, \"data\", \"index.json\")\n     html_file_name = os.path.join(workdir, \"data\", \"index.html\")\n     validation_report.save_as_json_file(json_file_name)\n@@ -121,60 +122,68 @@ def mainMethod(args):\n     logger.info(\"# Entering MER_MergeValidationResults mainMethod()\")\n     logger.info(\"#\")\n \n+    # Store the start time\n+    start_time = time.time()\n+\n+    # print all parameters to the screen\n+    print_input_arguments(args, logger)\n+\n     # Do not print astropy warnings\n     AnalysisUtils.ignore_astropy_warnings()\n \n     # Add some extra functionality to the MER data product bindings\n     mer_utils.init()\n \n+    # storage for the global index\n+    index_dict = {'detect': {\"text\": \"Detection validation\", \"path\": \"detectionValidation.html\"}, \n+                  'astrometry': {\"text\": \"Astrometry validation\", \"path\": \"astrometryValidation.html\"},\n+                  'photometry': {\"text\": \"Photometry validation\", \"path\": \"photometryValidation.html\"}}\n+\n     # Load the input analysis results\n     analysis_results = []\n+    key_sequence = []\n     analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.astrometry_validation)))\n-    \"\"\"\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.mer_star_psf_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.tu_star_psf_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.mosaicing_analysis_result)))\n+        os.path.join(args.workdir, args.photometry_result)))\n+    key_sequence.append('photometry')\n     analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.background_analysis_result)))\n+        os.path.join(args.workdir, args.astrometry_result)))\n+    key_sequence.append('astrometry')\n     analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.detection_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.crossmatch_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.morphology_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.photometry_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.photometry_plots_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.classification_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.final_catalog_analysis_result)))\n-    \"\"\"\n+        os.path.join(args.workdir, args.detection_result)))\n+    key_sequence.append('detect')\n \n     # Get the figure tar file names and the global result\n     figure_tar_file_names = []\n     global_result = \"PASSED\"\n \n-    for analysis_result in analysis_results:\n+    index_list = []\n+    for analysis_result in zip(analysis_results, key_sequence):\n         figure_tar_file_names.append(os.path.join(\n-            args.workdir, \"data\", analysis_result.get_figures_tar_file()))\n-\n-        if analysis_result.get_global_result() == \"FAILED\":\n+            args.workdir, \"data\", analysis_result[0].get_figures_tar_file()))\n+        if analysis_result[0].get_global_result() == \"FAILED\":\n             global_result = \"FAILED\"\n+        #index_list.append(index_dict[analysis_result[1]])\n+        index_list.append({'text': '%s %s'%(analysis_result[0].get_global_result(), index_dict[analysis_result[1]]['text']),\n+                           'path': index_dict[analysis_result[1]]['path']})\n \n     # Get the tile index, the observation ids and the processing mode\n     tile_index = analysis_results[0].get_tile_index()\n     observation_ids = analysis_results[0].get_observation_id_list()\n     processing_mode = analysis_results[0].get_processing_mode()\n \n+    # process the filling factor\n+    for act_result in analysis_results:\n+        act_filler = act_result.get_parameter(\"FILLING_FACTOR\")\n+        if act_filler is not None:\n+            filling_factor = act_filler.DoubleValue\n+            break\n+        else:\n+            filling_factor=0.0\n+\n     # Create the analysis report\n     logger.info(\"# Creating the merged validation report...\")\n-    report_file_names = create_analysis_report(tile_index, args.workdir)\n+    report_file_names = create_analysis_report(index_list, tile_index, args.workdir, filling_factor,\n+                                               processing_mode, global_result)\n \n     # Save all the analysis files into a single merged tar file\n     tar_file_name = mer_filename(\n@@ -195,6 +204,8 @@ def mainMethod(args):\n     analysis_result.save_xml(\n         os.path.join(args.workdir, args.merged_analysis_result))\n \n+    # Print the time spent running the step\n+    logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n     logger.info(\"#\")\n     logger.info(\"# Exiting MER_MergeValidationResults mainMethod()\")\n     logger.info(\"#\")\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ],
                        [
                            "@@ -170,7 +170,8 @@ def mainMethod(args):\n     tile_index = analysis_results[0].get_tile_index()\n     observation_ids = analysis_results[0].get_observation_id_list()\n     processing_mode = analysis_results[0].get_processing_mode()\n-    #filling_factor = None\n+\n+    # process the filling factor\n     for act_result in analysis_results:\n         act_filler = act_result.get_parameter(\"FILLING_FACTOR\")\n         if act_filler is not None:\n@@ -178,8 +179,6 @@ def mainMethod(args):\n             break\n         else:\n             filling_factor=0.0\n-        #if filling_factor is not None:\n-        #    break\n \n     # Create the analysis report\n     logger.info(\"# Creating the merged validation report...\")\n",
                            "Cosmetic changes",
                            "Martin Kuemmel",
                            "2023-07-21T11:36:23.000+02:00",
                            "0e33be74e6a76668d49c431ae231976683114a7d"
                        ],
                        [
                            "@@ -102,7 +102,7 @@ def create_analysis_report(index_list, tile_index, workdir, filling_factor, proc\n     validation_report.set_index(index_list)\n \n     # Save the analysis report in various formats\n-    validation_report.set_forward(forward_link=\"detectionValidation.html\")\n+    validation_report.set_forward(forward_link=\"photometryValidation.html\")\n     json_file_name = os.path.join(workdir, \"data\", \"index.json\")\n     html_file_name = os.path.join(workdir, \"data\", \"index.html\")\n     validation_report.save_as_json_file(json_file_name)\n@@ -143,14 +143,14 @@ def mainMethod(args):\n     analysis_results = []\n     key_sequence = []\n     analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.detection_result)))\n-    key_sequence.append('detect')\n+        os.path.join(args.workdir, args.photometry_result)))\n+    key_sequence.append('photometry')\n     analysis_results.append(dm_utils.read_product_metadata(\n         os.path.join(args.workdir, args.astrometry_result)))\n     key_sequence.append('astrometry')\n     analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.photometry_result)))\n-    key_sequence.append('photometry')\n+        os.path.join(args.workdir, args.detection_result)))\n+    key_sequence.append('detect')\n \n     # Get the figure tar file names and the global result\n     figure_tar_file_names = []\n@@ -170,7 +170,16 @@ def mainMethod(args):\n     tile_index = analysis_results[0].get_tile_index()\n     observation_ids = analysis_results[0].get_observation_id_list()\n     processing_mode = analysis_results[0].get_processing_mode()\n-    filling_factor = analysis_results[0].get_parameter(\"FILLING_FACTOR\").DoubleValue\n+    #filling_factor = None\n+    for act_result in analysis_results:\n+        act_filler = act_result.get_parameter(\"FILLING_FACTOR\")\n+        if act_filler is not None:\n+            filling_factor = act_filler.DoubleValue\n+            break\n+        else:\n+            filling_factor=0.0\n+        #if filling_factor is not None:\n+        #    break\n \n     # Create the analysis report\n     logger.info(\"# Creating the merged validation report...\")\n",
                            "Some mopping up and re-ordering",
                            "Martin Kuemmel",
                            "2023-07-21T10:47:49.000+02:00",
                            "1ff024aab348769fdd7dd60a20c39aae119902e7"
                        ],
                        [
                            "@@ -78,7 +78,7 @@ def defineSpecificProgramOptions():\n     return parser\n \n \n-def create_analysis_report(index_list, tile_index, workdir, global_result):\n+def create_analysis_report(index_list, tile_index, workdir, filling_factor, processing_mode, global_result):\n     \"\"\"Creates an analysis report.\n \n     Parameters\n@@ -96,7 +96,7 @@ def create_analysis_report(index_list, tile_index, workdir, global_result):\n     \"\"\"\n     # Initialize the analysis report\n     validation_report = AnalysisReport(\n-        \"%s MER validation report for tile %s\" % (global_result, tile_index))\n+        \"%s MER validation tile: %s filling: %.1f%% mode: %s\" % (global_result, tile_index, filling_factor, processing_mode))\n \n     # set the leading links\n     validation_report.set_index(index_list)\n@@ -170,10 +170,12 @@ def mainMethod(args):\n     tile_index = analysis_results[0].get_tile_index()\n     observation_ids = analysis_results[0].get_observation_id_list()\n     processing_mode = analysis_results[0].get_processing_mode()\n+    filling_factor = analysis_results[0].get_parameter(\"FILLING_FACTOR\").DoubleValue\n \n     # Create the analysis report\n     logger.info(\"# Creating the merged validation report...\")\n-    report_file_names = create_analysis_report(index_list, tile_index, args.workdir, global_result)\n+    report_file_names = create_analysis_report(index_list, tile_index, args.workdir, filling_factor,\n+                                               processing_mode, global_result)\n \n     # Save all the analysis files into a single merged tar file\n     tar_file_name = mer_filename(\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-18T18:37:53.000+02:00",
                            "78c5119e500255574c19c53cb5e9713d82f04f41"
                        ],
                        [
                            "@@ -65,6 +65,10 @@ def defineSpecificProgramOptions():\n                         default=\"astrometry_validation.json\", type=str,\n                         help=\"The mosaicing analysis result json file name.\")\n \n+    parser.add_argument(\"--photometry_result\", dest=\"photometry_result\",\n+                        default=\"photometry_validation.json\", type=str,\n+                        help=\"The photometry analysis result json file name.\")\n+\n     # Add the output parameters\n     parser.add_argument(\"--merged_analysis_result\",\n                         dest=\"merged_analysis_result\", type=str,\n@@ -132,7 +136,8 @@ def mainMethod(args):\n \n     # storage for the global index\n     index_dict = {'detect': {\"text\": \"Detection validation\", \"path\": \"detectionValidation.html\"}, \n-                  'astrometry': {\"text\": \"Astrometry validation\", \"path\": \"astrometryValidation.html\"}}\n+                  'astrometry': {\"text\": \"Astrometry validation\", \"path\": \"astrometryValidation.html\"},\n+                  'photometry': {\"text\": \"Photometry validation\", \"path\": \"photometryValidation.html\"}}\n \n     # Load the input analysis results\n     analysis_results = []\n@@ -143,6 +148,9 @@ def mainMethod(args):\n     analysis_results.append(dm_utils.read_product_metadata(\n         os.path.join(args.workdir, args.astrometry_result)))\n     key_sequence.append('astrometry')\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.photometry_result)))\n+    key_sequence.append('photometry')\n \n     # Get the figure tar file names and the global result\n     figure_tar_file_names = []\n",
                            "1. link the photometry validation to the merged",
                            "yfang",
                            "2023-07-18T18:37:14.000+02:00",
                            "6e649052ce71cc2177fab5e698374d8b3d3da380"
                        ],
                        [
                            "@@ -74,7 +74,7 @@ def defineSpecificProgramOptions():\n     return parser\n \n \n-def create_analysis_report(index_list, tile_index, workdir, global_result):\n+def create_analysis_report(index_list, tile_index, workdir, filling_factor, processing_mode, global_result):\n     \"\"\"Creates an analysis report.\n \n     Parameters\n@@ -92,7 +92,7 @@ def create_analysis_report(index_list, tile_index, workdir, global_result):\n     \"\"\"\n     # Initialize the analysis report\n     validation_report = AnalysisReport(\n-        \"%s MER validation report for tile %s\" % (global_result, tile_index))\n+        \"%s MER validation tile: %s filling: %.1f%% mode: %s\" % (global_result, tile_index, filling_factor, processing_mode))\n \n     # set the leading links\n     validation_report.set_index(index_list)\n@@ -162,10 +162,12 @@ def mainMethod(args):\n     tile_index = analysis_results[0].get_tile_index()\n     observation_ids = analysis_results[0].get_observation_id_list()\n     processing_mode = analysis_results[0].get_processing_mode()\n+    filling_factor = analysis_results[0].get_parameter(\"FILLING_FACTOR\").DoubleValue\n \n     # Create the analysis report\n     logger.info(\"# Creating the merged validation report...\")\n-    report_file_names = create_analysis_report(index_list, tile_index, args.workdir, global_result)\n+    report_file_names = create_analysis_report(index_list, tile_index, args.workdir, filling_factor,\n+                                               processing_mode, global_result)\n \n     # Save all the analysis files into a single merged tar file\n     tar_file_name = mer_filename(\n",
                            "Create a generic parameter for the filling factor",
                            "Martin Kuemmel",
                            "2023-07-11T16:22:45.000+02:00",
                            "ccc800212f1732126ed243791b6fafaf339c0029"
                        ],
                        [
                            "@@ -19,10 +19,10 @@\n \"\"\"\n File: python/MER_PsfMosaicValidation/MER_MergeAnalysisResults.py\n \n-Created on: 08/15/20\n-Author: Javier Gracia Carpio (jgracia@mpe.mpg.de)\n+Created on: 07/05/2023\n+Author: mkuemmel@usm.lmu.de\n \"\"\"\n-\n+import time\n import os.path\n import argparse\n \n@@ -36,6 +36,7 @@ from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n \n+from MER_DA.MERUtilities import print_input_arguments\n \n def defineSpecificProgramOptions():\n     \"\"\"Defines the command line input and output parameters specific to this\n@@ -56,15 +57,14 @@ def defineSpecificProgramOptions():\n     parser.add_argument(\"--logdir\", dest=\"logdir\",\n                         type=str, help=\"The logging directory path.\")\n \n-    #parser.add_argument(\"--mosaicing_analysis_resultastrometry_validation.json\",\n-    #                    dest=\"mosaicing_analysis_result\",\n-    #                    type=str, help=\"The mosaicing analysis result XML file \"\n-    #                    \"name.\")\n-    parser.add_argument(\"--astrometry_validation\", dest=\"astrometry_validation\",\n+    parser.add_argument(\"--detection_result\", dest=\"detection_result\",\n+                        default=\"detection_validation.json\", type=str,\n+                        help=\"The detection analysis result json file name.\")\n+\n+    parser.add_argument(\"--astrometry_result\", dest=\"astrometry_result\",\n                         default=\"astrometry_validation.json\", type=str,\n                         help=\"The mosaicing analysis result json file name.\")\n \n-\n     # Add the output parameters\n     parser.add_argument(\"--merged_analysis_result\",\n                         dest=\"merged_analysis_result\", type=str,\n@@ -74,7 +74,7 @@ def defineSpecificProgramOptions():\n     return parser\n \n \n-def create_analysis_report(workdir):\n+def create_analysis_report(index_list, tile_index, workdir, global_result):\n     \"\"\"Creates an analysis report.\n \n     Parameters\n@@ -90,20 +90,15 @@ def create_analysis_report(workdir):\n         A python list with the analysis report file names.\n \n     \"\"\"\n-    #def create_analysis_report(tile_index, workdir):\n     # Initialize the analysis report\n     validation_report = AnalysisReport(\n-        \"MER validation report for tile %s\" % 0)\n+        \"%s MER validation report for tile %s\" % (global_result, tile_index))\n \n-    # Add the index with the links to all the analysis reports\n-    reports_links = [\n-        {\"text\": \"Astrometry validation\",\n-         \"path\": \"astrometryValidation.html\"},\n-]\n-    validation_report.set_index(reports_links)\n+    # set the leading links\n+    validation_report.set_index(index_list)\n \n     # Save the analysis report in various formats\n-    validation_report.set_forward(forward_link=\"astrometryValidation.html\")\n+    validation_report.set_forward(forward_link=\"detectionValidation.html\")\n     json_file_name = os.path.join(workdir, \"data\", \"index.json\")\n     html_file_name = os.path.join(workdir, \"data\", \"index.html\")\n     validation_report.save_as_json_file(json_file_name)\n@@ -117,80 +112,73 @@ def mainMethod(args):\n \n     \"\"\"\n     # Get a logger instance\n-    logger = log.getLogger(\"MER_MergeAnalysisResults\")\n+    logger = log.getLogger(\"MER_MergeValidationResults\")\n \n     logger.info(\"#\")\n-    logger.info(\"# Entering MER_MergeAnalysisResults mainMethod()\")\n+    logger.info(\"# Entering MER_MergeValidationResults mainMethod()\")\n     logger.info(\"#\")\n \n+    # Store the start time\n+    start_time = time.time()\n+\n+    # print all parameters to the screen\n+    print_input_arguments(args, logger)\n+\n     # Do not print astropy warnings\n     AnalysisUtils.ignore_astropy_warnings()\n \n     # Add some extra functionality to the MER data product bindings\n     mer_utils.init()\n \n+    # storage for the global index\n+    index_dict = {'detect': {\"text\": \"Detection validation\", \"path\": \"detectionValidation.html\"}, \n+                  'astrometry': {\"text\": \"Astrometry validation\", \"path\": \"astrometryValidation.html\"}}\n+\n     # Load the input analysis results\n     analysis_results = []\n-    #analysis_results.append(dm_utils.read_product_metadata(\n-    #    os.path.join(args.workdir, 'data', args.astrometry_validation)))\n-    \"\"\"\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.mer_star_psf_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.tu_star_psf_analysis_result)))\n+    key_sequence = []\n     analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.mosaicing_analysis_result)))\n+        os.path.join(args.workdir, args.detection_result)))\n+    key_sequence.append('detect')\n     analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.background_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.detection_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.crossmatch_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.morphology_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.photometry_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.photometry_plots_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.classification_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.final_catalog_analysis_result)))\n-    \"\"\"\n+        os.path.join(args.workdir, args.astrometry_result)))\n+    key_sequence.append('astrometry')\n \n     # Get the figure tar file names and the global result\n     figure_tar_file_names = []\n     global_result = \"PASSED\"\n \n-    for analysis_result in analysis_results:\n+    index_list = []\n+    for analysis_result in zip(analysis_results, key_sequence):\n         figure_tar_file_names.append(os.path.join(\n-            args.workdir, \"data\", analysis_result.get_figures_tar_file()))\n-\n-        if analysis_result.get_global_result() == \"FAILED\":\n+            args.workdir, \"data\", analysis_result[0].get_figures_tar_file()))\n+        if analysis_result[0].get_global_result() == \"FAILED\":\n             global_result = \"FAILED\"\n+        #index_list.append(index_dict[analysis_result[1]])\n+        index_list.append({'text': '%s %s'%(analysis_result[0].get_global_result(), index_dict[analysis_result[1]]['text']),\n+                           'path': index_dict[analysis_result[1]]['path']})\n \n     # Get the tile index, the observation ids and the processing mode\n-    #tile_index = analysis_results[0].get_tile_index()\n-    #observation_ids = analysis_results[0].get_observation_id_list()\n-    #processing_mode = analysis_results[0].get_processing_mode()\n+    tile_index = analysis_results[0].get_tile_index()\n+    observation_ids = analysis_results[0].get_observation_id_list()\n+    processing_mode = analysis_results[0].get_processing_mode()\n \n     # Create the analysis report\n     logger.info(\"# Creating the merged validation report...\")\n-    #report_file_names = create_analysis_report(tile_index, args.workdir)\n-    report_file_names = create_analysis_report(args.workdir)\n+    report_file_names = create_analysis_report(index_list, tile_index, args.workdir, global_result)\n \n     # Save all the analysis files into a single merged tar file\n     tar_file_name = mer_filename(\n-        \"VALIDATION-RESULT\", tile_index=0, ext=\"tar.gz\")\n+        \"VALIDATION-RESULT\", tile_index=tile_index, ext=\"tar.gz\")\n     AnalysisUtils.save_tar_file(\n         os.path.join(args.workdir, \"data\", tar_file_name),\n         report_file_names + figure_tar_file_names)\n \n     # Create the analysis result data product\n     analysis_result = mer_utils.create_analysis_result(global_result)\n-    #analysis_result.set_tile_index(tile_index)\n-    #analysis_result.set_observation_id_list(observation_ids)\n-    #analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_tile_index(tile_index)\n+    analysis_result.set_observation_id_list(observation_ids)\n+    analysis_result.set_processing_mode(processing_mode)\n     analysis_result.set_figures_tar_file(tar_file_name)\n \n     # Save the analysis result data product as an XML file\n@@ -198,6 +186,8 @@ def mainMethod(args):\n     analysis_result.save_xml(\n         os.path.join(args.workdir, args.merged_analysis_result))\n \n+    # Print the time spent running the step\n+    logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n     logger.info(\"#\")\n-    logger.info(\"# Exiting MER_MergeAnalysisResults mainMethod()\")\n+    logger.info(\"# Exiting MER_MergeValidationResults mainMethod()\")\n     logger.info(\"#\")\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-10T15:27:04.000+02:00",
                            "b4030040f2cf4ffc0140a2f4f30e0e1b83a1ff07"
                        ],
                        [
                            "@@ -92,7 +92,7 @@ def create_analysis_report(index_list, tile_index, workdir, global_result):\n     \"\"\"\n     # Initialize the analysis report\n     validation_report = AnalysisReport(\n-        \"MER validation report for tile %s, result: %s\" % (tile_index, global_result))\n+        \"%s MER validation report for tile %s\" % (global_result, tile_index))\n \n     # set the leading links\n     validation_report.set_index(index_list)\n@@ -155,7 +155,7 @@ def mainMethod(args):\n         if analysis_result[0].get_global_result() == \"FAILED\":\n             global_result = \"FAILED\"\n         #index_list.append(index_dict[analysis_result[1]])\n-        index_list.append({'text': '%s: %s'%(index_dict[analysis_result[1]]['text'], analysis_result[0].get_global_result()),\n+        index_list.append({'text': '%s %s'%(analysis_result[0].get_global_result(), index_dict[analysis_result[1]]['text']),\n                            'path': index_dict[analysis_result[1]]['path']})\n \n     # Get the tile index, the observation ids and the processing mode\n",
                            "Some smaller improvements",
                            "Martin Kuemmel",
                            "2023-07-07T13:40:22.000+02:00",
                            "0c55c9795204ad36c1dd7b763090c972aebc0f7a"
                        ],
                        [
                            "@@ -19,10 +19,10 @@\n \"\"\"\n File: python/MER_PsfMosaicValidation/MER_MergeAnalysisResults.py\n \n-Created on: 08/15/20\n-Author: Javier Gracia Carpio (jgracia@mpe.mpg.de)\n+Created on: 07/05/2023\n+Author: mkuemmel@usm.lmu.de\n \"\"\"\n-\n+import time\n import os.path\n import argparse\n \n@@ -36,6 +36,7 @@ from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n \n+from MER_DA.MERUtilities import print_input_arguments\n \n def defineSpecificProgramOptions():\n     \"\"\"Defines the command line input and output parameters specific to this\n@@ -56,15 +57,14 @@ def defineSpecificProgramOptions():\n     parser.add_argument(\"--logdir\", dest=\"logdir\",\n                         type=str, help=\"The logging directory path.\")\n \n-    #parser.add_argument(\"--mosaicing_analysis_resultastrometry_validation.json\",\n-    #                    dest=\"mosaicing_analysis_result\",\n-    #                    type=str, help=\"The mosaicing analysis result XML file \"\n-    #                    \"name.\")\n-    parser.add_argument(\"--astrometry_result\", dest=\"astrometry_validation\",\n+    parser.add_argument(\"--detection_result\", dest=\"detection_result\",\n+                        default=\"detection_validation.json\", type=str,\n+                        help=\"The detection analysis result json file name.\")\n+\n+    parser.add_argument(\"--astrometry_result\", dest=\"astrometry_result\",\n                         default=\"astrometry_validation.json\", type=str,\n                         help=\"The mosaicing analysis result json file name.\")\n \n-\n     # Add the output parameters\n     parser.add_argument(\"--merged_analysis_result\",\n                         dest=\"merged_analysis_result\", type=str,\n@@ -74,7 +74,7 @@ def defineSpecificProgramOptions():\n     return parser\n \n \n-def create_analysis_report(tile_index, workdir):\n+def create_analysis_report(index_list, tile_index, workdir, global_result):\n     \"\"\"Creates an analysis report.\n \n     Parameters\n@@ -92,16 +92,13 @@ def create_analysis_report(tile_index, workdir):\n     \"\"\"\n     # Initialize the analysis report\n     validation_report = AnalysisReport(\n-        \"MER validation report for tile %s\" % tile_index)\n+        \"MER validation report for tile %s, result: %s\" % (tile_index, global_result))\n \n-    # Add the index with the links to all the analysis reports\n-    reports_links = [\n-        {\"text\": \"Astrometry validation\",\n-         \"path\": \"astrometryValidation.html\"}]\n-    validation_report.set_index(reports_links)\n+    # set the leading links\n+    validation_report.set_index(index_list)\n \n     # Save the analysis report in various formats\n-    validation_report.set_forward(forward_link=\"astrometryValidation.html\")\n+    validation_report.set_forward(forward_link=\"detectionValidation.html\")\n     json_file_name = os.path.join(workdir, \"data\", \"index.json\")\n     html_file_name = os.path.join(workdir, \"data\", \"index.html\")\n     validation_report.save_as_json_file(json_file_name)\n@@ -121,51 +118,45 @@ def mainMethod(args):\n     logger.info(\"# Entering MER_MergeValidationResults mainMethod()\")\n     logger.info(\"#\")\n \n+    # Store the start time\n+    start_time = time.time()\n+\n+    # print all parameters to the screen\n+    print_input_arguments(args, logger)\n+\n     # Do not print astropy warnings\n     AnalysisUtils.ignore_astropy_warnings()\n \n     # Add some extra functionality to the MER data product bindings\n     mer_utils.init()\n \n+    # storage for the global index\n+    index_dict = {'detect': {\"text\": \"Detection validation\", \"path\": \"detectionValidation.html\"}, \n+                  'astrometry': {\"text\": \"Astrometry validation\", \"path\": \"astrometryValidation.html\"}}\n+\n     # Load the input analysis results\n     analysis_results = []\n+    key_sequence = []\n     analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.astrometry_validation)))\n-    \"\"\"\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.mer_star_psf_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.tu_star_psf_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.mosaicing_analysis_result)))\n+        os.path.join(args.workdir, args.detection_result)))\n+    key_sequence.append('detect')\n     analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.background_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.detection_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.crossmatch_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.morphology_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.photometry_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.photometry_plots_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.classification_analysis_result)))\n-    analysis_results.append(dm_utils.read_product_metadata(\n-        os.path.join(args.workdir, args.final_catalog_analysis_result)))\n-    \"\"\"\n+        os.path.join(args.workdir, args.astrometry_result)))\n+    key_sequence.append('astrometry')\n \n     # Get the figure tar file names and the global result\n     figure_tar_file_names = []\n     global_result = \"PASSED\"\n \n-    for analysis_result in analysis_results:\n+    index_list = []\n+    for analysis_result in zip(analysis_results, key_sequence):\n         figure_tar_file_names.append(os.path.join(\n-            args.workdir, \"data\", analysis_result.get_figures_tar_file()))\n-\n-        if analysis_result.get_global_result() == \"FAILED\":\n+            args.workdir, \"data\", analysis_result[0].get_figures_tar_file()))\n+        if analysis_result[0].get_global_result() == \"FAILED\":\n             global_result = \"FAILED\"\n+        #index_list.append(index_dict[analysis_result[1]])\n+        index_list.append({'text': '%s: %s'%(index_dict[analysis_result[1]]['text'], analysis_result[0].get_global_result()),\n+                           'path': index_dict[analysis_result[1]]['path']})\n \n     # Get the tile index, the observation ids and the processing mode\n     tile_index = analysis_results[0].get_tile_index()\n@@ -174,7 +165,7 @@ def mainMethod(args):\n \n     # Create the analysis report\n     logger.info(\"# Creating the merged validation report...\")\n-    report_file_names = create_analysis_report(tile_index, args.workdir)\n+    report_file_names = create_analysis_report(index_list, tile_index, args.workdir, global_result)\n \n     # Save all the analysis files into a single merged tar file\n     tar_file_name = mer_filename(\n@@ -195,6 +186,8 @@ def mainMethod(args):\n     analysis_result.save_xml(\n         os.path.join(args.workdir, args.merged_analysis_result))\n \n+    # Print the time spent running the step\n+    logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n     logger.info(\"#\")\n     logger.info(\"# Exiting MER_MergeValidationResults mainMethod()\")\n     logger.info(\"#\")\n",
                            "Results are displayed as intended",
                            "Martin Kuemmel",
                            "2023-07-05T17:38:13.000+02:00",
                            "88b17ad283d888d70c3cf9f6bab4ca215139258e"
                        ],
                        [
                            "@@ -74,7 +74,7 @@ def defineSpecificProgramOptions():\n     return parser\n \n \n-def create_analysis_report(workdir):\n+def create_analysis_report(tile_index, workdir):\n     \"\"\"Creates an analysis report.\n \n     Parameters\n@@ -90,16 +90,14 @@ def create_analysis_report(workdir):\n         A python list with the analysis report file names.\n \n     \"\"\"\n-    #def create_analysis_report(tile_index, workdir):\n     # Initialize the analysis report\n     validation_report = AnalysisReport(\n-        \"MER validation report for tile %s\" % 0)\n+        \"MER validation report for tile %s\" % tile_index)\n \n     # Add the index with the links to all the analysis reports\n     reports_links = [\n         {\"text\": \"Astrometry validation\",\n-         \"path\": \"astrometryValidation.html\"},\n-]\n+         \"path\": \"astrometryValidation.html\"}]\n     validation_report.set_index(reports_links)\n \n     # Save the analysis report in various formats\n@@ -117,10 +115,10 @@ def mainMethod(args):\n \n     \"\"\"\n     # Get a logger instance\n-    logger = log.getLogger(\"MER_MergeAnalysisResults\")\n+    logger = log.getLogger(\"MER_MergeValidationResults\")\n \n     logger.info(\"#\")\n-    logger.info(\"# Entering MER_MergeAnalysisResults mainMethod()\")\n+    logger.info(\"# Entering MER_MergeValidationResults mainMethod()\")\n     logger.info(\"#\")\n \n     # Do not print astropy warnings\n@@ -131,8 +129,8 @@ def mainMethod(args):\n \n     # Load the input analysis results\n     analysis_results = []\n-    #analysis_results.append(dm_utils.read_product_metadata(\n-    #    os.path.join(args.workdir, 'data', args.astrometry_validation)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.astrometry_validation)))\n     \"\"\"\n     analysis_results.append(dm_utils.read_product_metadata(\n         os.path.join(args.workdir, args.mer_star_psf_analysis_result)))\n@@ -170,27 +168,26 @@ def mainMethod(args):\n             global_result = \"FAILED\"\n \n     # Get the tile index, the observation ids and the processing mode\n-    #tile_index = analysis_results[0].get_tile_index()\n-    #observation_ids = analysis_results[0].get_observation_id_list()\n-    #processing_mode = analysis_results[0].get_processing_mode()\n+    tile_index = analysis_results[0].get_tile_index()\n+    observation_ids = analysis_results[0].get_observation_id_list()\n+    processing_mode = analysis_results[0].get_processing_mode()\n \n     # Create the analysis report\n     logger.info(\"# Creating the merged validation report...\")\n-    #report_file_names = create_analysis_report(tile_index, args.workdir)\n-    report_file_names = create_analysis_report(args.workdir)\n+    report_file_names = create_analysis_report(tile_index, args.workdir)\n \n     # Save all the analysis files into a single merged tar file\n     tar_file_name = mer_filename(\n-        \"VALIDATION-RESULT\", tile_index=0, ext=\"tar.gz\")\n+        \"VALIDATION-RESULT\", tile_index=tile_index, ext=\"tar.gz\")\n     AnalysisUtils.save_tar_file(\n         os.path.join(args.workdir, \"data\", tar_file_name),\n         report_file_names + figure_tar_file_names)\n \n     # Create the analysis result data product\n     analysis_result = mer_utils.create_analysis_result(global_result)\n-    #analysis_result.set_tile_index(tile_index)\n-    #analysis_result.set_observation_id_list(observation_ids)\n-    #analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_tile_index(tile_index)\n+    analysis_result.set_observation_id_list(observation_ids)\n+    analysis_result.set_processing_mode(processing_mode)\n     analysis_result.set_figures_tar_file(tar_file_name)\n \n     # Save the analysis result data product as an XML file\n@@ -199,5 +196,5 @@ def mainMethod(args):\n         os.path.join(args.workdir, args.merged_analysis_result))\n \n     logger.info(\"#\")\n-    logger.info(\"# Exiting MER_MergeAnalysisResults mainMethod()\")\n+    logger.info(\"# Exiting MER_MergeValidationResults mainMethod()\")\n     logger.info(\"#\")\n",
                            "Some improvements for the XML information",
                            "Javier Gracia Carpio",
                            "2023-07-05T09:36:48.000+00:00",
                            "a2189f64fb4beee461d1b6a9705589ff184970c1"
                        ],
                        [
                            "@@ -60,7 +60,7 @@ def defineSpecificProgramOptions():\n     #                    dest=\"mosaicing_analysis_result\",\n     #                    type=str, help=\"The mosaicing analysis result XML file \"\n     #                    \"name.\")\n-    parser.add_argument(\"--astrometry_validation\", dest=\"astrometry_validation\",\n+    parser.add_argument(\"--astrometry_result\", dest=\"astrometry_validation\",\n                         default=\"astrometry_validation.json\", type=str,\n                         help=\"The mosaicing analysis result json file name.\")\n \n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T21:40:08.000+00:00",
                            "696982ed8506ddb56f2beca6b7fe88377fa08c21"
                        ],
                        [
                            "@@ -60,7 +60,7 @@ def defineSpecificProgramOptions():\n     #                    dest=\"mosaicing_analysis_result\",\n     #                    type=str, help=\"The mosaicing analysis result XML file \"\n     #                    \"name.\")\n-    parser.add_argument(\"--astrometry_validation\", dest=\"astrometry_validation\",\n+    parser.add_argument(\"--astrometry_result\", dest=\"astrometry_validation\",\n                         default=\"astrometry_validation.json\", type=str,\n                         help=\"The mosaicing analysis result json file name.\")\n \n",
                            "Making it pipeline ready",
                            "Martin Kuemmel",
                            "2023-07-04T23:17:20.000+02:00",
                            "f918deca60ada4d351444ba20467a7703195eb00"
                        ],
                        [
                            "@@ -0,0 +1,203 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+File: python/MER_PsfMosaicValidation/MER_MergeAnalysisResults.py\n+\n+Created on: 08/15/20\n+Author: Javier Gracia Carpio (jgracia@mpe.mpg.de)\n+\"\"\"\n+\n+import os.path\n+import argparse\n+\n+import ElementsKernel.Logging as log\n+\n+from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils.FileNaming import mer_filename\n+\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n+\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"Defines the command line input and output parameters specific to this\n+    program.\n+\n+    Returns\n+    -------\n+    ArgumentParser\n+\n+    \"\"\"\n+    # Get the parser instance\n+    parser = argparse.ArgumentParser()\n+\n+    # Add the input parameters\n+    parser.add_argument(\"--workdir\", dest=\"workdir\",\n+                        type=str, help=\"The working directory path.\")\n+\n+    parser.add_argument(\"--logdir\", dest=\"logdir\",\n+                        type=str, help=\"The logging directory path.\")\n+\n+    #parser.add_argument(\"--mosaicing_analysis_resultastrometry_validation.json\",\n+    #                    dest=\"mosaicing_analysis_result\",\n+    #                    type=str, help=\"The mosaicing analysis result XML file \"\n+    #                    \"name.\")\n+    parser.add_argument(\"--astrometry_validation\", dest=\"astrometry_validation\",\n+                        default=\"astrometry_validation.json\", type=str,\n+                        help=\"The mosaicing analysis result json file name.\")\n+\n+\n+    # Add the output parameters\n+    parser.add_argument(\"--merged_analysis_result\",\n+                        dest=\"merged_analysis_result\", type=str,\n+                        help=\"The merged analysis result output data product \"\n+                        \"XML file name.\")\n+\n+    return parser\n+\n+\n+def create_analysis_report(workdir):\n+    \"\"\"Creates an analysis report.\n+\n+    Parameters\n+    ----------\n+    tile_index: int\n+        The tile index.\n+    workdir: str\n+        The complete path to the working directory.\n+\n+    Returns\n+    -------\n+    list\n+        A python list with the analysis report file names.\n+\n+    \"\"\"\n+    #def create_analysis_report(tile_index, workdir):\n+    # Initialize the analysis report\n+    validation_report = AnalysisReport(\n+        \"MER validation report for tile %s\" % 0)\n+\n+    # Add the index with the links to all the analysis reports\n+    reports_links = [\n+        {\"text\": \"Astrometry validation\",\n+         \"path\": \"astrometryValidation.html\"},\n+]\n+    validation_report.set_index(reports_links)\n+\n+    # Save the analysis report in various formats\n+    validation_report.set_forward(forward_link=\"astrometryValidation.html\")\n+    json_file_name = os.path.join(workdir, \"data\", \"index.json\")\n+    html_file_name = os.path.join(workdir, \"data\", \"index.html\")\n+    validation_report.save_as_json_file(json_file_name)\n+    validation_report.save_as_html_file(html_file_name)\n+\n+    return [json_file_name, html_file_name]\n+\n+\n+def mainMethod(args):\n+    \"\"\" The \"main\" method.\n+\n+    \"\"\"\n+    # Get a logger instance\n+    logger = log.getLogger(\"MER_MergeAnalysisResults\")\n+\n+    logger.info(\"#\")\n+    logger.info(\"# Entering MER_MergeAnalysisResults mainMethod()\")\n+    logger.info(\"#\")\n+\n+    # Do not print astropy warnings\n+    AnalysisUtils.ignore_astropy_warnings()\n+\n+    # Add some extra functionality to the MER data product bindings\n+    mer_utils.init()\n+\n+    # Load the input analysis results\n+    analysis_results = []\n+    #analysis_results.append(dm_utils.read_product_metadata(\n+    #    os.path.join(args.workdir, 'data', args.astrometry_validation)))\n+    \"\"\"\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.mer_star_psf_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.tu_star_psf_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.mosaicing_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.background_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.detection_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.crossmatch_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.morphology_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.photometry_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.photometry_plots_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.classification_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.final_catalog_analysis_result)))\n+    \"\"\"\n+\n+    # Get the figure tar file names and the global result\n+    figure_tar_file_names = []\n+    global_result = \"PASSED\"\n+\n+    for analysis_result in analysis_results:\n+        figure_tar_file_names.append(os.path.join(\n+            args.workdir, \"data\", analysis_result.get_figures_tar_file()))\n+\n+        if analysis_result.get_global_result() == \"FAILED\":\n+            global_result = \"FAILED\"\n+\n+    # Get the tile index, the observation ids and the processing mode\n+    #tile_index = analysis_results[0].get_tile_index()\n+    #observation_ids = analysis_results[0].get_observation_id_list()\n+    #processing_mode = analysis_results[0].get_processing_mode()\n+\n+    # Create the analysis report\n+    logger.info(\"# Creating the merged validation report...\")\n+    #report_file_names = create_analysis_report(tile_index, args.workdir)\n+    report_file_names = create_analysis_report(args.workdir)\n+\n+    # Save all the analysis files into a single merged tar file\n+    tar_file_name = mer_filename(\n+        \"VALIDATION-RESULT\", tile_index=0, ext=\"tar.gz\")\n+    AnalysisUtils.save_tar_file(\n+        os.path.join(args.workdir, \"data\", tar_file_name),\n+        report_file_names + figure_tar_file_names)\n+\n+    # Create the analysis result data product\n+    analysis_result = mer_utils.create_analysis_result(global_result)\n+    #analysis_result.set_tile_index(tile_index)\n+    #analysis_result.set_observation_id_list(observation_ids)\n+    #analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_figures_tar_file(tar_file_name)\n+\n+    # Save the analysis result data product as an XML file\n+    logger.info(\"# Saving the merged validation result data product\")\n+    analysis_result.save_xml(\n+        os.path.join(args.workdir, args.merged_analysis_result))\n+\n+    logger.info(\"#\")\n+    logger.info(\"# Exiting MER_MergeAnalysisResults mainMethod()\")\n+    logger.info(\"#\")\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:28:10.000+00:00",
                            "e3224a51e80aec0f298e9607d359a618da467017"
                        ],
                        [
                            "@@ -0,0 +1,203 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+File: python/MER_PsfMosaicValidation/MER_MergeAnalysisResults.py\n+\n+Created on: 08/15/20\n+Author: Javier Gracia Carpio (jgracia@mpe.mpg.de)\n+\"\"\"\n+\n+import os.path\n+import argparse\n+\n+import ElementsKernel.Logging as log\n+\n+from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils.FileNaming import mer_filename\n+\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n+\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"Defines the command line input and output parameters specific to this\n+    program.\n+\n+    Returns\n+    -------\n+    ArgumentParser\n+\n+    \"\"\"\n+    # Get the parser instance\n+    parser = argparse.ArgumentParser()\n+\n+    # Add the input parameters\n+    parser.add_argument(\"--workdir\", dest=\"workdir\",\n+                        type=str, help=\"The working directory path.\")\n+\n+    parser.add_argument(\"--logdir\", dest=\"logdir\",\n+                        type=str, help=\"The logging directory path.\")\n+\n+    #parser.add_argument(\"--mosaicing_analysis_resultastrometry_validation.json\",\n+    #                    dest=\"mosaicing_analysis_result\",\n+    #                    type=str, help=\"The mosaicing analysis result XML file \"\n+    #                    \"name.\")\n+    parser.add_argument(\"--astrometry_validation\", dest=\"astrometry_validation\",\n+                        default=\"astrometry_validation.json\", type=str,\n+                        help=\"The mosaicing analysis result json file name.\")\n+\n+\n+    # Add the output parameters\n+    parser.add_argument(\"--merged_analysis_result\",\n+                        dest=\"merged_analysis_result\", type=str,\n+                        help=\"The merged analysis result output data product \"\n+                        \"XML file name.\")\n+\n+    return parser\n+\n+\n+def create_analysis_report(workdir):\n+    \"\"\"Creates an analysis report.\n+\n+    Parameters\n+    ----------\n+    tile_index: int\n+        The tile index.\n+    workdir: str\n+        The complete path to the working directory.\n+\n+    Returns\n+    -------\n+    list\n+        A python list with the analysis report file names.\n+\n+    \"\"\"\n+    #def create_analysis_report(tile_index, workdir):\n+    # Initialize the analysis report\n+    validation_report = AnalysisReport(\n+        \"MER validation report for tile %s\" % 0)\n+\n+    # Add the index with the links to all the analysis reports\n+    reports_links = [\n+        {\"text\": \"Astrometry validation\",\n+         \"path\": \"astrometryValidation.html\"},\n+]\n+    validation_report.set_index(reports_links)\n+\n+    # Save the analysis report in various formats\n+    validation_report.set_forward(forward_link=\"astrometryValidation.html\")\n+    json_file_name = os.path.join(workdir, \"data\", \"index.json\")\n+    html_file_name = os.path.join(workdir, \"data\", \"index.html\")\n+    validation_report.save_as_json_file(json_file_name)\n+    validation_report.save_as_html_file(html_file_name)\n+\n+    return [json_file_name, html_file_name]\n+\n+\n+def mainMethod(args):\n+    \"\"\" The \"main\" method.\n+\n+    \"\"\"\n+    # Get a logger instance\n+    logger = log.getLogger(\"MER_MergeAnalysisResults\")\n+\n+    logger.info(\"#\")\n+    logger.info(\"# Entering MER_MergeAnalysisResults mainMethod()\")\n+    logger.info(\"#\")\n+\n+    # Do not print astropy warnings\n+    AnalysisUtils.ignore_astropy_warnings()\n+\n+    # Add some extra functionality to the MER data product bindings\n+    mer_utils.init()\n+\n+    # Load the input analysis results\n+    analysis_results = []\n+    #analysis_results.append(dm_utils.read_product_metadata(\n+    #    os.path.join(args.workdir, 'data', args.astrometry_validation)))\n+    \"\"\"\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.mer_star_psf_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.tu_star_psf_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.mosaicing_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.background_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.detection_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.crossmatch_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.morphology_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.photometry_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.photometry_plots_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.classification_analysis_result)))\n+    analysis_results.append(dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.final_catalog_analysis_result)))\n+    \"\"\"\n+\n+    # Get the figure tar file names and the global result\n+    figure_tar_file_names = []\n+    global_result = \"PASSED\"\n+\n+    for analysis_result in analysis_results:\n+        figure_tar_file_names.append(os.path.join(\n+            args.workdir, \"data\", analysis_result.get_figures_tar_file()))\n+\n+        if analysis_result.get_global_result() == \"FAILED\":\n+            global_result = \"FAILED\"\n+\n+    # Get the tile index, the observation ids and the processing mode\n+    #tile_index = analysis_results[0].get_tile_index()\n+    #observation_ids = analysis_results[0].get_observation_id_list()\n+    #processing_mode = analysis_results[0].get_processing_mode()\n+\n+    # Create the analysis report\n+    logger.info(\"# Creating the merged validation report...\")\n+    #report_file_names = create_analysis_report(tile_index, args.workdir)\n+    report_file_names = create_analysis_report(args.workdir)\n+\n+    # Save all the analysis files into a single merged tar file\n+    tar_file_name = mer_filename(\n+        \"VALIDATION-RESULT\", tile_index=0, ext=\"tar.gz\")\n+    AnalysisUtils.save_tar_file(\n+        os.path.join(args.workdir, \"data\", tar_file_name),\n+        report_file_names + figure_tar_file_names)\n+\n+    # Create the analysis result data product\n+    analysis_result = mer_utils.create_analysis_result(global_result)\n+    #analysis_result.set_tile_index(tile_index)\n+    #analysis_result.set_observation_id_list(observation_ids)\n+    #analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_figures_tar_file(tar_file_name)\n+\n+    # Save the analysis result data product as an XML file\n+    logger.info(\"# Saving the merged validation result data product\")\n+    analysis_result.save_xml(\n+        os.path.join(args.workdir, args.merged_analysis_result))\n+\n+    logger.info(\"#\")\n+    logger.info(\"# Exiting MER_MergeAnalysisResults mainMethod()\")\n+    logger.info(\"#\")\n",
                            "Makes a first page.",
                            "Martin Kuemmel",
                            "2023-07-03T17:18:33.000+02:00",
                            "074876fe1564e889d6b110008f83d979769b2fc8"
                        ]
                    ],
                    "MER_Validation/python/MER_Validation/MER_PhotometryValidation.py": [
                        [
                            "@@ -30,31 +30,13 @@ from astropy.io import fits\n from scipy.interpolate import PchipInterpolator\n from scipy.stats import binned_statistic, median_abs_deviation\n from EL_NullValue import NullValueDefinition\n-\n-def jansky_to_mag(values):\n-    \"\"\"Converts flux values in Jansky units to AB magnitude units.\n-\n-    http://www.star.bristol.ac.uk/~mbt/stilts/sun256/uk.ac.starlink.ttools.func.Fluxes.html\n-\n-    Parameters\n-    ----------\n-    values: object\n-        A numpy array with the flux values in Jansky units.\n-\n-    Returns\n-    -------\n-    object\n-        A numpy array with the flux values in AB magnitude units.\n-\n-    \"\"\"\n-    return 2.5 * (23 - np.log10(values)) - 48.6\n+from MER_PsfMosaicValidation.CatalogUtils import CatalogUtils\n \n def get_gaia_mag(data, mag_name):\n     flux = data[\"FLUX_\" + mag_name]\n     fluxerr = data[\"FLUXERR_\" + mag_name]\n     mag = data[\"MAG_\" + mag_name]\n     magerr = 1.086 * fluxerr / flux\n-    # ind = (mag != np.nan) & (flux != NullValueDefinition().FLOAT)\n     ind = (~np.isnan(mag))\n     flag = (np.sum(ind) > 0)\n     return mag, magerr, flag\n@@ -64,7 +46,7 @@ def get_mer_mag(data, mag_name):\n         return none, none, False\n     flux = data[\"FLUX_\" + mag_name]\n     fluxerr = data[\"FLUXERR_\" + mag_name]\n-    mag = jansky_to_mag(1.0e-06*flux)\n+    mag = CatalogUtils.jansky_to_mag(1.0e-06*flux)\n     magerr = 1.086 * (fluxerr/flux)\n     ind = ((~np.isnan(mag)) & (flux != NullValueDefinition().DOUBLE) & (~np.isnan(flux)))\n     flag = (np.sum(ind) > 0)\n@@ -111,7 +93,7 @@ def read_mer_catalog(catalog_path, flux_column='FLUX_VIS_PSF', fluxerr_column='F\n     fluxerr = data[fluxerr_column]\n     data = data[selector]\n     hdu.close()\n-    mag = jansky_to_mag(1.0e-06*flux)\n+    mag = CatalogUtils.jansky_to_mag(1.0e-06*flux)\n     magerr = 1.086 * (fluxerr/flux)\n     selector = (mag >= 18.)\n     return ra, dec, flux, fluxerr, data\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T11:46:20.000+00:00",
                            "a83f468ea9bc0e5270859fcc7d1e7f8aa8bf922f"
                        ],
                        [
                            "@@ -29,6 +29,7 @@ import matplotlib.pyplot as plt\n from astropy.io import fits\n from scipy.interpolate import PchipInterpolator\n from scipy.stats import binned_statistic, median_abs_deviation\n+from EL_NullValue import NullValueDefinition\n \n def jansky_to_mag(values):\n     \"\"\"Converts flux values in Jansky units to AB magnitude units.\n@@ -48,6 +49,26 @@ def jansky_to_mag(values):\n     \"\"\"\n     return 2.5 * (23 - np.log10(values)) - 48.6\n \n+def get_gaia_mag(data, mag_name):\n+    flux = data[\"FLUX_\" + mag_name]\n+    fluxerr = data[\"FLUXERR_\" + mag_name]\n+    mag = data[\"MAG_\" + mag_name]\n+    magerr = 1.086 * fluxerr / flux\n+    # ind = (mag != np.nan) & (flux != NullValueDefinition().FLOAT)\n+    ind = (~np.isnan(mag))\n+    flag = (np.sum(ind) > 0)\n+    return mag, magerr, flag\n+\n+def get_mer_mag(data, mag_name):\n+    if not (\"FLUX_\" + mag_name in data.names):\n+        return none, none, False\n+    flux = data[\"FLUX_\" + mag_name]\n+    fluxerr = data[\"FLUXERR_\" + mag_name]\n+    mag = jansky_to_mag(1.0e-06*flux)\n+    magerr = 1.086 * (fluxerr/flux)\n+    ind = ((~np.isnan(mag)) & (flux != NullValueDefinition().DOUBLE) & (~np.isnan(flux)))\n+    flag = (np.sum(ind) > 0)\n+    return mag, magerr, flag\n \n def read_gaia_catalog(catalog_path):\n     hdu = fits.open(catalog_path)\n@@ -80,19 +101,19 @@ def read_gaia_catalog(catalog_path):\n def read_mer_catalog(catalog_path, flux_column='FLUX_VIS_PSF', fluxerr_column='FLUXERR_VIS_PSF', flag_column=\"VIS_DET\", flag_value=1, vis_detected=True):\n     hdu = fits.open(catalog_path)\n     data = hdu[1].data\n-    #flag = data[flag_column]\n-    #selector = (flag == flag_value)\n-    #if vis_detected:\n-    #    selector = selector & (data[\"VIS_DET\"] == 1)\n+    flag = data[flag_column]\n+    selector = (flag == flag_value)\n+    if vis_detected:\n+       selector = selector & (data[\"VIS_DET\"] == 1)\n     ra = data[\"RIGHT_ASCENSION\"]\n     dec = data[\"DECLINATION\"]\n     flux = data[flux_column]\n     fluxerr = data[fluxerr_column]\n-    #data = data[selector]\n-    #hdu.close()\n-    #mag = jansky_to_mag(1.0e-06*flux)\n-    #magerr = 1.086 * (fluxerr/flux)\n-    #selector = (mag >= 18.)\n+    data = data[selector]\n+    hdu.close()\n+    mag = jansky_to_mag(1.0e-06*flux)\n+    magerr = 1.086 * (fluxerr/flux)\n+    selector = (mag >= 18.)\n     return ra, dec, flux, fluxerr, data\n \n def get_trans_func(trans_func_data, x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_min=-1., bp_rp_max=3., nbins=10, plot_dir=None):\n@@ -118,42 +139,50 @@ def get_trans_func(trans_func_data, x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_\n         plt.plot(BP_MIN_RP_tf, G_MIN_VIS_tf, 'ro', label='data')\n         plt.plot(x, trans_func(x), '-', color='blue', label='transformation function')\n         plt.legend(loc='lower right', fancybox=True)\n-        plt.xlabel(\"BP - RP\", size='x-large')\n-        plt.ylabel(\"G - VIS\", size='x-large')\n+        plt.xlabel(\"X_Values\", size='x-large')\n+        plt.ylabel(\"Y_Values\", size='x-large')\n         plt.savefig(figname)\n+        plt.close('all')\n+    else:\n+        figname = None\n \n     return trans_func, trans_func_prime, bin_edges, BP_MIN_RP_tf, G_MIN_VIS_tf, bin_number, figname\n \n-def evaluate_deviation(mag_g_gaia, mag_bp_gaia, mag_rp_gaia, mag_mer, trans_func, \n-                    magerr_g_gaia=None, magerr_bp_gaia=None, magerr_rp_gaia=None,\n-                    magerr_mer = None, trans_func_prime=None, mag_mer_name='VIS_PSF',\n-                    bp_rp_min=-1., bp_rp_max=3., plot_dir=None, mer_data=None, save_outlier=False):\n+def evaluate_deviation(mag_A, mag_B, mag_C, mag_D, trans_func, \n+                    magerr_A=None, magerr_B=None, magerr_C=None,\n+                    magerr_D = None, trans_func_prime=None, mag_name_A='BP_GAIA',\n+                    mag_name_B='RP_GAIA', mag_name_C='G_GAIA', mag_name_D='VIS_PSF',\n+                    xmin=-1., xmax=3., nmad_diff_limit=0.05, plot_dir=None, mer_data=None, save_outlier=False):\n     \n-    g_mer = mag_g_gaia - mag_mer\n-    bp_rp = mag_bp_gaia - mag_rp_gaia\n-    selector = (bp_rp_min < bp_rp) & (bp_rp < bp_rp_max) & (~np.isnan(g_mer)) & (~np.isnan(bp_rp))\n+    x_values = mag_A - mag_B\n+    y_values = mag_C - mag_D\n+    selector = (x_values > xmin) & (x_values < xmax) & (~np.isnan(x_values)) & (~np.isnan(y_values))\n \n-    diff = g_mer[selector] - trans_func(bp_rp[selector])\n+    diff = y_values[selector] - trans_func(x_values[selector])\n     \n-    if save_outlier and (mer_data is not None):\n-        ind = selector & (np.abs(diff) > 1.)\n-        data_outlier = mer_data[ind]\n-        data_outlier_path = os.path.join(plot_dir, \"mer_outliers_%s.fits\"%mag_mer_name)\n-        fits.writeto(data_outlier_path, data_outlier, overwrite=True)\n+    # if save_outlier and (mer_data is not None):\n+    #     ind = selector & (np.abs(diff) > 1.)\n+    #     data_outlier = mer_data[ind]\n+    #     data_outlier_path = os.path.join(plot_dir, \"mer_outliers_%s.fits\"%mag_mer_name)\n+    #     fits.writeto(data_outlier_path, data_outlier, overwrite=True)\n \n     nmad_diff = 1.4826 * median_abs_deviation(diff)\n     mean_diff = np.mean(diff)\n     median_diff = np.median(diff)\n     mean_abs_diff = np.mean(np.abs(diff))\n+\n+    # Check if the photometry is ok\n+    nmad_diff_valid = nmad_diff < nmad_diff_limit\n+\n     if plot_dir:\n         fig, ax = plt.subplots()\n-        deviation_plot = os.path.join(plot_dir, \"photometry_validation_%s.png\"%mag_mer_name)\n-        ax.plot(bp_rp, g_mer, 'ro', label='data')\n-        x = np.linspace(bp_rp_min, bp_rp_max, 1000)\n-        ax.plot(x, trans_func(x), '-', color='blue', label='transformation function')\n+        deviation_plot = os.path.join(plot_dir, \"photometry_validation_%s-%s-%s-%s.png\"%(mag_name_A, mag_name_B, mag_name_C, mag_name_D))\n+        ax.plot(x_values, y_values, 'ro', label='data')\n+        x = np.linspace(xmin, xmax, 1000)\n+        ax.plot(x, trans_func(x), '-', color='blue', label='trans func')\n         ax.legend(loc='lower left', fancybox=True)\n-        ax.set_xlabel(\"BP - RP\", size='x-large')\n-        ax.set_ylabel(\"G - %s\"%(mag_mer_name), size='x-large')\n+        ax.set_xlabel(\"%s - %s\"%(mag_name_A, mag_name_B), size='x-large')\n+        ax.set_ylabel(\"%s - %s\"%(mag_name_C, mag_name_D), size='x-large')\n         # textstr = '\\n'.join((\n         #     r'mean_diff = %.4f'%(mean_diff),\n         #     r'mean_abs_diff = %.4f'%(mean_abs_diff),\n@@ -167,9 +196,11 @@ def evaluate_deviation(mag_g_gaia, mag_bp_gaia, mag_rp_gaia, mag_mer, trans_func\n         ax.text(0.6, 0.2, textstr, transform=ax.transAxes, fontsize=12, verticalalignment='top')\n         plt.savefig(deviation_plot)\n         plt.figure()\n-        bins = np.linspace(-0.5, 0.5, 51)\n+        # bins = np.linspace(-0.5, 0.5, 51)\n+        bins = np.linspace(-1, 1, 51)\n         plt.hist(diff, bins=bins, label='deviation')\n-        plt.xlabel(\"G - %s - predicted\"%(mag_mer_name), size='x-large')\n-        deviation_hist = os.path.join(plot_dir, \"hist_deviation_%s.png\"%mag_mer_name)\n+        plt.xlabel(\"%s - %s - predicted\"%(mag_name_C, mag_name_D), size='x-large')\n+        deviation_hist = os.path.join(plot_dir, \"hist_deviation_%s-%s-%s-%s.png\"%(mag_name_A, mag_name_B, mag_name_C, mag_name_D))\n         plt.savefig(deviation_hist)\n-    return mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist\n\\ No newline at end of file\n+        plt.close('all')\n+    return mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist, nmad_diff_valid\n\\ No newline at end of file\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ],
                        [
                            "@@ -29,6 +29,7 @@ import matplotlib.pyplot as plt\n from astropy.io import fits\n from scipy.interpolate import PchipInterpolator\n from scipy.stats import binned_statistic, median_abs_deviation\n+from EL_NullValue import NullValueDefinition\n \n def jansky_to_mag(values):\n     \"\"\"Converts flux values in Jansky units to AB magnitude units.\n@@ -53,14 +54,21 @@ def get_gaia_mag(data, mag_name):\n     fluxerr = data[\"FLUXERR_\" + mag_name]\n     mag = data[\"MAG_\" + mag_name]\n     magerr = 1.086 * fluxerr / flux\n-    return mag, magerr\n+    # ind = (mag != np.nan) & (flux != NullValueDefinition().FLOAT)\n+    ind = (~np.isnan(mag))\n+    flag = (np.sum(ind) > 0)\n+    return mag, magerr, flag\n \n def get_mer_mag(data, mag_name):\n+    if not (\"FLUX_\" + mag_name in data.names):\n+        return none, none, False\n     flux = data[\"FLUX_\" + mag_name]\n     fluxerr = data[\"FLUXERR_\" + mag_name]\n     mag = jansky_to_mag(1.0e-06*flux)\n     magerr = 1.086 * (fluxerr/flux)\n-    return mag, magerr\n+    ind = ((~np.isnan(mag)) & (flux != NullValueDefinition().DOUBLE) & (~np.isnan(flux)))\n+    flag = (np.sum(ind) > 0)\n+    return mag, magerr, flag\n \n def read_gaia_catalog(catalog_path):\n     hdu = fits.open(catalog_path)\n@@ -134,6 +142,9 @@ def get_trans_func(trans_func_data, x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_\n         plt.xlabel(\"X_Values\", size='x-large')\n         plt.ylabel(\"Y_Values\", size='x-large')\n         plt.savefig(figname)\n+        plt.close('all')\n+    else:\n+        figname = None\n \n     return trans_func, trans_func_prime, bin_edges, BP_MIN_RP_tf, G_MIN_VIS_tf, bin_number, figname\n \n@@ -141,7 +152,7 @@ def evaluate_deviation(mag_A, mag_B, mag_C, mag_D, trans_func,\n                     magerr_A=None, magerr_B=None, magerr_C=None,\n                     magerr_D = None, trans_func_prime=None, mag_name_A='BP_GAIA',\n                     mag_name_B='RP_GAIA', mag_name_C='G_GAIA', mag_name_D='VIS_PSF',\n-                    xmin=-1., xmax=3., plot_dir=None, mer_data=None, save_outlier=False):\n+                    xmin=-1., xmax=3., nmad_diff_limit=0.05, plot_dir=None, mer_data=None, save_outlier=False):\n     \n     x_values = mag_A - mag_B\n     y_values = mag_C - mag_D\n@@ -160,6 +171,9 @@ def evaluate_deviation(mag_A, mag_B, mag_C, mag_D, trans_func,\n     median_diff = np.median(diff)\n     mean_abs_diff = np.mean(np.abs(diff))\n \n+    # Check if the photometry is ok\n+    nmad_diff_valid = nmad_diff < nmad_diff_limit\n+\n     if plot_dir:\n         fig, ax = plt.subplots()\n         deviation_plot = os.path.join(plot_dir, \"photometry_validation_%s-%s-%s-%s.png\"%(mag_name_A, mag_name_B, mag_name_C, mag_name_D))\n@@ -188,54 +202,5 @@ def evaluate_deviation(mag_A, mag_B, mag_C, mag_D, trans_func,\n         plt.xlabel(\"%s - %s - predicted\"%(mag_name_C, mag_name_D), size='x-large')\n         deviation_hist = os.path.join(plot_dir, \"hist_deviation_%s-%s-%s-%s.png\"%(mag_name_A, mag_name_B, mag_name_C, mag_name_D))\n         plt.savefig(deviation_hist)\n-    return mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist\n-\n-# def evaluate_deviation(mag_g_gaia, mag_bp_gaia, mag_rp_gaia, mag_mer, trans_func, \n-#                     magerr_g_gaia=None, magerr_bp_gaia=None, magerr_rp_gaia=None,\n-#                     magerr_mer = None, trans_func_prime=None, mag_mer_name='VIS_PSF',\n-#                     bp_rp_min=-1., bp_rp_max=3., plot_dir=None, mer_data=None, save_outlier=False):\n-    \n-#     g_mer = mag_g_gaia - mag_mer\n-#     bp_rp = mag_bp_gaia - mag_rp_gaia\n-#     selector = (bp_rp_min < bp_rp) & (bp_rp < bp_rp_max) & (~np.isnan(g_mer)) & (~np.isnan(bp_rp))\n-\n-#     diff = g_mer[selector] - trans_func(bp_rp[selector])\n-    \n-#     if save_outlier and (mer_data is not None):\n-#         ind = selector & (np.abs(diff) > 1.)\n-#         data_outlier = mer_data[ind]\n-#         data_outlier_path = os.path.join(plot_dir, \"mer_outliers_%s.fits\"%mag_mer_name)\n-#         fits.writeto(data_outlier_path, data_outlier, overwrite=True)\n-\n-#     nmad_diff = 1.4826 * median_abs_deviation(diff)\n-#     mean_diff = np.mean(diff)\n-#     median_diff = np.median(diff)\n-#     mean_abs_diff = np.mean(np.abs(diff))\n-#     if plot_dir:\n-#         fig, ax = plt.subplots()\n-#         deviation_plot = os.path.join(plot_dir, \"photometry_validation_%s.png\"%mag_mer_name)\n-#         ax.plot(bp_rp, g_mer, 'ro', label='data')\n-#         x = np.linspace(bp_rp_min, bp_rp_max, 1000)\n-#         ax.plot(x, trans_func(x), '-', color='blue', label='transformation function')\n-#         ax.legend(loc='lower left', fancybox=True)\n-#         ax.set_xlabel(\"BP - RP\", size='x-large')\n-#         ax.set_ylabel(\"G - %s\"%(mag_mer_name), size='x-large')\n-#         # textstr = '\\n'.join((\n-#         #     r'mean_diff = %.4f'%(mean_diff),\n-#         #     r'mean_abs_diff = %.4f'%(mean_abs_diff),\n-#         #     r'NMAD_diff = %.4f'%(nmad_diff)\n-#         # ))\n-#         textstr = '\\n'.join((\n-#             r'median_diff = %.4f'%(median_diff),\n-#             r'mean_abs_diff = %.4f'%(mean_abs_diff),\n-#             r'NMAD_diff = %.4f'%(nmad_diff)\n-#         ))\n-#         ax.text(0.6, 0.2, textstr, transform=ax.transAxes, fontsize=12, verticalalignment='top')\n-#         plt.savefig(deviation_plot)\n-#         plt.figure()\n-#         bins = np.linspace(-0.5, 0.5, 51)\n-#         plt.hist(diff, bins=bins, label='deviation')\n-#         plt.xlabel(\"G - %s - predicted\"%(mag_mer_name), size='x-large')\n-#         deviation_hist = os.path.join(plot_dir, \"hist_deviation_%s.png\"%mag_mer_name)\n-#         plt.savefig(deviation_hist)\n-#     return mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist\n\\ No newline at end of file\n+        plt.close('all')\n+    return mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist, nmad_diff_valid\n\\ No newline at end of file\n",
                            "1. link the photometry validation to the merged",
                            "yfang",
                            "2023-07-18T18:37:14.000+02:00",
                            "6e649052ce71cc2177fab5e698374d8b3d3da380"
                        ],
                        [
                            "@@ -48,6 +48,19 @@ def jansky_to_mag(values):\n     \"\"\"\n     return 2.5 * (23 - np.log10(values)) - 48.6\n \n+def get_gaia_mag(data, mag_name):\n+    flux = data[\"FLUX_\" + mag_name]\n+    fluxerr = data[\"FLUXERR_\" + mag_name]\n+    mag = data[\"MAG_\" + mag_name]\n+    magerr = 1.086 * fluxerr / flux\n+    return mag, magerr\n+\n+def get_mer_mag(data, mag_name):\n+    flux = data[\"FLUX_\" + mag_name]\n+    fluxerr = data[\"FLUXERR_\" + mag_name]\n+    mag = jansky_to_mag(1.0e-06*flux)\n+    magerr = 1.086 * (fluxerr/flux)\n+    return mag, magerr\n \n def read_gaia_catalog(catalog_path):\n     hdu = fits.open(catalog_path)\n@@ -80,19 +93,19 @@ def read_gaia_catalog(catalog_path):\n def read_mer_catalog(catalog_path, flux_column='FLUX_VIS_PSF', fluxerr_column='FLUXERR_VIS_PSF', flag_column=\"VIS_DET\", flag_value=1, vis_detected=True):\n     hdu = fits.open(catalog_path)\n     data = hdu[1].data\n-    #flag = data[flag_column]\n-    #selector = (flag == flag_value)\n-    #if vis_detected:\n-    #    selector = selector & (data[\"VIS_DET\"] == 1)\n+    flag = data[flag_column]\n+    selector = (flag == flag_value)\n+    if vis_detected:\n+       selector = selector & (data[\"VIS_DET\"] == 1)\n     ra = data[\"RIGHT_ASCENSION\"]\n     dec = data[\"DECLINATION\"]\n     flux = data[flux_column]\n     fluxerr = data[fluxerr_column]\n-    #data = data[selector]\n-    #hdu.close()\n-    #mag = jansky_to_mag(1.0e-06*flux)\n-    #magerr = 1.086 * (fluxerr/flux)\n-    #selector = (mag >= 18.)\n+    data = data[selector]\n+    hdu.close()\n+    mag = jansky_to_mag(1.0e-06*flux)\n+    magerr = 1.086 * (fluxerr/flux)\n+    selector = (mag >= 18.)\n     return ra, dec, flux, fluxerr, data\n \n def get_trans_func(trans_func_data, x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_min=-1., bp_rp_max=3., nbins=10, plot_dir=None):\n@@ -118,42 +131,44 @@ def get_trans_func(trans_func_data, x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_\n         plt.plot(BP_MIN_RP_tf, G_MIN_VIS_tf, 'ro', label='data')\n         plt.plot(x, trans_func(x), '-', color='blue', label='transformation function')\n         plt.legend(loc='lower right', fancybox=True)\n-        plt.xlabel(\"BP - RP\", size='x-large')\n-        plt.ylabel(\"G - VIS\", size='x-large')\n+        plt.xlabel(\"X_Values\", size='x-large')\n+        plt.ylabel(\"Y_Values\", size='x-large')\n         plt.savefig(figname)\n \n     return trans_func, trans_func_prime, bin_edges, BP_MIN_RP_tf, G_MIN_VIS_tf, bin_number, figname\n \n-def evaluate_deviation(mag_g_gaia, mag_bp_gaia, mag_rp_gaia, mag_mer, trans_func, \n-                    magerr_g_gaia=None, magerr_bp_gaia=None, magerr_rp_gaia=None,\n-                    magerr_mer = None, trans_func_prime=None, mag_mer_name='VIS_PSF',\n-                    bp_rp_min=-1., bp_rp_max=3., plot_dir=None, mer_data=None, save_outlier=False):\n+def evaluate_deviation(mag_A, mag_B, mag_C, mag_D, trans_func, \n+                    magerr_A=None, magerr_B=None, magerr_C=None,\n+                    magerr_D = None, trans_func_prime=None, mag_name_A='BP_GAIA',\n+                    mag_name_B='RP_GAIA', mag_name_C='G_GAIA', mag_name_D='VIS_PSF',\n+                    xmin=-1., xmax=3., plot_dir=None, mer_data=None, save_outlier=False):\n     \n-    g_mer = mag_g_gaia - mag_mer\n-    bp_rp = mag_bp_gaia - mag_rp_gaia\n-    selector = (bp_rp_min < bp_rp) & (bp_rp < bp_rp_max) & (~np.isnan(g_mer)) & (~np.isnan(bp_rp))\n+    x_values = mag_A - mag_B\n+    y_values = mag_C - mag_D\n+    selector = (x_values > xmin) & (x_values < xmax) & (~np.isnan(x_values)) & (~np.isnan(y_values))\n \n-    diff = g_mer[selector] - trans_func(bp_rp[selector])\n+    diff = y_values[selector] - trans_func(x_values[selector])\n     \n-    if save_outlier and (mer_data is not None):\n-        ind = selector & (np.abs(diff) > 1.)\n-        data_outlier = mer_data[ind]\n-        data_outlier_path = os.path.join(plot_dir, \"mer_outliers_%s.fits\"%mag_mer_name)\n-        fits.writeto(data_outlier_path, data_outlier, overwrite=True)\n+    # if save_outlier and (mer_data is not None):\n+    #     ind = selector & (np.abs(diff) > 1.)\n+    #     data_outlier = mer_data[ind]\n+    #     data_outlier_path = os.path.join(plot_dir, \"mer_outliers_%s.fits\"%mag_mer_name)\n+    #     fits.writeto(data_outlier_path, data_outlier, overwrite=True)\n \n     nmad_diff = 1.4826 * median_abs_deviation(diff)\n     mean_diff = np.mean(diff)\n     median_diff = np.median(diff)\n     mean_abs_diff = np.mean(np.abs(diff))\n+\n     if plot_dir:\n         fig, ax = plt.subplots()\n-        deviation_plot = os.path.join(plot_dir, \"photometry_validation_%s.png\"%mag_mer_name)\n-        ax.plot(bp_rp, g_mer, 'ro', label='data')\n-        x = np.linspace(bp_rp_min, bp_rp_max, 1000)\n-        ax.plot(x, trans_func(x), '-', color='blue', label='transformation function')\n+        deviation_plot = os.path.join(plot_dir, \"photometry_validation_%s-%s-%s-%s.png\"%(mag_name_A, mag_name_B, mag_name_C, mag_name_D))\n+        ax.plot(x_values, y_values, 'ro', label='data')\n+        x = np.linspace(xmin, xmax, 1000)\n+        ax.plot(x, trans_func(x), '-', color='blue', label='trans func')\n         ax.legend(loc='lower left', fancybox=True)\n-        ax.set_xlabel(\"BP - RP\", size='x-large')\n-        ax.set_ylabel(\"G - %s\"%(mag_mer_name), size='x-large')\n+        ax.set_xlabel(\"%s - %s\"%(mag_name_A, mag_name_B), size='x-large')\n+        ax.set_ylabel(\"%s - %s\"%(mag_name_C, mag_name_D), size='x-large')\n         # textstr = '\\n'.join((\n         #     r'mean_diff = %.4f'%(mean_diff),\n         #     r'mean_abs_diff = %.4f'%(mean_abs_diff),\n@@ -167,9 +182,60 @@ def evaluate_deviation(mag_g_gaia, mag_bp_gaia, mag_rp_gaia, mag_mer, trans_func\n         ax.text(0.6, 0.2, textstr, transform=ax.transAxes, fontsize=12, verticalalignment='top')\n         plt.savefig(deviation_plot)\n         plt.figure()\n-        bins = np.linspace(-0.5, 0.5, 51)\n+        # bins = np.linspace(-0.5, 0.5, 51)\n+        bins = np.linspace(-1, 1, 51)\n         plt.hist(diff, bins=bins, label='deviation')\n-        plt.xlabel(\"G - %s - predicted\"%(mag_mer_name), size='x-large')\n-        deviation_hist = os.path.join(plot_dir, \"hist_deviation_%s.png\"%mag_mer_name)\n+        plt.xlabel(\"%s - %s - predicted\"%(mag_name_C, mag_name_D), size='x-large')\n+        deviation_hist = os.path.join(plot_dir, \"hist_deviation_%s-%s-%s-%s.png\"%(mag_name_A, mag_name_B, mag_name_C, mag_name_D))\n         plt.savefig(deviation_hist)\n-    return mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist\n\\ No newline at end of file\n+    return mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist\n+\n+# def evaluate_deviation(mag_g_gaia, mag_bp_gaia, mag_rp_gaia, mag_mer, trans_func, \n+#                     magerr_g_gaia=None, magerr_bp_gaia=None, magerr_rp_gaia=None,\n+#                     magerr_mer = None, trans_func_prime=None, mag_mer_name='VIS_PSF',\n+#                     bp_rp_min=-1., bp_rp_max=3., plot_dir=None, mer_data=None, save_outlier=False):\n+    \n+#     g_mer = mag_g_gaia - mag_mer\n+#     bp_rp = mag_bp_gaia - mag_rp_gaia\n+#     selector = (bp_rp_min < bp_rp) & (bp_rp < bp_rp_max) & (~np.isnan(g_mer)) & (~np.isnan(bp_rp))\n+\n+#     diff = g_mer[selector] - trans_func(bp_rp[selector])\n+    \n+#     if save_outlier and (mer_data is not None):\n+#         ind = selector & (np.abs(diff) > 1.)\n+#         data_outlier = mer_data[ind]\n+#         data_outlier_path = os.path.join(plot_dir, \"mer_outliers_%s.fits\"%mag_mer_name)\n+#         fits.writeto(data_outlier_path, data_outlier, overwrite=True)\n+\n+#     nmad_diff = 1.4826 * median_abs_deviation(diff)\n+#     mean_diff = np.mean(diff)\n+#     median_diff = np.median(diff)\n+#     mean_abs_diff = np.mean(np.abs(diff))\n+#     if plot_dir:\n+#         fig, ax = plt.subplots()\n+#         deviation_plot = os.path.join(plot_dir, \"photometry_validation_%s.png\"%mag_mer_name)\n+#         ax.plot(bp_rp, g_mer, 'ro', label='data')\n+#         x = np.linspace(bp_rp_min, bp_rp_max, 1000)\n+#         ax.plot(x, trans_func(x), '-', color='blue', label='transformation function')\n+#         ax.legend(loc='lower left', fancybox=True)\n+#         ax.set_xlabel(\"BP - RP\", size='x-large')\n+#         ax.set_ylabel(\"G - %s\"%(mag_mer_name), size='x-large')\n+#         # textstr = '\\n'.join((\n+#         #     r'mean_diff = %.4f'%(mean_diff),\n+#         #     r'mean_abs_diff = %.4f'%(mean_abs_diff),\n+#         #     r'NMAD_diff = %.4f'%(nmad_diff)\n+#         # ))\n+#         textstr = '\\n'.join((\n+#             r'median_diff = %.4f'%(median_diff),\n+#             r'mean_abs_diff = %.4f'%(mean_abs_diff),\n+#             r'NMAD_diff = %.4f'%(nmad_diff)\n+#         ))\n+#         ax.text(0.6, 0.2, textstr, transform=ax.transAxes, fontsize=12, verticalalignment='top')\n+#         plt.savefig(deviation_plot)\n+#         plt.figure()\n+#         bins = np.linspace(-0.5, 0.5, 51)\n+#         plt.hist(diff, bins=bins, label='deviation')\n+#         plt.xlabel(\"G - %s - predicted\"%(mag_mer_name), size='x-large')\n+#         deviation_hist = os.path.join(plot_dir, \"hist_deviation_%s.png\"%mag_mer_name)\n+#         plt.savefig(deviation_hist)\n+#     return mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist\n\\ No newline at end of file\n",
                            "re-organize photometry validation",
                            "yfang",
                            "2023-07-10T15:26:16.000+02:00",
                            "59dbe91c8025269aec5e6b35a0d61de128483ab7"
                        ],
                        [
                            "@@ -0,0 +1,175 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+:file: python/MER_Validation/MER_PhotometryValidation.py\n+\n+:date: 06/07/23\n+:author: yfang\n+\n+\"\"\"\n+import os\n+import numpy as np\n+import matplotlib.pyplot as plt\n+from astropy.io import fits\n+from scipy.interpolate import PchipInterpolator\n+from scipy.stats import binned_statistic, median_abs_deviation\n+\n+def jansky_to_mag(values):\n+    \"\"\"Converts flux values in Jansky units to AB magnitude units.\n+\n+    http://www.star.bristol.ac.uk/~mbt/stilts/sun256/uk.ac.starlink.ttools.func.Fluxes.html\n+\n+    Parameters\n+    ----------\n+    values: object\n+        A numpy array with the flux values in Jansky units.\n+\n+    Returns\n+    -------\n+    object\n+        A numpy array with the flux values in AB magnitude units.\n+\n+    \"\"\"\n+    return 2.5 * (23 - np.log10(values)) - 48.6\n+\n+\n+def read_gaia_catalog(catalog_path):\n+    hdu = fits.open(catalog_path)\n+    data = hdu[1].data\n+    ra = data[\"RA\"]\n+    dec = data[\"DEC\"]\n+    flux_g_gaia = data[\"FLUX_G_GAIA\"]\n+    fluxerr_g_gaia = data[\"FLUXERR_G_GAIA\"]\n+    flux_bp_gaia = data[\"FLUX_BP_GAIA\"]\n+    fluxerr_bp_gaia = data[\"FLUXERR_BP_GAIA\"]\n+    flux_rp_gaia = data[\"FLUX_RP_GAIA\"]\n+    fluxerr_rp_gaia = data[\"FLUXERR_RP_GAIA\"]\n+    mag_g_gaia = data[\"MAG_G_GAIA\"]\n+    mag_bp_gaia = data[\"MAG_BP_GAIA\"]\n+    mag_rp_gaia = data[\"MAG_RP_GAIA\"]\n+    hdu.close()\n+    \n+    # Convert to AB mags\n+    # mag_g_gaia = -2.5 * np.log10(flux_g_gaia) + 25.8010\n+    # # mag_g_gaia = -2.5 * np.log10(flux_g_gaia) + 25.7934\n+    magerr_g_gaia = 1.086 * fluxerr_g_gaia / flux_g_gaia\n+    # mag_bp_gaia = -2.5 * np.log10(flux_bp_gaia) + 25.3540\n+    # # mag_bp_gaia = -2.5 * np.log10(flux_bp_gaia) + 25.3806\n+    magerr_bp_gaia = 1.086 * fluxerr_bp_gaia / flux_bp_gaia\n+    # mag_rp_gaia = -2.5 * np.log10(flux_rp_gaia) + 25.1040\n+    # # mag_rp_gaia = -2.5 * np.log10(flux_rp_gaia) + 25.1161\n+    magerr_rp_gaia = 1.086 * fluxerr_rp_gaia / flux_rp_gaia\n+    return ra, dec, mag_g_gaia, magerr_g_gaia, mag_bp_gaia, magerr_bp_gaia, mag_rp_gaia, magerr_rp_gaia\n+\n+def read_mer_catalog(catalog_path, flux_column='FLUX_VIS_PSF', fluxerr_column='FLUXERR_VIS_PSF', flag_column=\"VIS_DET\", flag_value=1, vis_detected=True):\n+    hdu = fits.open(catalog_path)\n+    data = hdu[1].data\n+    #flag = data[flag_column]\n+    #selector = (flag == flag_value)\n+    #if vis_detected:\n+    #    selector = selector & (data[\"VIS_DET\"] == 1)\n+    ra = data[\"RIGHT_ASCENSION\"]\n+    dec = data[\"DECLINATION\"]\n+    flux = data[flux_column]\n+    fluxerr = data[fluxerr_column]\n+    #data = data[selector]\n+    #hdu.close()\n+    #mag = jansky_to_mag(1.0e-06*flux)\n+    #magerr = 1.086 * (fluxerr/flux)\n+    #selector = (mag >= 18.)\n+    return ra, dec, flux, fluxerr, data\n+\n+def get_trans_func(trans_func_data, x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_min=-1., bp_rp_max=3., nbins=10, plot_dir=None):\n+    hdu = fits.open(trans_func_data)\n+    tf_data = hdu[1].data\n+    BP_MIN_RP_tf = tf_data[\"X_Values\"]\n+    G_MIN_VIS_tf = tf_data[\"Y_Values\"]\n+    \n+    selector = (~np.isnan(BP_MIN_RP_tf)) & (~np.isnan(G_MIN_VIS_tf))\n+    BP_MIN_RP_tf = BP_MIN_RP_tf[selector]\n+    G_MIN_VIS_tf = G_MIN_VIS_tf[selector]\n+\n+    bin_edges = np.linspace(bp_rp_min, bp_rp_max, nbins)\n+    bin_mids = (bin_edges[:-1] + bin_edges[1:])/2.\n+    stats, _, bin_number = binned_statistic(x=BP_MIN_RP_tf, values=G_MIN_VIS_tf, bins=bin_edges)\n+    trans_func = PchipInterpolator(bin_mids, stats)\n+    trans_func_prime = trans_func.derivative()\n+    \n+    if plot_dir:\n+        plt.figure()\n+        figname = os.path.join(plot_dir, \"transformation_func.png\")\n+        x = np.linspace(bin_mids.min(), bin_mids.max(), 1000)\n+        plt.plot(BP_MIN_RP_tf, G_MIN_VIS_tf, 'ro', label='data')\n+        plt.plot(x, trans_func(x), '-', color='blue', label='transformation function')\n+        plt.legend(loc='lower right', fancybox=True)\n+        plt.xlabel(\"BP - RP\", size='x-large')\n+        plt.ylabel(\"G - VIS\", size='x-large')\n+        plt.savefig(figname)\n+\n+    return trans_func, trans_func_prime, bin_edges, BP_MIN_RP_tf, G_MIN_VIS_tf, bin_number, figname\n+\n+def evaluate_deviation(mag_g_gaia, mag_bp_gaia, mag_rp_gaia, mag_mer, trans_func, \n+                    magerr_g_gaia=None, magerr_bp_gaia=None, magerr_rp_gaia=None,\n+                    magerr_mer = None, trans_func_prime=None, mag_mer_name='VIS_PSF',\n+                    bp_rp_min=-1., bp_rp_max=3., plot_dir=None, mer_data=None, save_outlier=False):\n+    \n+    g_mer = mag_g_gaia - mag_mer\n+    bp_rp = mag_bp_gaia - mag_rp_gaia\n+    selector = (bp_rp_min < bp_rp) & (bp_rp < bp_rp_max) & (~np.isnan(g_mer)) & (~np.isnan(bp_rp))\n+\n+    diff = g_mer[selector] - trans_func(bp_rp[selector])\n+    \n+    if save_outlier and (mer_data is not None):\n+        ind = selector & (np.abs(diff) > 1.)\n+        data_outlier = mer_data[ind]\n+        data_outlier_path = os.path.join(plot_dir, \"mer_outliers_%s.fits\"%mag_mer_name)\n+        fits.writeto(data_outlier_path, data_outlier, overwrite=True)\n+\n+    nmad_diff = 1.4826 * median_abs_deviation(diff)\n+    mean_diff = np.mean(diff)\n+    median_diff = np.median(diff)\n+    mean_abs_diff = np.mean(np.abs(diff))\n+    if plot_dir:\n+        fig, ax = plt.subplots()\n+        deviation_plot = os.path.join(plot_dir, \"photometry_validation_%s.png\"%mag_mer_name)\n+        ax.plot(bp_rp, g_mer, 'ro', label='data')\n+        x = np.linspace(bp_rp_min, bp_rp_max, 1000)\n+        ax.plot(x, trans_func(x), '-', color='blue', label='transformation function')\n+        ax.legend(loc='lower left', fancybox=True)\n+        ax.set_xlabel(\"BP - RP\", size='x-large')\n+        ax.set_ylabel(\"G - %s\"%(mag_mer_name), size='x-large')\n+        # textstr = '\\n'.join((\n+        #     r'mean_diff = %.4f'%(mean_diff),\n+        #     r'mean_abs_diff = %.4f'%(mean_abs_diff),\n+        #     r'NMAD_diff = %.4f'%(nmad_diff)\n+        # ))\n+        textstr = '\\n'.join((\n+            r'median_diff = %.4f'%(median_diff),\n+            r'mean_abs_diff = %.4f'%(mean_abs_diff),\n+            r'NMAD_diff = %.4f'%(nmad_diff)\n+        ))\n+        ax.text(0.6, 0.2, textstr, transform=ax.transAxes, fontsize=12, verticalalignment='top')\n+        plt.savefig(deviation_plot)\n+        plt.figure()\n+        bins = np.linspace(-0.5, 0.5, 51)\n+        plt.hist(diff, bins=bins, label='deviation')\n+        plt.xlabel(\"G - %s - predicted\"%(mag_mer_name), size='x-large')\n+        deviation_hist = os.path.join(plot_dir, \"hist_deviation_%s.png\"%mag_mer_name)\n+        plt.savefig(deviation_hist)\n+    return mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist\n\\ No newline at end of file\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:28:10.000+00:00",
                            "e3224a51e80aec0f298e9607d359a618da467017"
                        ],
                        [
                            "@@ -80,20 +80,20 @@ def read_gaia_catalog(catalog_path):\n def read_mer_catalog(catalog_path, flux_column='FLUX_VIS_PSF', fluxerr_column='FLUXERR_VIS_PSF', flag_column=\"VIS_DET\", flag_value=1, vis_detected=True):\n     hdu = fits.open(catalog_path)\n     data = hdu[1].data\n-    flag = data[flag_column]\n-    selector = (flag == flag_value)\n-    if vis_detected:\n-        selector = selector & (data[\"VIS_DET\"] == 1)\n-    ra = data[\"RIGHT_ASCENSION\"][selector]\n-    dec = data[\"DECLINATION\"][selector]\n-    flux = data[flux_column][selector]\n-    fluxerr = data[fluxerr_column][selector]\n-    data = data[selector]\n-    hdu.close()\n-    mag = jansky_to_mag(1.0e-06*flux)\n-    magerr = 1.086 * (fluxerr/flux)\n-    selector = (mag >= 18.)\n-    return ra[selector], dec[selector], mag[selector], magerr[selector], data[selector]\n+    #flag = data[flag_column]\n+    #selector = (flag == flag_value)\n+    #if vis_detected:\n+    #    selector = selector & (data[\"VIS_DET\"] == 1)\n+    ra = data[\"RIGHT_ASCENSION\"]\n+    dec = data[\"DECLINATION\"]\n+    flux = data[flux_column]\n+    fluxerr = data[fluxerr_column]\n+    #data = data[selector]\n+    #hdu.close()\n+    #mag = jansky_to_mag(1.0e-06*flux)\n+    #magerr = 1.086 * (fluxerr/flux)\n+    #selector = (mag >= 18.)\n+    return ra, dec, flux, fluxerr, data\n \n def get_trans_func(trans_func_data, x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_min=-1., bp_rp_max=3., nbins=10, plot_dir=None):\n     hdu = fits.open(trans_func_data)\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-06-30T17:34:51.000+02:00",
                            "6d9a612f0e2d7a188f993d6b01a6edbd5ff5acae"
                        ],
                        [
                            "@@ -80,20 +80,20 @@ def read_gaia_catalog(catalog_path):\n def read_mer_catalog(catalog_path, flux_column='FLUX_VIS_PSF', fluxerr_column='FLUXERR_VIS_PSF', flag_column=\"VIS_DET\", flag_value=1, vis_detected=True):\n     hdu = fits.open(catalog_path)\n     data = hdu[1].data\n-    flag = data[flag_column]\n-    selector = (flag == flag_value)\n-    if vis_detected:\n-        selector = selector & (data[\"VIS_DET\"] == 1)\n-    ra = data[\"RIGHT_ASCENSION\"][selector]\n-    dec = data[\"DECLINATION\"][selector]\n-    flux = data[flux_column][selector]\n-    fluxerr = data[fluxerr_column][selector]\n-    data = data[selector]\n-    hdu.close()\n-    mag = jansky_to_mag(1.0e-06*flux)\n-    magerr = 1.086 * (fluxerr/flux)\n-    selector = (mag >= 18.)\n-    return ra[selector], dec[selector], mag[selector], magerr[selector], data[selector]\n+    #flag = data[flag_column]\n+    #selector = (flag == flag_value)\n+    #if vis_detected:\n+    #    selector = selector & (data[\"VIS_DET\"] == 1)\n+    ra = data[\"RIGHT_ASCENSION\"]\n+    dec = data[\"DECLINATION\"]\n+    flux = data[flux_column]\n+    fluxerr = data[fluxerr_column]\n+    #data = data[selector]\n+    #hdu.close()\n+    #mag = jansky_to_mag(1.0e-06*flux)\n+    #magerr = 1.086 * (fluxerr/flux)\n+    #selector = (mag >= 18.)\n+    return ra, dec, flux, fluxerr, data\n \n def get_trans_func(trans_func_data, x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_min=-1., bp_rp_max=3., nbins=10, plot_dir=None):\n     hdu = fits.open(trans_func_data)\n",
                            "Astrometry Validation kind of works now",
                            "Martin Kuemmel",
                            "2023-06-30T17:21:02.000+02:00",
                            "86f4592b671eafc5641ccdb2329d95cb560f4578"
                        ],
                        [
                            "@@ -28,7 +28,7 @@ import numpy as np\n import matplotlib.pyplot as plt\n from astropy.io import fits\n from scipy.interpolate import PchipInterpolator\n-from scipy.stats import binned_statistic, median_absolute_deviation\n+from scipy.stats import binned_statistic, median_abs_deviation\n \n def jansky_to_mag(values):\n     \"\"\"Converts flux values in Jansky units to AB magnitude units.\n@@ -141,7 +141,7 @@ def evaluate_deviation(mag_g_gaia, mag_bp_gaia, mag_rp_gaia, mag_mer, trans_func\n         data_outlier_path = os.path.join(plot_dir, \"mer_outliers_%s.fits\"%mag_mer_name)\n         fits.writeto(data_outlier_path, data_outlier, overwrite=True)\n \n-    nmad_diff = 1.4826 * median_absolute_deviation(diff)\n+    nmad_diff = 1.4826 * median_abs_deviation(diff)\n     mean_diff = np.mean(diff)\n     median_diff = np.median(diff)\n     mean_abs_diff = np.mean(np.abs(diff))\n",
                            "modified the codes to make sure they are compatible with newer version of scipy",
                            "yfang",
                            "2023-06-28T16:39:55.000+02:00",
                            "fb1768e9f1bef1acafdd7f1425494afe816099cd"
                        ],
                        [
                            "@@ -77,20 +77,23 @@ def read_gaia_catalog(catalog_path):\n     magerr_rp_gaia = 1.086 * fluxerr_rp_gaia / flux_rp_gaia\n     return ra, dec, mag_g_gaia, magerr_g_gaia, mag_bp_gaia, magerr_bp_gaia, mag_rp_gaia, magerr_rp_gaia\n \n-def read_mer_catalog(catalog_path, flux_column='FLUX_VIS_PSF', fluxerr_column='FLUXERR_VIS_PSF'):\n+def read_mer_catalog(catalog_path, flux_column='FLUX_VIS_PSF', fluxerr_column='FLUXERR_VIS_PSF', flag_column=\"VIS_DET\", flag_value=1, vis_detected=True):\n     hdu = fits.open(catalog_path)\n     data = hdu[1].data\n-    flag = data[\"VIS_DET\"]\n-    selector = (flag == 1)\n+    flag = data[flag_column]\n+    selector = (flag == flag_value)\n+    if vis_detected:\n+        selector = selector & (data[\"VIS_DET\"] == 1)\n     ra = data[\"RIGHT_ASCENSION\"][selector]\n     dec = data[\"DECLINATION\"][selector]\n     flux = data[flux_column][selector]\n     fluxerr = data[fluxerr_column][selector]\n+    data = data[selector]\n     hdu.close()\n     mag = jansky_to_mag(1.0e-06*flux)\n     magerr = 1.086 * (fluxerr/flux)\n     selector = (mag >= 18.)\n-    return ra[selector], dec[selector], mag[selector], magerr[selector]\n+    return ra[selector], dec[selector], mag[selector], magerr[selector], data[selector]\n \n def get_trans_func(trans_func_data, x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_min=-1., bp_rp_max=3., nbins=10, plot_dir=None):\n     hdu = fits.open(trans_func_data)\n@@ -124,13 +127,23 @@ def get_trans_func(trans_func_data, x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_\n def evaluate_deviation(mag_g_gaia, mag_bp_gaia, mag_rp_gaia, mag_mer, trans_func, \n                     magerr_g_gaia=None, magerr_bp_gaia=None, magerr_rp_gaia=None,\n                     magerr_mer = None, trans_func_prime=None, mag_mer_name='VIS_PSF',\n-                    bp_rp_min=-1., bp_rp_max=3., plot_dir=None):\n+                    bp_rp_min=-1., bp_rp_max=3., plot_dir=None, mer_data=None, save_outlier=False):\n+    \n     g_mer = mag_g_gaia - mag_mer\n     bp_rp = mag_bp_gaia - mag_rp_gaia\n     selector = (bp_rp_min < bp_rp) & (bp_rp < bp_rp_max) & (~np.isnan(g_mer)) & (~np.isnan(bp_rp))\n+\n     diff = g_mer[selector] - trans_func(bp_rp[selector])\n+    \n+    if save_outlier and (mer_data is not None):\n+        ind = selector & (np.abs(diff) > 1.)\n+        data_outlier = mer_data[ind]\n+        data_outlier_path = os.path.join(plot_dir, \"mer_outliers_%s.fits\"%mag_mer_name)\n+        fits.writeto(data_outlier_path, data_outlier, overwrite=True)\n+\n     nmad_diff = 1.4826 * median_absolute_deviation(diff)\n     mean_diff = np.mean(diff)\n+    median_diff = np.median(diff)\n     mean_abs_diff = np.mean(np.abs(diff))\n     if plot_dir:\n         fig, ax = plt.subplots()\n@@ -141,8 +154,13 @@ def evaluate_deviation(mag_g_gaia, mag_bp_gaia, mag_rp_gaia, mag_mer, trans_func\n         ax.legend(loc='lower left', fancybox=True)\n         ax.set_xlabel(\"BP - RP\", size='x-large')\n         ax.set_ylabel(\"G - %s\"%(mag_mer_name), size='x-large')\n+        # textstr = '\\n'.join((\n+        #     r'mean_diff = %.4f'%(mean_diff),\n+        #     r'mean_abs_diff = %.4f'%(mean_abs_diff),\n+        #     r'NMAD_diff = %.4f'%(nmad_diff)\n+        # ))\n         textstr = '\\n'.join((\n-            r'mean_diff = %.4f'%(mean_diff),\n+            r'median_diff = %.4f'%(median_diff),\n             r'mean_abs_diff = %.4f'%(mean_abs_diff),\n             r'NMAD_diff = %.4f'%(nmad_diff)\n         ))\n",
                            "fix gaia_selector to handle NANs",
                            "yfang",
                            "2023-06-28T16:25:00.000+02:00",
                            "4081f6b38e5d1db83b22ce8cb6d4c40ef9a07a19"
                        ],
                        [
                            "@@ -0,0 +1,157 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+:file: python/MER_Validation/MER_PhotometryValidation.py\n+\n+:date: 06/07/23\n+:author: yfang\n+\n+\"\"\"\n+import os\n+import numpy as np\n+import matplotlib.pyplot as plt\n+from astropy.io import fits\n+from scipy.interpolate import PchipInterpolator\n+from scipy.stats import binned_statistic, median_absolute_deviation\n+\n+def jansky_to_mag(values):\n+    \"\"\"Converts flux values in Jansky units to AB magnitude units.\n+\n+    http://www.star.bristol.ac.uk/~mbt/stilts/sun256/uk.ac.starlink.ttools.func.Fluxes.html\n+\n+    Parameters\n+    ----------\n+    values: object\n+        A numpy array with the flux values in Jansky units.\n+\n+    Returns\n+    -------\n+    object\n+        A numpy array with the flux values in AB magnitude units.\n+\n+    \"\"\"\n+    return 2.5 * (23 - np.log10(values)) - 48.6\n+\n+\n+def read_gaia_catalog(catalog_path):\n+    hdu = fits.open(catalog_path)\n+    data = hdu[1].data\n+    ra = data[\"RA\"]\n+    dec = data[\"DEC\"]\n+    flux_g_gaia = data[\"FLUX_G_GAIA\"]\n+    fluxerr_g_gaia = data[\"FLUXERR_G_GAIA\"]\n+    flux_bp_gaia = data[\"FLUX_BP_GAIA\"]\n+    fluxerr_bp_gaia = data[\"FLUXERR_BP_GAIA\"]\n+    flux_rp_gaia = data[\"FLUX_RP_GAIA\"]\n+    fluxerr_rp_gaia = data[\"FLUXERR_RP_GAIA\"]\n+    mag_g_gaia = data[\"MAG_G_GAIA\"]\n+    mag_bp_gaia = data[\"MAG_BP_GAIA\"]\n+    mag_rp_gaia = data[\"MAG_RP_GAIA\"]\n+    hdu.close()\n+    \n+    # Convert to AB mags\n+    # mag_g_gaia = -2.5 * np.log10(flux_g_gaia) + 25.8010\n+    # # mag_g_gaia = -2.5 * np.log10(flux_g_gaia) + 25.7934\n+    magerr_g_gaia = 1.086 * fluxerr_g_gaia / flux_g_gaia\n+    # mag_bp_gaia = -2.5 * np.log10(flux_bp_gaia) + 25.3540\n+    # # mag_bp_gaia = -2.5 * np.log10(flux_bp_gaia) + 25.3806\n+    magerr_bp_gaia = 1.086 * fluxerr_bp_gaia / flux_bp_gaia\n+    # mag_rp_gaia = -2.5 * np.log10(flux_rp_gaia) + 25.1040\n+    # # mag_rp_gaia = -2.5 * np.log10(flux_rp_gaia) + 25.1161\n+    magerr_rp_gaia = 1.086 * fluxerr_rp_gaia / flux_rp_gaia\n+    return ra, dec, mag_g_gaia, magerr_g_gaia, mag_bp_gaia, magerr_bp_gaia, mag_rp_gaia, magerr_rp_gaia\n+\n+def read_mer_catalog(catalog_path, flux_column='FLUX_VIS_PSF', fluxerr_column='FLUXERR_VIS_PSF'):\n+    hdu = fits.open(catalog_path)\n+    data = hdu[1].data\n+    flag = data[\"VIS_DET\"]\n+    selector = (flag == 1)\n+    ra = data[\"RIGHT_ASCENSION\"][selector]\n+    dec = data[\"DECLINATION\"][selector]\n+    flux = data[flux_column][selector]\n+    fluxerr = data[fluxerr_column][selector]\n+    hdu.close()\n+    mag = jansky_to_mag(1.0e-06*flux)\n+    magerr = 1.086 * (fluxerr/flux)\n+    selector = (mag >= 18.)\n+    return ra[selector], dec[selector], mag[selector], magerr[selector]\n+\n+def get_trans_func(trans_func_data, x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_min=-1., bp_rp_max=3., nbins=10, plot_dir=None):\n+    hdu = fits.open(trans_func_data)\n+    tf_data = hdu[1].data\n+    BP_MIN_RP_tf = tf_data[\"X_Values\"]\n+    G_MIN_VIS_tf = tf_data[\"Y_Values\"]\n+    \n+    selector = (~np.isnan(BP_MIN_RP_tf)) & (~np.isnan(G_MIN_VIS_tf))\n+    BP_MIN_RP_tf = BP_MIN_RP_tf[selector]\n+    G_MIN_VIS_tf = G_MIN_VIS_tf[selector]\n+\n+    bin_edges = np.linspace(bp_rp_min, bp_rp_max, nbins)\n+    bin_mids = (bin_edges[:-1] + bin_edges[1:])/2.\n+    stats, _, bin_number = binned_statistic(x=BP_MIN_RP_tf, values=G_MIN_VIS_tf, bins=bin_edges)\n+    trans_func = PchipInterpolator(bin_mids, stats)\n+    trans_func_prime = trans_func.derivative()\n+    \n+    if plot_dir:\n+        plt.figure()\n+        figname = os.path.join(plot_dir, \"transformation_func.png\")\n+        x = np.linspace(bin_mids.min(), bin_mids.max(), 1000)\n+        plt.plot(BP_MIN_RP_tf, G_MIN_VIS_tf, 'ro', label='data')\n+        plt.plot(x, trans_func(x), '-', color='blue', label='transformation function')\n+        plt.legend(loc='lower right', fancybox=True)\n+        plt.xlabel(\"BP - RP\", size='x-large')\n+        plt.ylabel(\"G - VIS\", size='x-large')\n+        plt.savefig(figname)\n+\n+    return trans_func, trans_func_prime, bin_edges, BP_MIN_RP_tf, G_MIN_VIS_tf, bin_number, figname\n+\n+def evaluate_deviation(mag_g_gaia, mag_bp_gaia, mag_rp_gaia, mag_mer, trans_func, \n+                    magerr_g_gaia=None, magerr_bp_gaia=None, magerr_rp_gaia=None,\n+                    magerr_mer = None, trans_func_prime=None, mag_mer_name='VIS_PSF',\n+                    bp_rp_min=-1., bp_rp_max=3., plot_dir=None):\n+    g_mer = mag_g_gaia - mag_mer\n+    bp_rp = mag_bp_gaia - mag_rp_gaia\n+    selector = (bp_rp_min < bp_rp) & (bp_rp < bp_rp_max) & (~np.isnan(g_mer)) & (~np.isnan(bp_rp))\n+    diff = g_mer[selector] - trans_func(bp_rp[selector])\n+    nmad_diff = 1.4826 * median_absolute_deviation(diff)\n+    mean_diff = np.mean(diff)\n+    mean_abs_diff = np.mean(np.abs(diff))\n+    if plot_dir:\n+        fig, ax = plt.subplots()\n+        deviation_plot = os.path.join(plot_dir, \"photometry_validation_%s.png\"%mag_mer_name)\n+        ax.plot(bp_rp, g_mer, 'ro', label='data')\n+        x = np.linspace(bp_rp_min, bp_rp_max, 1000)\n+        ax.plot(x, trans_func(x), '-', color='blue', label='transformation function')\n+        ax.legend(loc='lower left', fancybox=True)\n+        ax.set_xlabel(\"BP - RP\", size='x-large')\n+        ax.set_ylabel(\"G - %s\"%(mag_mer_name), size='x-large')\n+        textstr = '\\n'.join((\n+            r'mean_diff = %.4f'%(mean_diff),\n+            r'mean_abs_diff = %.4f'%(mean_abs_diff),\n+            r'NMAD_diff = %.4f'%(nmad_diff)\n+        ))\n+        ax.text(0.6, 0.2, textstr, transform=ax.transAxes, fontsize=12, verticalalignment='top')\n+        plt.savefig(deviation_plot)\n+        plt.figure()\n+        bins = np.linspace(-0.5, 0.5, 51)\n+        plt.hist(diff, bins=bins, label='deviation')\n+        plt.xlabel(\"G - %s - predicted\"%(mag_mer_name), size='x-large')\n+        deviation_hist = os.path.join(plot_dir, \"hist_deviation_%s.png\"%mag_mer_name)\n+        plt.savefig(deviation_hist)\n+    return mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist\n\\ No newline at end of file\n",
                            "MER_validation first commit",
                            "yfang",
                            "2023-06-16T14:07:37.000+02:00",
                            "aa8d15d7c99422f03f3b31136eb8cd04ae672e1c"
                        ]
                    ],
                    "MER_Validation/python/MER_Validation/MER_PhotometryValidationPrg.py": [
                        [
                            "@@ -197,21 +197,22 @@ def mainMethod(args):\n             mer_selector = numpy.argwhere(eval(band[\"selection\"]))[:, 0]\n         else:\n             mer_selector = numpy.arange(len(mer[column_name]))\n-        \n-        logger.info(len(mag[band[\"column_names\"][3]][mer_selector]))\n+\n+        # Make sure no multiple Gaia matches:\n+        v, c = numpy.unique(mer_data['GAIA_ID'][mer_selector], return_counts=True)\n+        mer_selector = mer_selector[numpy.argwhere(c == 1)[:, 0]]\n         logger.info(len(mer_data['GAIA_ID'][mer_selector]))\n \n         # Match to the Gaia sources\n-        if \"Gaia\" in band[\"column_catalogs\"]:\n-            source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_ID'][mer_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n-            \n-            for column_name, column_catalog in zip(band[\"column_names\"], band[\"column_catalogs\"]):\n-                if column_catalog == \"Gaia\":\n-                    mag[column_name] = mag[column_name][gaia_indices]\n-                    magerr[column_name] = magerr[column_name][gaia_indices]\n-                elif column_catalog == \"MER\":\n-                    mag[column_name] = mag[column_name][mer_selector][mer_indices]\n-                    magerr[column_name] = magerr[column_name][mer_selector][mer_indices]\n+        source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_ID'][mer_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n+        \n+        for column_name, column_catalog in zip(band[\"column_names\"], band[\"column_catalogs\"]):\n+            if column_catalog == \"Gaia\":\n+                mag[column_name] = mag[column_name][gaia_indices]\n+                magerr[column_name] = magerr[column_name][gaia_indices]\n+            elif column_catalog == \"MER\":\n+                mag[column_name] = mag[column_name][mer_selector][mer_indices]\n+                magerr[column_name] = magerr[column_name][mer_selector][mer_indices]\n \n         logger.info(\"number of sources after selection = %d\"%(len(mag[band[\"column_names\"][0]])))\n \n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-16T11:46:20.000+00:00",
                            "a83f468ea9bc0e5270859fcc7d1e7f8aa8bf922f"
                        ],
                        [
                            "@@ -102,6 +102,9 @@ def create_analysis_report(results_dict, workdir, logger):\n                                         AnalysisFigure(results_dict[band_name][\"plot_files\"][\"photometry_validation_hist\"], latex_scale=0.55)])\n         analysis_report.add_section(validation_section)\n     \n+    analysis_report.set_backward('index.html')\n+    analysis_report.set_forward(\"astrometryValidation.html\")\n+\n     # Add an index to the analysis report\n     analysis_report.add_index()\n     json_file_name = os.path.join(workdir, \"data\", \"photometryValidation.json\")\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-27T17:00:08.000+02:00",
                            "a29716cea96bd9952a85e0d027784845fe5b7f03"
                        ],
                        [
                            "@@ -194,21 +194,22 @@ def mainMethod(args):\n             mer_selector = numpy.argwhere(eval(band[\"selection\"]))[:, 0]\n         else:\n             mer_selector = numpy.arange(len(mer[column_name]))\n-        \n-        logger.info(len(mag[band[\"column_names\"][3]][mer_selector]))\n+\n+        # Make sure no multiple Gaia matches:\n+        v, c = numpy.unique(mer_data['GAIA_ID'][mer_selector], return_counts=True)\n+        mer_selector = mer_selector[numpy.argwhere(c == 1)[:, 0]]\n         logger.info(len(mer_data['GAIA_ID'][mer_selector]))\n \n         # Match to the Gaia sources\n-        if \"Gaia\" in band[\"column_catalogs\"]:\n-            source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_ID'][mer_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n-            \n-            for column_name, column_catalog in zip(band[\"column_names\"], band[\"column_catalogs\"]):\n-                if column_catalog == \"Gaia\":\n-                    mag[column_name] = mag[column_name][gaia_indices]\n-                    magerr[column_name] = magerr[column_name][gaia_indices]\n-                elif column_catalog == \"MER\":\n-                    mag[column_name] = mag[column_name][mer_selector][mer_indices]\n-                    magerr[column_name] = magerr[column_name][mer_selector][mer_indices]\n+        source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_ID'][mer_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n+        \n+        for column_name, column_catalog in zip(band[\"column_names\"], band[\"column_catalogs\"]):\n+            if column_catalog == \"Gaia\":\n+                mag[column_name] = mag[column_name][gaia_indices]\n+                magerr[column_name] = magerr[column_name][gaia_indices]\n+            elif column_catalog == \"MER\":\n+                mag[column_name] = mag[column_name][mer_selector][mer_indices]\n+                magerr[column_name] = magerr[column_name][mer_selector][mer_indices]\n \n         logger.info(\"number of sources after selection = %d\"%(len(mag[band[\"column_names\"][0]])))\n \n",
                            "require Gaia matches for colour-colour types of",
                            "yfang",
                            "2023-07-27T16:59:39.000+02:00",
                            "721bdbcccc76bf138baae7ef42dd4c9007e645bd"
                        ],
                        [
                            "@@ -0,0 +1,267 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\n+\"\"\"\n+:file: python/MER_Validation/MER_ValidationPrg.py\n+\n+:date: 06/07/23\n+:author: yfang\n+\n+\"\"\"\n+\n+import os\n+import argparse\n+import json\n+import ElementsKernel.Logging as log\n+from ElementsKernel.Auxiliary import getAuxiliaryPath\n+\n+import numpy\n+from astropy.io import fits\n+\n+from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils import ExtDmUtils as ext_utils\n+from MER_DA import MER_CrossMatchModule\n+from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisTable import AnalysisTable\n+from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n+from MER_DataModelUtils.FileNaming import mer_filename\n+from EL_NullValue import NullValueDefinition\n+\n+from .MER_PhotometryValidation import get_trans_func, evaluate_deviation, get_gaia_mag, get_mer_mag\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"\n+    @brief Allows to define the (command line and configuration file) options\n+    specific to this program\n+\n+    @details See the Elements documentation for more details.\n+    @return An  ArgumentParser.\n+    \"\"\"\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n+                        default='./', help='Path to the working directory: \"%(default)s\"!')\n+    parser.add_argument('--final_catalog', dest='final_catalog', type=str, required=True,\n+                        help='path to the catalog to be validated')\n+    parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n+                        help='path to the gaia cutout')\n+    parser.add_argument(\"--configuration_set\", dest=\"configuration_set\",\n+                        type=str, help=\"The MER Configuration Set product XML \"\n+                        \"file name.\")\n+    parser.add_argument(\"--logdir\", dest=\"logdir\", required=False, default='./',\n+                        type=str, help='The logging directory path: \"%(default)s\"!')\n+    parser.add_argument('--output_json', dest='output_json', type=str, required=False,\n+                        default='photometry_validation.json', help='Json file for output, default: \"photometry_validation.json\")!')\n+    parser.add_argument(\"--analysis_result\", dest=\"analysis_result\",\n+                        type=str, help=\"The analysis result output data \"\n+                        \"product XML file name.\")\n+\n+    return parser\n+\n+def create_analysis_report(results_dict, workdir, logger):\n+    logger.info(\"# Creating the analysis report!\")\n+    analysis_report = AnalysisReport(\"MER photometry validations\")\n+    \n+    # Create the table of validation results:\n+    validation_section = AnalysisSection(\"photometry validation results\")\n+    row_names = ['All']\n+    validation_results = [True]\n+    for band_name in results_dict.keys():\n+        validation_results[0] = validation_results[0] & results_dict[band_name]['nmad_diff_valid']\n+        row_names.append(band_name + ' offset NMAD')\n+        validation_results.append(results_dict[band_name]['nmad_diff_valid'])\n+    validation_table = AnalysisTable(['validation quantity', 'Result'],\n+                                    [row_names, ['%s'%a for a in validation_results]])\n+    validation_section.add_table(validation_table)\n+    analysis_report.add_section(validation_section)\n+\n+    for band_name in results_dict.keys():\n+        validation_section = AnalysisSection(band_name + \" photometry validation\")\n+        validation_section.set_figures([\n+                                        AnalysisFigure(results_dict[band_name][\"plot_files\"][\"photometry_validation_scatter\"], latex_scale=0.55),\n+                                        AnalysisFigure(results_dict[band_name][\"plot_files\"][\"photometry_validation_hist\"], latex_scale=0.55)])\n+        analysis_report.add_section(validation_section)\n+    \n+    analysis_report.set_backward('index.html')\n+    analysis_report.set_forward(\"astrometryValidation.html\")\n+\n+    # Add an index to the analysis report\n+    analysis_report.add_index()\n+    json_file_name = os.path.join(workdir, \"data\", \"photometryValidation.json\")\n+    html_file_name = os.path.join(workdir, \"data\", \"photometryValidation.html\")\n+    pdflatex_file_name = os.path.join(workdir, \"data\", \"photometryValidation.tex\")\n+    analysis_report.save_as_json_file(json_file_name)\n+    analysis_report.save_as_html_file(html_file_name)\n+    analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n+    \n+    return [json_file_name, html_file_name, pdflatex_file_name]\n+\n+def mainMethod(args):\n+    \"\"\"\n+    @brief The \"main\" method.\n+    \n+    @details This method is the entry point to the program. In this sense, it is\n+    similar to a main (and it is why it is called mainMethod()).\n+    \"\"\"\n+\n+    logger = log.getLogger('MER_PhotometryValidationPrg')\n+\n+    logger.info('#')\n+    logger.info('# Entering MER_PhotometryValidationPrg mainMethod()')\n+    logger.info('#')\n+\n+    # Add some extra functionality to the MER data product bindings\n+    mer_utils.init()\n+    ext_utils.init()\n+\n+    # Load the configuration parameters\n+    configuration_parameters = AnalysisUtils.get_configuration_parameters(\n+        os.path.join(args.workdir, args.configuration_set),\n+        \"photometry_validation\", args.workdir)\n+\n+    # Load the MER final catalog\n+    final_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.final_catalog))\n+    tile_id = final_catalog.get_tile_index()\n+    gaia_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.gaia_cutout))\n+\n+    # get all table data    \n+    mer_data = fits.getdata(os.path.join(args.workdir, 'data', final_catalog.get_data()))\n+    gaia_data = fits.getdata(os.path.join(args.workdir, 'data', gaia_catalog.get_data()))\n+\n+    # Dictionary to store validation results\n+    results_dict = {}\n+    plots_list = []\n+    global_result = True\n+    plot_dir = os.path.join(args.workdir, 'data')\n+\n+    for band_name, band in configuration_parameters.items():\n+\n+        mag = {}\n+        magerr = {}\n+        results_dict[band_name] = {}\n+        results_dict[band_name][\"plot_files\"] = {}\n+        \n+        # Get tansformation function\n+        trans_func_path = getAuxiliaryPath(band[\"transformation_function\"])\n+        trans_func, trans_func_prime, bin_edges, BP_MIN_RP_tf, G_MIN_VIS_tf, bin_number, _ = get_trans_func(trans_func_path, \n+            x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_min=band[\"interpolation_range\"][0], bp_rp_max=band[\"interpolation_range\"][1], nbins=10)\n+\n+        # Alwyas get VIS detection magnitude for later MER objects selection\n+        mag['DETECTION_TOTAL'], magerr['DETECTION_TOTAL'], flag = get_mer_mag(mer_data, 'DETECTION_TOTAL')\n+        if not flag:\n+            logger.info(\"FLUX_DETECTION_TOTAL column not valid\")\n+            if band_name in results_dict:\n+                del results_dict[band_name]\n+            continue\n+        \n+        flag = True\n+        for column_name, column_catalog in zip(band[\"column_names\"], band[\"column_catalogs\"]):\n+            if column_catalog == \"Gaia\":\n+                mag[column_name], magerr[column_name], flag = get_gaia_mag(gaia_data, column_name)\n+                if not flag:\n+                    logger.info(\"%s column not valid\"%(column_name))\n+                    break\n+            elif column_catalog == \"MER\":\n+                mag[column_name], magerr[column_name], flag = get_mer_mag(mer_data, column_name)\n+                if not flag:\n+                    logger.info(\"%s column not valid\"%(\"FLUX_\" + column_name))\n+                    break\n+        if not flag:\n+            if band_name in results_dict:\n+                del results_dict[band_name]\n+            continue\n+\n+        if len(band[\"selection\"]) > 0:\n+            mer_selector = numpy.argwhere(eval(band[\"selection\"]))[:, 0]\n+        else:\n+            mer_selector = numpy.arange(len(mer[column_name]))\n+        \n+        logger.info(len(mag[band[\"column_names\"][3]][mer_selector]))\n+        logger.info(len(mer_data['GAIA_ID'][mer_selector]))\n+\n+        # Match to the Gaia sources\n+        if \"Gaia\" in band[\"column_catalogs\"]:\n+            source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_ID'][mer_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n+            \n+            for column_name, column_catalog in zip(band[\"column_names\"], band[\"column_catalogs\"]):\n+                if column_catalog == \"Gaia\":\n+                    mag[column_name] = mag[column_name][gaia_indices]\n+                    magerr[column_name] = magerr[column_name][gaia_indices]\n+                elif column_catalog == \"MER\":\n+                    mag[column_name] = mag[column_name][mer_selector][mer_indices]\n+                    magerr[column_name] = magerr[column_name][mer_selector][mer_indices]\n+\n+        logger.info(\"number of sources after selection = %d\"%(len(mag[band[\"column_names\"][0]])))\n+\n+        mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist, nmad_diff_valid = evaluate_deviation(mag[band[\"column_names\"][0]], mag[band[\"column_names\"][1]], \n+            mag[band[\"column_names\"][2]], mag[band[\"column_names\"][3]], trans_func, magerr[band[\"column_names\"][0]], \n+            magerr[band[\"column_names\"][1]], magerr[band[\"column_names\"][2]], magerr[band[\"column_names\"][3]], trans_func_prime=trans_func_prime, \n+            mag_name_A=band[\"column_names\"][0], mag_name_B=band[\"column_names\"][1], mag_name_C=band[\"column_names\"][2], mag_name_D=band[\"column_names\"][3],\n+            xmin=band[\"interpolation_range\"][0], xmax=band[\"interpolation_range\"][1], nmad_diff_limit=band['nmad_diff_limit'], plot_dir=plot_dir, mer_data=None, save_outlier=True)\n+        \n+        global_result = global_result & nmad_diff_valid\n+\n+        results_dict[band_name][\"plot_files\"][\"photometry_validation_scatter\"] = deviation_plot\n+        results_dict[band_name][\"plot_files\"][\"photometry_validation_hist\"] = deviation_hist\n+        results_dict[band_name]['nmad_diff_valid'] = bool(nmad_diff_valid)\n+        plots_list.append(deviation_plot)\n+        plots_list.append(deviation_hist)\n+        # results_dict[band_name][\"plot_files\"][\"vis_transformation_function\"] = trans_func_plot\n+    \n+    report_file_names = create_analysis_report(results_dict, workdir=args.workdir, logger=logger)\n+\n+    # logger.info(\"mean deviation = %.5f\"%(mean_diff))\n+    # logger.info(\"mean absolute deviation = %.5f\"%(mean_abs_diff))\n+    # logger.info(\"NMAD of deviation= %.5f\"%(nmad_diff))\n+\n+    # Writing to sample.json\n+    output_json_path = os.path.join(args.workdir, 'data', args.output_json)\n+    with open(output_json_path, \"w+\") as out_json:\n+        out_json.write(json.dumps(results_dict, indent=4))\n+\n+    tar_file_name = mer_filename(\n+        \"VALIDATION-RESULT\", prefix=\"PHOTOMETRY\", tile_index=tile_id, ext=\"tar.gz\")\n+    AnalysisUtils.save_tar_file(\n+        os.path.join(args.workdir, \"data\", tar_file_name),\n+        report_file_names + [output_json_path] + [plot_file for plot_file in plots_list])\n+    \n+    if global_result:\n+        global_result = \"PASSED\"\n+    else:\n+        global_result = \"FAILED\"\n+\n+    analysis_result = mer_utils.create_analysis_result(global_result)\n+    analysis_result.set_tile_index(tile_id)\n+    # analysis_result.set_observation_id_list(observation_ids)\n+    # analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_figures_tar_file(tar_file_name)\n+    \n+    # Save the analysis result data product as an XML file\n+    logger.info(\"# Saving the analysis result data product\")\n+    analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n+\n+    logger.info('#')\n+    logger.info('# Exiting MER_ValidationPrg mainMethod()')\n+    logger.info('#')\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ],
                        [
                            "@@ -102,6 +102,9 @@ def create_analysis_report(results_dict, workdir, logger):\n                                         AnalysisFigure(results_dict[band_name][\"plot_files\"][\"photometry_validation_hist\"], latex_scale=0.55)])\n         analysis_report.add_section(validation_section)\n     \n+    analysis_report.set_backward('index.html')\n+    analysis_report.set_forward(\"astrometryValidation.html\")\n+\n     # Add an index to the analysis report\n     analysis_report.add_index()\n     json_file_name = os.path.join(workdir, \"data\", \"photometryValidation.json\")\n",
                            "Some mopping up and re-ordering",
                            "Martin Kuemmel",
                            "2023-07-21T10:47:49.000+02:00",
                            "1ff024aab348769fdd7dd60a20c39aae119902e7"
                        ],
                        [
                            "@@ -151,6 +151,7 @@ def mainMethod(args):\n     results_dict = {}\n     plots_list = []\n     global_result = True\n+    plot_dir = os.path.join(args.workdir, 'data')\n \n     for band_name, band in configuration_parameters.items():\n \n@@ -215,7 +216,7 @@ def mainMethod(args):\n             mag[band[\"column_names\"][2]], mag[band[\"column_names\"][3]], trans_func, magerr[band[\"column_names\"][0]], \n             magerr[band[\"column_names\"][1]], magerr[band[\"column_names\"][2]], magerr[band[\"column_names\"][3]], trans_func_prime=trans_func_prime, \n             mag_name_A=band[\"column_names\"][0], mag_name_B=band[\"column_names\"][1], mag_name_C=band[\"column_names\"][2], mag_name_D=band[\"column_names\"][3],\n-            xmin=band[\"interpolation_range\"][0], xmax=band[\"interpolation_range\"][1], nmad_diff_limit=band['nmad_diff_limit'], plot_dir=args.workdir, mer_data=None, save_outlier=True)\n+            xmin=band[\"interpolation_range\"][0], xmax=band[\"interpolation_range\"][1], nmad_diff_limit=band['nmad_diff_limit'], plot_dir=plot_dir, mer_data=None, save_outlier=True)\n         \n         global_result = global_result & nmad_diff_valid\n \n",
                            "move  photometryValidation figures to /data folder",
                            "yfang",
                            "2023-07-20T15:55:00.000+02:00",
                            "930f792eda7125c903db644363e20217fb0c05e5"
                        ],
                        [
                            "@@ -68,6 +68,8 @@ def defineSpecificProgramOptions():\n     parser.add_argument(\"--configuration_set\", dest=\"configuration_set\",\n                         type=str, help=\"The MER Configuration Set product XML \"\n                         \"file name.\")\n+    parser.add_argument(\"--logdir\", dest=\"logdir\", required=False, default='./',\n+                        type=str, help='The logging directory path: \"%(default)s\"!')\n     parser.add_argument('--output_json', dest='output_json', type=str, required=False,\n                         default='photometry_validation.json', help='Json file for output, default: \"photometry_validation.json\")!')\n     parser.add_argument(\"--analysis_result\", dest=\"analysis_result\",\n",
                            "add --logdir to ArgumentParsar in",
                            "yfang",
                            "2023-07-20T14:59:29.000+02:00",
                            "9b048484d9d81c3c8763834eeb853d1b60cb6618"
                        ],
                        [
                            "@@ -27,6 +27,7 @@\n \n import os\n import argparse\n+import json\n import ElementsKernel.Logging as log\n from ElementsKernel.Auxiliary import getAuxiliaryPath\n \n@@ -40,11 +41,12 @@ from MER_DA import MER_CrossMatchModule\n from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisTable import AnalysisTable\n from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n+from MER_DataModelUtils.FileNaming import mer_filename\n from EL_NullValue import NullValueDefinition\n \n from .MER_PhotometryValidation import get_trans_func, evaluate_deviation, get_gaia_mag, get_mer_mag\n-# from .MER_PhotometryValidation import read_gaia_catalog, read_mer_catalog\n \n def defineSpecificProgramOptions():\n     \"\"\"\n@@ -63,46 +65,46 @@ def defineSpecificProgramOptions():\n                         help='path to the catalog to be validated')\n     parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n                         help='path to the gaia cutout')\n-    # parser.add_argument('--trans_func', dest='trans_func', type=str, required=True,\n-    #                     help='path to the cataog of stars to construct transformation')\n-    parser.add_argument('--plot_dir', dest='plot_dir', type=str, required=False,\n-                        help='path to put figures, produce no figures if not given')\n-    # parser.add_argument('--mer_flux_column', dest='flux_column', type=str, required=False,\n-    #                     default='FLUX_VIS_PSF')\n-    # parser.add_argument('--mer_fluxerr_column', dest='fluxerr_column', type=str, required=False,\n-    #                     default='FLUXERR_VIS_PSF')\n-    # parser.add_argument('--mer_flag_column', dest='mer_flag_column', type=str, required=False,\n-    #                     default='VIS_DET')\n-    # parser.add_argument('--mer_flag_value', dest='mer_flag_value', type=int, required=False,\n-    #                     default=1)\n-    # parser.add_argument('--mer_mag_name', dest='mer_mag_name', type=str, required=False,\n-    #                     default='VIS_PSF')\n     parser.add_argument(\"--configuration_set\", dest=\"configuration_set\",\n                         type=str, help=\"The MER Configuration Set product XML \"\n                         \"file name.\")\n     parser.add_argument('--output_json', dest='output_json', type=str, required=False,\n                         default='photometry_validation.json', help='Json file for output, default: \"photometry_validation.json\")!')\n+    parser.add_argument(\"--analysis_result\", dest=\"analysis_result\",\n+                        type=str, help=\"The analysis result output data \"\n+                        \"product XML file name.\")\n \n     return parser\n \n def create_analysis_report(results_dict, workdir, logger):\n     logger.info(\"# Creating the analysis report!\")\n     analysis_report = AnalysisReport(\"MER photometry validations\")\n-    vis_photometry_validation_section = AnalysisSection(\"VIS photometry validation\")\n-    vis_photometry_validation_section.set_figures([\n-                                        AnalysisFigure(results_dict[\"plot_files\"][\"vis_transformation_function\"], latex_scale=0.55),\n-                                        AnalysisFigure(results_dict[\"plot_files\"][\"photometry_validation_vis_detection_scatter\"], latex_scale=0.55),\n-                                        AnalysisFigure(results_dict[\"plot_files\"][\"photometry_validation_vis_detection_hist\"], latex_scale=0.55)])\n-    analysis_report.add_section(vis_photometry_validation_section)\n+    \n+    # Create the table of validation results:\n+    validation_section = AnalysisSection(\"photometry validation results\")\n+    row_names = ['All']\n+    validation_results = [True]\n+    for band_name in results_dict.keys():\n+        validation_results[0] = validation_results[0] & results_dict[band_name]['nmad_diff_valid']\n+        row_names.append(band_name + ' offset NMAD')\n+        validation_results.append(results_dict[band_name]['nmad_diff_valid'])\n+    validation_table = AnalysisTable(['validation quantity', 'Result'],\n+                                    [row_names, ['%s'%a for a in validation_results]])\n+    validation_section.add_table(validation_table)\n+    analysis_report.add_section(validation_section)\n+\n+    for band_name in results_dict.keys():\n+        validation_section = AnalysisSection(band_name + \" photometry validation\")\n+        validation_section.set_figures([\n+                                        AnalysisFigure(results_dict[band_name][\"plot_files\"][\"photometry_validation_scatter\"], latex_scale=0.55),\n+                                        AnalysisFigure(results_dict[band_name][\"plot_files\"][\"photometry_validation_hist\"], latex_scale=0.55)])\n+        analysis_report.add_section(validation_section)\n     \n     # Add an index to the analysis report\n     analysis_report.add_index()\n-    # json_file_name = os.path.join(workdir, \"data\", \"mer_photometry_validations.json\")\n-    # html_file_name = os.path.join(workdir, \"data\", \"mer_photometry_validations.html\")\n-    # pdflatex_file_name = os.path.join(workdir, \"data\", \"mer_photometry_validations.tex\")\n-    json_file_name = os.path.join(workdir, \"mer_photometry_validations.json\")\n-    html_file_name = os.path.join(workdir, \"mer_photometry_validations.html\")\n-    pdflatex_file_name = os.path.join(workdir, \"mer_photometry_validations.tex\")\n+    json_file_name = os.path.join(workdir, \"data\", \"photometryValidation.json\")\n+    html_file_name = os.path.join(workdir, \"data\", \"photometryValidation.html\")\n+    pdflatex_file_name = os.path.join(workdir, \"data\", \"photometryValidation.tex\")\n     analysis_report.save_as_json_file(json_file_name)\n     analysis_report.save_as_html_file(html_file_name)\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n@@ -123,9 +125,6 @@ def mainMethod(args):\n     logger.info('# Entering MER_PhotometryValidationPrg mainMethod()')\n     logger.info('#')\n \n-    results_dict = {}\n-    results_dict[\"plot_files\"] = {}\n-\n     # Add some extra functionality to the MER data product bindings\n     mer_utils.init()\n     ext_utils.init()\n@@ -138,6 +137,7 @@ def mainMethod(args):\n     # Load the MER final catalog\n     final_catalog = dm_utils.read_product_metadata(\n         os.path.join(args.workdir, args.final_catalog))\n+    tile_id = final_catalog.get_tile_index()\n     gaia_catalog = dm_utils.read_product_metadata(\n         os.path.join(args.workdir, args.gaia_cutout))\n \n@@ -145,30 +145,48 @@ def mainMethod(args):\n     mer_data = fits.getdata(os.path.join(args.workdir, 'data', final_catalog.get_data()))\n     gaia_data = fits.getdata(os.path.join(args.workdir, 'data', gaia_catalog.get_data()))\n \n-    # select the GAIA ID's in the final catalog    \n-    # gaia_selector=numpy.where(numpy.logical_and(mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG, mer_data['GAIA_ID']>0),True, False)\n-    # logger.info('# No. of GAIA matches: %i' % len(mer_data['GAIA_ID'][gaia_selector]))\n-    # results_dict['n_gaia_matches'] = len(mer_data['GAIA_ID'][gaia_selector])\n-\n-    # # intersect the GAIA ID's from the final catalog with the GAIA catalog\n-    # source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_ID'][gaia_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n+    # Dictionary to store validation results\n+    results_dict = {}\n+    plots_list = []\n+    global_result = True\n \n     for band_name, band in configuration_parameters.items():\n \n         mag = {}\n         magerr = {}\n+        results_dict[band_name] = {}\n+        results_dict[band_name][\"plot_files\"] = {}\n         \n         # Get tansformation function\n         trans_func_path = getAuxiliaryPath(band[\"transformation_function\"])\n-        trans_func, trans_func_prime, bin_edges, BP_MIN_RP_tf, G_MIN_VIS_tf, bin_number, trans_func_plot = get_trans_func(trans_func_path, \n-            x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_min=band[\"interpolation_range\"][0], bp_rp_max=band[\"interpolation_range\"][1], nbins=10, plot_dir=args.plot_dir)\n+        trans_func, trans_func_prime, bin_edges, BP_MIN_RP_tf, G_MIN_VIS_tf, bin_number, _ = get_trans_func(trans_func_path, \n+            x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_min=band[\"interpolation_range\"][0], bp_rp_max=band[\"interpolation_range\"][1], nbins=10)\n+\n+        # Alwyas get VIS detection magnitude for later MER objects selection\n+        mag['DETECTION_TOTAL'], magerr['DETECTION_TOTAL'], flag = get_mer_mag(mer_data, 'DETECTION_TOTAL')\n+        if not flag:\n+            logger.info(\"FLUX_DETECTION_TOTAL column not valid\")\n+            if band_name in results_dict:\n+                del results_dict[band_name]\n+            continue\n         \n+        flag = True\n         for column_name, column_catalog in zip(band[\"column_names\"], band[\"column_catalogs\"]):\n             if column_catalog == \"Gaia\":\n-                mag[column_name], magerr[column_name] = get_gaia_mag(gaia_data, column_name)\n+                mag[column_name], magerr[column_name], flag = get_gaia_mag(gaia_data, column_name)\n+                if not flag:\n+                    logger.info(\"%s column not valid\"%(column_name))\n+                    break\n             elif column_catalog == \"MER\":\n-                mag[column_name], magerr[column_name] = get_mer_mag(mer_data, column_name)\n-            \n+                mag[column_name], magerr[column_name], flag = get_mer_mag(mer_data, column_name)\n+                if not flag:\n+                    logger.info(\"%s column not valid\"%(\"FLUX_\" + column_name))\n+                    break\n+        if not flag:\n+            if band_name in results_dict:\n+                del results_dict[band_name]\n+            continue\n+\n         if len(band[\"selection\"]) > 0:\n             mer_selector = numpy.argwhere(eval(band[\"selection\"]))[:, 0]\n         else:\n@@ -180,11 +198,6 @@ def mainMethod(args):\n         # Match to the Gaia sources\n         if \"Gaia\" in band[\"column_catalogs\"]:\n             source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_ID'][mer_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n-\n-            print(source_ids)\n-            print(mer_data['GAIA_ID'][mer_selector])\n-            print(numpy.unique(mer_data['GAIA_ID'][mer_selector]))\n-            print(len(gaia_data['SOURCE_ID']))\n             \n             for column_name, column_catalog in zip(band[\"column_names\"], band[\"column_catalogs\"]):\n                 if column_catalog == \"Gaia\":\n@@ -196,86 +209,52 @@ def mainMethod(args):\n \n         logger.info(\"number of sources after selection = %d\"%(len(mag[band[\"column_names\"][0]])))\n \n-        mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist = evaluate_deviation(mag[band[\"column_names\"][0]], mag[band[\"column_names\"][1]], \n+        mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist, nmad_diff_valid = evaluate_deviation(mag[band[\"column_names\"][0]], mag[band[\"column_names\"][1]], \n             mag[band[\"column_names\"][2]], mag[band[\"column_names\"][3]], trans_func, magerr[band[\"column_names\"][0]], \n             magerr[band[\"column_names\"][1]], magerr[band[\"column_names\"][2]], magerr[band[\"column_names\"][3]], trans_func_prime=trans_func_prime, \n             mag_name_A=band[\"column_names\"][0], mag_name_B=band[\"column_names\"][1], mag_name_C=band[\"column_names\"][2], mag_name_D=band[\"column_names\"][3],\n-            xmin=band[\"interpolation_range\"][0], xmax=band[\"interpolation_range\"][1], plot_dir=args.plot_dir, mer_data=None, save_outlier=True)\n-\n-        results_dict[\"plot_files\"][\"photometry_validation_vis_detection_scatter\"] = deviation_plot\n-        results_dict[\"plot_files\"][\"photometry_validation_vis_detection_hist\"] = deviation_hist\n-        results_dict[\"plot_files\"][\"vis_transformation_function\"] = trans_func_plot\n-\n-\n-    # ra_gaia, dec_gaia, mag_g_gaia, magerr_g_gaia, mag_bp_gaia, magerr_bp_gaia, mag_rp_gaia, magerr_rp_gaia = read_gaia_catalog(catalog_path=args.gaia_cutout)\n-    # ra_mer, dec_mer, mag_vis_psf, magerr_vis_psf, mer_data = read_mer_catalog(catalog_path=args.mer_catalog, \n-    #     flux_column=args.flux_column, \n-    #     fluxerr_column=args.fluxerr_column,\n-    #     flag_column=args.mer_flag_column,\n-    #     flag_value=args.mer_flag_value\n-    #     )\n-\n-    # # Cross match Gaia and MER catalog\n-    # matched_idx, matched_quality, tot_matched = MER_CrossMatchModule.MER_match_catalogs_sky(ra1 = ra_mer,\n-    #                                                                                         dec1 = dec_mer,\n-    #                                                                                         ra2 = ra_gaia,\n-    #                                                                                         dec2 = dec_gaia,\n-    #                                                                                         id_col_cat2 = np.arange(len(ra_gaia)),\n-    #                                                                                         max_dist = 0.6,\n-    #                                                                                         col1 = [],\n-    #                                                                                         col2 = [],\n-    #                                                                                         thresh = [],\n-    #                                                                                         weights = [])\n-\n-    # matched_idx = np.array(matched_idx)\n-    # mer_selector = np.where(matched_idx != -1)[0]\n-    # matched_idx = matched_idx[mer_selector]\n-    # mag_vis_psf_matched = mag_vis_psf[mer_selector]\n-    # magerr_vis_psf_matched = magerr_vis_psf[mer_selector]\n-    \n-    # # For testing\n-    # mer_data_matched = mer_data[mer_selector]\n+            xmin=band[\"interpolation_range\"][0], xmax=band[\"interpolation_range\"][1], nmad_diff_limit=band['nmad_diff_limit'], plot_dir=args.workdir, mer_data=None, save_outlier=True)\n+        \n+        global_result = global_result & nmad_diff_valid\n+\n+        results_dict[band_name][\"plot_files\"][\"photometry_validation_scatter\"] = deviation_plot\n+        results_dict[band_name][\"plot_files\"][\"photometry_validation_hist\"] = deviation_hist\n+        results_dict[band_name]['nmad_diff_valid'] = bool(nmad_diff_valid)\n+        plots_list.append(deviation_plot)\n+        plots_list.append(deviation_hist)\n+        # results_dict[band_name][\"plot_files\"][\"vis_transformation_function\"] = trans_func_plot\n     \n-    # mag_g_gaia_matched = []\n-    # magerr_g_gaia_matched = []\n-    # mag_bp_gaia_matched = []\n-    # magerr_bp_gaia_matched = []\n-    # mag_rp_gaia_matched = []\n-    # magerr_rp_gaia_matched = []\n-\n-    # for i in range(len(mer_selector)):\n-    #     mag_g_gaia_matched.append(mag_g_gaia[matched_idx[i]])\n-    #     magerr_g_gaia_matched.append(magerr_g_gaia[matched_idx[i]])\n-    #     mag_bp_gaia_matched.append(mag_bp_gaia[matched_idx[i]])\n-    #     magerr_bp_gaia_matched.append(magerr_bp_gaia[matched_idx[i]])\n-    #     mag_rp_gaia_matched.append(mag_rp_gaia[matched_idx[i]])\n-    #     magerr_rp_gaia_matched.append(magerr_rp_gaia[matched_idx[i]])\n-    # mag_g_gaia_matched = np.array(mag_g_gaia_matched)\n-    # magerr_g_gaia_matched = np.array(magerr_g_gaia_matched)\n-    # mag_bp_gaia_matched = np.array(mag_bp_gaia_matched)\n-    # magerr_bp_gaia_matched = np.array(magerr_bp_gaia_matched)\n-    # mag_rp_gaia_matched = np.array(mag_rp_gaia_matched)\n-    # magerr_rp_gaia_matched = np.array(mag_rp_gaia_matched)\n-\n-    # # Get tansformation function\n-    # trans_func, trans_func_prime, bin_edges, BP_MIN_RP_tf, G_MIN_VIS_tf, bin_number, trans_func_plot = get_trans_func(args.trans_func,\n-    #                 x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_min=-1., bp_rp_max=3., nbins=10, plot_dir=args.plot_dir)\n-\n-    # mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist = evaluate_deviation(mag_g_gaia_matched, mag_bp_gaia_matched, \n-    #                 mag_rp_gaia_matched, mag_vis_psf_matched, trans_func, \n-    #                 magerr_g_gaia_matched, magerr_bp_gaia_matched, magerr_rp_gaia_matched,\n-    #                 magerr_vis_psf_matched, trans_func_prime=trans_func_prime, mag_mer_name=args.mer_mag_name,\n-    #                 bp_rp_min=-1., bp_rp_max=3., plot_dir=args.plot_dir, mer_data=mer_data_matched, save_outlier=True)\n+    report_file_names = create_analysis_report(results_dict, workdir=args.workdir, logger=logger)\n+\n+    # logger.info(\"mean deviation = %.5f\"%(mean_diff))\n+    # logger.info(\"mean absolute deviation = %.5f\"%(mean_abs_diff))\n+    # logger.info(\"NMAD of deviation= %.5f\"%(nmad_diff))\n+\n+    # Writing to sample.json\n+    output_json_path = os.path.join(args.workdir, 'data', args.output_json)\n+    with open(output_json_path, \"w+\") as out_json:\n+        out_json.write(json.dumps(results_dict, indent=4))\n+\n+    tar_file_name = mer_filename(\n+        \"VALIDATION-RESULT\", prefix=\"PHOTOMETRY\", tile_index=tile_id, ext=\"tar.gz\")\n+    AnalysisUtils.save_tar_file(\n+        os.path.join(args.workdir, \"data\", tar_file_name),\n+        report_file_names + [output_json_path] + [plot_file for plot_file in plots_list])\n     \n-    # results_dict[\"plot_files\"][\"photometry_validation_vis_detection_scatter\"] = deviation_plot\n-    # results_dict[\"plot_files\"][\"photometry_validation_vis_detection_hist\"] = deviation_hist\n-    # results_dict[\"plot_files\"][\"vis_transformation_function\"] = trans_func_plot\n+    if global_result:\n+        global_result = \"PASSED\"\n+    else:\n+        global_result = \"FAILED\"\n+\n+    analysis_result = mer_utils.create_analysis_result(global_result)\n+    analysis_result.set_tile_index(tile_id)\n+    # analysis_result.set_observation_id_list(observation_ids)\n+    # analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_figures_tar_file(tar_file_name)\n     \n-    report_file_names = create_analysis_report(results_dict, workdir=args.plot_dir, logger=logger)\n-\n-    logger.info(\"mean deviation = %.5f\"%(mean_diff))\n-    logger.info(\"mean absolute deviation = %.5f\"%(mean_abs_diff))\n-    logger.info(\"NMAD of deviation= %.5f\"%(nmad_diff))\n+    # Save the analysis result data product as an XML file\n+    logger.info(\"# Saving the analysis result data product\")\n+    analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n \n     logger.info('#')\n     logger.info('# Exiting MER_ValidationPrg mainMethod()')\n",
                            "1. link the photometry validation to the merged",
                            "yfang",
                            "2023-07-18T18:37:14.000+02:00",
                            "6e649052ce71cc2177fab5e698374d8b3d3da380"
                        ],
                        [
                            "@@ -0,0 +1,282 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\n+\"\"\"\n+:file: python/MER_Validation/MER_ValidationPrg.py\n+\n+:date: 06/07/23\n+:author: yfang\n+\n+\"\"\"\n+\n+import os\n+import argparse\n+import ElementsKernel.Logging as log\n+from ElementsKernel.Auxiliary import getAuxiliaryPath\n+\n+import numpy\n+from astropy.io import fits\n+\n+from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils import ExtDmUtils as ext_utils\n+from MER_DA import MER_CrossMatchModule\n+from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n+from EL_NullValue import NullValueDefinition\n+\n+from .MER_PhotometryValidation import get_trans_func, evaluate_deviation, get_gaia_mag, get_mer_mag\n+# from .MER_PhotometryValidation import read_gaia_catalog, read_mer_catalog\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"\n+    @brief Allows to define the (command line and configuration file) options\n+    specific to this program\n+\n+    @details See the Elements documentation for more details.\n+    @return An  ArgumentParser.\n+    \"\"\"\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n+                        default='./', help='Path to the working directory: \"%(default)s\"!')\n+    parser.add_argument('--final_catalog', dest='final_catalog', type=str, required=True,\n+                        help='path to the catalog to be validated')\n+    parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n+                        help='path to the gaia cutout')\n+    # parser.add_argument('--trans_func', dest='trans_func', type=str, required=True,\n+    #                     help='path to the cataog of stars to construct transformation')\n+    parser.add_argument('--plot_dir', dest='plot_dir', type=str, required=False,\n+                        help='path to put figures, produce no figures if not given')\n+    # parser.add_argument('--mer_flux_column', dest='flux_column', type=str, required=False,\n+    #                     default='FLUX_VIS_PSF')\n+    # parser.add_argument('--mer_fluxerr_column', dest='fluxerr_column', type=str, required=False,\n+    #                     default='FLUXERR_VIS_PSF')\n+    # parser.add_argument('--mer_flag_column', dest='mer_flag_column', type=str, required=False,\n+    #                     default='VIS_DET')\n+    # parser.add_argument('--mer_flag_value', dest='mer_flag_value', type=int, required=False,\n+    #                     default=1)\n+    # parser.add_argument('--mer_mag_name', dest='mer_mag_name', type=str, required=False,\n+    #                     default='VIS_PSF')\n+    parser.add_argument(\"--configuration_set\", dest=\"configuration_set\",\n+                        type=str, help=\"The MER Configuration Set product XML \"\n+                        \"file name.\")\n+    parser.add_argument('--output_json', dest='output_json', type=str, required=False,\n+                        default='photometry_validation.json', help='Json file for output, default: \"photometry_validation.json\")!')\n+\n+    return parser\n+\n+def create_analysis_report(results_dict, workdir, logger):\n+    logger.info(\"# Creating the analysis report!\")\n+    analysis_report = AnalysisReport(\"MER photometry validations\")\n+    vis_photometry_validation_section = AnalysisSection(\"VIS photometry validation\")\n+    vis_photometry_validation_section.set_figures([\n+                                        AnalysisFigure(results_dict[\"plot_files\"][\"vis_transformation_function\"], latex_scale=0.55),\n+                                        AnalysisFigure(results_dict[\"plot_files\"][\"photometry_validation_vis_detection_scatter\"], latex_scale=0.55),\n+                                        AnalysisFigure(results_dict[\"plot_files\"][\"photometry_validation_vis_detection_hist\"], latex_scale=0.55)])\n+    analysis_report.add_section(vis_photometry_validation_section)\n+    \n+    # Add an index to the analysis report\n+    analysis_report.add_index()\n+    # json_file_name = os.path.join(workdir, \"data\", \"mer_photometry_validations.json\")\n+    # html_file_name = os.path.join(workdir, \"data\", \"mer_photometry_validations.html\")\n+    # pdflatex_file_name = os.path.join(workdir, \"data\", \"mer_photometry_validations.tex\")\n+    json_file_name = os.path.join(workdir, \"mer_photometry_validations.json\")\n+    html_file_name = os.path.join(workdir, \"mer_photometry_validations.html\")\n+    pdflatex_file_name = os.path.join(workdir, \"mer_photometry_validations.tex\")\n+    analysis_report.save_as_json_file(json_file_name)\n+    analysis_report.save_as_html_file(html_file_name)\n+    analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n+    \n+    return [json_file_name, html_file_name, pdflatex_file_name]\n+\n+def mainMethod(args):\n+    \"\"\"\n+    @brief The \"main\" method.\n+    \n+    @details This method is the entry point to the program. In this sense, it is\n+    similar to a main (and it is why it is called mainMethod()).\n+    \"\"\"\n+\n+    logger = log.getLogger('MER_PhotometryValidationPrg')\n+\n+    logger.info('#')\n+    logger.info('# Entering MER_PhotometryValidationPrg mainMethod()')\n+    logger.info('#')\n+\n+    results_dict = {}\n+    results_dict[\"plot_files\"] = {}\n+\n+    # Add some extra functionality to the MER data product bindings\n+    mer_utils.init()\n+    ext_utils.init()\n+\n+    # Load the configuration parameters\n+    configuration_parameters = AnalysisUtils.get_configuration_parameters(\n+        os.path.join(args.workdir, args.configuration_set),\n+        \"photometry_validation\", args.workdir)\n+\n+    # Load the MER final catalog\n+    final_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.final_catalog))\n+    gaia_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.gaia_cutout))\n+\n+    # get all table data    \n+    mer_data = fits.getdata(os.path.join(args.workdir, 'data', final_catalog.get_data()))\n+    gaia_data = fits.getdata(os.path.join(args.workdir, 'data', gaia_catalog.get_data()))\n+\n+    # select the GAIA ID's in the final catalog    \n+    # gaia_selector=numpy.where(numpy.logical_and(mer_data['GAIA_ID'] != NullValueDefinition().LONG_LONG, mer_data['GAIA_ID']>0),True, False)\n+    # logger.info('# No. of GAIA matches: %i' % len(mer_data['GAIA_ID'][gaia_selector]))\n+    # results_dict['n_gaia_matches'] = len(mer_data['GAIA_ID'][gaia_selector])\n+\n+    # # intersect the GAIA ID's from the final catalog with the GAIA catalog\n+    # source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_ID'][gaia_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n+\n+    for band_name, band in configuration_parameters.items():\n+\n+        mag = {}\n+        magerr = {}\n+        \n+        # Get tansformation function\n+        trans_func_path = getAuxiliaryPath(band[\"transformation_function\"])\n+        trans_func, trans_func_prime, bin_edges, BP_MIN_RP_tf, G_MIN_VIS_tf, bin_number, trans_func_plot = get_trans_func(trans_func_path, \n+            x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_min=band[\"interpolation_range\"][0], bp_rp_max=band[\"interpolation_range\"][1], nbins=10, plot_dir=args.plot_dir)\n+        \n+        for column_name, column_catalog in zip(band[\"column_names\"], band[\"column_catalogs\"]):\n+            if column_catalog == \"Gaia\":\n+                mag[column_name], magerr[column_name] = get_gaia_mag(gaia_data, column_name)\n+            elif column_catalog == \"MER\":\n+                mag[column_name], magerr[column_name] = get_mer_mag(mer_data, column_name)\n+            \n+        if len(band[\"selection\"]) > 0:\n+            mer_selector = numpy.argwhere(eval(band[\"selection\"]))[:, 0]\n+        else:\n+            mer_selector = numpy.arange(len(mer[column_name]))\n+        \n+        logger.info(len(mag[band[\"column_names\"][3]][mer_selector]))\n+        logger.info(len(mer_data['GAIA_ID'][mer_selector]))\n+\n+        # Match to the Gaia sources\n+        if \"Gaia\" in band[\"column_catalogs\"]:\n+            source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_ID'][mer_selector], gaia_data['SOURCE_ID'], assume_unique=False, return_indices=True)\n+\n+            print(source_ids)\n+            print(mer_data['GAIA_ID'][mer_selector])\n+            print(numpy.unique(mer_data['GAIA_ID'][mer_selector]))\n+            print(len(gaia_data['SOURCE_ID']))\n+            \n+            for column_name, column_catalog in zip(band[\"column_names\"], band[\"column_catalogs\"]):\n+                if column_catalog == \"Gaia\":\n+                    mag[column_name] = mag[column_name][gaia_indices]\n+                    magerr[column_name] = magerr[column_name][gaia_indices]\n+                elif column_catalog == \"MER\":\n+                    mag[column_name] = mag[column_name][mer_selector][mer_indices]\n+                    magerr[column_name] = magerr[column_name][mer_selector][mer_indices]\n+\n+        logger.info(\"number of sources after selection = %d\"%(len(mag[band[\"column_names\"][0]])))\n+\n+        mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist = evaluate_deviation(mag[band[\"column_names\"][0]], mag[band[\"column_names\"][1]], \n+            mag[band[\"column_names\"][2]], mag[band[\"column_names\"][3]], trans_func, magerr[band[\"column_names\"][0]], \n+            magerr[band[\"column_names\"][1]], magerr[band[\"column_names\"][2]], magerr[band[\"column_names\"][3]], trans_func_prime=trans_func_prime, \n+            mag_name_A=band[\"column_names\"][0], mag_name_B=band[\"column_names\"][1], mag_name_C=band[\"column_names\"][2], mag_name_D=band[\"column_names\"][3],\n+            xmin=band[\"interpolation_range\"][0], xmax=band[\"interpolation_range\"][1], plot_dir=args.plot_dir, mer_data=None, save_outlier=True)\n+\n+        results_dict[\"plot_files\"][\"photometry_validation_vis_detection_scatter\"] = deviation_plot\n+        results_dict[\"plot_files\"][\"photometry_validation_vis_detection_hist\"] = deviation_hist\n+        results_dict[\"plot_files\"][\"vis_transformation_function\"] = trans_func_plot\n+\n+\n+    # ra_gaia, dec_gaia, mag_g_gaia, magerr_g_gaia, mag_bp_gaia, magerr_bp_gaia, mag_rp_gaia, magerr_rp_gaia = read_gaia_catalog(catalog_path=args.gaia_cutout)\n+    # ra_mer, dec_mer, mag_vis_psf, magerr_vis_psf, mer_data = read_mer_catalog(catalog_path=args.mer_catalog, \n+    #     flux_column=args.flux_column, \n+    #     fluxerr_column=args.fluxerr_column,\n+    #     flag_column=args.mer_flag_column,\n+    #     flag_value=args.mer_flag_value\n+    #     )\n+\n+    # # Cross match Gaia and MER catalog\n+    # matched_idx, matched_quality, tot_matched = MER_CrossMatchModule.MER_match_catalogs_sky(ra1 = ra_mer,\n+    #                                                                                         dec1 = dec_mer,\n+    #                                                                                         ra2 = ra_gaia,\n+    #                                                                                         dec2 = dec_gaia,\n+    #                                                                                         id_col_cat2 = np.arange(len(ra_gaia)),\n+    #                                                                                         max_dist = 0.6,\n+    #                                                                                         col1 = [],\n+    #                                                                                         col2 = [],\n+    #                                                                                         thresh = [],\n+    #                                                                                         weights = [])\n+\n+    # matched_idx = np.array(matched_idx)\n+    # mer_selector = np.where(matched_idx != -1)[0]\n+    # matched_idx = matched_idx[mer_selector]\n+    # mag_vis_psf_matched = mag_vis_psf[mer_selector]\n+    # magerr_vis_psf_matched = magerr_vis_psf[mer_selector]\n+    \n+    # # For testing\n+    # mer_data_matched = mer_data[mer_selector]\n+    \n+    # mag_g_gaia_matched = []\n+    # magerr_g_gaia_matched = []\n+    # mag_bp_gaia_matched = []\n+    # magerr_bp_gaia_matched = []\n+    # mag_rp_gaia_matched = []\n+    # magerr_rp_gaia_matched = []\n+\n+    # for i in range(len(mer_selector)):\n+    #     mag_g_gaia_matched.append(mag_g_gaia[matched_idx[i]])\n+    #     magerr_g_gaia_matched.append(magerr_g_gaia[matched_idx[i]])\n+    #     mag_bp_gaia_matched.append(mag_bp_gaia[matched_idx[i]])\n+    #     magerr_bp_gaia_matched.append(magerr_bp_gaia[matched_idx[i]])\n+    #     mag_rp_gaia_matched.append(mag_rp_gaia[matched_idx[i]])\n+    #     magerr_rp_gaia_matched.append(magerr_rp_gaia[matched_idx[i]])\n+    # mag_g_gaia_matched = np.array(mag_g_gaia_matched)\n+    # magerr_g_gaia_matched = np.array(magerr_g_gaia_matched)\n+    # mag_bp_gaia_matched = np.array(mag_bp_gaia_matched)\n+    # magerr_bp_gaia_matched = np.array(magerr_bp_gaia_matched)\n+    # mag_rp_gaia_matched = np.array(mag_rp_gaia_matched)\n+    # magerr_rp_gaia_matched = np.array(mag_rp_gaia_matched)\n+\n+    # # Get tansformation function\n+    # trans_func, trans_func_prime, bin_edges, BP_MIN_RP_tf, G_MIN_VIS_tf, bin_number, trans_func_plot = get_trans_func(args.trans_func,\n+    #                 x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_min=-1., bp_rp_max=3., nbins=10, plot_dir=args.plot_dir)\n+\n+    # mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist = evaluate_deviation(mag_g_gaia_matched, mag_bp_gaia_matched, \n+    #                 mag_rp_gaia_matched, mag_vis_psf_matched, trans_func, \n+    #                 magerr_g_gaia_matched, magerr_bp_gaia_matched, magerr_rp_gaia_matched,\n+    #                 magerr_vis_psf_matched, trans_func_prime=trans_func_prime, mag_mer_name=args.mer_mag_name,\n+    #                 bp_rp_min=-1., bp_rp_max=3., plot_dir=args.plot_dir, mer_data=mer_data_matched, save_outlier=True)\n+    \n+    # results_dict[\"plot_files\"][\"photometry_validation_vis_detection_scatter\"] = deviation_plot\n+    # results_dict[\"plot_files\"][\"photometry_validation_vis_detection_hist\"] = deviation_hist\n+    # results_dict[\"plot_files\"][\"vis_transformation_function\"] = trans_func_plot\n+    \n+    report_file_names = create_analysis_report(results_dict, workdir=args.plot_dir, logger=logger)\n+\n+    logger.info(\"mean deviation = %.5f\"%(mean_diff))\n+    logger.info(\"mean absolute deviation = %.5f\"%(mean_abs_diff))\n+    logger.info(\"NMAD of deviation= %.5f\"%(nmad_diff))\n+\n+    logger.info('#')\n+    logger.info('# Exiting MER_ValidationPrg mainMethod()')\n+    logger.info('#')\n",
                            "re-organize photometry validation",
                            "yfang",
                            "2023-07-10T15:26:16.000+02:00",
                            "59dbe91c8025269aec5e6b35a0d61de128483ab7"
                        ]
                    ],
                    "CMakeLists.txt": [
                        [
                            "@@ -20,4 +20,4 @@ elements_project(MER_Validation 10.2 USE Elements 6.2.1\n                                         MER_Morphology 10.2\n                                         MER_PSFHomogenization 10.2\n                                         ST_DataModelTools 9.2.2\n-                                        EL_Utils 1.4.2)\n+                                        EL_Utils 1.5.1)\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-08-14T17:59:16.000+02:00",
                            "928031fdcc2cd7bbfbfadfdec41cfcb87e6d57f9"
                        ],
                        [
                            "@@ -20,4 +20,4 @@ elements_project(MER_Validation 10.2 USE Elements 6.2.1\n                                         MER_Morphology 10.2\n                                         MER_PSFHomogenization 10.2\n                                         ST_DataModelTools 9.2.2\n-                                        EL_Utils 1.4.1)\n+                                        EL_Utils 1.4.2)\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-08-11T15:41:07.000+02:00",
                            "3439f2b2c5d1617a26353d57808735c69cf7a538"
                        ],
                        [
                            "@@ -19,5 +19,5 @@ elements_project(MER_Validation 10.2 USE Elements 6.2.1\n                                         MER_Classification 10.2\n                                         MER_Morphology 10.2\n                                         MER_PSFHomogenization 10.2\n-                                        ST_DataModelTools 9.2.1\n+                                        ST_DataModelTools 9.2.2\n                                         EL_Utils 1.4.1)\n",
                            "add depth validation & background validation",
                            "yfang",
                            "2023-08-11T15:40:10.000+02:00",
                            "62463cc0ce935f15628eb27c736293e7b3af7e99"
                        ],
                        [
                            "@@ -19,5 +19,5 @@ elements_project(MER_Validation 10.2 USE Elements 6.2.1\n                                         MER_Classification 10.2\n                                         MER_Morphology 10.2\n                                         MER_PSFHomogenization 10.2\n-                                        ST_DataModelTools 9.2.1\n-                                        EL_Utils 1.4.1)\n+                                        ST_DataModelTools 9.2.2\n+                                        EL_Utils 1.4.2)\n",
                            "Merge branch 'develop' of gitlab.euclid-sgs.uk:PF-MER/MER_Validation into develop",
                            "Elie Soubrie",
                            "2023-08-11T13:11:12.000+00:00",
                            "83a7d7f2c8e3bc62d52bb2339cc5be25af953621"
                        ],
                        [
                            "@@ -19,5 +19,5 @@ elements_project(MER_Validation 10.2 USE Elements 6.2.1\n                                         MER_Classification 10.2\n                                         MER_Morphology 10.2\n                                         MER_PSFHomogenization 10.2\n-                                        ST_DataModelTools 9.2.1\n-                                        EL_Utils 1.4.1)\n+                                        ST_DataModelTools 9.2.2\n+                                        EL_Utils 1.4.2)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-08-11T13:00:12.000+00:00",
                            "2612a5557ac825db9ac7c62bb98ad7cd92b1f0a7"
                        ],
                        [
                            "@@ -12,11 +12,12 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_Validation 10.1 USE Elements 6.2.1\n-                                        MER_DA 10.1\n-                                        MER_PsfMosaic 10.1\n-                                        MER_DataModelUtils 10.1\n-                                        MER_Classification 10.1\n-                                        MER_Morphology 10.1\n+elements_project(MER_Validation 10.2 USE Elements 6.2.1\n+                                        MER_DA 10.2\n+                                        MER_PsfMosaic 10.2\n+                                        MER_DataModelUtils 10.2\n+                                        MER_Classification 10.2\n+                                        MER_Morphology 10.2\n+                                        MER_PSFHomogenization 10.2\n                                         ST_DataModelTools 9.2.1\n                                         EL_Utils 1.4.1)\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-10T15:27:04.000+02:00",
                            "b4030040f2cf4ffc0140a2f4f30e0e1b83a1ff07"
                        ],
                        [
                            "@@ -18,5 +18,6 @@ elements_project(MER_Validation 10.2 USE Elements 6.2.1\n                                         MER_DataModelUtils 10.2\n                                         MER_Classification 10.2\n                                         MER_Morphology 10.2\n+                                        MER_PSFHomogenization 10.2\n                                         ST_DataModelTools 9.2.1\n                                         EL_Utils 1.4.1)\n",
                            "Adds missing dependency",
                            "Javier Gracia Carpio",
                            "2023-07-05T10:20:54.000+00:00",
                            "a8e9763de968b1d9b295a9f3c1edacd915709baf"
                        ],
                        [
                            "@@ -12,11 +12,11 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_Validation 10.1 USE Elements 6.2.1\n-                                        MER_DA 10.1\n-                                        MER_PsfMosaic 10.1\n-                                        MER_DataModelUtils 10.1\n-                                        MER_Classification 10.1\n-                                        MER_Morphology 10.1\n+elements_project(MER_Validation 10.2 USE Elements 6.2.1\n+                                        MER_DA 10.2\n+                                        MER_PsfMosaic 10.2\n+                                        MER_DataModelUtils 10.2\n+                                        MER_Classification 10.2\n+                                        MER_Morphology 10.2\n                                         ST_DataModelTools 9.2.1\n                                         EL_Utils 1.4.1)\n",
                            "Merge remote-tracking branch 'origin/develop' into",
                            "Martin Kuemmel",
                            "2023-07-04T21:06:22.000+02:00",
                            "9df9a0bbe52422666d398f4cedc0bca63a870d5c"
                        ],
                        [
                            "@@ -12,11 +12,11 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_Validation 10.1 USE Elements 6.2.1\n-                                        MER_DA 10.1\n-                                        MER_PsfMosaic 10.1\n-                                        MER_DataModelUtils 10.1\n-                                        MER_Classification 10.1\n-                                        MER_Morphology 10.1\n+elements_project(MER_Validation 10.2 USE Elements 6.2.1\n+                                        MER_DA 10.2\n+                                        MER_PsfMosaic 10.2\n+                                        MER_DataModelUtils 10.2\n+                                        MER_Classification 10.2\n+                                        MER_Morphology 10.2\n                                         ST_DataModelTools 9.2.1\n                                         EL_Utils 1.4.1)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-07-03T15:17:45.000+00:00",
                            "d7a0e033806501818a0676dcd134d85801655769"
                        ],
                        [
                            "@@ -12,16 +12,6 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-<<<<<<< HEAD\n-elements_project(MER_Validation 10.0 USE Elements 6.2.1\n-                                        MER_DA 10.1\n-                                        MER_PsfMosaic 10.0\n-                                        MER_DataModelUtils 10.0\n-                                        MER_Classification 10.0\n-                                        MER_Morphology 10.0\n-                                        ST_DataModelTools 9.1.2\n-                                        EL_Utils 1.3.1)\n-=======\n elements_project(MER_Validation 10.1 USE Elements 6.2.1\n                                         MER_DA 10.1\n                                         MER_PsfMosaic 10.1\n@@ -30,4 +20,3 @@ elements_project(MER_Validation 10.1 USE Elements 6.2.1\n                                         MER_Morphology 10.1\n                                         ST_DataModelTools 9.2.1\n                                         EL_Utils 1.4.1)\n->>>>>>> 16a0a46648c99b5e0035918932822d664758c402\n",
                            "modified the codes to make sure they are compatible with newer version of scipy",
                            "yfang",
                            "2023-06-28T16:39:55.000+02:00",
                            "fb1768e9f1bef1acafdd7f1425494afe816099cd"
                        ],
                        [
                            "@@ -12,6 +12,7 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n+<<<<<<< HEAD\n elements_project(MER_Validation 10.0 USE Elements 6.2.1\n                                         MER_DA 10.1\n                                         MER_PsfMosaic 10.0\n@@ -20,3 +21,13 @@ elements_project(MER_Validation 10.0 USE Elements 6.2.1\n                                         MER_Morphology 10.0\n                                         ST_DataModelTools 9.1.2\n                                         EL_Utils 1.3.1)\n+=======\n+elements_project(MER_Validation 10.1 USE Elements 6.2.1\n+                                        MER_DA 10.1\n+                                        MER_PsfMosaic 10.1\n+                                        MER_DataModelUtils 10.1\n+                                        MER_Classification 10.1\n+                                        MER_Morphology 10.1\n+                                        ST_DataModelTools 9.2.1\n+                                        EL_Utils 1.4.1)\n+>>>>>>> 16a0a46648c99b5e0035918932822d664758c402\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ],
                        [
                            "@@ -12,8 +12,8 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_Validation 10.0 USE Elements 6.1.1\n-                                        MER_DA 10.0\n+elements_project(MER_Validation 10.0 USE Elements 6.2.1\n+                                        MER_DA 10.1\n                                         MER_PsfMosaic 10.0\n                                         MER_DataModelUtils 10.0\n                                         MER_Classification 10.0\n",
                            "update cmakelist",
                            "yfang",
                            "2023-06-28T16:25:38.000+02:00",
                            "01f5f3552f85811020b0d40502d52306d89491a7"
                        ],
                        [
                            "@@ -12,11 +12,11 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_Validation 10.0 USE Elements 6.1.1\n-                                        MER_DA 10.0\n-                                        MER_PsfMosaic 10.0\n-                                        MER_DataModelUtils 10.0\n-                                        MER_Classification 10.0\n-                                        MER_Morphology 10.0\n-                                        ST_DataModelTools 9.1.2\n-                                        EL_Utils 1.3.1)\n+elements_project(MER_Validation 10.1 USE Elements 6.2.1\n+                                        MER_DA 10.1\n+                                        MER_PsfMosaic 10.1\n+                                        MER_DataModelUtils 10.1\n+                                        MER_Classification 10.1\n+                                        MER_Morphology 10.1\n+                                        ST_DataModelTools 9.2.1\n+                                        EL_Utils 1.4.1)\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:35:11.000+00:00",
                            "1a900abe2a5650a85ec0fbde2e25dc6f7b5b6022"
                        ]
                    ],
                    "MER_DetectionValidation/python/MER_DetectionValidation/MER_DetectionValidationPrg.py": [
                        [
                            "@@ -631,6 +631,13 @@ def mainMethod(args):\n     analysis_result.set_processing_mode(processing_mode)\n     analysis_result.set_figures_tar_file(tar_file_name)\n \n+    # create and store a generic key/value pair\n+    filling_parameter = dm_utils.create_generic_kv_parameter(key=\"FILLING_FACTOR\",\n+                                                             value=round(100.*filling_factor, 1), \n+                                                             value_type=\"double\", unit=\"[%]\",\n+                                                             description=\"tile filling factor\")\n+    analysis_result.add_parameter(filling_parameter)\n+\n     # Save the analysis result data product as an XML file\n     logger.info(\"# Saving the analysis result data product\")\n     analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-08-11T15:41:07.000+02:00",
                            "3439f2b2c5d1617a26353d57808735c69cf7a538"
                        ],
                        [
                            "@@ -30,6 +30,7 @@ import os.path\n import json\n import tempfile\n import numpy\n+import time\n \n import argparse\n import ElementsKernel.Logging as log\n@@ -359,6 +360,9 @@ def mainMethod(args):\n     logger.info('# Entering MER_DetectionValidationPrg mainMethod()')\n     logger.info('#')\n \n+    # Store the start time\n+    start_time = time.time()\n+\n     # print all parameters to the screen\n     print_input_arguments(args, logger)\n \n@@ -631,6 +635,9 @@ def mainMethod(args):\n     logger.info(\"# Saving the analysis result data product\")\n     analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n \n+    # Print the time spent running the step\n+    logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n+\n     logger.info('#')\n     logger.info('# Exiting MER_DetectionValidationPrg mainMethod()')\n     logger.info('#')\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-06-16T14:11:46.000+02:00",
                            "504febbf2c08fe2012b74d4f6aae5c5693624ea2"
                        ]
                    ],
                    "MER_MorphologyValidation/CMakeLists.txt": [
                        [
                            "@@ -72,6 +72,7 @@ elements_add_python_program(MER_MorphologyPlotConcentrationHistogram MER_Morphol\n elements_add_python_program(MER_MorphologyPlotGiniHistogram MER_MorphologyValidation.MER_MorphologyPlotGiniHistogram)\n elements_add_python_program(MER_MorphologyPlotM20Histogram MER_MorphologyValidation.MER_MorphologyPlotM20Histogram)\n elements_add_python_program(MER_MorphologyPlotSmoothnessHistogram MER_MorphologyValidation.MER_MorphologyPlotSmoothnessHistogram)\n+elements_add_python_program(MER_SersicValidationPrg MER_MorphologyValidation.MER_SersicValidationPrg)\n \n \n #===============================================================================\n@@ -80,4 +81,4 @@ elements_add_python_program(MER_MorphologyPlotSmoothnessHistogram MER_Morphology\n #          elements_install_conf_files()\n #===============================================================================\n elements_install_conf_files()\n-elements_install_aux_files()\n\\ No newline at end of file\n+elements_install_aux_files()\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-08-11T15:41:07.000+02:00",
                            "3439f2b2c5d1617a26353d57808735c69cf7a538"
                        ]
                    ],
                    "MER_MorphologyValidation/conf/MER_MorphologyValidation/MER_SersicValidationPrg.conf": [
                        [
                            "@@ -0,0 +1 @@\n+# Write your program options here. e.g. : option = string\n\\ No newline at end of file\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-08-11T15:41:07.000+02:00",
                            "3439f2b2c5d1617a26353d57808735c69cf7a538"
                        ]
                    ],
                    "MER_MorphologyValidation/python/MER_MorphologyValidation/MER_MorphologyValidationPrg.py": [
                        [
                            "@@ -37,6 +37,8 @@ from MER_MorphologyValidation import MER_MorphologyPlotAsymmetryHistogram\n from MER_MorphologyValidation import MER_MorphologyPlotSmoothnessHistogram\n from MER_MorphologyValidation import MER_MorphologyPlotGiniHistogram\n from MER_MorphologyValidation import MER_MorphologyPlotM20Histogram\n+from MER_MorphologyValidation import MER_SersicPlots\n+\n from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n@@ -109,6 +111,44 @@ def create_analysis_report(morphology_figures, tile_index, workdir, logger):\n         [AnalysisFigure(morphology_figures['m20_plot'], latex_scale=0.55)])\n     analysis_report.add_section(morphology_m20_section)\n \n+    # add the sersic chapters if they exist\n+    if 'sersic_radius' in morphology_figures:\n+        # Create a new analysis section\n+        sersic_validation_intro_section = AnalysisSection(\"Sersic Fitting Validation\")\n+        sersic_intro = ['The following plots compare the morphological parameters determined with a Sersic fit',\n+                        'with the given values from the TU catalog. Unfortunately there is a discrepancy between ',\n+                        'simulated model (DISK+BULGE) and the fitted model (Sersic). Since the distribution of',\n+                        'bulge_fraction shows a bi-modal feature, the TU objects are split between \"disks\"',\n+                        '(bulge_fraction<0.1) and bulges (bulge_fraction>0.9), and the comparison is done using',\n+                        'the TU components of these two sub-populations.']\n+        sersic_validation_intro_section.set_text(sersic_intro)\n+        analysis_report.add_section(sersic_validation_intro_section)\n+    \n+        sersic_radii_section = AnalysisSection(\"Disk/Bulge radii\")\n+        sersic_radii_section.set_figures(\n+            [AnalysisFigure(morphology_figures['sersic_radius'], latex_scale=0.55)])\n+        analysis_report.add_section(sersic_radii_section)\n+        \n+        sersic_bulgeaxratio_section = AnalysisSection(\"Disk/Bulge axis ratios\")\n+        sersic_bulgeaxratio_section.set_figures(\n+            [AnalysisFigure(morphology_figures['sersic_axratio'], latex_scale=0.55)])\n+        analysis_report.add_section(sersic_bulgeaxratio_section)\n+    \n+        sersic_angle_section = AnalysisSection(\"Disk/Bulge angle\")\n+        sersic_angle_section.set_figures(\n+            [AnalysisFigure(morphology_figures['sersic_angle'], latex_scale=0.55)])\n+        analysis_report.add_section(sersic_angle_section)\n+    \n+        sersic_bulgeindex_section = AnalysisSection(\"Bulges Sersic indices\")\n+        sersic_bulgeindex_section.set_figures(\n+            [AnalysisFigure(morphology_figures['sersic_index_bulge'], latex_scale=0.55)])\n+        analysis_report.add_section(sersic_bulgeindex_section)\n+    \n+        sersic_histindex_section = AnalysisSection(\"Disk/Bulge Sersic index histograms\")\n+        sersic_histindex_section.set_figures(\n+            [AnalysisFigure(morphology_figures['sersic_index_histo'], latex_scale=0.55)])\n+        analysis_report.add_section(sersic_histindex_section)\n+    \n     # Add an index to the analysis report\n     analysis_report.add_index()\n \n@@ -234,6 +274,26 @@ def mainMethod(args):\n     morphology_figures['m20_plot'] = m20_plot_file\n     histo_m20_plot.plot(out_plot_name=m20_plot_file)\n \n+    # get names for the plot files\n+    radius_plot_file = os.path.join(figsdir, '%s_sersic_radius.png'%matched_catalog.get_data().split('.fits')[0])\n+    sersic_indices_histo_file = os.path.join(figsdir, '%s_sersic_indices_histo.png'%matched_catalog.get_data().split('.fits')[0])\n+    sersic_indices_bulge_file = os.path.join(figsdir, '%s_sersic_indices_bulges.png'%matched_catalog.get_data().split('.fits')[0])\n+    ax_ratio_file = os.path.join(figsdir, '%s_sersic_axratio.png'%matched_catalog.get_data().split('.fits')[0])\n+    angle_plot_file = os.path.join(figsdir, '%s_sersic_angle.png'%matched_catalog.get_data().split('.fits')[0])\n+\n+    # make the sersic plots    \n+    sersic_plots = MER_SersicPlots.MER_SersicPlots(matched_catalog_file, logger)\n+    ret_value = sersic_plots.make_sersic_fit_plots(vis_mag_lim=24.0, plot_path=radius_plot_file,\n+                                                   plot_pathII=sersic_indices_histo_file, plot_pathIII=sersic_indices_bulge_file,\n+                                                   plot_pathIV=ax_ratio_file, plot_pathV=angle_plot_file)\n+\n+    if ret_value:\n+        morphology_figures['sersic_radius'] = radius_plot_file\n+        morphology_figures['sersic_index_histo'] = sersic_indices_histo_file\n+        morphology_figures['sersic_index_bulge'] = sersic_indices_bulge_file\n+        morphology_figures['sersic_axratio'] = ax_ratio_file\n+        morphology_figures['sersic_angle'] = angle_plot_file\n+\n     # Create the analysis report\n     logger.info(\"# Creating the morphology analysis report...\")\n     report_file_names = create_analysis_report(\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-08-11T15:41:07.000+02:00",
                            "3439f2b2c5d1617a26353d57808735c69cf7a538"
                        ],
                        [
                            "@@ -111,41 +111,43 @@ def create_analysis_report(morphology_figures, tile_index, workdir, logger):\n         [AnalysisFigure(morphology_figures['m20_plot'], latex_scale=0.55)])\n     analysis_report.add_section(morphology_m20_section)\n \n-    # Create a new analysis section\n-    sersic_validation_intro_section = AnalysisSection(\"Sersic Fitting Validation\")\n-    sersic_intro = ['The following plots compare the morphological parameters determined with a Sersic fit',\n-                    'with the given values from the TU catalog. Unfortunately there is a discrepancy between ',\n-                    'simulated model (DISK+BULGE) and the fitted model (Sersic). Since the distribution of',\n-                    'bulge_fraction shows a bi-modal feature, the TU objects are split between \"disks\"',\n-                    '(bulge_fraction<0.1) and bulges (bulge_fraction>0.9), and the comparison is done using',\n-                    'the TU components of these two sub-populations.']\n-    sersic_validation_intro_section.set_text(sersic_intro)\n-    analysis_report.add_section(sersic_validation_intro_section)\n-\n-    sersic_radii_section = AnalysisSection(\"Disk/Bulge radii\")\n-    sersic_radii_section.set_figures(\n-        [AnalysisFigure(morphology_figures['sersic_radius'], latex_scale=0.55)])\n-    analysis_report.add_section(sersic_radii_section)\n+    # add the sersic chapters if they exist\n+    if 'sersic_radius' in morphology_figures:\n+        # Create a new analysis section\n+        sersic_validation_intro_section = AnalysisSection(\"Sersic Fitting Validation\")\n+        sersic_intro = ['The following plots compare the morphological parameters determined with a Sersic fit',\n+                        'with the given values from the TU catalog. Unfortunately there is a discrepancy between ',\n+                        'simulated model (DISK+BULGE) and the fitted model (Sersic). Since the distribution of',\n+                        'bulge_fraction shows a bi-modal feature, the TU objects are split between \"disks\"',\n+                        '(bulge_fraction<0.1) and bulges (bulge_fraction>0.9), and the comparison is done using',\n+                        'the TU components of these two sub-populations.']\n+        sersic_validation_intro_section.set_text(sersic_intro)\n+        analysis_report.add_section(sersic_validation_intro_section)\n+    \n+        sersic_radii_section = AnalysisSection(\"Disk/Bulge radii\")\n+        sersic_radii_section.set_figures(\n+            [AnalysisFigure(morphology_figures['sersic_radius'], latex_scale=0.55)])\n+        analysis_report.add_section(sersic_radii_section)\n+        \n+        sersic_bulgeaxratio_section = AnalysisSection(\"Disk/Bulge axis ratios\")\n+        sersic_bulgeaxratio_section.set_figures(\n+            [AnalysisFigure(morphology_figures['sersic_axratio'], latex_scale=0.55)])\n+        analysis_report.add_section(sersic_bulgeaxratio_section)\n+    \n+        sersic_angle_section = AnalysisSection(\"Disk/Bulge angle\")\n+        sersic_angle_section.set_figures(\n+            [AnalysisFigure(morphology_figures['sersic_angle'], latex_scale=0.55)])\n+        analysis_report.add_section(sersic_angle_section)\n     \n-    sersic_bulgeaxratio_section = AnalysisSection(\"Disk/Bulge axis ratios\")\n-    sersic_bulgeaxratio_section.set_figures(\n-        [AnalysisFigure(morphology_figures['sersic_axratio'], latex_scale=0.55)])\n-    analysis_report.add_section(sersic_bulgeaxratio_section)\n-\n-    sersic_angle_section = AnalysisSection(\"Disk/Bulge angle\")\n-    sersic_angle_section.set_figures(\n-        [AnalysisFigure(morphology_figures['sersic_angle'], latex_scale=0.55)])\n-    analysis_report.add_section(sersic_angle_section)\n-\n-    sersic_bulgeindex_section = AnalysisSection(\"Bulges Sersic indices\")\n-    sersic_bulgeindex_section.set_figures(\n-        [AnalysisFigure(morphology_figures['sersic_index_bulge'], latex_scale=0.55)])\n-    analysis_report.add_section(sersic_bulgeindex_section)\n-\n-    sersic_histindex_section = AnalysisSection(\"Disk/Bulge Sersic index histograms\")\n-    sersic_histindex_section.set_figures(\n-        [AnalysisFigure(morphology_figures['sersic_index_histo'], latex_scale=0.55)])\n-    analysis_report.add_section(sersic_histindex_section)\n+        sersic_bulgeindex_section = AnalysisSection(\"Bulges Sersic indices\")\n+        sersic_bulgeindex_section.set_figures(\n+            [AnalysisFigure(morphology_figures['sersic_index_bulge'], latex_scale=0.55)])\n+        analysis_report.add_section(sersic_bulgeindex_section)\n+    \n+        sersic_histindex_section = AnalysisSection(\"Disk/Bulge Sersic index histograms\")\n+        sersic_histindex_section.set_figures(\n+            [AnalysisFigure(morphology_figures['sersic_index_histo'], latex_scale=0.55)])\n+        analysis_report.add_section(sersic_histindex_section)\n     \n     # Add an index to the analysis report\n     analysis_report.add_index()\n@@ -278,18 +280,19 @@ def mainMethod(args):\n     sersic_indices_bulge_file = os.path.join(figsdir, '%s_sersic_indices_bulges.png'%matched_catalog.get_data().split('.fits')[0])\n     ax_ratio_file = os.path.join(figsdir, '%s_sersic_axratio.png'%matched_catalog.get_data().split('.fits')[0])\n     angle_plot_file = os.path.join(figsdir, '%s_sersic_angle.png'%matched_catalog.get_data().split('.fits')[0])\n-    morphology_figures['sersic_radius'] = radius_plot_file\n-    morphology_figures['sersic_index_histo'] = sersic_indices_histo_file\n-    morphology_figures['sersic_index_bulge'] = sersic_indices_bulge_file\n-    morphology_figures['sersic_axratio'] = ax_ratio_file\n-    morphology_figures['sersic_angle'] = angle_plot_file\n \n     # make the sersic plots    \n     sersic_plots = MER_SersicPlots.MER_SersicPlots(matched_catalog_file, logger)\n-    sersic_plots.make_sersic_fit_plots(vis_mag_lim=24.0, plot_path=radius_plot_file,\n-                                       plot_pathII=sersic_indices_histo_file, plot_pathIII=sersic_indices_bulge_file,\n-                                       plot_pathIV=ax_ratio_file, plot_pathV=angle_plot_file)\n-\n+    ret_value = sersic_plots.make_sersic_fit_plots(vis_mag_lim=24.0, plot_path=radius_plot_file,\n+                                                   plot_pathII=sersic_indices_histo_file, plot_pathIII=sersic_indices_bulge_file,\n+                                                   plot_pathIV=ax_ratio_file, plot_pathV=angle_plot_file)\n+\n+    if ret_value:\n+        morphology_figures['sersic_radius'] = radius_plot_file\n+        morphology_figures['sersic_index_histo'] = sersic_indices_histo_file\n+        morphology_figures['sersic_index_bulge'] = sersic_indices_bulge_file\n+        morphology_figures['sersic_axratio'] = ax_ratio_file\n+        morphology_figures['sersic_angle'] = angle_plot_file\n \n     # Create the analysis report\n     logger.info(\"# Creating the morphology analysis report...\")\n",
                            "Now works also if no fitting was done.",
                            "Martin Kuemmel",
                            "2023-07-13T17:28:21.000+02:00",
                            "6f55025775dd6d26d895814cc45d9944c8c6a201"
                        ],
                        [
                            "@@ -111,6 +111,17 @@ def create_analysis_report(morphology_figures, tile_index, workdir, logger):\n         [AnalysisFigure(morphology_figures['m20_plot'], latex_scale=0.55)])\n     analysis_report.add_section(morphology_m20_section)\n \n+    # Create a new analysis section\n+    sersic_validation_intro_section = AnalysisSection(\"Sersic Fitting Validation\")\n+    sersic_intro = ['The following plots compare the morphological parameters determined with a Sersic fit',\n+                    'with the given values from the TU catalog. Unfortunately there is a discrepancy between ',\n+                    'simulated model (DISK+BULGE) and the fitted model (Sersic). Since the distribution of',\n+                    'bulge_fraction shows a bi-modal feature, the TU objects are split between \"disks\"',\n+                    '(bulge_fraction<0.1) and bulges (bulge_fraction>0.9), and the comparison is done using',\n+                    'the TU components of these two sub-populations.']\n+    sersic_validation_intro_section.set_text(sersic_intro)\n+    analysis_report.add_section(sersic_validation_intro_section)\n+\n     sersic_radii_section = AnalysisSection(\"Disk/Bulge radii\")\n     sersic_radii_section.set_figures(\n         [AnalysisFigure(morphology_figures['sersic_radius'], latex_scale=0.55)])\n",
                            "Added some introduction",
                            "Martin Kuemmel",
                            "2023-07-13T15:24:03.000+02:00",
                            "bc104146b03160bab4c72db89e179898f1004a09"
                        ],
                        [
                            "@@ -111,17 +111,27 @@ def create_analysis_report(morphology_figures, tile_index, workdir, logger):\n         [AnalysisFigure(morphology_figures['m20_plot'], latex_scale=0.55)])\n     analysis_report.add_section(morphology_m20_section)\n \n-    sersic_radii_section = AnalysisSection(\"Sersic fit radii\")\n+    sersic_radii_section = AnalysisSection(\"Disk/Bulge radii\")\n     sersic_radii_section.set_figures(\n         [AnalysisFigure(morphology_figures['sersic_radius'], latex_scale=0.55)])\n     analysis_report.add_section(sersic_radii_section)\n     \n-    sersic_bulgeindex_section = AnalysisSection(\"Sersic indices bulges\")\n+    sersic_bulgeaxratio_section = AnalysisSection(\"Disk/Bulge axis ratios\")\n+    sersic_bulgeaxratio_section.set_figures(\n+        [AnalysisFigure(morphology_figures['sersic_axratio'], latex_scale=0.55)])\n+    analysis_report.add_section(sersic_bulgeaxratio_section)\n+\n+    sersic_angle_section = AnalysisSection(\"Disk/Bulge angle\")\n+    sersic_angle_section.set_figures(\n+        [AnalysisFigure(morphology_figures['sersic_angle'], latex_scale=0.55)])\n+    analysis_report.add_section(sersic_angle_section)\n+\n+    sersic_bulgeindex_section = AnalysisSection(\"Bulges Sersic indices\")\n     sersic_bulgeindex_section.set_figures(\n         [AnalysisFigure(morphology_figures['sersic_index_bulge'], latex_scale=0.55)])\n     analysis_report.add_section(sersic_bulgeindex_section)\n \n-    sersic_histindex_section = AnalysisSection(\"Sersic index histograms\")\n+    sersic_histindex_section = AnalysisSection(\"Disk/Bulge Sersic index histograms\")\n     sersic_histindex_section.set_figures(\n         [AnalysisFigure(morphology_figures['sersic_index_histo'], latex_scale=0.55)])\n     analysis_report.add_section(sersic_histindex_section)\n@@ -252,17 +262,22 @@ def mainMethod(args):\n     histo_m20_plot.plot(out_plot_name=m20_plot_file)\n \n     # get names for the plot files\n-    disk_radius_plot_file = os.path.join(figsdir, '%s_disk_radius.png'%matched_catalog.get_data().split('.fits')[0])\n-    sersic_indices_plot_file = os.path.join(figsdir, '%s_sersic_indices.png'%matched_catalog.get_data().split('.fits')[0])\n-    sersic_indices_bulge_file = os.path.join(figsdir, '%s_sersic_bulges.png'%matched_catalog.get_data().split('.fits')[0])\n-    morphology_figures['sersic_radius'] = disk_radius_plot_file\n-    morphology_figures['sersic_index_histo'] = sersic_indices_plot_file\n+    radius_plot_file = os.path.join(figsdir, '%s_sersic_radius.png'%matched_catalog.get_data().split('.fits')[0])\n+    sersic_indices_histo_file = os.path.join(figsdir, '%s_sersic_indices_histo.png'%matched_catalog.get_data().split('.fits')[0])\n+    sersic_indices_bulge_file = os.path.join(figsdir, '%s_sersic_indices_bulges.png'%matched_catalog.get_data().split('.fits')[0])\n+    ax_ratio_file = os.path.join(figsdir, '%s_sersic_axratio.png'%matched_catalog.get_data().split('.fits')[0])\n+    angle_plot_file = os.path.join(figsdir, '%s_sersic_angle.png'%matched_catalog.get_data().split('.fits')[0])\n+    morphology_figures['sersic_radius'] = radius_plot_file\n+    morphology_figures['sersic_index_histo'] = sersic_indices_histo_file\n     morphology_figures['sersic_index_bulge'] = sersic_indices_bulge_file\n+    morphology_figures['sersic_axratio'] = ax_ratio_file\n+    morphology_figures['sersic_angle'] = angle_plot_file\n \n     # make the sersic plots    \n     sersic_plots = MER_SersicPlots.MER_SersicPlots(matched_catalog_file, logger)\n-    sersic_plots.make_radius_plot(vis_mag_lim=24.0, plot_path=disk_radius_plot_file,\n-                                  plot_pathII=sersic_indices_plot_file, plot_pathIII=sersic_indices_bulge_file)\n+    sersic_plots.make_sersic_fit_plots(vis_mag_lim=24.0, plot_path=radius_plot_file,\n+                                       plot_pathII=sersic_indices_histo_file, plot_pathIII=sersic_indices_bulge_file,\n+                                       plot_pathIV=ax_ratio_file, plot_pathV=angle_plot_file)\n \n \n     # Create the analysis report\n",
                            "Added some documentation",
                            "Martin Kuemmel",
                            "2023-07-13T14:49:37.000+02:00",
                            "7330292b2591706cbd16dd9469f77072478917c1"
                        ],
                        [
                            "@@ -37,6 +37,8 @@ from MER_MorphologyValidation import MER_MorphologyPlotAsymmetryHistogram\n from MER_MorphologyValidation import MER_MorphologyPlotSmoothnessHistogram\n from MER_MorphologyValidation import MER_MorphologyPlotGiniHistogram\n from MER_MorphologyValidation import MER_MorphologyPlotM20Histogram\n+from MER_MorphologyValidation import MER_SersicPlots\n+\n from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n@@ -109,6 +111,21 @@ def create_analysis_report(morphology_figures, tile_index, workdir, logger):\n         [AnalysisFigure(morphology_figures['m20_plot'], latex_scale=0.55)])\n     analysis_report.add_section(morphology_m20_section)\n \n+    sersic_radii_section = AnalysisSection(\"Sersic fit radii\")\n+    sersic_radii_section.set_figures(\n+        [AnalysisFigure(morphology_figures['sersic_radius'], latex_scale=0.55)])\n+    analysis_report.add_section(sersic_radii_section)\n+    \n+    sersic_bulgeindex_section = AnalysisSection(\"Sersic indices bulges\")\n+    sersic_bulgeindex_section.set_figures(\n+        [AnalysisFigure(morphology_figures['sersic_index_bulge'], latex_scale=0.55)])\n+    analysis_report.add_section(sersic_bulgeindex_section)\n+\n+    sersic_histindex_section = AnalysisSection(\"Sersic index histograms\")\n+    sersic_histindex_section.set_figures(\n+        [AnalysisFigure(morphology_figures['sersic_index_histo'], latex_scale=0.55)])\n+    analysis_report.add_section(sersic_histindex_section)\n+    \n     # Add an index to the analysis report\n     analysis_report.add_index()\n \n@@ -234,6 +251,20 @@ def mainMethod(args):\n     morphology_figures['m20_plot'] = m20_plot_file\n     histo_m20_plot.plot(out_plot_name=m20_plot_file)\n \n+    # get names for the plot files\n+    disk_radius_plot_file = os.path.join(figsdir, '%s_disk_radius.png'%matched_catalog.get_data().split('.fits')[0])\n+    sersic_indices_plot_file = os.path.join(figsdir, '%s_sersic_indices.png'%matched_catalog.get_data().split('.fits')[0])\n+    sersic_indices_bulge_file = os.path.join(figsdir, '%s_sersic_bulges.png'%matched_catalog.get_data().split('.fits')[0])\n+    morphology_figures['sersic_radius'] = disk_radius_plot_file\n+    morphology_figures['sersic_index_histo'] = sersic_indices_plot_file\n+    morphology_figures['sersic_index_bulge'] = sersic_indices_bulge_file\n+\n+    # make the sersic plots    \n+    sersic_plots = MER_SersicPlots.MER_SersicPlots(matched_catalog_file, logger)\n+    sersic_plots.make_radius_plot(vis_mag_lim=24.0, plot_path=disk_radius_plot_file,\n+                                  plot_pathII=sersic_indices_plot_file, plot_pathIII=sersic_indices_bulge_file)\n+\n+\n     # Create the analysis report\n     logger.info(\"# Creating the morphology analysis report...\")\n     report_file_names = create_analysis_report(\n",
                            "Integrated the Sersic plots into the 'normal' morphology part.",
                            "Martin Kuemmel",
                            "2023-07-12T16:49:11.000+02:00",
                            "564805f360b42785dc7d27b5d8e5ea4fa0d79391"
                        ]
                    ],
                    "MER_MorphologyValidation/python/MER_MorphologyValidation/MER_SersicPlots.py": [
                        [
                            "@@ -0,0 +1,323 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+:file: python/MER_MorphologyValidation/MER_SersicPlots.py\n+\n+:date: 07/12/23\n+:author: mkuemmel@usm.lmu.de\n+\n+\"\"\"\n+import os.path\n+\n+import numpy\n+from astropy.io import fits\n+import matplotlib.pyplot as plt\n+\n+from MER_PsfMosaicValidation.CatalogUtils import CatalogUtils\n+\n+from EL_NullValue import NullValueDefinition, DTypeName\n+\n+class MER_SersicPlots(object):\n+    \"\"\"\n+    \"\"\"\n+    def __init__(self, matched_catalog_path, logger=None):\n+        \"\"\"\n+        Initializes the class\n+        \"\"\"\n+        # store the input\n+        self._matched_catalog_path = matched_catalog_path\n+        self._logger               = logger\n+\n+        #null_val = NullValueDefinition()\n+        #self._null_float = null_val.FLOAT \n+        #self._null_double = null_val.DOUBLE \n+        self._null_float = NullValueDefinition.FLOAT \n+        self._null_double = NullValueDefinition.DOUBLE \n+\n+        # create the selector and do the selection\n+        self._disk_selector, self._bulge_selector = self._setup_morpholgy_selection(matched_catalog_path)\n+\n+    def _info(self, message):\n+        \"\"\"General method for user feedback\n+        \"\"\"\n+        # push to the logger if existing\n+        if self._logger is not None:\n+            self._logger.info('# %s' % message)\n+        else:\n+            # push to stdout\n+            print('# %s'%message)\n+\n+    def _setup_morpholgy_selection(self, matched_catalog_path):\n+        \"\"\"\n+        \"\"\"\n+        matched_data = fits.getdata(matched_catalog_path)\n+\n+        # make a selection for the disks and the bulges\n+        disk_selector = numpy.where(numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float, matched_data['TU_BULGE_FRACTION']<0.1), True, False)\n+        bulge_selector = numpy.where(numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float, matched_data['TU_BULGE_FRACTION']>0.9), True, False)\n+    \n+        return disk_selector, bulge_selector\n+\n+    def _get_sersic_data(self, vis_mag_lim=None):\n+        \"\"\"\n+        \"\"\"\n+        self._info('Loading data from: %s'%self._matched_catalog_path)\n+        matched_data = fits.getdata(self._matched_catalog_path)\n+\n+        disk_data = {}\n+        bulge_data = {}\n+        \n+        # get the disk data\n+        disk_data['disk_radius_sepp'] = matched_data['SERSIC_SERSIC_RADIUS'][self._disk_selector]\n+        disk_data['disk_nsersic_sepp'] = matched_data['SERSIC_SERSIC_INDEX'][self._disk_selector]\n+        disk_data['disk_axratio_sepp'] = matched_data['SERSIC_SERSIC_AXIS_RATIO'][self._disk_selector]\n+        disk_data['disk_angle_sepp'] = matched_data['SERSIC_ANGLE'][self._disk_selector]\n+\n+        # disk radius must be scaled to [pix]\n+        disk_data['disk_radius_tu'] = matched_data['TU_DISK_R50'][self._disk_selector]/.1\n+        disk_data['disk_nsersic'] = matched_data['TU_BULGE_NSERSIC'][self._disk_selector]\n+        disk_data['disk_angle'] = matched_data['TU_DISK_ANGLE'][self._disk_selector]\n+        disk_data['disk_inclination_angle'] = matched_data['TU_INCLINATION_ANGLE'][self._disk_selector]\n+\n+        # if given, apply a magnitude cut\n+        if vis_mag_lim is not None:\n+            vis_mag = CatalogUtils.jansky_to_mag(1.e-6 * matched_data['TU_FNU_VIS'][self._disk_selector])\n+            mag_selector = numpy.where(vis_mag < vis_mag_lim, True, False)\n+            for one_key in disk_data:\n+                disk_data[one_key] = disk_data[one_key][mag_selector]\n+\n+\n+        # get the bulge data\n+        bulge_data['bulge_radius_sepp'] = matched_data['SERSIC_SERSIC_RADIUS'][self._bulge_selector]\n+        bulge_data['bulge_nsersic_sepp'] = matched_data['SERSIC_SERSIC_INDEX'][self._bulge_selector]\n+        bulge_data['bulge_axratio_sepp'] = matched_data['SERSIC_SERSIC_AXIS_RATIO'][self._bulge_selector]\n+        bulge_data['bulge_angle_sepp'] = matched_data['SERSIC_ANGLE'][self._bulge_selector]\n+\n+        # bulge radius must be scaled to [pix]\n+        bulge_data['bulge_radius_tu'] = matched_data['TU_BULGE_R50'][self._bulge_selector]/.1\n+        bulge_data['bulge_nsersic'] = matched_data['TU_BULGE_NSERSIC'][self._bulge_selector]\n+        bulge_data['bulge_axratio'] = matched_data['TU_BULGE_AXIS_RATIO'][self._bulge_selector]\n+        bulge_data['bulge_angle'] = matched_data['TU_DISK_ANGLE'][self._bulge_selector]\n+        bulge_data['bulge_inclination_angle'] = matched_data['TU_INCLINATION_ANGLE'][self._bulge_selector]\n+\n+        # if given, apply a magnitude cut\n+        if vis_mag_lim is not None:\n+            vis_mag = CatalogUtils.jansky_to_mag(1.e-6 * matched_data['TU_FNU_VIS'][self._bulge_selector])\n+            mag_selector = numpy.where(vis_mag < vis_mag_lim, True, False)\n+            for one_key in bulge_data:\n+                bulge_data[one_key] = bulge_data[one_key][mag_selector]\n+\n+        # count disks and bulges\n+        tmp_array = numpy.copy(disk_data['disk_radius_sepp'])\n+        NullValueDefinition.null_to_nan(tmp_array, DTypeName.FLOAT)\n+        n_disk = numpy.count_nonzero(~numpy.isnan(tmp_array))\n+        tmp_array = numpy.copy(bulge_data['bulge_radius_sepp'])\n+        NullValueDefinition.null_to_nan(tmp_array, DTypeName.FLOAT)\n+        n_bulge = numpy.count_nonzero(~numpy.isnan(tmp_array))\n+\n+        self._info('No. of disks: %i'%n_disk)\n+        self._info('No. of bulges: %i'%n_bulge)\n+\n+        # return all data\n+        return disk_data, bulge_data, n_disk, n_bulge\n+\n+    def _make_radius_plot(self, disk_data, bulge_data, vis_mag_lim, plot_path='radius.png'):\n+        \"\"\"\n+        \"\"\"\n+        self._info('Starting the radius plot!')\n+\n+        # start the plot\n+        fig=plt.figure(figsize=(9,6))\n+        ax=fig.add_subplot(111)\n+\n+        # make a scatter plot\n+        ax.scatter(disk_data['disk_radius_tu'], disk_data['disk_radius_sepp'], marker='o', c='red', s=1)\n+        ax.scatter(bulge_data['bulge_radius_tu'], bulge_data['bulge_radius_sepp'], marker='o', c='blue', s=1)\n+        ax.legend(labels=['disks', 'bulges'], loc='lower right')\n+\n+        # set labels and title\n+        ax.set_xlabel('DISK/BULGE_R50 [pix]',fontsize=18)\n+        ax.set_ylabel('Disk/Bulge radius SE++ [pix]',fontsize=18)\n+        ax.set_title('Disk/Bulge radius (VIS<%.2f)'%vis_mag_lim, fontsize=20)\n+\n+        # set limits\n+        ax.set_xlim(0.0, 10.0)\n+        ax.set_ylim(0.0, 15.0)\n+        ax.grid(visible=True)\n+\n+        # finish the plot\n+        plt.subplots_adjust(bottom=0.1, right=0.9, top=0.95, left=0.1)\n+        plt.savefig(plot_path)\n+        self._info('Plot saved to: %s' % plot_path)\n+        plt.close()\n+\n+        return plot_path\n+\n+    def _make_index_histograms(self, disk_data, bulge_data, vis_mag_lim, plot_path='indexhisto_plot.png'):\n+        \"\"\"\n+        \"\"\"\n+        self._info('Starting the sersic histo plot!')\n+\n+        # start the plot\n+        fig=plt.figure(figsize=(9,6))\n+        ax=fig.add_subplot(111)\n+\n+        # define the bins\n+        bins=(-.2,5.8, 0.3)\n+        histo_bins = bins[0] + bins[2]*numpy.arange((bins[1]-bins[0])/bins[2]+1)\n+\n+        # assemble the axis plots\n+        #hist_type='barstacked'\n+        #alpha=.5\n+        hist_type='step'\n+        alpha=1.0\n+        disk_nsersic_n, disk_nsersich_bins, disk_nsersic_patches = plt.hist(disk_data['disk_nsersic_sepp'], bins=histo_bins, histtype=hist_type, facecolor='r', alpha=alpha, log=True)\n+        bulge_nsersic_n, bulge_nsersich_bins, bulge_nsersic_patches = plt.hist(bulge_data['bulge_nsersic_sepp'], bins=histo_bins, histtype=hist_type, facecolor='b', alpha=alpha, log=True)\n+        bulge_nsersic_tu_n, bulge_nsersich_tu_bins, bulge_nsersic_tu_patches = plt.hist(bulge_data['bulge_nsersic'], bins=histo_bins, histtype=hist_type, facecolor='g', alpha=alpha, log=True)\n+\n+        # plot the legend\n+        ax.legend(labels=['disks SE++', 'bulges SE++', 'bulges TU'], loc='upper left')\n+\n+        # set labels and title\n+        ax.set_xlabel('Sersic indices',fontsize=18)\n+        ax.set_ylabel('N',fontsize=18)\n+        ax.set_title('Sersic Index Distribution (VIS<%.2f)'%vis_mag_lim, fontsize=20)\n+\n+        # store the plot\n+        self._info('Saving Plots in : %s' % plot_path)\n+        plt.savefig(plot_path)\n+        plt.close()\n+\n+        return plot_path\n+        \n+    def _make_bulge_index_plot(self, bulge_data, vis_mag_lim, plot_path='bulge_axradius_plot.png'):\n+        \"\"\"\n+        \"\"\"\n+        self._info('Starting the sersic index plot for bulges!')\n+\n+        # start the plot\n+        fig=plt.figure(figsize=(9,6))\n+        ax=fig.add_subplot(111)\n+\n+        # make a scatter plot\n+        ax.scatter(bulge_data['bulge_nsersic'], bulge_data['bulge_nsersic_sepp'], marker='o', c='red', s=2.5)\n+\n+        # set labels and title\n+        ax.set_xlabel('Bulge Axis Ratio TU',fontsize=18)\n+        ax.set_ylabel('Bulge Axis Ratio SE++',fontsize=18)\n+        ax.set_title('Bulge Sersic Index (VIS<%.2f)'%vis_mag_lim, fontsize=20)\n+\n+        # set the limits\n+        ax.set_xlim(-0.2, 5.8)\n+        ax.set_ylim(-0.2, 5.8)\n+        ax.grid(visible=True)\n+\n+        # finish the plot\n+        plt.subplots_adjust(bottom=0.1, right=0.9, top=0.95, left=0.1)\n+        plt.savefig(plot_path)\n+        self._info('Plot saved to: %s' % plot_path)\n+        plt.close()\n+\n+        return plot_path\n+\n+    def _make_axratio_plot(self, disk_data, bulge_data, vis_mag_lim, plot_path='axratio_plot.png'):\n+        \"\"\"\n+        \"\"\"\n+        self._info('Starting the axis ratio plot!')\n+        \n+        # start the plot\n+        fig=plt.figure(figsize=(9,6))\n+        ax=fig.add_subplot(111)\n+\n+        # make a scatter plot\n+        #disk_data['disk_inclination_angle']\n+        #ax.scatter(bulge_data['bulge_nsersic'], bulge_data['bulge_nsersic_sepp'], marker='o', c='red', s=2.5)\n+        ax.scatter(numpy.cos(numpy.deg2rad(disk_data['disk_inclination_angle'])), disk_data['disk_axratio_sepp'], marker='o', c='red', s=1.5)\n+        ax.scatter(bulge_data['bulge_axratio'], bulge_data['bulge_axratio_sepp'], marker='o', c='blue', s=1.5)\n+        ax.legend(labels=['disks', 'bulges'], loc='upper left')\n+\n+        # set labels and title\n+        ax.set_xlabel('Disk/Bulge Axis Ratio TU',fontsize=18)\n+        ax.set_ylabel('Disk/Bulge Axis Ratio SE++',fontsize=18)\n+        ax.set_title('Disk/Bulge Axis Ratio (VIS<%.2f)'%vis_mag_lim, fontsize=20)\n+\n+        # set the limits\n+        ax.set_xlim(-0, 1.0)\n+        ax.set_ylim(-0, 1.0)\n+        ax.grid(visible=True)\n+\n+        # finish the plot\n+        plt.subplots_adjust(bottom=0.1, right=0.9, top=0.95, left=0.1)\n+        plt.savefig(plot_path)\n+        self._info('Plot saved to: %s' % plot_path)\n+        plt.close()\n+\n+        return plot_path\n+\n+    def _make_angle_plot(self, disk_data, bulge_data, vis_mag_lim, plot_path='angle_plot.png'):\n+        \"\"\"\n+        \"\"\"\n+        self._info('Starting the angle plot!')\n+\n+        # start the plot\n+        fig=plt.figure(figsize=(9,6))\n+        ax=fig.add_subplot(111)\n+\n+        # make a scatter plot\n+        ax.scatter((disk_data['disk_angle']+180.)%180, disk_data['disk_angle_sepp']+90., marker='o', c='red', s=1.5)\n+        ax.scatter((bulge_data['bulge_angle']+180.)%180., bulge_data['bulge_angle_sepp']+90., marker='o', c='blue', s=1.5)\n+        ax.legend(labels=['disks', 'bulges'], loc='upper left')\n+\n+        # set labels and title\n+        ax.set_xlabel('Disk/Bulge Axis Angle TU',fontsize=18)\n+        ax.set_ylabel('Disk/Bulge Axis Angle SE++',fontsize=18)\n+        ax.set_title('Disk/Bulge Axis Angle (VIS<%.2f)'%vis_mag_lim, fontsize=20)\n+\n+        # set the limits\n+        ax.set_xlim(-5, 185.0)\n+        ax.set_ylim(-5, 185.0)\n+        ax.grid(visible=True)\n+\n+        # finish the plot\n+        plt.subplots_adjust(bottom=0.1, right=0.9, top=0.95, left=0.1)\n+        plt.savefig(plot_path)\n+        self._info('Plot saved to: %s' % plot_path)\n+        plt.close()\n+\n+        return plot_path\n+\n+    def make_sersic_fit_plots(self, vis_mag_lim=None, plot_path='disk_radius.png',\n+                         plot_pathII='indexhisto_plot.png', plot_pathIII='index_plot.png',\n+                         plot_pathIV='axratio_plot.png', plot_pathV='angle_plot.png'):\n+        \"\"\"\n+        \"\"\"\n+        # get all relevant data\n+        disk_data, bulge_data, n_disk, n_bulge = self._get_sersic_data(vis_mag_lim=vis_mag_lim)\n+\n+        # get back if there is nothing to do\n+        if n_disk < 1 and n_bulge < 1:\n+            return False\n+\n+        self._make_radius_plot(disk_data, bulge_data, vis_mag_lim, plot_path=plot_path)\n+        self._make_axratio_plot(disk_data, bulge_data, vis_mag_lim, plot_path=plot_pathIV)\n+        self._make_angle_plot(disk_data, bulge_data, vis_mag_lim, plot_path=plot_pathV)\n+        self._make_index_histograms(disk_data, bulge_data, vis_mag_lim, plot_path=plot_pathII)\n+        self._make_bulge_index_plot(bulge_data, vis_mag_lim, plot_path=plot_pathIII)\n+\n+        return True\n\\ No newline at end of file\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-08-11T15:41:07.000+02:00",
                            "3439f2b2c5d1617a26353d57808735c69cf7a538"
                        ],
                        [
                            "@@ -94,6 +94,7 @@ class MER_SersicPlots(object):\n         disk_data['disk_nsersic'] = matched_data['TU_BULGE_NSERSIC'][self._disk_selector]\n         disk_data['disk_angle'] = matched_data['TU_DISK_ANGLE'][self._disk_selector]\n         disk_data['disk_inclination_angle'] = matched_data['TU_INCLINATION_ANGLE'][self._disk_selector]\n+        disk_data['disk_axratio'] = numpy.cos(numpy.deg2rad(disk_data['disk_inclination_angle']))\n \n         # if given, apply a magnitude cut\n         if vis_mag_lim is not None:\n@@ -147,18 +148,18 @@ class MER_SersicPlots(object):\n         ax=fig.add_subplot(111)\n \n         # make a scatter plot\n-        ax.scatter(disk_data['disk_radius_tu'], disk_data['disk_radius_sepp'], marker='o', c='red', s=1)\n-        ax.scatter(bulge_data['bulge_radius_tu'], bulge_data['bulge_radius_sepp'], marker='o', c='blue', s=1)\n+        ax.scatter(disk_data['disk_radius_tu']/numpy.sqrt(disk_data['disk_axratio']), disk_data['disk_radius_sepp'], marker='o', c='red', s=1)\n+        ax.scatter(bulge_data['bulge_radius_tu']/numpy.sqrt(bulge_data['bulge_axratio']), bulge_data['bulge_radius_sepp'], marker='o', c='blue', s=1)\n         ax.legend(labels=['disks', 'bulges'], loc='lower right')\n \n         # set labels and title\n-        ax.set_xlabel('DISK/BULGE_R50 [pix]',fontsize=18)\n-        ax.set_ylabel('Disk/Bulge radius SE++ [pix]',fontsize=18)\n+        ax.set_xlabel('DISK/BULGE (major-axis) [pix]',fontsize=18)\n+        ax.set_ylabel('Disk/Bulge radius (major-axis) SE++ [pix]',fontsize=18)\n         ax.set_title('Disk/Bulge radius (VIS<%.2f)'%vis_mag_lim, fontsize=20)\n \n         # set limits\n-        ax.set_xlim(0.0, 10.0)\n-        ax.set_ylim(0.0, 15.0)\n+        ax.set_xlim(0., 20.0)\n+        ax.set_ylim(0., 20.0)\n         ax.grid(visible=True)\n \n         # finish the plot\n@@ -248,7 +249,8 @@ class MER_SersicPlots(object):\n         # make a scatter plot\n         #disk_data['disk_inclination_angle']\n         #ax.scatter(bulge_data['bulge_nsersic'], bulge_data['bulge_nsersic_sepp'], marker='o', c='red', s=2.5)\n-        ax.scatter(numpy.cos(numpy.deg2rad(disk_data['disk_inclination_angle'])), disk_data['disk_axratio_sepp'], marker='o', c='red', s=1.5)\n+        #ax.scatter(numpy.cos(numpy.deg2rad(disk_data['disk_inclination_angle'])), disk_data['disk_axratio_sepp'], marker='o', c='red', s=1.5)\n+        ax.scatter(disk_data['disk_axratio'], disk_data['disk_axratio_sepp'], marker='o', c='red', s=1.5)\n         ax.scatter(bulge_data['bulge_axratio'], bulge_data['bulge_axratio_sepp'], marker='o', c='blue', s=1.5)\n         ax.legend(labels=['disks', 'bulges'], loc='upper left')\n \n",
                            "Include the correction for the sersic radius",
                            "Martin Kuemmel",
                            "2023-07-27T17:20:57.000+02:00",
                            "a80a36169f7251b1faf76d4d1925f1dbe4bde0ac"
                        ],
                        [
                            "@@ -68,14 +68,6 @@ class MER_SersicPlots(object):\n         \"\"\"\n         matched_data = fits.getdata(matched_catalog_path)\n \n-        # \n-        #disk_selector = numpy.where(numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float,\n-        #                                              numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float, \n-        #                                                                matched_data['TU_BULGE_FRACTION']<0.1)), True, False)\n-        #bulge_selector = numpy.where(numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float,\n-        #                                               numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float, \n-        #                                                                 matched_data['TU_BULGE_FRACTION']>0.9)), True, False)\n-        \n         # make a selection for the disks and the bulges\n         disk_selector = numpy.where(numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float, matched_data['TU_BULGE_FRACTION']<0.1), True, False)\n         bulge_selector = numpy.where(numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float, matched_data['TU_BULGE_FRACTION']>0.9), True, False)\n",
                            "Improved the data selection",
                            "Martin Kuemmel",
                            "2023-07-17T11:53:48.000+02:00",
                            "7dfaa16628e74314ecc4c7c2026ccb469cc9efb7"
                        ],
                        [
                            "@@ -31,7 +31,7 @@ import matplotlib.pyplot as plt\n \n from MER_PsfMosaicValidation.CatalogUtils import CatalogUtils\n \n-from EL_NullValue import NullValueDefinition \n+from EL_NullValue import NullValueDefinition, DTypeName\n \n class MER_SersicPlots(object):\n     \"\"\"\n@@ -44,10 +44,11 @@ class MER_SersicPlots(object):\n         self._matched_catalog_path = matched_catalog_path\n         self._logger               = logger\n \n-        null_val = NullValueDefinition()\n-        self._null_float = null_val.FLOAT \n-        self._null_double = null_val.DOUBLE \n-        self._info('nullnull: %s %s' % (str(self._null_float), str(self._null_double)))\n+        #null_val = NullValueDefinition()\n+        #self._null_float = null_val.FLOAT \n+        #self._null_double = null_val.DOUBLE \n+        self._null_float = NullValueDefinition.FLOAT \n+        self._null_double = NullValueDefinition.DOUBLE \n \n         # create the selector and do the selection\n         self._disk_selector, self._bulge_selector = self._setup_morpholgy_selection(matched_catalog_path)\n@@ -66,30 +67,18 @@ class MER_SersicPlots(object):\n         \"\"\"\n         \"\"\"\n         matched_data = fits.getdata(matched_catalog_path)\n-        #morpho_data = fits.getdata(morphology_catalog_file)\n-        #352    true    SERSIC_SERSIC_RADIUS    $352    Float    arcsec        E    \n-        #353    true    SERSIC_SERSIC_RADIUS_ERR    $353    Float    arcsec        E    \n-        #354    true    SERSIC_SERSIC_AXIS_RATIO    $354    Float    NA        E    \n-        #355    true    SERSIC_SERSIC_AXIS_RATIO_ERR    $355    Float    NA        E    \n-        #356    true    SERSIC_SERSIC_INDEX    $356    Float    NA        E    \n-        #357    true    SERSIC_SERSIC_INDEX_ERR    $357    Float    NA        E    \n-        #358    true    SERSIC_ANGLE    $358    Float    deg        E    \n \n+        # \n+        #disk_selector = numpy.where(numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float,\n+        #                                              numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float, \n+        #                                                                matched_data['TU_BULGE_FRACTION']<0.1)), True, False)\n+        #bulge_selector = numpy.where(numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float,\n+        #                                               numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float, \n+        #                                                                 matched_data['TU_BULGE_FRACTION']>0.9)), True, False)\n         \n-        \n-        #disk_selector = numpy.where(matched_data['SERSIC_SERSIC_RADIUS']!=null_float, True, False)\n-        disk_selector = numpy.where(numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float,\n-                                                      numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float, \n-                                                                        matched_data['TU_BULGE_FRACTION']<0.1)), True, False)\n-        bulge_selector = numpy.where(numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float,\n-                                                       numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float, \n-                                                                         matched_data['TU_BULGE_FRACTION']>0.9)), True, False)\n-        #vis_mag = CatalogUtils.jansky_to_mag(1.e-6 * matched_data['TU_FNU_VIS'])\n-    \n-        #self._info('disks: %i'%numpy.sum(disk_selector))\n-        #self._info('disks: %s'%str(disk_selector))\n-        #self._info('bulges: %i'%numpy.sum(bulge_selector))\n-        #self._info('vis_mag: %s'%str(vis_mag))\n+        # make a selection for the disks and the bulges\n+        disk_selector = numpy.where(numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float, matched_data['TU_BULGE_FRACTION']<0.1), True, False)\n+        bulge_selector = numpy.where(numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float, matched_data['TU_BULGE_FRACTION']>0.9), True, False)\n     \n         return disk_selector, bulge_selector\n \n@@ -142,8 +131,19 @@ class MER_SersicPlots(object):\n             for one_key in bulge_data:\n                 bulge_data[one_key] = bulge_data[one_key][mag_selector]\n \n+        # count disks and bulges\n+        tmp_array = numpy.copy(disk_data['disk_radius_sepp'])\n+        NullValueDefinition.null_to_nan(tmp_array, DTypeName.FLOAT)\n+        n_disk = numpy.count_nonzero(~numpy.isnan(tmp_array))\n+        tmp_array = numpy.copy(bulge_data['bulge_radius_sepp'])\n+        NullValueDefinition.null_to_nan(tmp_array, DTypeName.FLOAT)\n+        n_bulge = numpy.count_nonzero(~numpy.isnan(tmp_array))\n+\n+        self._info('No. of disks: %i'%n_disk)\n+        self._info('No. of bulges: %i'%n_bulge)\n+\n         # return all data\n-        return disk_data, bulge_data\n+        return disk_data, bulge_data, n_disk, n_bulge\n \n     def _make_radius_plot(self, disk_data, bulge_data, vis_mag_lim, plot_path='radius.png'):\n         \"\"\"\n@@ -161,7 +161,7 @@ class MER_SersicPlots(object):\n \n         # set labels and title\n         ax.set_xlabel('DISK/BULGE_R50 [pix]',fontsize=18)\n-        ax.set_ylabel('Disk/Bulge radius [pix]',fontsize=18)\n+        ax.set_ylabel('Disk/Bulge radius SE++ [pix]',fontsize=18)\n         ax.set_title('Disk/Bulge radius (VIS<%.2f)'%vis_mag_lim, fontsize=20)\n \n         # set limits\n@@ -316,10 +316,16 @@ class MER_SersicPlots(object):\n         \"\"\"\n         \"\"\"\n         # get all relevant data\n-        disk_data, bulge_data = self._get_sersic_data(vis_mag_lim=vis_mag_lim)\n+        disk_data, bulge_data, n_disk, n_bulge = self._get_sersic_data(vis_mag_lim=vis_mag_lim)\n+\n+        # get back if there is nothing to do\n+        if n_disk < 1 and n_bulge < 1:\n+            return False\n \n         self._make_radius_plot(disk_data, bulge_data, vis_mag_lim, plot_path=plot_path)\n         self._make_axratio_plot(disk_data, bulge_data, vis_mag_lim, plot_path=plot_pathIV)\n         self._make_angle_plot(disk_data, bulge_data, vis_mag_lim, plot_path=plot_pathV)\n         self._make_index_histograms(disk_data, bulge_data, vis_mag_lim, plot_path=plot_pathII)\n         self._make_bulge_index_plot(bulge_data, vis_mag_lim, plot_path=plot_pathIII)\n+\n+        return True\n\\ No newline at end of file\n",
                            "Now works also if no fitting was done.",
                            "Martin Kuemmel",
                            "2023-07-13T17:28:21.000+02:00",
                            "6f55025775dd6d26d895814cc45d9944c8c6a201"
                        ],
                        [
                            "@@ -200,7 +200,7 @@ class MER_SersicPlots(object):\n         bulge_nsersic_tu_n, bulge_nsersich_tu_bins, bulge_nsersic_tu_patches = plt.hist(bulge_data['bulge_nsersic'], bins=histo_bins, histtype=hist_type, facecolor='g', alpha=alpha, log=True)\n \n         # plot the legend\n-        ax.legend(labels=['disks', 'bulges', 'TU bulges'], loc='upper left')\n+        ax.legend(labels=['disks SE++', 'bulges SE++', 'bulges TU'], loc='upper left')\n \n         # set labels and title\n         ax.set_xlabel('Sersic indices',fontsize=18)\n@@ -298,8 +298,8 @@ class MER_SersicPlots(object):\n         ax.set_title('Disk/Bulge Axis Angle (VIS<%.2f)'%vis_mag_lim, fontsize=20)\n \n         # set the limits\n-        ax.set_xlim(0, 180.0)\n-        ax.set_ylim(0, 180.0)\n+        ax.set_xlim(-5, 185.0)\n+        ax.set_ylim(-5, 185.0)\n         ax.grid(visible=True)\n \n         # finish the plot\n",
                            "Added some introduction",
                            "Martin Kuemmel",
                            "2023-07-13T15:24:03.000+02:00",
                            "bc104146b03160bab4c72db89e179898f1004a09"
                        ],
                        [
                            "@@ -102,17 +102,19 @@ class MER_SersicPlots(object):\n         disk_data = {}\n         bulge_data = {}\n         \n-        # get the data and apply a SNR selection\n+        # get the disk data\n         disk_data['disk_radius_sepp'] = matched_data['SERSIC_SERSIC_RADIUS'][self._disk_selector]\n         disk_data['disk_nsersic_sepp'] = matched_data['SERSIC_SERSIC_INDEX'][self._disk_selector]\n         disk_data['disk_axratio_sepp'] = matched_data['SERSIC_SERSIC_AXIS_RATIO'][self._disk_selector]\n         disk_data['disk_angle_sepp'] = matched_data['SERSIC_ANGLE'][self._disk_selector]\n \n+        # disk radius must be scaled to [pix]\n         disk_data['disk_radius_tu'] = matched_data['TU_DISK_R50'][self._disk_selector]/.1\n         disk_data['disk_nsersic'] = matched_data['TU_BULGE_NSERSIC'][self._disk_selector]\n         disk_data['disk_angle'] = matched_data['TU_DISK_ANGLE'][self._disk_selector]\n         disk_data['disk_inclination_angle'] = matched_data['TU_INCLINATION_ANGLE'][self._disk_selector]\n \n+        # if given, apply a magnitude cut\n         if vis_mag_lim is not None:\n             vis_mag = CatalogUtils.jansky_to_mag(1.e-6 * matched_data['TU_FNU_VIS'][self._disk_selector])\n             mag_selector = numpy.where(vis_mag < vis_mag_lim, True, False)\n@@ -120,51 +122,34 @@ class MER_SersicPlots(object):\n                 disk_data[one_key] = disk_data[one_key][mag_selector]\n \n \n-        # get the data and apply a SNR selection\n+        # get the bulge data\n         bulge_data['bulge_radius_sepp'] = matched_data['SERSIC_SERSIC_RADIUS'][self._bulge_selector]\n         bulge_data['bulge_nsersic_sepp'] = matched_data['SERSIC_SERSIC_INDEX'][self._bulge_selector]\n         bulge_data['bulge_axratio_sepp'] = matched_data['SERSIC_SERSIC_AXIS_RATIO'][self._bulge_selector]\n         bulge_data['bulge_angle_sepp'] = matched_data['SERSIC_ANGLE'][self._bulge_selector]\n \n+        # bulge radius must be scaled to [pix]\n         bulge_data['bulge_radius_tu'] = matched_data['TU_BULGE_R50'][self._bulge_selector]/.1\n         bulge_data['bulge_nsersic'] = matched_data['TU_BULGE_NSERSIC'][self._bulge_selector]\n         bulge_data['bulge_axratio'] = matched_data['TU_BULGE_AXIS_RATIO'][self._bulge_selector]\n+        bulge_data['bulge_angle'] = matched_data['TU_DISK_ANGLE'][self._bulge_selector]\n         bulge_data['bulge_inclination_angle'] = matched_data['TU_INCLINATION_ANGLE'][self._bulge_selector]\n \n+        # if given, apply a magnitude cut\n         if vis_mag_lim is not None:\n             vis_mag = CatalogUtils.jansky_to_mag(1.e-6 * matched_data['TU_FNU_VIS'][self._bulge_selector])\n             mag_selector = numpy.where(vis_mag < vis_mag_lim, True, False)\n             for one_key in bulge_data:\n                 bulge_data[one_key] = bulge_data[one_key][mag_selector]\n \n-\n-\n-        ##352    true    SERSIC_SERSIC_RADIUS    $352    Float    arcsec        E    \n-        ##353    true    SERSIC_SERSIC_RADIUS_ERR    $353    Float    arcsec        E    \n-        ##354    true    SERSIC_SERSIC_AXIS_RATIO    $354    Float    NA        E    \n-        ##355    true    SERSIC_SERSIC_AXIS_RATIO_ERR    $355    Float    NA        E    \n-        ##356    true    SERSIC_SERSIC_INDEX    $356    Float    NA        E    \n-        ##357    true    SERSIC_SERSIC_INDEX_ERR    $357    Float    NA        E    \n-        ##358    true    SERSIC_ANGLE    $358    Float    deg        E    \n-        ##461    true    TU_BULGE_FRACTION    $461    Double            D    \n-        ##462    true    TU_BULGE_R50    $462    Double            D    \n-        ##463    true    TU_DISK_R50    $463    Double            D    \n-        ##464    true    TU_BULGE_NSERSIC    $464    Double            D    \n-        ##465    true    TU_BULGE_AXIS_RATIO    $465    Double            D    \n-        ##466    true    TU_INCLINATION_ANGLE    $466    Double            D    \n-        ##467    true    TU_DISK_ANGLE    $467    Double            D    \n-\n+        # return all data\n         return disk_data, bulge_data\n \n-\n-    def make_radius_plot(self, vis_mag_lim=None, plot_path='disk_radius.png',\n-                         plot_pathII='indexhisto_plot.png', plot_pathIII='index_plot.png'):\n+    def _make_radius_plot(self, disk_data, bulge_data, vis_mag_lim, plot_path='radius.png'):\n         \"\"\"\n         \"\"\"\n-        # get all relevant data\n-        disk_data, bulge_data = self._get_sersic_data(vis_mag_lim=vis_mag_lim)\n+        self._info('Starting the radius plot!')\n \n-        self._info('Starting the plot!')\n         # start the plot\n         fig=plt.figure(figsize=(9,6))\n         ax=fig.add_subplot(111)\n@@ -172,29 +157,40 @@ class MER_SersicPlots(object):\n         # make a scatter plot\n         ax.scatter(disk_data['disk_radius_tu'], disk_data['disk_radius_sepp'], marker='o', c='red', s=1)\n         ax.scatter(bulge_data['bulge_radius_tu'], bulge_data['bulge_radius_sepp'], marker='o', c='blue', s=1)\n+        ax.legend(labels=['disks', 'bulges'], loc='lower right')\n \n         # set labels and title\n         ax.set_xlabel('DISK/BULGE_R50 [pix]',fontsize=18)\n         ax.set_ylabel('Disk/Bulge radius [pix]',fontsize=18)\n         ax.set_title('Disk/Bulge radius (VIS<%.2f)'%vis_mag_lim, fontsize=20)\n \n+        # set limits\n         ax.set_xlim(0.0, 10.0)\n         ax.set_ylim(0.0, 15.0)\n         ax.grid(visible=True)\n \n+        # finish the plot\n         plt.subplots_adjust(bottom=0.1, right=0.9, top=0.95, left=0.1)\n-\n         plt.savefig(plot_path)\n         self._info('Plot saved to: %s' % plot_path)\n         plt.close()\n \n+        return plot_path\n+\n+    def _make_index_histograms(self, disk_data, bulge_data, vis_mag_lim, plot_path='indexhisto_plot.png'):\n+        \"\"\"\n+        \"\"\"\n+        self._info('Starting the sersic histo plot!')\n+\n         # start the plot\n         fig=plt.figure(figsize=(9,6))\n         ax=fig.add_subplot(111)\n \n+        # define the bins\n         bins=(-.2,5.8, 0.3)\n         histo_bins = bins[0] + bins[2]*numpy.arange((bins[1]-bins[0])/bins[2]+1)\n \n+        # assemble the axis plots\n         #hist_type='barstacked'\n         #alpha=.5\n         hist_type='step'\n@@ -212,10 +208,17 @@ class MER_SersicPlots(object):\n         ax.set_title('Sersic Index Distribution (VIS<%.2f)'%vis_mag_lim, fontsize=20)\n \n         # store the plot\n-        self._info('Saving Plots in : %s' % plot_pathII)\n-        plt.savefig(plot_pathII)\n+        self._info('Saving Plots in : %s' % plot_path)\n+        plt.savefig(plot_path)\n         plt.close()\n \n+        return plot_path\n+        \n+    def _make_bulge_index_plot(self, bulge_data, vis_mag_lim, plot_path='bulge_axradius_plot.png'):\n+        \"\"\"\n+        \"\"\"\n+        self._info('Starting the sersic index plot for bulges!')\n+\n         # start the plot\n         fig=plt.figure(figsize=(9,6))\n         ax=fig.add_subplot(111)\n@@ -224,16 +227,99 @@ class MER_SersicPlots(object):\n         ax.scatter(bulge_data['bulge_nsersic'], bulge_data['bulge_nsersic_sepp'], marker='o', c='red', s=2.5)\n \n         # set labels and title\n-        ax.set_xlabel('Bulge Sersic Index TU',fontsize=18)\n-        ax.set_ylabel('Bulge Sersic Index SE++',fontsize=18)\n+        ax.set_xlabel('Bulge Axis Ratio TU',fontsize=18)\n+        ax.set_ylabel('Bulge Axis Ratio SE++',fontsize=18)\n         ax.set_title('Bulge Sersic Index (VIS<%.2f)'%vis_mag_lim, fontsize=20)\n \n+        # set the limits\n         ax.set_xlim(-0.2, 5.8)\n         ax.set_ylim(-0.2, 5.8)\n         ax.grid(visible=True)\n \n+        # finish the plot\n+        plt.subplots_adjust(bottom=0.1, right=0.9, top=0.95, left=0.1)\n+        plt.savefig(plot_path)\n+        self._info('Plot saved to: %s' % plot_path)\n+        plt.close()\n+\n+        return plot_path\n+\n+    def _make_axratio_plot(self, disk_data, bulge_data, vis_mag_lim, plot_path='axratio_plot.png'):\n+        \"\"\"\n+        \"\"\"\n+        self._info('Starting the axis ratio plot!')\n+        \n+        # start the plot\n+        fig=plt.figure(figsize=(9,6))\n+        ax=fig.add_subplot(111)\n+\n+        # make a scatter plot\n+        #disk_data['disk_inclination_angle']\n+        #ax.scatter(bulge_data['bulge_nsersic'], bulge_data['bulge_nsersic_sepp'], marker='o', c='red', s=2.5)\n+        ax.scatter(numpy.cos(numpy.deg2rad(disk_data['disk_inclination_angle'])), disk_data['disk_axratio_sepp'], marker='o', c='red', s=1.5)\n+        ax.scatter(bulge_data['bulge_axratio'], bulge_data['bulge_axratio_sepp'], marker='o', c='blue', s=1.5)\n+        ax.legend(labels=['disks', 'bulges'], loc='upper left')\n+\n+        # set labels and title\n+        ax.set_xlabel('Disk/Bulge Axis Ratio TU',fontsize=18)\n+        ax.set_ylabel('Disk/Bulge Axis Ratio SE++',fontsize=18)\n+        ax.set_title('Disk/Bulge Axis Ratio (VIS<%.2f)'%vis_mag_lim, fontsize=20)\n+\n+        # set the limits\n+        ax.set_xlim(-0, 1.0)\n+        ax.set_ylim(-0, 1.0)\n+        ax.grid(visible=True)\n+\n+        # finish the plot\n         plt.subplots_adjust(bottom=0.1, right=0.9, top=0.95, left=0.1)\n+        plt.savefig(plot_path)\n+        self._info('Plot saved to: %s' % plot_path)\n+        plt.close()\n+\n+        return plot_path\n \n-        plt.savefig(plot_pathIII)\n-        self._info('Plot saved to: %s' % plot_pathIII)\n+    def _make_angle_plot(self, disk_data, bulge_data, vis_mag_lim, plot_path='angle_plot.png'):\n+        \"\"\"\n+        \"\"\"\n+        self._info('Starting the angle plot!')\n+\n+        # start the plot\n+        fig=plt.figure(figsize=(9,6))\n+        ax=fig.add_subplot(111)\n+\n+        # make a scatter plot\n+        ax.scatter((disk_data['disk_angle']+180.)%180, disk_data['disk_angle_sepp']+90., marker='o', c='red', s=1.5)\n+        ax.scatter((bulge_data['bulge_angle']+180.)%180., bulge_data['bulge_angle_sepp']+90., marker='o', c='blue', s=1.5)\n+        ax.legend(labels=['disks', 'bulges'], loc='upper left')\n+\n+        # set labels and title\n+        ax.set_xlabel('Disk/Bulge Axis Angle TU',fontsize=18)\n+        ax.set_ylabel('Disk/Bulge Axis Angle SE++',fontsize=18)\n+        ax.set_title('Disk/Bulge Axis Angle (VIS<%.2f)'%vis_mag_lim, fontsize=20)\n+\n+        # set the limits\n+        ax.set_xlim(0, 180.0)\n+        ax.set_ylim(0, 180.0)\n+        ax.grid(visible=True)\n+\n+        # finish the plot\n+        plt.subplots_adjust(bottom=0.1, right=0.9, top=0.95, left=0.1)\n+        plt.savefig(plot_path)\n+        self._info('Plot saved to: %s' % plot_path)\n         plt.close()\n+\n+        return plot_path\n+\n+    def make_sersic_fit_plots(self, vis_mag_lim=None, plot_path='disk_radius.png',\n+                         plot_pathII='indexhisto_plot.png', plot_pathIII='index_plot.png',\n+                         plot_pathIV='axratio_plot.png', plot_pathV='angle_plot.png'):\n+        \"\"\"\n+        \"\"\"\n+        # get all relevant data\n+        disk_data, bulge_data = self._get_sersic_data(vis_mag_lim=vis_mag_lim)\n+\n+        self._make_radius_plot(disk_data, bulge_data, vis_mag_lim, plot_path=plot_path)\n+        self._make_axratio_plot(disk_data, bulge_data, vis_mag_lim, plot_path=plot_pathIV)\n+        self._make_angle_plot(disk_data, bulge_data, vis_mag_lim, plot_path=plot_pathV)\n+        self._make_index_histograms(disk_data, bulge_data, vis_mag_lim, plot_path=plot_pathII)\n+        self._make_bulge_index_plot(bulge_data, vis_mag_lim, plot_path=plot_pathIII)\n",
                            "Added some documentation",
                            "Martin Kuemmel",
                            "2023-07-13T14:49:37.000+02:00",
                            "7330292b2591706cbd16dd9469f77072478917c1"
                        ],
                        [
                            "@@ -0,0 +1,239 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+:file: python/MER_MorphologyValidation/MER_SersicPlots.py\n+\n+:date: 07/12/23\n+:author: mkuemmel@usm.lmu.de\n+\n+\"\"\"\n+import os.path\n+\n+import numpy\n+from astropy.io import fits\n+import matplotlib.pyplot as plt\n+\n+from MER_PsfMosaicValidation.CatalogUtils import CatalogUtils\n+\n+from EL_NullValue import NullValueDefinition \n+\n+class MER_SersicPlots(object):\n+    \"\"\"\n+    \"\"\"\n+    def __init__(self, matched_catalog_path, logger=None):\n+        \"\"\"\n+        Initializes the class\n+        \"\"\"\n+        # store the input\n+        self._matched_catalog_path = matched_catalog_path\n+        self._logger               = logger\n+\n+        null_val = NullValueDefinition()\n+        self._null_float = null_val.FLOAT \n+        self._null_double = null_val.DOUBLE \n+        self._info('nullnull: %s %s' % (str(self._null_float), str(self._null_double)))\n+\n+        # create the selector and do the selection\n+        self._disk_selector, self._bulge_selector = self._setup_morpholgy_selection(matched_catalog_path)\n+\n+    def _info(self, message):\n+        \"\"\"General method for user feedback\n+        \"\"\"\n+        # push to the logger if existing\n+        if self._logger is not None:\n+            self._logger.info('# %s' % message)\n+        else:\n+            # push to stdout\n+            print('# %s'%message)\n+\n+    def _setup_morpholgy_selection(self, matched_catalog_path):\n+        \"\"\"\n+        \"\"\"\n+        matched_data = fits.getdata(matched_catalog_path)\n+        #morpho_data = fits.getdata(morphology_catalog_file)\n+        #352    true    SERSIC_SERSIC_RADIUS    $352    Float    arcsec        E    \n+        #353    true    SERSIC_SERSIC_RADIUS_ERR    $353    Float    arcsec        E    \n+        #354    true    SERSIC_SERSIC_AXIS_RATIO    $354    Float    NA        E    \n+        #355    true    SERSIC_SERSIC_AXIS_RATIO_ERR    $355    Float    NA        E    \n+        #356    true    SERSIC_SERSIC_INDEX    $356    Float    NA        E    \n+        #357    true    SERSIC_SERSIC_INDEX_ERR    $357    Float    NA        E    \n+        #358    true    SERSIC_ANGLE    $358    Float    deg        E    \n+\n+        \n+        \n+        #disk_selector = numpy.where(matched_data['SERSIC_SERSIC_RADIUS']!=null_float, True, False)\n+        disk_selector = numpy.where(numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float,\n+                                                      numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float, \n+                                                                        matched_data['TU_BULGE_FRACTION']<0.1)), True, False)\n+        bulge_selector = numpy.where(numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float,\n+                                                       numpy.logical_and(matched_data['SERSIC_SERSIC_RADIUS']!=self._null_float, \n+                                                                         matched_data['TU_BULGE_FRACTION']>0.9)), True, False)\n+        #vis_mag = CatalogUtils.jansky_to_mag(1.e-6 * matched_data['TU_FNU_VIS'])\n+    \n+        #self._info('disks: %i'%numpy.sum(disk_selector))\n+        #self._info('disks: %s'%str(disk_selector))\n+        #self._info('bulges: %i'%numpy.sum(bulge_selector))\n+        #self._info('vis_mag: %s'%str(vis_mag))\n+    \n+        return disk_selector, bulge_selector\n+\n+    def _get_sersic_data(self, vis_mag_lim=None):\n+        \"\"\"\n+        \"\"\"\n+        self._info('Loading data from: %s'%self._matched_catalog_path)\n+        matched_data = fits.getdata(self._matched_catalog_path)\n+\n+        disk_data = {}\n+        bulge_data = {}\n+        \n+        # get the data and apply a SNR selection\n+        disk_data['disk_radius_sepp'] = matched_data['SERSIC_SERSIC_RADIUS'][self._disk_selector]\n+        disk_data['disk_nsersic_sepp'] = matched_data['SERSIC_SERSIC_INDEX'][self._disk_selector]\n+        disk_data['disk_axratio_sepp'] = matched_data['SERSIC_SERSIC_AXIS_RATIO'][self._disk_selector]\n+        disk_data['disk_angle_sepp'] = matched_data['SERSIC_ANGLE'][self._disk_selector]\n+\n+        disk_data['disk_radius_tu'] = matched_data['TU_DISK_R50'][self._disk_selector]/.1\n+        disk_data['disk_nsersic'] = matched_data['TU_BULGE_NSERSIC'][self._disk_selector]\n+        disk_data['disk_angle'] = matched_data['TU_DISK_ANGLE'][self._disk_selector]\n+        disk_data['disk_inclination_angle'] = matched_data['TU_INCLINATION_ANGLE'][self._disk_selector]\n+\n+        if vis_mag_lim is not None:\n+            vis_mag = CatalogUtils.jansky_to_mag(1.e-6 * matched_data['TU_FNU_VIS'][self._disk_selector])\n+            mag_selector = numpy.where(vis_mag < vis_mag_lim, True, False)\n+            for one_key in disk_data:\n+                disk_data[one_key] = disk_data[one_key][mag_selector]\n+\n+\n+        # get the data and apply a SNR selection\n+        bulge_data['bulge_radius_sepp'] = matched_data['SERSIC_SERSIC_RADIUS'][self._bulge_selector]\n+        bulge_data['bulge_nsersic_sepp'] = matched_data['SERSIC_SERSIC_INDEX'][self._bulge_selector]\n+        bulge_data['bulge_axratio_sepp'] = matched_data['SERSIC_SERSIC_AXIS_RATIO'][self._bulge_selector]\n+        bulge_data['bulge_angle_sepp'] = matched_data['SERSIC_ANGLE'][self._bulge_selector]\n+\n+        bulge_data['bulge_radius_tu'] = matched_data['TU_BULGE_R50'][self._bulge_selector]/.1\n+        bulge_data['bulge_nsersic'] = matched_data['TU_BULGE_NSERSIC'][self._bulge_selector]\n+        bulge_data['bulge_axratio'] = matched_data['TU_BULGE_AXIS_RATIO'][self._bulge_selector]\n+        bulge_data['bulge_inclination_angle'] = matched_data['TU_INCLINATION_ANGLE'][self._bulge_selector]\n+\n+        if vis_mag_lim is not None:\n+            vis_mag = CatalogUtils.jansky_to_mag(1.e-6 * matched_data['TU_FNU_VIS'][self._bulge_selector])\n+            mag_selector = numpy.where(vis_mag < vis_mag_lim, True, False)\n+            for one_key in bulge_data:\n+                bulge_data[one_key] = bulge_data[one_key][mag_selector]\n+\n+\n+\n+        ##352    true    SERSIC_SERSIC_RADIUS    $352    Float    arcsec        E    \n+        ##353    true    SERSIC_SERSIC_RADIUS_ERR    $353    Float    arcsec        E    \n+        ##354    true    SERSIC_SERSIC_AXIS_RATIO    $354    Float    NA        E    \n+        ##355    true    SERSIC_SERSIC_AXIS_RATIO_ERR    $355    Float    NA        E    \n+        ##356    true    SERSIC_SERSIC_INDEX    $356    Float    NA        E    \n+        ##357    true    SERSIC_SERSIC_INDEX_ERR    $357    Float    NA        E    \n+        ##358    true    SERSIC_ANGLE    $358    Float    deg        E    \n+        ##461    true    TU_BULGE_FRACTION    $461    Double            D    \n+        ##462    true    TU_BULGE_R50    $462    Double            D    \n+        ##463    true    TU_DISK_R50    $463    Double            D    \n+        ##464    true    TU_BULGE_NSERSIC    $464    Double            D    \n+        ##465    true    TU_BULGE_AXIS_RATIO    $465    Double            D    \n+        ##466    true    TU_INCLINATION_ANGLE    $466    Double            D    \n+        ##467    true    TU_DISK_ANGLE    $467    Double            D    \n+\n+        return disk_data, bulge_data\n+\n+\n+    def make_radius_plot(self, vis_mag_lim=None, plot_path='disk_radius.png',\n+                         plot_pathII='indexhisto_plot.png', plot_pathIII='index_plot.png'):\n+        \"\"\"\n+        \"\"\"\n+        # get all relevant data\n+        disk_data, bulge_data = self._get_sersic_data(vis_mag_lim=vis_mag_lim)\n+\n+        self._info('Starting the plot!')\n+        # start the plot\n+        fig=plt.figure(figsize=(9,6))\n+        ax=fig.add_subplot(111)\n+\n+        # make a scatter plot\n+        ax.scatter(disk_data['disk_radius_tu'], disk_data['disk_radius_sepp'], marker='o', c='red', s=1)\n+        ax.scatter(bulge_data['bulge_radius_tu'], bulge_data['bulge_radius_sepp'], marker='o', c='blue', s=1)\n+\n+        # set labels and title\n+        ax.set_xlabel('DISK/BULGE_R50 [pix]',fontsize=18)\n+        ax.set_ylabel('Disk/Bulge radius [pix]',fontsize=18)\n+        ax.set_title('Disk/Bulge radius (VIS<%.2f)'%vis_mag_lim, fontsize=20)\n+\n+        ax.set_xlim(0.0, 10.0)\n+        ax.set_ylim(0.0, 15.0)\n+        ax.grid(visible=True)\n+\n+        plt.subplots_adjust(bottom=0.1, right=0.9, top=0.95, left=0.1)\n+\n+        plt.savefig(plot_path)\n+        self._info('Plot saved to: %s' % plot_path)\n+        plt.close()\n+\n+        # start the plot\n+        fig=plt.figure(figsize=(9,6))\n+        ax=fig.add_subplot(111)\n+\n+        bins=(-.2,5.8, 0.3)\n+        histo_bins = bins[0] + bins[2]*numpy.arange((bins[1]-bins[0])/bins[2]+1)\n+\n+        #hist_type='barstacked'\n+        #alpha=.5\n+        hist_type='step'\n+        alpha=1.0\n+        disk_nsersic_n, disk_nsersich_bins, disk_nsersic_patches = plt.hist(disk_data['disk_nsersic_sepp'], bins=histo_bins, histtype=hist_type, facecolor='r', alpha=alpha, log=True)\n+        bulge_nsersic_n, bulge_nsersich_bins, bulge_nsersic_patches = plt.hist(bulge_data['bulge_nsersic_sepp'], bins=histo_bins, histtype=hist_type, facecolor='b', alpha=alpha, log=True)\n+        bulge_nsersic_tu_n, bulge_nsersich_tu_bins, bulge_nsersic_tu_patches = plt.hist(bulge_data['bulge_nsersic'], bins=histo_bins, histtype=hist_type, facecolor='g', alpha=alpha, log=True)\n+\n+        # plot the legend\n+        ax.legend(labels=['disks', 'bulges', 'TU bulges'], loc='upper left')\n+\n+        # set labels and title\n+        ax.set_xlabel('Sersic indices',fontsize=18)\n+        ax.set_ylabel('N',fontsize=18)\n+        ax.set_title('Sersic Index Distribution (VIS<%.2f)'%vis_mag_lim, fontsize=20)\n+\n+        # store the plot\n+        self._info('Saving Plots in : %s' % plot_pathII)\n+        plt.savefig(plot_pathII)\n+        plt.close()\n+\n+        # start the plot\n+        fig=plt.figure(figsize=(9,6))\n+        ax=fig.add_subplot(111)\n+\n+        # make a scatter plot\n+        ax.scatter(bulge_data['bulge_nsersic'], bulge_data['bulge_nsersic_sepp'], marker='o', c='red', s=2.5)\n+\n+        # set labels and title\n+        ax.set_xlabel('Bulge Sersic Index TU',fontsize=18)\n+        ax.set_ylabel('Bulge Sersic Index SE++',fontsize=18)\n+        ax.set_title('Bulge Sersic Index (VIS<%.2f)'%vis_mag_lim, fontsize=20)\n+\n+        ax.set_xlim(-0.2, 5.8)\n+        ax.set_ylim(-0.2, 5.8)\n+        ax.grid(visible=True)\n+\n+        plt.subplots_adjust(bottom=0.1, right=0.9, top=0.95, left=0.1)\n+\n+        plt.savefig(plot_pathIII)\n+        self._info('Plot saved to: %s' % plot_pathIII)\n+        plt.close()\n",
                            "Adding three plots for the Sersic fitting",
                            "Martin Kuemmel",
                            "2023-07-12T16:01:07.000+02:00",
                            "8daf5e378d7ede307e6d7a4477e2e8d9dcf8806e"
                        ]
                    ],
                    "MER_MorphologyValidation/python/MER_MorphologyValidation/MER_SersicValidationPrg.py": [
                        [
                            "@@ -0,0 +1,142 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\n+\"\"\"\n+:file: python/MER_MorphologyValidation/MER_SersicValidationPrg.py\n+\n+:date: 07/11/23\n+:author: mkuemmel@usm.lmu.de\n+\n+\"\"\"\n+import time\n+import os.path\n+import argparse\n+import ElementsKernel.Logging as log\n+\n+import numpy\n+from astropy.io import fits\n+\n+from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils.FileNaming import mer_filename\n+\n+from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n+from MER_PsfMosaicValidation.CatalogUtils import CatalogUtils\n+\n+from MER_MorphologyValidation import MER_SersicPlots\n+\n+from EL_NullValue import NullValueDefinition \n+\n+from MER_DA.MERUtilities import print_input_arguments\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"\n+    @brief Allows to define the (command line and configuration file) options\n+    specific to this program\n+\n+    @details See the Elements documentation for more details.\n+    @return An  ArgumentParser.\n+    \"\"\"\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser.add_argument('--matched_catalog', dest='matched_catalog', type=str, required=True,\n+                        help='Catalog of matched sources XML.')\n+    parser.add_argument('--vis_lim_ab', dest='vis_lim_ab', type=float, required=False,\n+                        default=24.0, help='Limiting VIS_AB magnitude.')\n+    parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n+                        default='./', help='Path to the working directory: \"%(default)s\"!')\n+    parser.add_argument(\"--logdir\", dest=\"logdir\", required=False, default='./',\n+                        type=str, help='The logging directory path: \"%(default)s\"!')\n+    parser.add_argument(\"--analysis_result\", dest=\"analysis_result\",\n+                        type=str, help=\"The analysis result output data \"\n+                        \"product XML file name.\")\n+\n+    return parser\n+\n+\n+def mainMethod(args):\n+    \"\"\"\n+    @brief The \"main\" method.\n+    \n+    @details This method is the entry point to the program. In this sense, it is\n+    similar to a main (and it is why it is called mainMethod()).\n+    \"\"\"\n+\n+    logger = log.getLogger('MER_SersicValidationPrg')\n+\n+    logger.info('#')\n+    logger.info('# Entering MER_SersicValidationPrg mainMethod()')\n+    logger.info('#')\n+\n+    # Do not print astropy warnings\n+    AnalysisUtils.ignore_astropy_warnings()\n+\n+    # Add some extra functionality to the MER data product bindings\n+    mer_utils.init()\n+\n+    # Store the start time\n+    start_time = time.time()\n+\n+    # print all parameters to the screen\n+    print_input_arguments(args, logger)\n+\n+    # Create the figures directory\n+    figsdir = os.path.join(args.workdir, \"data\", \"sersicFigures\")\n+    AnalysisUtils.create_directory(figsdir)\n+\n+    # Load the final Matched MER+TU catalog\n+    matched_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.matched_catalog))\n+\n+    # Get the final Matched MER+TU catalog name\n+    matched_catalog_file = os.path.join(args.workdir, \"data\", matched_catalog.get_data())\n+    #logger.info(matched_catalog_file)\n+    morphology_catalog_file = os.path.join(args.workdir, \"data\", matched_catalog.get_morphology_catalog())\n+    #logger.info(morphology_catalog_file)\n+\n+    null_val = NullValueDefinition()\n+    null_float = null_val.FLOAT \n+    null_double = null_val.DOUBLE \n+    logger.info('nullnull: %s %s' % (str(null_float), str(null_double)))\n+    \n+\n+    # Get the tile index, the observation ids and the processing mode\n+    tile_index = matched_catalog.get_tile_index()\n+    observation_ids = matched_catalog.get_observation_id_list()\n+    processing_mode = matched_catalog.get_processing_mode()\n+\n+    # get names for the plot files\n+    disk_radius_plot_file = os.path.join(figsdir, '%s_disk_radius.png'%matched_catalog.get_data().split('.fits')[0])\n+    sersic_indices_plot_file = os.path.join(figsdir, '%s_sersic_indices.png'%matched_catalog.get_data().split('.fits')[0])\n+    sersic_indices_bulge_file = os.path.join(figsdir, '%s_sersic_bulges.png'%matched_catalog.get_data().split('.fits')[0])\n+\n+    # make the sersic plots    \n+    sersic_plots = MER_SersicPlots.MER_SersicPlots(matched_catalog_file, logger)\n+    sersic_plots.make_sersic_fit_plots(vis_mag_lim=args.vis_lim_ab, plot_path=disk_radius_plot_file,\n+                                  plot_pathII=sersic_indices_plot_file, plot_pathIII=sersic_indices_bulge_file)\n+\n+    # Print the time spent running the step\n+    logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n+    logger.info('#')\n+    logger.info('# Exiting MER_SersicValidationPrg mainMethod()')\n+    logger.info('#')\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-08-11T15:41:07.000+02:00",
                            "3439f2b2c5d1617a26353d57808735c69cf7a538"
                        ],
                        [
                            "@@ -132,7 +132,7 @@ def mainMethod(args):\n \n     # make the sersic plots    \n     sersic_plots = MER_SersicPlots.MER_SersicPlots(matched_catalog_file, logger)\n-    sersic_plots.make_radius_plot(vis_mag_lim=args.vis_lim_ab, plot_path=disk_radius_plot_file,\n+    sersic_plots.make_sersic_fit_plots(vis_mag_lim=args.vis_lim_ab, plot_path=disk_radius_plot_file,\n                                   plot_pathII=sersic_indices_plot_file, plot_pathIII=sersic_indices_bulge_file)\n \n     # Print the time spent running the step\n",
                            "Added some documentation",
                            "Martin Kuemmel",
                            "2023-07-13T14:49:37.000+02:00",
                            "7330292b2591706cbd16dd9469f77072478917c1"
                        ],
                        [
                            "@@ -21,7 +21,7 @@\n :file: python/MER_MorphologyValidation/MER_SersicValidationPrg.py\n \n :date: 07/11/23\n-:author: mkuemmel\n+:author: mkuemmel@usm.lmu.de\n \n \"\"\"\n import time\n",
                            "Added some documentation",
                            "Martin Kuemmel",
                            "2023-07-12T16:04:37.000+02:00",
                            "62b30338894de44ce6ed383dd11ccbaf8befa3ca"
                        ],
                        [
                            "@@ -0,0 +1,142 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\n+\"\"\"\n+:file: python/MER_MorphologyValidation/MER_SersicValidationPrg.py\n+\n+:date: 07/11/23\n+:author: mkuemmel\n+\n+\"\"\"\n+import time\n+import os.path\n+import argparse\n+import ElementsKernel.Logging as log\n+\n+import numpy\n+from astropy.io import fits\n+\n+from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils.FileNaming import mer_filename\n+\n+from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n+from MER_PsfMosaicValidation.CatalogUtils import CatalogUtils\n+\n+from MER_MorphologyValidation import MER_SersicPlots\n+\n+from EL_NullValue import NullValueDefinition \n+\n+from MER_DA.MERUtilities import print_input_arguments\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"\n+    @brief Allows to define the (command line and configuration file) options\n+    specific to this program\n+\n+    @details See the Elements documentation for more details.\n+    @return An  ArgumentParser.\n+    \"\"\"\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser.add_argument('--matched_catalog', dest='matched_catalog', type=str, required=True,\n+                        help='Catalog of matched sources XML.')\n+    parser.add_argument('--vis_lim_ab', dest='vis_lim_ab', type=float, required=False,\n+                        default=24.0, help='Limiting VIS_AB magnitude.')\n+    parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n+                        default='./', help='Path to the working directory: \"%(default)s\"!')\n+    parser.add_argument(\"--logdir\", dest=\"logdir\", required=False, default='./',\n+                        type=str, help='The logging directory path: \"%(default)s\"!')\n+    parser.add_argument(\"--analysis_result\", dest=\"analysis_result\",\n+                        type=str, help=\"The analysis result output data \"\n+                        \"product XML file name.\")\n+\n+    return parser\n+\n+\n+def mainMethod(args):\n+    \"\"\"\n+    @brief The \"main\" method.\n+    \n+    @details This method is the entry point to the program. In this sense, it is\n+    similar to a main (and it is why it is called mainMethod()).\n+    \"\"\"\n+\n+    logger = log.getLogger('MER_SersicValidationPrg')\n+\n+    logger.info('#')\n+    logger.info('# Entering MER_SersicValidationPrg mainMethod()')\n+    logger.info('#')\n+\n+    # Do not print astropy warnings\n+    AnalysisUtils.ignore_astropy_warnings()\n+\n+    # Add some extra functionality to the MER data product bindings\n+    mer_utils.init()\n+\n+    # Store the start time\n+    start_time = time.time()\n+\n+    # print all parameters to the screen\n+    print_input_arguments(args, logger)\n+\n+    # Create the figures directory\n+    figsdir = os.path.join(args.workdir, \"data\", \"sersicFigures\")\n+    AnalysisUtils.create_directory(figsdir)\n+\n+    # Load the final Matched MER+TU catalog\n+    matched_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.matched_catalog))\n+\n+    # Get the final Matched MER+TU catalog name\n+    matched_catalog_file = os.path.join(args.workdir, \"data\", matched_catalog.get_data())\n+    #logger.info(matched_catalog_file)\n+    morphology_catalog_file = os.path.join(args.workdir, \"data\", matched_catalog.get_morphology_catalog())\n+    #logger.info(morphology_catalog_file)\n+\n+    null_val = NullValueDefinition()\n+    null_float = null_val.FLOAT \n+    null_double = null_val.DOUBLE \n+    logger.info('nullnull: %s %s' % (str(null_float), str(null_double)))\n+    \n+\n+    # Get the tile index, the observation ids and the processing mode\n+    tile_index = matched_catalog.get_tile_index()\n+    observation_ids = matched_catalog.get_observation_id_list()\n+    processing_mode = matched_catalog.get_processing_mode()\n+\n+    # get names for the plot files\n+    disk_radius_plot_file = os.path.join(figsdir, '%s_disk_radius.png'%matched_catalog.get_data().split('.fits')[0])\n+    sersic_indices_plot_file = os.path.join(figsdir, '%s_sersic_indices.png'%matched_catalog.get_data().split('.fits')[0])\n+    sersic_indices_bulge_file = os.path.join(figsdir, '%s_sersic_bulges.png'%matched_catalog.get_data().split('.fits')[0])\n+\n+    # make the sersic plots    \n+    sersic_plots = MER_SersicPlots.MER_SersicPlots(matched_catalog_file, logger)\n+    sersic_plots.make_radius_plot(vis_mag_lim=args.vis_lim_ab, plot_path=disk_radius_plot_file,\n+                                  plot_pathII=sersic_indices_plot_file, plot_pathIII=sersic_indices_bulge_file)\n+\n+    # Print the time spent running the step\n+    logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n+    logger.info('#')\n+    logger.info('# Exiting MER_SersicValidationPrg mainMethod()')\n+    logger.info('#')\n",
                            "Adding three plots for the Sersic fitting",
                            "Martin Kuemmel",
                            "2023-07-12T16:01:07.000+02:00",
                            "8daf5e378d7ede307e6d7a4477e2e8d9dcf8806e"
                        ]
                    ],
                    "MER_MorphologyValidation/tests/python/MER_SersicPlots_test.py": [
                        [
                            "@@ -0,0 +1,38 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+:file: tests/python/MER_SersicPlots_test.py\n+\n+:date: 07/12/23\n+:author: mkuemmel@usm.lmu.de\n+\"\"\"\n+\n+import pytest\n+import MER_MorphologyValidation.MER_SersicPlots\n+\n+class TestMER_SersicPlots(object):\n+    \"\"\"\n+    @class TestMER_SersicPlots\n+\n+    @brief Unit Test class\n+    !!! Test class example for python             !!!\n+    !!! Please remove it and add your tests there !!!\n+    \"\"\"\n+    def testFailure(self):\n+        assert True, \"!!!! Please implement your tests !!!!\"\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-08-11T15:41:07.000+02:00",
                            "3439f2b2c5d1617a26353d57808735c69cf7a538"
                        ],
                        [
                            "@@ -20,7 +20,7 @@\n :file: tests/python/MER_SersicPlots_test.py\n \n :date: 07/12/23\n-:author: mkuemmel\n+:author: mkuemmel@usm.lmu.de\n \"\"\"\n \n import pytest\n",
                            "Added some documentation",
                            "Martin Kuemmel",
                            "2023-07-12T16:04:37.000+02:00",
                            "62b30338894de44ce6ed383dd11ccbaf8befa3ca"
                        ],
                        [
                            "@@ -0,0 +1,38 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+:file: tests/python/MER_SersicPlots_test.py\n+\n+:date: 07/12/23\n+:author: mkuemmel\n+\"\"\"\n+\n+import pytest\n+import MER_MorphologyValidation.MER_SersicPlots\n+\n+class TestMER_SersicPlots(object):\n+    \"\"\"\n+    @class TestMER_SersicPlots\n+\n+    @brief Unit Test class\n+    !!! Test class example for python             !!!\n+    !!! Please remove it and add your tests there !!!\n+    \"\"\"\n+    def testFailure(self):\n+        assert True, \"!!!! Please implement your tests !!!!\"\n",
                            "Adding three plots for the Sersic fitting",
                            "Martin Kuemmel",
                            "2023-07-12T16:01:07.000+02:00",
                            "8daf5e378d7ede307e6d7a4477e2e8d9dcf8806e"
                        ]
                    ],
                    "MER_PhotometryValidation/python/MER_PhotometryValidation/MER_PlotPhotUtils.py": [
                        [
                            "@@ -397,7 +397,7 @@ class PlotPhotUtils:\n                                 else: #if mer['VIS_DET'][i]==1: #VIS detected\n                                     ddd=tug_m[j]\n                             elif j<0: # TU star\n-                                if ((band!='DET')&(mer['VIS_DET'][i]==0)): # NIR detected\n+                                if ((band=='DET')&(mer['VIS_DET'][i]==0)): # NIR detected\n                                     ddd=facZP*0.33333*(1.e6*tus[1].data['TU_FNU_Y_NISP'][-j]+1.e6*tus[1].data['TU_FNU_J_NISP'][-j]+1.e6*tus[1].data['TU_FNU_H_NISP'][-j])  \n                                 else: #if mer['VIS_DET'][i]==1: #VIS detected\n                                     ddd=tus_m[-j]\n@@ -421,10 +421,11 @@ class PlotPhotUtils:\n                             X[i]=-2.5*np.log10(ddd)+zpTU\n                             Xsn[i]=mer_m[i]/mer_errm[i]\n                             if f=='M':\n-                                if (j<0):\n-                                    Y[i]=-2.5*np.log10(fff/tus_m[-j])\n-                                else:\n-                                    Y[i]=-2.5*np.log10(fff/tug_m[j])\n+                                # if (j<0):\n+                                #     Y[i]=-2.5*np.log10(fff/tus_m[-j])\n+                                # else:\n+                                #     Y[i]=-2.5*np.log10(fff/tug_m[j])\n+                                Y[i]=-2.5*np.log10(fff/ddd)\n                                 W[i]=weightfac+1.0/(1.098*mer_errm[i]/fff)\n                             elif f=='F':\n                                 Y[i]=(fff-ddd)/ddd\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-08-11T15:41:07.000+02:00",
                            "3439f2b2c5d1617a26353d57808735c69cf7a538"
                        ],
                        [
                            "@@ -397,7 +397,7 @@ class PlotPhotUtils:\n                                 else: #if mer['VIS_DET'][i]==1: #VIS detected\n                                     ddd=tug_m[j]\n                             elif j<0: # TU star\n-                                if ((band!='DET')&(mer['VIS_DET'][i]==0)): # NIR detected\n+                                if ((band=='DET')&(mer['VIS_DET'][i]==0)): # NIR detected\n                                     ddd=facZP*0.33333*(1.e6*tus[1].data['TU_FNU_Y_NISP'][-j]+1.e6*tus[1].data['TU_FNU_J_NISP'][-j]+1.e6*tus[1].data['TU_FNU_H_NISP'][-j])  \n                                 else: #if mer['VIS_DET'][i]==1: #VIS detected\n                                     ddd=tus_m[-j]\n",
                            "Bugfix for no-VIS photometry plots developed by @emiliano",
                            "Martin Kuemmel",
                            "2023-07-28T14:58:47.000+02:00",
                            "dc298f5cc84d31aa0fa82a5846a1aa0852d77276"
                        ],
                        [
                            "@@ -421,10 +421,11 @@ class PlotPhotUtils:\n                             X[i]=-2.5*np.log10(ddd)+zpTU\n                             Xsn[i]=mer_m[i]/mer_errm[i]\n                             if f=='M':\n-                                if (j<0):\n-                                    Y[i]=-2.5*np.log10(fff/tus_m[-j])\n-                                else:\n-                                    Y[i]=-2.5*np.log10(fff/tug_m[j])\n+                                # if (j<0):\n+                                #     Y[i]=-2.5*np.log10(fff/tus_m[-j])\n+                                # else:\n+                                #     Y[i]=-2.5*np.log10(fff/tug_m[j])\n+                                Y[i]=-2.5*np.log10(fff/ddd)\n                                 W[i]=weightfac+1.0/(1.098*mer_errm[i]/fff)\n                             elif f=='F':\n                                 Y[i]=(fff-ddd)/ddd\n",
                            "Fix in NIR detected fluxes",
                            "Erik Romelli",
                            "2023-07-25T14:54:03.000+02:00",
                            "aae8899ceb08bf73300bbc0fe62f39674d13f2df"
                        ],
                        [
                            "@@ -117,10 +117,9 @@ class PlotPhotUtils:\n \n         band = tu_band\n \n-        if band=='ALL':\n+        if band == 'ALL':\n             plotallbands = True\n             if band_list:\n-                band_list.remove('ALL')\n                 bands = band_list\n             else:\n                 bands=['DET',\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ],
                        [
                            "@@ -117,10 +117,9 @@ class PlotPhotUtils:\n \n         band = tu_band\n \n-        if band=='ALL':\n+        if band == 'ALL':\n             plotallbands = True\n             if band_list:\n-                band_list.remove('ALL')\n                 bands = band_list\n             else:\n                 bands=['DET',\n",
                            "fixed a bug in DET plot",
                            "Erik Romelli",
                            "2023-06-16T17:10:16.000+02:00",
                            "a25c5764ebe245521a64159211c3d5f692b44617"
                        ],
                        [
                            "@@ -278,7 +278,6 @@ class PlotPhotUtils:\n         #========================= START LOOP ON BANDS ==========================#\n         \n         for band in bands:\n-            print(band)\n \n             # find TU fluxes\n             if band!='DET':\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-06-16T14:11:46.000+02:00",
                            "504febbf2c08fe2012b74d4f6aae5c5693624ea2"
                        ]
                    ],
                    "MER_PsfMosaicValidation/CMakeLists.txt": [
                        [
                            "@@ -65,6 +65,7 @@ elements_install_aux_files()\n elements_add_python_program(MER_PsfAnalysis MER_PsfMosaicValidation.MER_PsfAnalysis)\n elements_add_python_program(MER_MerStarPsfAnalysis MER_PsfMosaicValidation.MER_MerStarPsfAnalysis)\n elements_add_python_program(MER_TuStarPsfAnalysis MER_PsfMosaicValidation.MER_TuStarPsfAnalysis)\n+elements_add_python_program(MER_GaiaPsfAnalysis MER_PsfMosaicValidation.MER_GaiaPsfAnalysis)\n elements_add_python_program(MER_CrossmatchAnalysis MER_PsfMosaicValidation.MER_CrossmatchAnalysis)\n elements_add_python_program(MER_PhotometryAnalysis MER_PsfMosaicValidation.MER_PhotometryAnalysis)\n elements_add_python_program(MER_MergeAnalysisResults MER_PsfMosaicValidation.MER_MergeAnalysisResults)\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-08-11T15:41:07.000+02:00",
                            "3439f2b2c5d1617a26353d57808735c69cf7a538"
                        ]
                    ],
                    "MER_PsfMosaicValidation/python/MER_PsfMosaicValidation/MER_MergeAnalysisResults.py": [
                        [
                            "@@ -117,13 +117,17 @@ def defineSpecificProgramOptions():\n     return parser\n \n \n-def create_analysis_report(tile_index, workdir):\n+def create_analysis_report(processing_mode, tile_index, filling_factor, workdir):\n     \"\"\"Creates an analysis report.\n \n     Parameters\n     ----------\n+    processing_mode: str\n+        The processing mode.\n     tile_index: int\n         The tile index.\n+    filling_factor: float\n+        The tile filling factor\n     workdir: str\n         The complete path to the working directory.\n \n@@ -135,7 +139,8 @@ def create_analysis_report(tile_index, workdir):\n     \"\"\"\n     # Initialize the analysis report\n     analysis_report = AnalysisReport(\n-        \"MER analysis reports for tile %s\" % tile_index)\n+        \"%s: MER analysis reports %s filling %.1f%%\" % (\n+            processing_mode, tile_index, filling_factor))\n \n     # Add the index with the links to all the analysis reports\n     reports_links = [\n@@ -234,9 +239,16 @@ def mainMethod(args):\n     observation_ids = analysis_results[0].get_observation_id_list()\n     processing_mode = analysis_results[0].get_processing_mode()\n \n+    # Get the tile filling factor\n+    det_results = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.detection_analysis_result))\n+    filling_factor = det_results.get_parameter(\"FILLING_FACTOR\").DoubleValue\n+\n+\n     # Create the analysis report\n     logger.info(\"# Creating the merged analysis report...\")\n-    report_file_names = create_analysis_report(tile_index, args.workdir)\n+    report_file_names = create_analysis_report(\n+        processing_mode, tile_index, filling_factor, args.workdir)\n \n     # Save all the analysis files into a single merged tar file\n     tar_file_name = mer_filename(\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-08-11T15:41:07.000+02:00",
                            "3439f2b2c5d1617a26353d57808735c69cf7a538"
                        ],
                        [
                            "@@ -122,8 +122,12 @@ def create_analysis_report(processing_mode, tile_index, filling_factor, workdir)\n \n     Parameters\n     ----------\n+    processing_mode: str\n+        The processing mode.\n     tile_index: int\n         The tile index.\n+    filling_factor: float\n+        The tile filling factor\n     workdir: str\n         The complete path to the working directory.\n \n@@ -135,7 +139,8 @@ def create_analysis_report(processing_mode, tile_index, filling_factor, workdir)\n     \"\"\"\n     # Initialize the analysis report\n     analysis_report = AnalysisReport(\n-        \"%s: MER analysis reports %s filling %.1f%%\" % (processing_mode, tile_index, filling_factor))\n+        \"%s: MER analysis reports %s filling %.1f%%\" % (\n+            processing_mode, tile_index, filling_factor))\n \n     # Add the index with the links to all the analysis reports\n     reports_links = [\n@@ -233,7 +238,8 @@ def mainMethod(args):\n     tile_index = analysis_results[0].get_tile_index()\n     observation_ids = analysis_results[0].get_observation_id_list()\n     processing_mode = analysis_results[0].get_processing_mode()\n-    \n+\n+    # Get the tile filling factor\n     det_results = dm_utils.read_product_metadata(\n         os.path.join(args.workdir, args.detection_analysis_result))\n     filling_factor = det_results.get_parameter(\"FILLING_FACTOR\").DoubleValue\n@@ -241,7 +247,8 @@ def mainMethod(args):\n \n     # Create the analysis report\n     logger.info(\"# Creating the merged analysis report...\")\n-    report_file_names = create_analysis_report(processing_mode, tile_index, filling_factor, args.workdir)\n+    report_file_names = create_analysis_report(\n+        processing_mode, tile_index, filling_factor, args.workdir)\n \n     # Save all the analysis files into a single merged tar file\n     tar_file_name = mer_filename(\n",
                            "Adds the PSF validation reports + some code refactoring",
                            "Javier Gracia Carpio",
                            "2023-08-10T14:17:45.000+00:00",
                            "ad784eefa5b97030d0d46324765803dc0ceef220"
                        ],
                        [
                            "@@ -117,7 +117,7 @@ def defineSpecificProgramOptions():\n     return parser\n \n \n-def create_analysis_report(tile_index, workdir):\n+def create_analysis_report(processing_mode, tile_index, filling_factor, workdir):\n     \"\"\"Creates an analysis report.\n \n     Parameters\n@@ -135,7 +135,7 @@ def create_analysis_report(tile_index, workdir):\n     \"\"\"\n     # Initialize the analysis report\n     analysis_report = AnalysisReport(\n-        \"MER analysis reports for tile %s\" % tile_index)\n+        \"%s: MER analysis reports %s filling %.1f%%\" % (processing_mode, tile_index, filling_factor))\n \n     # Add the index with the links to all the analysis reports\n     reports_links = [\n@@ -233,10 +233,15 @@ def mainMethod(args):\n     tile_index = analysis_results[0].get_tile_index()\n     observation_ids = analysis_results[0].get_observation_id_list()\n     processing_mode = analysis_results[0].get_processing_mode()\n+    \n+    det_results = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.detection_analysis_result))\n+    filling_factor = det_results.get_parameter(\"FILLING_FACTOR\").DoubleValue\n+\n \n     # Create the analysis report\n     logger.info(\"# Creating the merged analysis report...\")\n-    report_file_names = create_analysis_report(tile_index, args.workdir)\n+    report_file_names = create_analysis_report(processing_mode, tile_index, filling_factor, args.workdir)\n \n     # Save all the analysis files into a single merged tar file\n     tar_file_name = mer_filename(\n",
                            "Merge branch 'feature/improved_index' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-18T11:28:20.000+00:00",
                            "b5fa0250db14d003f8fc3f48be1201a7c5671a39"
                        ],
                        [
                            "@@ -117,7 +117,7 @@ def defineSpecificProgramOptions():\n     return parser\n \n \n-def create_analysis_report(tile_index, workdir):\n+def create_analysis_report(processing_mode, tile_index, filling_factor, workdir):\n     \"\"\"Creates an analysis report.\n \n     Parameters\n@@ -135,7 +135,7 @@ def create_analysis_report(tile_index, workdir):\n     \"\"\"\n     # Initialize the analysis report\n     analysis_report = AnalysisReport(\n-        \"MER analysis reports for tile %s\" % tile_index)\n+        \"%s: MER analysis reports %s filling %.1f%%\" % (processing_mode, tile_index, filling_factor))\n \n     # Add the index with the links to all the analysis reports\n     reports_links = [\n@@ -233,10 +233,15 @@ def mainMethod(args):\n     tile_index = analysis_results[0].get_tile_index()\n     observation_ids = analysis_results[0].get_observation_id_list()\n     processing_mode = analysis_results[0].get_processing_mode()\n+    \n+    det_results = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.detection_analysis_result))\n+    filling_factor = det_results.get_parameter(\"FILLING_FACTOR\").DoubleValue\n+\n \n     # Create the analysis report\n     logger.info(\"# Creating the merged analysis report...\")\n-    report_file_names = create_analysis_report(tile_index, args.workdir)\n+    report_file_names = create_analysis_report(processing_mode, tile_index, filling_factor, args.workdir)\n \n     # Save all the analysis files into a single merged tar file\n     tar_file_name = mer_filename(\n",
                            "Displays mode and filling factor on the index page",
                            "Martin Kuemmel",
                            "2023-07-18T10:51:16.000+02:00",
                            "f12b01dcff5be2a644b1d622f2afdaf02f24eb6a"
                        ]
                    ],
                    "MER_Validation/python/MER_Validation/MER_DetValidationPrg.py": [
                        [
                            "@@ -107,6 +107,7 @@ def create_analysis_report(results_dict, tile_index, workdir, logger):\n     html_file_name = os.path.join(workdir, \"data\", \"detectionValidation.html\")\n     pdflatex_file_name = os.path.join(workdir, \"data\", \"detectionValidation.tex\")\n     analysis_report.set_backward('astrometryValidation.html')\n+    analysis_report.set_forward('classificationValidation.html')\n     analysis_report.save_as_json_file(json_file_name)\n     analysis_report.save_as_html_file(html_file_name)\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-08-11T15:41:07.000+02:00",
                            "3439f2b2c5d1617a26353d57808735c69cf7a538"
                        ],
                        [
                            "@@ -106,8 +106,7 @@ def create_analysis_report(results_dict, tile_index, workdir, logger):\n     json_file_name = os.path.join(workdir, \"data\", \"detectionValidation.json\")\n     html_file_name = os.path.join(workdir, \"data\", \"detectionValidation.html\")\n     pdflatex_file_name = os.path.join(workdir, \"data\", \"detectionValidation.tex\")\n-    analysis_report.set_backward('index.html')\n-    analysis_report.set_forward(\"astrometryValidation.html\")\n+    analysis_report.set_backward('astrometryValidation.html')\n     analysis_report.save_as_json_file(json_file_name)\n     analysis_report.save_as_html_file(html_file_name)\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n@@ -216,7 +215,8 @@ def mainMethod(args):\n \n     results_dict['quick_plots'] = MER_QuickFigures.create_detection_figures(final_catalog_path, tile_id, args.workdir,\n                                                                             os.path.join(args.workdir,'data'), logger=logger)\n-    for index in range(len(results_dict['quick_plots'])):\n+    n_quickplot = len(results_dict['quick_plots'])\n+    for index in range(n_quickplot):\n         results_dict['density_qplot_%i'%index] = results_dict['quick_plots'][index].get_file_name()\n         \n     results_dict['density_valid'] = bool(density_stats['median'] > configuration_parameters['density_min'])\n@@ -237,7 +237,8 @@ def mainMethod(args):\n         \"VALIDATION-RESULT\", prefix=\"MOSAICING\", tile_index=tile_id, ext=\"tar.gz\")\n     AnalysisUtils.save_tar_file(\n         os.path.join(args.workdir, \"data\", tar_file_name),\n-        report_file_names + [output_json_path, results_dict['density_plot']])\n+        report_file_names + [output_json_path, results_dict['density_plot']]+\n+        [results_dict['density_qplot_%i'%index] for i in range(n_quickplot)])\n         #report_file_names + [figsdir, output_json_path])\n \n     # Create the analysis result data product\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-27T17:00:08.000+02:00",
                            "a29716cea96bd9952a85e0d027784845fe5b7f03"
                        ],
                        [
                            "@@ -24,6 +24,7 @@\n :author: mkuemmel@usm.lmu.de\n \n \"\"\"\n+import json\n import time\n import os.path\n \n@@ -45,6 +46,72 @@ from MER_PsfMosaicValidation.AnalysisTable import AnalysisTable\n from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n \n from MER_DetectionValidation import MER_DensityPlot\n+from MER_QuickValidation import MER_QuickFigures\n+\n+from MER_DA.MERUtilities import print_input_arguments\n+\n+def create_analysis_report(results_dict, tile_index, workdir, logger):\n+    \"\"\"Creates an analysis report.\n+\n+    Parameters\n+    ----------\n+    results_dict: dictionary\n+        All results from the detection analysis\n+    tile_index: int\n+        The MER tile index.\n+    workdir: str\n+        The complete path to the working directory.\n+    logger: object\n+        A logger instance.\n+\n+    Returns\n+    -------\n+    list\n+        A python list with the analysis report file names.\n+\n+    \"\"\"\n+    logger.info(\"# Creating the analysis report!\")\n+\n+    # Initialize the analysis report without filling factor\n+    analysis_report = AnalysisReport('MER detection validation (filling factor: %.1f%%)'%(100.*results_dict['filling_factor']))\n+\n+    # Create a new analysis section and add all validation results\n+    validation_section = AnalysisSection(\"Detection validation\")\n+    validation_table = AnalysisTable(['Validation quantity', 'Result'],\n+                                     [['All', 'Density'],\n+                                      ['%s' % results_dict['valid'], '%s' % results_dict['density_valid']]\n+                                      ])\n+    validation_section.add_table(validation_table)\n+    analysis_report.add_section(validation_section)\n+\n+   # Create a new analysis section and add the crossmatch figure\n+    density_plot_section = AnalysisSection(\"Detection density results\")\n+    density_plot_section.set_figures([AnalysisFigure(results_dict['density_plot'],latex_scale=0.55)])\n+    analysis_report.add_section(density_plot_section)\n+\n+    density_plot_section_I = AnalysisSection(\"Detection position results\")\n+    density_plot_section_I.set_figures([results_dict['quick_plots'][0]])\n+    analysis_report.add_section(density_plot_section_I)\n+\n+    density_plot_section_II = AnalysisSection(\"Detection brightness results\")\n+    density_plot_section_II.set_figures([results_dict['quick_plots'][1]])\n+    analysis_report.add_section(density_plot_section_II)\n+\n+    results_dict['quick_plots']\n+\n+    # Add an index to the analysis report\n+    analysis_report.add_index()\n+\n+    # Save the analysis report in various formats\n+    json_file_name = os.path.join(workdir, \"data\", \"detectionValidation.json\")\n+    html_file_name = os.path.join(workdir, \"data\", \"detectionValidation.html\")\n+    pdflatex_file_name = os.path.join(workdir, \"data\", \"detectionValidation.tex\")\n+    analysis_report.set_backward('astrometryValidation.html')\n+    analysis_report.save_as_json_file(json_file_name)\n+    analysis_report.save_as_html_file(html_file_name)\n+    analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n+\n+    return [json_file_name, html_file_name, pdflatex_file_name]\n \n def defineSpecificProgramOptions():\n     \"\"\"\n@@ -65,8 +132,8 @@ def defineSpecificProgramOptions():\n                         help='path to the gaia cutout')\n     parser.add_argument('--tile_file', dest='tile_file', type=str, required=False,\n                         default=None, help='The tile file: \"%(default)s\"!')\n-    parser.add_argument('--output_json', dest='output_json', type=str, required=False,\n-                        default='astrometry_validation.json', help='Json file for output, default: \"astrometry_validation.json\")!')\n+    parser.add_argument('--detection_json', dest='detection_json', type=str, required=False,\n+                        default='detection_json.json', help='Json file for output, default: \"detection_json.json\")!')\n     parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n                         default='./', help='Path to the working directory: \"%(default)s\"!')\n     parser.add_argument(\"--logdir\", dest=\"logdir\", required=False, default='./',\n@@ -98,6 +165,9 @@ def mainMethod(args):\n     # Store the start time\n     start_time = time.time()\n \n+    # print all parameters to the screen\n+    print_input_arguments(args, logger)\n+\n     # start the dict for the results\n     results_dict = {}\n \n@@ -105,15 +175,23 @@ def mainMethod(args):\n     mer_utils.init()\n     ext_utils.init() \n \n+    # needs be refined\n+    results_dict['valid'] = True\n+\n     # Load the configuration parameters\n     configuration_parameters = AnalysisUtils.get_configuration_parameters(\n         os.path.join(args.workdir, args.configuration_set),\n-        \"astrometry_validation\", args.workdir)\n+        \"detection_validation\", args.workdir)\n+\n+    logger.info(configuration_parameters)\n \n     # Load the MER final catalog\n     final_catalog = dm_utils.read_product_metadata(\n         os.path.join(args.workdir, args.final_catalog))\n     final_catalog_path = os.path.join(args.workdir, \"data\", final_catalog.get_data())\n+    tile_id = final_catalog.get_tile_index()\n+    observation_ids = final_catalog.get_observation_id_list()\n+    processing_mode = final_catalog.get_processing_mode()\n \n     # load the GAIA cutout   \n     gaia_cutout = dm_utils.read_product_metadata(os.path.join(args.workdir, args.gaia_cutout))\n@@ -123,16 +201,69 @@ def mainMethod(args):\n     gaia_data = fits.getdata(gaia_cutout_path)\n     mer_data = fits.getdata(final_catalog_path)\n \n-\n     # make the object density plot per healpix\n     hpdensity_plot_file = os.path.join(args.workdir, 'data', final_catalog.get_data().split('.fits')[0] + '_hpdensity.png')\n     density_plot = MER_DensityPlot.MER_DensityPlot(final_catalog_path, os.path.join(args.workdir, args.tile_file),\n                                                    'RIGHT_ASCENSION', 'DECLINATION',\n                                                    None, logger=logger)\n-    density_plot.make_healpix_plot(hpdensity_plot_file)\n-    #plot_dict['filling_factor'] = density_plot.get_filling_factor()\n-    #plot_dict['density_plot'] = hpdensity_plot_file\n+    density_stats = density_plot.make_healpix_plot(hpdensity_plot_file)\n+    \n+    logger.info(density_stats)\n+\n+    results_dict['filling_factor'] = density_plot.get_filling_factor()\n+    results_dict['density_plot'] = hpdensity_plot_file\n+\n+    results_dict['quick_plots'] = MER_QuickFigures.create_detection_figures(final_catalog_path, tile_id, args.workdir,\n+                                                                            os.path.join(args.workdir,'data'), logger=logger)\n+    n_quickplot = len(results_dict['quick_plots'])\n+    for index in range(n_quickplot):\n+        results_dict['density_qplot_%i'%index] = results_dict['quick_plots'][index].get_file_name()\n+        \n+    results_dict['density_valid'] = bool(density_stats['median'] > configuration_parameters['density_min'])\n+    results_dict['valid'] = results_dict['valid'] & results_dict['density_valid']\n+\n+    report_file_names = create_analysis_report(results_dict, tile_id, args.workdir, logger)\n+    del results_dict['quick_plots']\n+\n+    # Writing to sample.json\n+    output_json_path = os.path.join(args.workdir, 'data', args.detection_json)\n+    with open(output_json_path, \"w+\") as out_json:\n+        out_json.write(json.dumps(results_dict, indent=4))\n+\n+    # Save all the analysis files into a tar file\n+    #tar_file_name = mer_filename(\n+    #    \"VALIDATION-RESULT\", prefix=\"ASTROMETRY\", tile_index=tile_id, ext=\"tar.gz\")\n+    tar_file_name = mer_filename(\n+        \"VALIDATION-RESULT\", prefix=\"MOSAICING\", tile_index=tile_id, ext=\"tar.gz\")\n+    AnalysisUtils.save_tar_file(\n+        os.path.join(args.workdir, \"data\", tar_file_name),\n+        report_file_names + [output_json_path, results_dict['density_plot']]+\n+        [results_dict['density_qplot_%i'%index] for i in range(n_quickplot)])\n+        #report_file_names + [figsdir, output_json_path])\n+\n+    # Create the analysis result data product\n+    if results_dict['valid']:\n+        global_result = \"PASSED\"\n+    else:\n+        global_result = \"FAILED\"\n+\n+    # create and decorate the resulting XML\n+    analysis_result = mer_utils.create_analysis_result(global_result)\n+    analysis_result.set_tile_index(tile_id)\n+    analysis_result.set_observation_id_list(observation_ids)\n+    analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_figures_tar_file(tar_file_name)\n+\n+    # create and store a generic key/value pair\n+    filling_parameter = dm_utils.create_generic_kv_parameter(key=\"FILLING_FACTOR\",\n+                                                             value=round(100.*results_dict['filling_factor'], 1), \n+                                                             value_type=\"double\", unit=\"[%]\",\n+                                                             description=\"tile filling factor\")\n+    analysis_result.add_parameter(filling_parameter)\n \n+    # Save the analysis result data product as an XML file\n+    logger.info(\"# Saving the analysis result data product\")\n+    analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n \n     # Print the time spent running the step\n     logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ],
                        [
                            "@@ -106,8 +106,7 @@ def create_analysis_report(results_dict, tile_index, workdir, logger):\n     json_file_name = os.path.join(workdir, \"data\", \"detectionValidation.json\")\n     html_file_name = os.path.join(workdir, \"data\", \"detectionValidation.html\")\n     pdflatex_file_name = os.path.join(workdir, \"data\", \"detectionValidation.tex\")\n-    analysis_report.set_backward('index.html')\n-    analysis_report.set_forward(\"astrometryValidation.html\")\n+    analysis_report.set_backward('astrometryValidation.html')\n     analysis_report.save_as_json_file(json_file_name)\n     analysis_report.save_as_html_file(html_file_name)\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n@@ -216,7 +215,8 @@ def mainMethod(args):\n \n     results_dict['quick_plots'] = MER_QuickFigures.create_detection_figures(final_catalog_path, tile_id, args.workdir,\n                                                                             os.path.join(args.workdir,'data'), logger=logger)\n-    for index in range(len(results_dict['quick_plots'])):\n+    n_quickplot = len(results_dict['quick_plots'])\n+    for index in range(n_quickplot):\n         results_dict['density_qplot_%i'%index] = results_dict['quick_plots'][index].get_file_name()\n         \n     results_dict['density_valid'] = bool(density_stats['median'] > configuration_parameters['density_min'])\n@@ -237,7 +237,8 @@ def mainMethod(args):\n         \"VALIDATION-RESULT\", prefix=\"MOSAICING\", tile_index=tile_id, ext=\"tar.gz\")\n     AnalysisUtils.save_tar_file(\n         os.path.join(args.workdir, \"data\", tar_file_name),\n-        report_file_names + [output_json_path, results_dict['density_plot']])\n+        report_file_names + [output_json_path, results_dict['density_plot']]+\n+        [results_dict['density_qplot_%i'%index] for i in range(n_quickplot)])\n         #report_file_names + [figsdir, output_json_path])\n \n     # Create the analysis result data product\n",
                            "Some mopping up and re-ordering",
                            "Martin Kuemmel",
                            "2023-07-21T10:47:49.000+02:00",
                            "1ff024aab348769fdd7dd60a20c39aae119902e7"
                        ],
                        [
                            "@@ -107,7 +107,7 @@ def create_analysis_report(results_dict, tile_index, workdir, logger):\n     html_file_name = os.path.join(workdir, \"data\", \"detectionValidation.html\")\n     pdflatex_file_name = os.path.join(workdir, \"data\", \"detectionValidation.tex\")\n     analysis_report.set_backward('index.html')\n-    analysis_report.set_forward(os.path.join(workdir, \"data\", \"astrometryValidation.html\"))\n+    analysis_report.set_forward(\"astrometryValidation.html\")\n     analysis_report.save_as_json_file(json_file_name)\n     analysis_report.save_as_html_file(html_file_name)\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n@@ -191,6 +191,8 @@ def mainMethod(args):\n         os.path.join(args.workdir, args.final_catalog))\n     final_catalog_path = os.path.join(args.workdir, \"data\", final_catalog.get_data())\n     tile_id = final_catalog.get_tile_index()\n+    observation_ids = final_catalog.get_observation_id_list()\n+    processing_mode = final_catalog.get_processing_mode()\n \n     # load the GAIA cutout   \n     gaia_cutout = dm_utils.read_product_metadata(os.path.join(args.workdir, args.gaia_cutout))\n@@ -214,7 +216,9 @@ def mainMethod(args):\n \n     results_dict['quick_plots'] = MER_QuickFigures.create_detection_figures(final_catalog_path, tile_id, args.workdir,\n                                                                             os.path.join(args.workdir,'data'), logger=logger)\n-\n+    for index in range(len(results_dict['quick_plots'])):\n+        results_dict['density_qplot_%i'%index] = results_dict['quick_plots'][index].get_file_name()\n+        \n     results_dict['density_valid'] = bool(density_stats['median'] > configuration_parameters['density_min'])\n     results_dict['valid'] = results_dict['valid'] & results_dict['density_valid']\n \n@@ -242,12 +246,20 @@ def mainMethod(args):\n     else:\n         global_result = \"FAILED\"\n \n+    # create and decorate the resulting XML\n     analysis_result = mer_utils.create_analysis_result(global_result)\n     analysis_result.set_tile_index(tile_id)\n-    #analysis_result.set_observation_id_list(observation_ids)\n-    #analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_observation_id_list(observation_ids)\n+    analysis_result.set_processing_mode(processing_mode)\n     analysis_result.set_figures_tar_file(tar_file_name)\n \n+    # create and store a generic key/value pair\n+    filling_parameter = dm_utils.create_generic_kv_parameter(key=\"FILLING_FACTOR\",\n+                                                             value=round(100.*results_dict['filling_factor'], 1), \n+                                                             value_type=\"double\", unit=\"[%]\",\n+                                                             description=\"tile filling factor\")\n+    analysis_result.add_parameter(filling_parameter)\n+\n     # Save the analysis result data product as an XML file\n     logger.info(\"# Saving the analysis result data product\")\n     analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-18T18:37:53.000+02:00",
                            "78c5119e500255574c19c53cb5e9713d82f04f41"
                        ],
                        [
                            "@@ -255,7 +255,7 @@ def mainMethod(args):\n \n     # create and store a generic key/value pair\n     filling_parameter = dm_utils.create_generic_kv_parameter(key=\"FILLING_FACTOR\",\n-                                                             value=100.*results_dict['filling_factor'], \n+                                                             value=round(100.*results_dict['filling_factor'], 1), \n                                                              value_type=\"double\", unit=\"[%]\",\n                                                              description=\"tile filling factor\")\n     analysis_result.add_parameter(filling_parameter)\n",
                            "Small format change for the filling factor",
                            "Martin Kuemmel",
                            "2023-07-18T13:25:40.000+02:00",
                            "f2afe2b352324b8803af91129213192383fecfd4"
                        ],
                        [
                            "@@ -107,7 +107,7 @@ def create_analysis_report(results_dict, tile_index, workdir, logger):\n     html_file_name = os.path.join(workdir, \"data\", \"detectionValidation.html\")\n     pdflatex_file_name = os.path.join(workdir, \"data\", \"detectionValidation.tex\")\n     analysis_report.set_backward('index.html')\n-    analysis_report.set_forward(os.path.join(workdir, \"data\", \"astrometryValidation.html\"))\n+    analysis_report.set_forward(\"astrometryValidation.html\")\n     analysis_report.save_as_json_file(json_file_name)\n     analysis_report.save_as_html_file(html_file_name)\n     analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n@@ -191,6 +191,8 @@ def mainMethod(args):\n         os.path.join(args.workdir, args.final_catalog))\n     final_catalog_path = os.path.join(args.workdir, \"data\", final_catalog.get_data())\n     tile_id = final_catalog.get_tile_index()\n+    observation_ids = final_catalog.get_observation_id_list()\n+    processing_mode = final_catalog.get_processing_mode()\n \n     # load the GAIA cutout   \n     gaia_cutout = dm_utils.read_product_metadata(os.path.join(args.workdir, args.gaia_cutout))\n@@ -214,7 +216,9 @@ def mainMethod(args):\n \n     results_dict['quick_plots'] = MER_QuickFigures.create_detection_figures(final_catalog_path, tile_id, args.workdir,\n                                                                             os.path.join(args.workdir,'data'), logger=logger)\n-\n+    for index in range(len(results_dict['quick_plots'])):\n+        results_dict['density_qplot_%i'%index] = results_dict['quick_plots'][index].get_file_name()\n+        \n     results_dict['density_valid'] = bool(density_stats['median'] > configuration_parameters['density_min'])\n     results_dict['valid'] = results_dict['valid'] & results_dict['density_valid']\n \n@@ -242,12 +246,20 @@ def mainMethod(args):\n     else:\n         global_result = \"FAILED\"\n \n+    # create and decorate the resulting XML\n     analysis_result = mer_utils.create_analysis_result(global_result)\n     analysis_result.set_tile_index(tile_id)\n-    #analysis_result.set_observation_id_list(observation_ids)\n-    #analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_observation_id_list(observation_ids)\n+    analysis_result.set_processing_mode(processing_mode)\n     analysis_result.set_figures_tar_file(tar_file_name)\n \n+    # create and store a generic key/value pair\n+    filling_parameter = dm_utils.create_generic_kv_parameter(key=\"FILLING_FACTOR\",\n+                                                             value=100.*results_dict['filling_factor'], \n+                                                             value_type=\"double\", unit=\"[%]\",\n+                                                             description=\"tile filling factor\")\n+    analysis_result.add_parameter(filling_parameter)\n+\n     # Save the analysis result data product as an XML file\n     logger.info(\"# Saving the analysis result data product\")\n     analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n",
                            "Create a generic parameter for the filling factor",
                            "Martin Kuemmel",
                            "2023-07-11T16:22:45.000+02:00",
                            "ccc800212f1732126ed243791b6fafaf339c0029"
                        ],
                        [
                            "@@ -0,0 +1,259 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\n+\"\"\"\n+:file: python/MER_Validation/MER_DetValidationPrg.py\n+\n+:date: 07/04/23\n+:author: mkuemmel@usm.lmu.de\n+\n+\"\"\"\n+import json\n+import time\n+import os.path\n+\n+import argparse\n+import ElementsKernel.Logging as log\n+\n+from astropy.io import fits\n+from astropy import units as u\n+\n+from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils import ExtDmUtils as ext_utils\n+from MER_DataModelUtils.FileNaming import mer_filename\n+\n+from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisTable import AnalysisTable\n+from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n+\n+from MER_DetectionValidation import MER_DensityPlot\n+from MER_QuickValidation import MER_QuickFigures\n+\n+from MER_DA.MERUtilities import print_input_arguments\n+\n+def create_analysis_report(results_dict, tile_index, workdir, logger):\n+    \"\"\"Creates an analysis report.\n+\n+    Parameters\n+    ----------\n+    results_dict: dictionary\n+        All results from the detection analysis\n+    tile_index: int\n+        The MER tile index.\n+    workdir: str\n+        The complete path to the working directory.\n+    logger: object\n+        A logger instance.\n+\n+    Returns\n+    -------\n+    list\n+        A python list with the analysis report file names.\n+\n+    \"\"\"\n+    logger.info(\"# Creating the analysis report!\")\n+\n+    # Initialize the analysis report without filling factor\n+    analysis_report = AnalysisReport('MER detection validation (filling factor: %.1f%%)'%(100.*results_dict['filling_factor']))\n+\n+    # Create a new analysis section and add all validation results\n+    validation_section = AnalysisSection(\"Detection validation\")\n+    validation_table = AnalysisTable(['Validation quantity', 'Result'],\n+                                     [['All', 'Density'],\n+                                      ['%s' % results_dict['valid'], '%s' % results_dict['density_valid']]\n+                                      ])\n+    validation_section.add_table(validation_table)\n+    analysis_report.add_section(validation_section)\n+\n+   # Create a new analysis section and add the crossmatch figure\n+    density_plot_section = AnalysisSection(\"Detection density results\")\n+    density_plot_section.set_figures([AnalysisFigure(results_dict['density_plot'],latex_scale=0.55)])\n+    analysis_report.add_section(density_plot_section)\n+\n+    density_plot_section_I = AnalysisSection(\"Detection position results\")\n+    density_plot_section_I.set_figures([results_dict['quick_plots'][0]])\n+    analysis_report.add_section(density_plot_section_I)\n+\n+    density_plot_section_II = AnalysisSection(\"Detection brightness results\")\n+    density_plot_section_II.set_figures([results_dict['quick_plots'][1]])\n+    analysis_report.add_section(density_plot_section_II)\n+\n+    results_dict['quick_plots']\n+\n+    # Add an index to the analysis report\n+    analysis_report.add_index()\n+\n+    # Save the analysis report in various formats\n+    json_file_name = os.path.join(workdir, \"data\", \"detectionValidation.json\")\n+    html_file_name = os.path.join(workdir, \"data\", \"detectionValidation.html\")\n+    pdflatex_file_name = os.path.join(workdir, \"data\", \"detectionValidation.tex\")\n+    analysis_report.set_backward('index.html')\n+    analysis_report.set_forward(os.path.join(workdir, \"data\", \"astrometryValidation.html\"))\n+    analysis_report.save_as_json_file(json_file_name)\n+    analysis_report.save_as_html_file(html_file_name)\n+    analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n+\n+    return [json_file_name, html_file_name, pdflatex_file_name]\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"\n+    @brief Allows to define the (command line and configuration file) options\n+    specific to this program\n+\n+    @details See the Elements documentation for more details.\n+    @return An  ArgumentParser.\n+    \"\"\"\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser.add_argument('--final_catalog', dest='final_catalog', type=str, required=True,\n+                        help='XML-path to the catalog to be validated')\n+    parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n+                        help='path to the gaia cutout')\n+    parser.add_argument('--tile_file', dest='tile_file', type=str, required=False,\n+                        default=None, help='The tile file: \"%(default)s\"!')\n+    parser.add_argument('--detection_json', dest='detection_json', type=str, required=False,\n+                        default='detection_json.json', help='Json file for output, default: \"detection_json.json\")!')\n+    parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n+                        default='./', help='Path to the working directory: \"%(default)s\"!')\n+    parser.add_argument(\"--logdir\", dest=\"logdir\", required=False, default='./',\n+                        type=str, help='The logging directory path: \"%(default)s\"!')\n+    parser.add_argument(\"--analysis_result\", dest=\"analysis_result\",\n+                        type=str, help=\"The analysis result output data \"\n+                        \"product XML file name.\")\n+    parser.add_argument(\"--configuration_set\", dest=\"configuration_set\",\n+                        type=str, help=\"The MER Configuration Set product XML \"\n+                        \"file name.\")\n+\n+    return parser\n+\n+\n+def mainMethod(args):\n+    \"\"\"\n+    @brief The \"main\" method.\n+    \n+    @details This method is the entry point to the program. In this sense, it is\n+    similar to a main (and it is why it is called mainMethod()).\n+    \"\"\"\n+\n+    logger = log.getLogger('MER_DetValidationPrg')\n+\n+    logger.info('#')\n+    logger.info('# Entering MER_DetValidationPrg mainMethod()')\n+    logger.info('#')\n+\n+    # Store the start time\n+    start_time = time.time()\n+\n+    # print all parameters to the screen\n+    print_input_arguments(args, logger)\n+\n+    # start the dict for the results\n+    results_dict = {}\n+\n+    # Add some extra functionality to the MER data product bindings\n+    mer_utils.init()\n+    ext_utils.init() \n+\n+    # needs be refined\n+    results_dict['valid'] = True\n+\n+    # Load the configuration parameters\n+    configuration_parameters = AnalysisUtils.get_configuration_parameters(\n+        os.path.join(args.workdir, args.configuration_set),\n+        \"detection_validation\", args.workdir)\n+\n+    logger.info(configuration_parameters)\n+\n+    # Load the MER final catalog\n+    final_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.final_catalog))\n+    final_catalog_path = os.path.join(args.workdir, \"data\", final_catalog.get_data())\n+    tile_id = final_catalog.get_tile_index()\n+\n+    # load the GAIA cutout   \n+    gaia_cutout = dm_utils.read_product_metadata(os.path.join(args.workdir, args.gaia_cutout))\n+    gaia_cutout_path = os.path.join(args.workdir, 'data', gaia_cutout.get_data())\n+            \n+    # get all table data    \n+    gaia_data = fits.getdata(gaia_cutout_path)\n+    mer_data = fits.getdata(final_catalog_path)\n+\n+    # make the object density plot per healpix\n+    hpdensity_plot_file = os.path.join(args.workdir, 'data', final_catalog.get_data().split('.fits')[0] + '_hpdensity.png')\n+    density_plot = MER_DensityPlot.MER_DensityPlot(final_catalog_path, os.path.join(args.workdir, args.tile_file),\n+                                                   'RIGHT_ASCENSION', 'DECLINATION',\n+                                                   None, logger=logger)\n+    density_stats = density_plot.make_healpix_plot(hpdensity_plot_file)\n+    \n+    logger.info(density_stats)\n+\n+    results_dict['filling_factor'] = density_plot.get_filling_factor()\n+    results_dict['density_plot'] = hpdensity_plot_file\n+\n+    results_dict['quick_plots'] = MER_QuickFigures.create_detection_figures(final_catalog_path, tile_id, args.workdir,\n+                                                                            os.path.join(args.workdir,'data'), logger=logger)\n+\n+    results_dict['density_valid'] = bool(density_stats['median'] > configuration_parameters['density_min'])\n+    results_dict['valid'] = results_dict['valid'] & results_dict['density_valid']\n+\n+    report_file_names = create_analysis_report(results_dict, tile_id, args.workdir, logger)\n+    del results_dict['quick_plots']\n+\n+    # Writing to sample.json\n+    output_json_path = os.path.join(args.workdir, 'data', args.detection_json)\n+    with open(output_json_path, \"w+\") as out_json:\n+        out_json.write(json.dumps(results_dict, indent=4))\n+\n+    # Save all the analysis files into a tar file\n+    #tar_file_name = mer_filename(\n+    #    \"VALIDATION-RESULT\", prefix=\"ASTROMETRY\", tile_index=tile_id, ext=\"tar.gz\")\n+    tar_file_name = mer_filename(\n+        \"VALIDATION-RESULT\", prefix=\"MOSAICING\", tile_index=tile_id, ext=\"tar.gz\")\n+    AnalysisUtils.save_tar_file(\n+        os.path.join(args.workdir, \"data\", tar_file_name),\n+        report_file_names + [output_json_path, results_dict['density_plot']])\n+        #report_file_names + [figsdir, output_json_path])\n+\n+    # Create the analysis result data product\n+    if results_dict['valid']:\n+        global_result = \"PASSED\"\n+    else:\n+        global_result = \"FAILED\"\n+\n+    analysis_result = mer_utils.create_analysis_result(global_result)\n+    analysis_result.set_tile_index(tile_id)\n+    #analysis_result.set_observation_id_list(observation_ids)\n+    #analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_figures_tar_file(tar_file_name)\n+\n+    # Save the analysis result data product as an XML file\n+    logger.info(\"# Saving the analysis result data product\")\n+    analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n+\n+    # Print the time spent running the step\n+    logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n+    logger.info('#')\n+    logger.info('# Exiting MER_DetValidationPrg mainMethod()')\n+    logger.info('#')\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-10T15:27:04.000+02:00",
                            "b4030040f2cf4ffc0140a2f4f30e0e1b83a1ff07"
                        ],
                        [
                            "@@ -77,6 +77,12 @@ def create_analysis_report(results_dict, tile_index, workdir, logger):\n \n     # Create a new analysis section and add all validation results\n     validation_section = AnalysisSection(\"Detection validation\")\n+    validation_table = AnalysisTable(['Validation quantity', 'Result'],\n+                                     [['All', 'Density'],\n+                                      ['%s' % results_dict['valid'], '%s' % results_dict['density_valid']]\n+                                      ])\n+    validation_section.add_table(validation_table)\n+    analysis_report.add_section(validation_section)\n \n    # Create a new analysis section and add the crossmatch figure\n     density_plot_section = AnalysisSection(\"Detection density results\")\n@@ -127,8 +133,8 @@ def defineSpecificProgramOptions():\n                         help='path to the gaia cutout')\n     parser.add_argument('--tile_file', dest='tile_file', type=str, required=False,\n                         default=None, help='The tile file: \"%(default)s\"!')\n-    parser.add_argument('--astrometry_json', dest='astrometry_json', type=str, required=False,\n-                        default='astrometry_validation.json', help='Json file for output, default: \"astrometry_validation.json\")!')\n+    parser.add_argument('--detection_json', dest='detection_json', type=str, required=False,\n+                        default='detection_json.json', help='Json file for output, default: \"detection_json.json\")!')\n     parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n                         default='./', help='Path to the working directory: \"%(default)s\"!')\n     parser.add_argument(\"--logdir\", dest=\"logdir\", required=False, default='./',\n@@ -170,10 +176,15 @@ def mainMethod(args):\n     mer_utils.init()\n     ext_utils.init() \n \n+    # needs be refined\n+    results_dict['valid'] = True\n+\n     # Load the configuration parameters\n     configuration_parameters = AnalysisUtils.get_configuration_parameters(\n         os.path.join(args.workdir, args.configuration_set),\n-        \"astrometry_validation\", args.workdir)\n+        \"detection_validation\", args.workdir)\n+\n+    logger.info(configuration_parameters)\n \n     # Load the MER final catalog\n     final_catalog = dm_utils.read_product_metadata(\n@@ -189,17 +200,14 @@ def mainMethod(args):\n     gaia_data = fits.getdata(gaia_cutout_path)\n     mer_data = fits.getdata(final_catalog_path)\n \n-    # needs be refined\n-    results_dict['valid'] = True\n-\n     # make the object density plot per healpix\n     hpdensity_plot_file = os.path.join(args.workdir, 'data', final_catalog.get_data().split('.fits')[0] + '_hpdensity.png')\n     density_plot = MER_DensityPlot.MER_DensityPlot(final_catalog_path, os.path.join(args.workdir, args.tile_file),\n                                                    'RIGHT_ASCENSION', 'DECLINATION',\n                                                    None, logger=logger)\n-    density_plot.make_healpix_plot(hpdensity_plot_file)\n-    #plot_dict['filling_factor'] = density_plot.get_filling_factor()\n-    #plot_dict['density_plot'] = hpdensity_plot_file\n+    density_stats = density_plot.make_healpix_plot(hpdensity_plot_file)\n+    \n+    logger.info(density_stats)\n \n     results_dict['filling_factor'] = density_plot.get_filling_factor()\n     results_dict['density_plot'] = hpdensity_plot_file\n@@ -207,11 +215,14 @@ def mainMethod(args):\n     results_dict['quick_plots'] = MER_QuickFigures.create_detection_figures(final_catalog_path, tile_id, args.workdir,\n                                                                             os.path.join(args.workdir,'data'), logger=logger)\n \n+    results_dict['density_valid'] = bool(density_stats['median'] > configuration_parameters['density_min'])\n+    results_dict['valid'] = results_dict['valid'] & results_dict['density_valid']\n+\n     report_file_names = create_analysis_report(results_dict, tile_id, args.workdir, logger)\n     del results_dict['quick_plots']\n \n     # Writing to sample.json\n-    output_json_path = os.path.join(args.workdir, 'data', args.astrometry_json)\n+    output_json_path = os.path.join(args.workdir, 'data', args.detection_json)\n     with open(output_json_path, \"w+\") as out_json:\n         out_json.write(json.dumps(results_dict, indent=4))\n \n",
                            "Some smaller improvements",
                            "Martin Kuemmel",
                            "2023-07-07T13:40:22.000+02:00",
                            "0c55c9795204ad36c1dd7b763090c972aebc0f7a"
                        ],
                        [
                            "@@ -24,6 +24,7 @@\n :author: mkuemmel@usm.lmu.de\n \n \"\"\"\n+import json\n import time\n import os.path\n \n@@ -45,6 +46,67 @@ from MER_PsfMosaicValidation.AnalysisTable import AnalysisTable\n from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n \n from MER_DetectionValidation import MER_DensityPlot\n+from MER_QuickValidation import MER_QuickFigures\n+\n+from MER_DA.MERUtilities import print_input_arguments\n+\n+def create_analysis_report(results_dict, tile_index, workdir, logger):\n+    \"\"\"Creates an analysis report.\n+\n+    Parameters\n+    ----------\n+    results_dict: dictionary\n+        All results from the detection analysis\n+    tile_index: int\n+        The MER tile index.\n+    workdir: str\n+        The complete path to the working directory.\n+    logger: object\n+        A logger instance.\n+\n+    Returns\n+    -------\n+    list\n+        A python list with the analysis report file names.\n+\n+    \"\"\"\n+    logger.info(\"# Creating the analysis report!\")\n+\n+    # Initialize the analysis report without filling factor\n+    analysis_report = AnalysisReport('MER detection validation (filling factor: %.1f%%)'%(100.*results_dict['filling_factor']))\n+\n+    # Create a new analysis section and add all validation results\n+    validation_section = AnalysisSection(\"Detection validation\")\n+\n+   # Create a new analysis section and add the crossmatch figure\n+    density_plot_section = AnalysisSection(\"Detection density results\")\n+    density_plot_section.set_figures([AnalysisFigure(results_dict['density_plot'],latex_scale=0.55)])\n+    analysis_report.add_section(density_plot_section)\n+\n+    density_plot_section_I = AnalysisSection(\"Detection position results\")\n+    density_plot_section_I.set_figures([results_dict['quick_plots'][0]])\n+    analysis_report.add_section(density_plot_section_I)\n+\n+    density_plot_section_II = AnalysisSection(\"Detection brightness results\")\n+    density_plot_section_II.set_figures([results_dict['quick_plots'][1]])\n+    analysis_report.add_section(density_plot_section_II)\n+\n+    results_dict['quick_plots']\n+\n+    # Add an index to the analysis report\n+    analysis_report.add_index()\n+\n+    # Save the analysis report in various formats\n+    json_file_name = os.path.join(workdir, \"data\", \"detectionValidation.json\")\n+    html_file_name = os.path.join(workdir, \"data\", \"detectionValidation.html\")\n+    pdflatex_file_name = os.path.join(workdir, \"data\", \"detectionValidation.tex\")\n+    analysis_report.set_backward('index.html')\n+    analysis_report.set_forward(os.path.join(workdir, \"data\", \"astrometryValidation.html\"))\n+    analysis_report.save_as_json_file(json_file_name)\n+    analysis_report.save_as_html_file(html_file_name)\n+    analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n+\n+    return [json_file_name, html_file_name, pdflatex_file_name]\n \n def defineSpecificProgramOptions():\n     \"\"\"\n@@ -65,7 +127,7 @@ def defineSpecificProgramOptions():\n                         help='path to the gaia cutout')\n     parser.add_argument('--tile_file', dest='tile_file', type=str, required=False,\n                         default=None, help='The tile file: \"%(default)s\"!')\n-    parser.add_argument('--output_json', dest='output_json', type=str, required=False,\n+    parser.add_argument('--astrometry_json', dest='astrometry_json', type=str, required=False,\n                         default='astrometry_validation.json', help='Json file for output, default: \"astrometry_validation.json\")!')\n     parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n                         default='./', help='Path to the working directory: \"%(default)s\"!')\n@@ -98,6 +160,9 @@ def mainMethod(args):\n     # Store the start time\n     start_time = time.time()\n \n+    # print all parameters to the screen\n+    print_input_arguments(args, logger)\n+\n     # start the dict for the results\n     results_dict = {}\n \n@@ -114,6 +179,7 @@ def mainMethod(args):\n     final_catalog = dm_utils.read_product_metadata(\n         os.path.join(args.workdir, args.final_catalog))\n     final_catalog_path = os.path.join(args.workdir, \"data\", final_catalog.get_data())\n+    tile_id = final_catalog.get_tile_index()\n \n     # load the GAIA cutout   \n     gaia_cutout = dm_utils.read_product_metadata(os.path.join(args.workdir, args.gaia_cutout))\n@@ -123,6 +189,8 @@ def mainMethod(args):\n     gaia_data = fits.getdata(gaia_cutout_path)\n     mer_data = fits.getdata(final_catalog_path)\n \n+    # needs be refined\n+    results_dict['valid'] = True\n \n     # make the object density plot per healpix\n     hpdensity_plot_file = os.path.join(args.workdir, 'data', final_catalog.get_data().split('.fits')[0] + '_hpdensity.png')\n@@ -133,6 +201,45 @@ def mainMethod(args):\n     #plot_dict['filling_factor'] = density_plot.get_filling_factor()\n     #plot_dict['density_plot'] = hpdensity_plot_file\n \n+    results_dict['filling_factor'] = density_plot.get_filling_factor()\n+    results_dict['density_plot'] = hpdensity_plot_file\n+\n+    results_dict['quick_plots'] = MER_QuickFigures.create_detection_figures(final_catalog_path, tile_id, args.workdir,\n+                                                                            os.path.join(args.workdir,'data'), logger=logger)\n+\n+    report_file_names = create_analysis_report(results_dict, tile_id, args.workdir, logger)\n+    del results_dict['quick_plots']\n+\n+    # Writing to sample.json\n+    output_json_path = os.path.join(args.workdir, 'data', args.astrometry_json)\n+    with open(output_json_path, \"w+\") as out_json:\n+        out_json.write(json.dumps(results_dict, indent=4))\n+\n+    # Save all the analysis files into a tar file\n+    #tar_file_name = mer_filename(\n+    #    \"VALIDATION-RESULT\", prefix=\"ASTROMETRY\", tile_index=tile_id, ext=\"tar.gz\")\n+    tar_file_name = mer_filename(\n+        \"VALIDATION-RESULT\", prefix=\"MOSAICING\", tile_index=tile_id, ext=\"tar.gz\")\n+    AnalysisUtils.save_tar_file(\n+        os.path.join(args.workdir, \"data\", tar_file_name),\n+        report_file_names + [output_json_path, results_dict['density_plot']])\n+        #report_file_names + [figsdir, output_json_path])\n+\n+    # Create the analysis result data product\n+    if results_dict['valid']:\n+        global_result = \"PASSED\"\n+    else:\n+        global_result = \"FAILED\"\n+\n+    analysis_result = mer_utils.create_analysis_result(global_result)\n+    analysis_result.set_tile_index(tile_id)\n+    #analysis_result.set_observation_id_list(observation_ids)\n+    #analysis_result.set_processing_mode(processing_mode)\n+    analysis_result.set_figures_tar_file(tar_file_name)\n+\n+    # Save the analysis result data product as an XML file\n+    logger.info(\"# Saving the analysis result data product\")\n+    analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n \n     # Print the time spent running the step\n     logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n",
                            "Results are displayed as intended",
                            "Martin Kuemmel",
                            "2023-07-05T17:38:13.000+02:00",
                            "88b17ad283d888d70c3cf9f6bab4ca215139258e"
                        ],
                        [
                            "@@ -0,0 +1,141 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\n+\"\"\"\n+:file: python/MER_Validation/MER_DetValidationPrg.py\n+\n+:date: 07/04/23\n+:author: mkuemmel@usm.lmu.de\n+\n+\"\"\"\n+import time\n+import os.path\n+\n+import argparse\n+import ElementsKernel.Logging as log\n+\n+from astropy.io import fits\n+from astropy import units as u\n+\n+from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils import ExtDmUtils as ext_utils\n+from MER_DataModelUtils.FileNaming import mer_filename\n+\n+from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisTable import AnalysisTable\n+from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n+\n+from MER_DetectionValidation import MER_DensityPlot\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"\n+    @brief Allows to define the (command line and configuration file) options\n+    specific to this program\n+\n+    @details See the Elements documentation for more details.\n+    @return An  ArgumentParser.\n+    \"\"\"\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser.add_argument('--final_catalog', dest='final_catalog', type=str, required=True,\n+                        help='XML-path to the catalog to be validated')\n+    parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n+                        help='path to the gaia cutout')\n+    parser.add_argument('--tile_file', dest='tile_file', type=str, required=False,\n+                        default=None, help='The tile file: \"%(default)s\"!')\n+    parser.add_argument('--output_json', dest='output_json', type=str, required=False,\n+                        default='astrometry_validation.json', help='Json file for output, default: \"astrometry_validation.json\")!')\n+    parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n+                        default='./', help='Path to the working directory: \"%(default)s\"!')\n+    parser.add_argument(\"--logdir\", dest=\"logdir\", required=False, default='./',\n+                        type=str, help='The logging directory path: \"%(default)s\"!')\n+    parser.add_argument(\"--analysis_result\", dest=\"analysis_result\",\n+                        type=str, help=\"The analysis result output data \"\n+                        \"product XML file name.\")\n+    parser.add_argument(\"--configuration_set\", dest=\"configuration_set\",\n+                        type=str, help=\"The MER Configuration Set product XML \"\n+                        \"file name.\")\n+\n+    return parser\n+\n+\n+def mainMethod(args):\n+    \"\"\"\n+    @brief The \"main\" method.\n+    \n+    @details This method is the entry point to the program. In this sense, it is\n+    similar to a main (and it is why it is called mainMethod()).\n+    \"\"\"\n+\n+    logger = log.getLogger('MER_DetValidationPrg')\n+\n+    logger.info('#')\n+    logger.info('# Entering MER_DetValidationPrg mainMethod()')\n+    logger.info('#')\n+\n+    # Store the start time\n+    start_time = time.time()\n+\n+    # start the dict for the results\n+    results_dict = {}\n+\n+    # Add some extra functionality to the MER data product bindings\n+    mer_utils.init()\n+    ext_utils.init() \n+\n+    # Load the configuration parameters\n+    configuration_parameters = AnalysisUtils.get_configuration_parameters(\n+        os.path.join(args.workdir, args.configuration_set),\n+        \"astrometry_validation\", args.workdir)\n+\n+    # Load the MER final catalog\n+    final_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.final_catalog))\n+    final_catalog_path = os.path.join(args.workdir, \"data\", final_catalog.get_data())\n+\n+    # load the GAIA cutout   \n+    gaia_cutout = dm_utils.read_product_metadata(os.path.join(args.workdir, args.gaia_cutout))\n+    gaia_cutout_path = os.path.join(args.workdir, 'data', gaia_cutout.get_data())\n+            \n+    # get all table data    \n+    gaia_data = fits.getdata(gaia_cutout_path)\n+    mer_data = fits.getdata(final_catalog_path)\n+\n+\n+    # make the object density plot per healpix\n+    hpdensity_plot_file = os.path.join(args.workdir, 'data', final_catalog.get_data().split('.fits')[0] + '_hpdensity.png')\n+    density_plot = MER_DensityPlot.MER_DensityPlot(final_catalog_path, os.path.join(args.workdir, args.tile_file),\n+                                                   'RIGHT_ASCENSION', 'DECLINATION',\n+                                                   None, logger=logger)\n+    density_plot.make_healpix_plot(hpdensity_plot_file)\n+    #plot_dict['filling_factor'] = density_plot.get_filling_factor()\n+    #plot_dict['density_plot'] = hpdensity_plot_file\n+\n+\n+    # Print the time spent running the step\n+    logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n+    logger.info('#')\n+    logger.info('# Exiting MER_DetValidationPrg mainMethod()')\n+    logger.info('#')\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T21:40:08.000+00:00",
                            "696982ed8506ddb56f2beca6b7fe88377fa08c21"
                        ],
                        [
                            "@@ -0,0 +1,141 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\n+\"\"\"\n+:file: python/MER_Validation/MER_DetValidationPrg.py\n+\n+:date: 07/04/23\n+:author: mkuemmel@usm.lmu.de\n+\n+\"\"\"\n+import time\n+import os.path\n+\n+import argparse\n+import ElementsKernel.Logging as log\n+\n+from astropy.io import fits\n+from astropy import units as u\n+\n+from MER_DataModelUtils import DmUtils as dm_utils\n+from MER_DataModelUtils import MerDmUtils as mer_utils\n+from MER_DataModelUtils import ExtDmUtils as ext_utils\n+from MER_DataModelUtils.FileNaming import mer_filename\n+\n+from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+from MER_PsfMosaicValidation.AnalysisTable import AnalysisTable\n+from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n+\n+from MER_DetectionValidation import MER_DensityPlot\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"\n+    @brief Allows to define the (command line and configuration file) options\n+    specific to this program\n+\n+    @details See the Elements documentation for more details.\n+    @return An  ArgumentParser.\n+    \"\"\"\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser.add_argument('--final_catalog', dest='final_catalog', type=str, required=True,\n+                        help='XML-path to the catalog to be validated')\n+    parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n+                        help='path to the gaia cutout')\n+    parser.add_argument('--tile_file', dest='tile_file', type=str, required=False,\n+                        default=None, help='The tile file: \"%(default)s\"!')\n+    parser.add_argument('--output_json', dest='output_json', type=str, required=False,\n+                        default='astrometry_validation.json', help='Json file for output, default: \"astrometry_validation.json\")!')\n+    parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n+                        default='./', help='Path to the working directory: \"%(default)s\"!')\n+    parser.add_argument(\"--logdir\", dest=\"logdir\", required=False, default='./',\n+                        type=str, help='The logging directory path: \"%(default)s\"!')\n+    parser.add_argument(\"--analysis_result\", dest=\"analysis_result\",\n+                        type=str, help=\"The analysis result output data \"\n+                        \"product XML file name.\")\n+    parser.add_argument(\"--configuration_set\", dest=\"configuration_set\",\n+                        type=str, help=\"The MER Configuration Set product XML \"\n+                        \"file name.\")\n+\n+    return parser\n+\n+\n+def mainMethod(args):\n+    \"\"\"\n+    @brief The \"main\" method.\n+    \n+    @details This method is the entry point to the program. In this sense, it is\n+    similar to a main (and it is why it is called mainMethod()).\n+    \"\"\"\n+\n+    logger = log.getLogger('MER_DetValidationPrg')\n+\n+    logger.info('#')\n+    logger.info('# Entering MER_DetValidationPrg mainMethod()')\n+    logger.info('#')\n+\n+    # Store the start time\n+    start_time = time.time()\n+\n+    # start the dict for the results\n+    results_dict = {}\n+\n+    # Add some extra functionality to the MER data product bindings\n+    mer_utils.init()\n+    ext_utils.init() \n+\n+    # Load the configuration parameters\n+    configuration_parameters = AnalysisUtils.get_configuration_parameters(\n+        os.path.join(args.workdir, args.configuration_set),\n+        \"astrometry_validation\", args.workdir)\n+\n+    # Load the MER final catalog\n+    final_catalog = dm_utils.read_product_metadata(\n+        os.path.join(args.workdir, args.final_catalog))\n+    final_catalog_path = os.path.join(args.workdir, \"data\", final_catalog.get_data())\n+\n+    # load the GAIA cutout   \n+    gaia_cutout = dm_utils.read_product_metadata(os.path.join(args.workdir, args.gaia_cutout))\n+    gaia_cutout_path = os.path.join(args.workdir, 'data', gaia_cutout.get_data())\n+            \n+    # get all table data    \n+    gaia_data = fits.getdata(gaia_cutout_path)\n+    mer_data = fits.getdata(final_catalog_path)\n+\n+\n+    # make the object density plot per healpix\n+    hpdensity_plot_file = os.path.join(args.workdir, 'data', final_catalog.get_data().split('.fits')[0] + '_hpdensity.png')\n+    density_plot = MER_DensityPlot.MER_DensityPlot(final_catalog_path, os.path.join(args.workdir, args.tile_file),\n+                                                   'RIGHT_ASCENSION', 'DECLINATION',\n+                                                   None, logger=logger)\n+    density_plot.make_healpix_plot(hpdensity_plot_file)\n+    #plot_dict['filling_factor'] = density_plot.get_filling_factor()\n+    #plot_dict['density_plot'] = hpdensity_plot_file\n+\n+\n+    # Print the time spent running the step\n+    logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n+    logger.info('#')\n+    logger.info('# Exiting MER_DetValidationPrg mainMethod()')\n+    logger.info('#')\n",
                            "Started integrating detection validation",
                            "Martin Kuemmel",
                            "2023-07-04T20:56:37.000+02:00",
                            "597608469db752cb043620ddd90606a13a97cd52"
                        ]
                    ],
                    "MER_DetectionValidation/python/MER_DetectionValidation/MER_DensityPlot.py": [
                        [
                            "@@ -158,3 +158,5 @@ class MER_DensityPlot(object):\n         hp_plot = MER_HealpixPlot.MER_HealpixPlot(self._healpix_indices, self._density_histogram,\n                                                   self._input_selector.get_moc_order(), self._logger)\n         hp_plot.plot(plot_file)\n+\n+        return hp_plot.get_stats()\n\\ No newline at end of file\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ]
                    ],
                    "MER_DetectionValidation/python/MER_DetectionValidation/MER_HealpixPlot.py": [
                        [
                            "@@ -115,6 +115,11 @@ class MER_HealpixPlot(object):\n         \"\"\"\n         return (value-self._colour_stats['min'])/self._colour_stats['range']\n \n+    def get_stats(self):\n+        \"\"\"\n+        \"\"\"\n+        return self._histo_stats\n+\n     def plot(self, plot_file):\n         \"\"\"\n         \"\"\"\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ],
                        [
                            "@@ -216,8 +216,8 @@ class MER_HealpixPlot(object):\n             plt.show()\n         else:\n             # write to a plot file\n-            #fig.savefig(plot_file, overwrite=True)\n-            plt.savefig(plot_file, overwrite=True)\n+            #fig.savefig(plot_file)\n+            plt.savefig(plot_file)\n             # give feedback\n             self._info('Plot saved in file: %s!' % plot_file)\n         \n\\ No newline at end of file\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ],
                        [
                            "@@ -216,8 +216,8 @@ class MER_HealpixPlot(object):\n             plt.show()\n         else:\n             # write to a plot file\n-            #fig.savefig(plot_file, overwrite=True)\n-            plt.savefig(plot_file, overwrite=True)\n+            #fig.savefig(plot_file)\n+            plt.savefig(plot_file)\n             # give feedback\n             self._info('Plot saved in file: %s!' % plot_file)\n         \n\\ No newline at end of file\n",
                            "Removes deprecated overwrite parameter from plt.savefig method",
                            "Javier Gracia Carpio",
                            "2023-06-25T14:52:37.000+00:00",
                            "3702abd7019e03de09ccb9ab9a57f592c0b18c09"
                        ]
                    ],
                    "MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF15-0002797_20230120T201904.492276Z_BPRP_GVIS_line.fits": [
                        [
                            "Binary files /dev/null and b/MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF15-0002797_20230120T201904.492276Z_BPRP_GVIS_line.fits differ\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ]
                    ],
                    "MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GHNISP_line.fits": [
                        [
                            "Binary files /dev/null and b/MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GHNISP_line.fits differ\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ]
                    ],
                    "MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GJNISP_line.fits": [
                        [
                            "Binary files /dev/null and b/MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GJNISP_line.fits differ\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ]
                    ],
                    "MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GYNISP_line.fits": [
                        [
                            "Binary files /dev/null and b/MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_GYNISP_line.fits differ\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ]
                    ],
                    "MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_G_line.fits": [
                        [
                            "Binary files /dev/null and b/MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_G_line.fits differ\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ]
                    ],
                    "MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_I_line.fits": [
                        [
                            "Binary files /dev/null and b/MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_I_line.fits differ\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ]
                    ],
                    "MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_R_line.fits": [
                        [
                            "Binary files /dev/null and b/MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_R_line.fits differ\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ]
                    ],
                    "MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_Z_line.fits": [
                        [
                            "Binary files /dev/null and b/MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_DECAM_Z_line.fits differ\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ]
                    ],
                    "MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_HSC_Z_line.fits": [
                        [
                            "Binary files /dev/null and b/MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_HSC_Z_line.fits differ\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ]
                    ],
                    "MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_JPCAM_G_line.fits": [
                        [
                            "Binary files /dev/null and b/MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_JPCAM_G_line.fits differ\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ]
                    ],
                    "MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_MEGACAM_R_line.fits": [
                        [
                            "Binary files /dev/null and b/MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_MEGACAM_R_line.fits differ\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ]
                    ],
                    "MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_PANSTARRS_I_line.fits": [
                        [
                            "Binary files /dev/null and b/MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_PANSTARRS_I_line.fits differ\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ]
                    ],
                    "MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_PANSTARRS_Z_line.fits": [
                        [
                            "Binary files /dev/null and b/MER_Validation/auxdir/EUC_SIM_STAR-0AC1F6B1AF16-0003745_20230120T210159.029706Z_BPRP_G_PANSTARRS_Z_line.fits differ\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ]
                    ],
                    "MER_Validation/auxdir/EUC_SIM_STAR-CATALOG_06CC2173BBE8-0008009_20230120T200847.836558Z_DECAM_GR_I_MEGACAM_U_line.fits": [
                        [
                            "Binary files /dev/null and b/MER_Validation/auxdir/EUC_SIM_STAR-CATALOG_06CC2173BBE8-0008009_20230120T200847.836558Z_DECAM_GR_I_MEGACAM_U_line.fits differ\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ]
                    ],
                    "MER_Validation/python/MER_Validation/MER_ValidationPrg.py": [
                        [
                            "@@ -1,186 +0,0 @@\n-#\n-# Copyright (C) 2012-2020 Euclid Science Ground Segment\n-#\n-# This library is free software; you can redistribute it and/or modify it under\n-# the terms of the GNU Lesser General Public License as published by the Free\n-# Software Foundation; either version 3.0 of the License, or (at your option)\n-# any later version.\n-#\n-# This library is distributed in the hope that it will be useful, but WITHOUT\n-# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n-# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n-# details.\n-#\n-# You should have received a copy of the GNU Lesser General Public License\n-# along with this library; if not, write to the Free Software Foundation, Inc.,\n-# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n-#\n-\n-\n-\"\"\"\n-:file: python/MER_Validation/MER_ValidationPrg.py\n-\n-:date: 06/07/23\n-:author: yfang\n-\n-\"\"\"\n-\n-import os\n-import argparse\n-import ElementsKernel.Logging as log\n-\n-import numpy as np\n-\n-from MER_DA import MER_CrossMatchModule\n-from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n-from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n-from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n-\n-from .MER_PhotometryValidation import get_trans_func, read_gaia_catalog, read_mer_catalog, evaluate_deviation\n-\n-def defineSpecificProgramOptions():\n-    \"\"\"\n-    @brief Allows to define the (command line and configuration file) options\n-    specific to this program\n-\n-    @details See the Elements documentation for more details.\n-    @return An  ArgumentParser.\n-    \"\"\"\n-\n-    parser = argparse.ArgumentParser()\n-\n-    parser.add_argument('--mer_catalog', dest='mer_catalog', type=str, required=True,\n-                        help='path to the catalog to be validated')\n-    parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n-                        help='path to the gaia cutout')\n-    parser.add_argument('--trans_func', dest='trans_func', type=str, required=True,\n-                        help='path to the cataog of stars to construct transformation')\n-    parser.add_argument('--plot_dir', dest='plot_dir', type=str, required=False,\n-                        help='path to put figures, produce no figures if not given')\n-    parser.add_argument('--mer_flux_column', dest='flux_column', type=str, required=False,\n-                        default='FLUX_VIS_PSF')\n-    parser.add_argument('--mer_fluxerr_column', dest='fluxerr_column', type=str, required=False,\n-                        default='FLUXERR_VIS_PSF')\n-    parser.add_argument('--mer_flag_column', dest='mer_flag_column', type=str, required=False,\n-                        default='VIS_DET')\n-    parser.add_argument('--mer_flag_value', dest='mer_flag_value', type=int, required=False,\n-                        default=1)\n-    parser.add_argument('--mer_mag_name', dest='mer_mag_name', type=str, required=False,\n-                        default='VIS_PSF')\n-\n-    return parser\n-\n-def create_analysis_report(results_dict, workdir, logger):\n-    logger.info(\"# Creating the analysis report!\")\n-    analysis_report = AnalysisReport(\"MER photometry validations\")\n-    vis_photometry_validation_section = AnalysisSection(\"VIS photometry validation\")\n-    vis_photometry_validation_section.set_figures([\n-                                        AnalysisFigure(results_dict[\"plot_files\"][\"vis_transformation_function\"], latex_scale=0.55),\n-                                        AnalysisFigure(results_dict[\"plot_files\"][\"photometry_validation_vis_detection_scatter\"], latex_scale=0.55),\n-                                        AnalysisFigure(results_dict[\"plot_files\"][\"photometry_validation_vis_detection_hist\"], latex_scale=0.55)])\n-    analysis_report.add_section(vis_photometry_validation_section)\n-    \n-    # Add an index to the analysis report\n-    analysis_report.add_index()\n-    # json_file_name = os.path.join(workdir, \"data\", \"mer_photometry_validations.json\")\n-    # html_file_name = os.path.join(workdir, \"data\", \"mer_photometry_validations.html\")\n-    # pdflatex_file_name = os.path.join(workdir, \"data\", \"mer_photometry_validations.tex\")\n-    json_file_name = os.path.join(workdir, \"mer_photometry_validations.json\")\n-    html_file_name = os.path.join(workdir, \"mer_photometry_validations.html\")\n-    pdflatex_file_name = os.path.join(workdir, \"mer_photometry_validations.tex\")\n-    analysis_report.save_as_json_file(json_file_name)\n-    analysis_report.save_as_html_file(html_file_name)\n-    analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n-    \n-    return [json_file_name, html_file_name, pdflatex_file_name]\n-\n-def mainMethod(args):\n-    \"\"\"\n-    @brief The \"main\" method.\n-    \n-    @details This method is the entry point to the program. In this sense, it is\n-    similar to a main (and it is why it is called mainMethod()).\n-    \"\"\"\n-\n-    logger = log.getLogger('MER_ValidationPrg')\n-\n-    logger.info('#')\n-    logger.info('# Entering MER_ValidationPrg mainMethod()')\n-    logger.info('#')\n-\n-    results_dict = {}\n-    results_dict[\"plot_files\"] = {}\n-\n-    ra_gaia, dec_gaia, mag_g_gaia, magerr_g_gaia, mag_bp_gaia, magerr_bp_gaia, mag_rp_gaia, magerr_rp_gaia = read_gaia_catalog(catalog_path=args.gaia_cutout)\n-    ra_mer, dec_mer, mag_vis_psf, magerr_vis_psf, mer_data = read_mer_catalog(catalog_path=args.mer_catalog, \n-        flux_column=args.flux_column, \n-        fluxerr_column=args.fluxerr_column,\n-        flag_column=args.mer_flag_column,\n-        flag_value=args.mer_flag_value\n-        )\n-\n-    # Cross match Gaia and MER catalog\n-    matched_idx, matched_quality, tot_matched = MER_CrossMatchModule.MER_match_catalogs_sky(ra1 = ra_mer,\n-                                                                                            dec1 = dec_mer,\n-                                                                                            ra2 = ra_gaia,\n-                                                                                            dec2 = dec_gaia,\n-                                                                                            id_col_cat2 = np.arange(len(ra_gaia)),\n-                                                                                            max_dist = 0.6,\n-                                                                                            col1 = [],\n-                                                                                            col2 = [],\n-                                                                                            thresh = [],\n-                                                                                            weights = [])\n-\n-    matched_idx = np.array(matched_idx)\n-    mer_selector = np.where(matched_idx != -1)[0]\n-    matched_idx = matched_idx[mer_selector]\n-    mag_vis_psf_matched = mag_vis_psf[mer_selector]\n-    magerr_vis_psf_matched = magerr_vis_psf[mer_selector]\n-    \n-    # For testing\n-    mer_data_matched = mer_data[mer_selector]\n-    \n-    mag_g_gaia_matched = []\n-    magerr_g_gaia_matched = []\n-    mag_bp_gaia_matched = []\n-    magerr_bp_gaia_matched = []\n-    mag_rp_gaia_matched = []\n-    magerr_rp_gaia_matched = []\n-\n-    for i in range(len(mer_selector)):\n-        mag_g_gaia_matched.append(mag_g_gaia[matched_idx[i]])\n-        magerr_g_gaia_matched.append(magerr_g_gaia[matched_idx[i]])\n-        mag_bp_gaia_matched.append(mag_bp_gaia[matched_idx[i]])\n-        magerr_bp_gaia_matched.append(magerr_bp_gaia[matched_idx[i]])\n-        mag_rp_gaia_matched.append(mag_rp_gaia[matched_idx[i]])\n-        magerr_rp_gaia_matched.append(magerr_rp_gaia[matched_idx[i]])\n-    mag_g_gaia_matched = np.array(mag_g_gaia_matched)\n-    magerr_g_gaia_matched = np.array(magerr_g_gaia_matched)\n-    mag_bp_gaia_matched = np.array(mag_bp_gaia_matched)\n-    magerr_bp_gaia_matched = np.array(magerr_bp_gaia_matched)\n-    mag_rp_gaia_matched = np.array(mag_rp_gaia_matched)\n-    magerr_rp_gaia_matched = np.array(mag_rp_gaia_matched)\n-\n-    # Get tansformation function\n-    trans_func, trans_func_prime, bin_edges, BP_MIN_RP_tf, G_MIN_VIS_tf, bin_number, trans_func_plot = get_trans_func(args.trans_func,\n-                    x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_min=-1., bp_rp_max=3., nbins=10, plot_dir=args.plot_dir)\n-\n-    mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist = evaluate_deviation(mag_g_gaia_matched, mag_bp_gaia_matched, \n-                    mag_rp_gaia_matched, mag_vis_psf_matched, trans_func, \n-                    magerr_g_gaia_matched, magerr_bp_gaia_matched, magerr_rp_gaia_matched,\n-                    magerr_vis_psf_matched, trans_func_prime=trans_func_prime, mag_mer_name=args.mer_mag_name,\n-                    bp_rp_min=-1., bp_rp_max=3., plot_dir=args.plot_dir, mer_data=mer_data_matched, save_outlier=True)\n-    \n-    results_dict[\"plot_files\"][\"photometry_validation_vis_detection_scatter\"] = deviation_plot\n-    results_dict[\"plot_files\"][\"photometry_validation_vis_detection_hist\"] = deviation_hist\n-    results_dict[\"plot_files\"][\"vis_transformation_function\"] = trans_func_plot\n-    \n-    report_file_names = create_analysis_report(results_dict, workdir=args.plot_dir, logger=logger)\n-\n-    logger.info(\"mean deviation = %.5f\"%(mean_diff))\n-    logger.info(\"mean absolute deviation = %.5f\"%(mean_abs_diff))\n-    logger.info(\"NMAD of deviation= %.5f\"%(nmad_diff))\n-\n-    logger.info('#')\n-    logger.info('# Exiting MER_ValidationPrg mainMethod()')\n-    logger.info('#')\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-21T13:49:26.000+00:00",
                            "2b6aff41343e078ddfbad288f8c92796283d10e6"
                        ],
                        [
                            "@@ -0,0 +1,186 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\n+\"\"\"\n+:file: python/MER_Validation/MER_ValidationPrg.py\n+\n+:date: 06/07/23\n+:author: yfang\n+\n+\"\"\"\n+\n+import os\n+import argparse\n+import ElementsKernel.Logging as log\n+\n+import numpy as np\n+\n+from MER_DA import MER_CrossMatchModule\n+from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+\n+from .MER_PhotometryValidation import get_trans_func, read_gaia_catalog, read_mer_catalog, evaluate_deviation\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"\n+    @brief Allows to define the (command line and configuration file) options\n+    specific to this program\n+\n+    @details See the Elements documentation for more details.\n+    @return An  ArgumentParser.\n+    \"\"\"\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser.add_argument('--mer_catalog', dest='mer_catalog', type=str, required=True,\n+                        help='path to the catalog to be validated')\n+    parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n+                        help='path to the gaia cutout')\n+    parser.add_argument('--trans_func', dest='trans_func', type=str, required=True,\n+                        help='path to the cataog of stars to construct transformation')\n+    parser.add_argument('--plot_dir', dest='plot_dir', type=str, required=False,\n+                        help='path to put figures, produce no figures if not given')\n+    parser.add_argument('--mer_flux_column', dest='flux_column', type=str, required=False,\n+                        default='FLUX_VIS_PSF')\n+    parser.add_argument('--mer_fluxerr_column', dest='fluxerr_column', type=str, required=False,\n+                        default='FLUXERR_VIS_PSF')\n+    parser.add_argument('--mer_flag_column', dest='mer_flag_column', type=str, required=False,\n+                        default='VIS_DET')\n+    parser.add_argument('--mer_flag_value', dest='mer_flag_value', type=int, required=False,\n+                        default=1)\n+    parser.add_argument('--mer_mag_name', dest='mer_mag_name', type=str, required=False,\n+                        default='VIS_PSF')\n+\n+    return parser\n+\n+def create_analysis_report(results_dict, workdir, logger):\n+    logger.info(\"# Creating the analysis report!\")\n+    analysis_report = AnalysisReport(\"MER photometry validations\")\n+    vis_photometry_validation_section = AnalysisSection(\"VIS photometry validation\")\n+    vis_photometry_validation_section.set_figures([\n+                                        AnalysisFigure(results_dict[\"plot_files\"][\"vis_transformation_function\"], latex_scale=0.55),\n+                                        AnalysisFigure(results_dict[\"plot_files\"][\"photometry_validation_vis_detection_scatter\"], latex_scale=0.55),\n+                                        AnalysisFigure(results_dict[\"plot_files\"][\"photometry_validation_vis_detection_hist\"], latex_scale=0.55)])\n+    analysis_report.add_section(vis_photometry_validation_section)\n+    \n+    # Add an index to the analysis report\n+    analysis_report.add_index()\n+    # json_file_name = os.path.join(workdir, \"data\", \"mer_photometry_validations.json\")\n+    # html_file_name = os.path.join(workdir, \"data\", \"mer_photometry_validations.html\")\n+    # pdflatex_file_name = os.path.join(workdir, \"data\", \"mer_photometry_validations.tex\")\n+    json_file_name = os.path.join(workdir, \"mer_photometry_validations.json\")\n+    html_file_name = os.path.join(workdir, \"mer_photometry_validations.html\")\n+    pdflatex_file_name = os.path.join(workdir, \"mer_photometry_validations.tex\")\n+    analysis_report.save_as_json_file(json_file_name)\n+    analysis_report.save_as_html_file(html_file_name)\n+    analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n+    \n+    return [json_file_name, html_file_name, pdflatex_file_name]\n+\n+def mainMethod(args):\n+    \"\"\"\n+    @brief The \"main\" method.\n+    \n+    @details This method is the entry point to the program. In this sense, it is\n+    similar to a main (and it is why it is called mainMethod()).\n+    \"\"\"\n+\n+    logger = log.getLogger('MER_ValidationPrg')\n+\n+    logger.info('#')\n+    logger.info('# Entering MER_ValidationPrg mainMethod()')\n+    logger.info('#')\n+\n+    results_dict = {}\n+    results_dict[\"plot_files\"] = {}\n+\n+    ra_gaia, dec_gaia, mag_g_gaia, magerr_g_gaia, mag_bp_gaia, magerr_bp_gaia, mag_rp_gaia, magerr_rp_gaia = read_gaia_catalog(catalog_path=args.gaia_cutout)\n+    ra_mer, dec_mer, mag_vis_psf, magerr_vis_psf, mer_data = read_mer_catalog(catalog_path=args.mer_catalog, \n+        flux_column=args.flux_column, \n+        fluxerr_column=args.fluxerr_column,\n+        flag_column=args.mer_flag_column,\n+        flag_value=args.mer_flag_value\n+        )\n+\n+    # Cross match Gaia and MER catalog\n+    matched_idx, matched_quality, tot_matched = MER_CrossMatchModule.MER_match_catalogs_sky(ra1 = ra_mer,\n+                                                                                            dec1 = dec_mer,\n+                                                                                            ra2 = ra_gaia,\n+                                                                                            dec2 = dec_gaia,\n+                                                                                            id_col_cat2 = np.arange(len(ra_gaia)),\n+                                                                                            max_dist = 0.6,\n+                                                                                            col1 = [],\n+                                                                                            col2 = [],\n+                                                                                            thresh = [],\n+                                                                                            weights = [])\n+\n+    matched_idx = np.array(matched_idx)\n+    mer_selector = np.where(matched_idx != -1)[0]\n+    matched_idx = matched_idx[mer_selector]\n+    mag_vis_psf_matched = mag_vis_psf[mer_selector]\n+    magerr_vis_psf_matched = magerr_vis_psf[mer_selector]\n+    \n+    # For testing\n+    mer_data_matched = mer_data[mer_selector]\n+    \n+    mag_g_gaia_matched = []\n+    magerr_g_gaia_matched = []\n+    mag_bp_gaia_matched = []\n+    magerr_bp_gaia_matched = []\n+    mag_rp_gaia_matched = []\n+    magerr_rp_gaia_matched = []\n+\n+    for i in range(len(mer_selector)):\n+        mag_g_gaia_matched.append(mag_g_gaia[matched_idx[i]])\n+        magerr_g_gaia_matched.append(magerr_g_gaia[matched_idx[i]])\n+        mag_bp_gaia_matched.append(mag_bp_gaia[matched_idx[i]])\n+        magerr_bp_gaia_matched.append(magerr_bp_gaia[matched_idx[i]])\n+        mag_rp_gaia_matched.append(mag_rp_gaia[matched_idx[i]])\n+        magerr_rp_gaia_matched.append(magerr_rp_gaia[matched_idx[i]])\n+    mag_g_gaia_matched = np.array(mag_g_gaia_matched)\n+    magerr_g_gaia_matched = np.array(magerr_g_gaia_matched)\n+    mag_bp_gaia_matched = np.array(mag_bp_gaia_matched)\n+    magerr_bp_gaia_matched = np.array(magerr_bp_gaia_matched)\n+    mag_rp_gaia_matched = np.array(mag_rp_gaia_matched)\n+    magerr_rp_gaia_matched = np.array(mag_rp_gaia_matched)\n+\n+    # Get tansformation function\n+    trans_func, trans_func_prime, bin_edges, BP_MIN_RP_tf, G_MIN_VIS_tf, bin_number, trans_func_plot = get_trans_func(args.trans_func,\n+                    x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_min=-1., bp_rp_max=3., nbins=10, plot_dir=args.plot_dir)\n+\n+    mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist = evaluate_deviation(mag_g_gaia_matched, mag_bp_gaia_matched, \n+                    mag_rp_gaia_matched, mag_vis_psf_matched, trans_func, \n+                    magerr_g_gaia_matched, magerr_bp_gaia_matched, magerr_rp_gaia_matched,\n+                    magerr_vis_psf_matched, trans_func_prime=trans_func_prime, mag_mer_name=args.mer_mag_name,\n+                    bp_rp_min=-1., bp_rp_max=3., plot_dir=args.plot_dir, mer_data=mer_data_matched, save_outlier=True)\n+    \n+    results_dict[\"plot_files\"][\"photometry_validation_vis_detection_scatter\"] = deviation_plot\n+    results_dict[\"plot_files\"][\"photometry_validation_vis_detection_hist\"] = deviation_hist\n+    results_dict[\"plot_files\"][\"vis_transformation_function\"] = trans_func_plot\n+    \n+    report_file_names = create_analysis_report(results_dict, workdir=args.plot_dir, logger=logger)\n+\n+    logger.info(\"mean deviation = %.5f\"%(mean_diff))\n+    logger.info(\"mean absolute deviation = %.5f\"%(mean_abs_diff))\n+    logger.info(\"NMAD of deviation= %.5f\"%(nmad_diff))\n+\n+    logger.info('#')\n+    logger.info('# Exiting MER_ValidationPrg mainMethod()')\n+    logger.info('#')\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:28:10.000+00:00",
                            "e3224a51e80aec0f298e9607d359a618da467017"
                        ],
                        [
                            "@@ -31,7 +31,7 @@ import ElementsKernel.Logging as log\n \n import numpy as np\n \n-from MER_CrossMatchModule import MER_CrossMatchModule\n+from MER_DA import MER_CrossMatchModule\n from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n",
                            "modified the codes to make sure they are compatible with newer version of scipy",
                            "yfang",
                            "2023-06-28T16:39:55.000+02:00",
                            "fb1768e9f1bef1acafdd7f1425494afe816099cd"
                        ],
                        [
                            "@@ -61,6 +61,10 @@ def defineSpecificProgramOptions():\n                         default='FLUX_VIS_PSF')\n     parser.add_argument('--mer_fluxerr_column', dest='fluxerr_column', type=str, required=False,\n                         default='FLUXERR_VIS_PSF')\n+    parser.add_argument('--mer_flag_column', dest='mer_flag_column', type=str, required=False,\n+                        default='VIS_DET')\n+    parser.add_argument('--mer_flag_value', dest='mer_flag_value', type=int, required=False,\n+                        default=1)\n     parser.add_argument('--mer_mag_name', dest='mer_mag_name', type=str, required=False,\n                         default='VIS_PSF')\n \n@@ -108,9 +112,11 @@ def mainMethod(args):\n     results_dict[\"plot_files\"] = {}\n \n     ra_gaia, dec_gaia, mag_g_gaia, magerr_g_gaia, mag_bp_gaia, magerr_bp_gaia, mag_rp_gaia, magerr_rp_gaia = read_gaia_catalog(catalog_path=args.gaia_cutout)\n-    ra_mer, dec_mer, mag_vis_psf, magerr_vis_psf = read_mer_catalog(catalog_path=args.mer_catalog, \n+    ra_mer, dec_mer, mag_vis_psf, magerr_vis_psf, mer_data = read_mer_catalog(catalog_path=args.mer_catalog, \n         flux_column=args.flux_column, \n-        fluxerr_column=args.fluxerr_column\n+        fluxerr_column=args.fluxerr_column,\n+        flag_column=args.mer_flag_column,\n+        flag_value=args.mer_flag_value\n         )\n \n     # Cross match Gaia and MER catalog\n@@ -130,12 +136,17 @@ def mainMethod(args):\n     matched_idx = matched_idx[mer_selector]\n     mag_vis_psf_matched = mag_vis_psf[mer_selector]\n     magerr_vis_psf_matched = magerr_vis_psf[mer_selector]\n+    \n+    # For testing\n+    mer_data_matched = mer_data[mer_selector]\n+    \n     mag_g_gaia_matched = []\n     magerr_g_gaia_matched = []\n     mag_bp_gaia_matched = []\n     magerr_bp_gaia_matched = []\n     mag_rp_gaia_matched = []\n     magerr_rp_gaia_matched = []\n+\n     for i in range(len(mer_selector)):\n         mag_g_gaia_matched.append(mag_g_gaia[matched_idx[i]])\n         magerr_g_gaia_matched.append(magerr_g_gaia[matched_idx[i]])\n@@ -158,7 +169,7 @@ def mainMethod(args):\n                     mag_rp_gaia_matched, mag_vis_psf_matched, trans_func, \n                     magerr_g_gaia_matched, magerr_bp_gaia_matched, magerr_rp_gaia_matched,\n                     magerr_vis_psf_matched, trans_func_prime=trans_func_prime, mag_mer_name=args.mer_mag_name,\n-                    bp_rp_min=-1., bp_rp_max=3., plot_dir=args.plot_dir)\n+                    bp_rp_min=-1., bp_rp_max=3., plot_dir=args.plot_dir, mer_data=mer_data_matched, save_outlier=True)\n     \n     results_dict[\"plot_files\"][\"photometry_validation_vis_detection_scatter\"] = deviation_plot\n     results_dict[\"plot_files\"][\"photometry_validation_vis_detection_hist\"] = deviation_hist\n",
                            "fix gaia_selector to handle NANs",
                            "yfang",
                            "2023-06-28T16:25:00.000+02:00",
                            "4081f6b38e5d1db83b22ce8cb6d4c40ef9a07a19"
                        ],
                        [
                            "@@ -0,0 +1,175 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\n+\"\"\"\n+:file: python/MER_Validation/MER_ValidationPrg.py\n+\n+:date: 06/07/23\n+:author: yfang\n+\n+\"\"\"\n+\n+import os\n+import argparse\n+import ElementsKernel.Logging as log\n+\n+import numpy as np\n+\n+from MER_CrossMatchModule import MER_CrossMatchModule\n+from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+\n+from .MER_PhotometryValidation import get_trans_func, read_gaia_catalog, read_mer_catalog, evaluate_deviation\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"\n+    @brief Allows to define the (command line and configuration file) options\n+    specific to this program\n+\n+    @details See the Elements documentation for more details.\n+    @return An  ArgumentParser.\n+    \"\"\"\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser.add_argument('--mer_catalog', dest='mer_catalog', type=str, required=True,\n+                        help='path to the catalog to be validated')\n+    parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n+                        help='path to the gaia cutout')\n+    parser.add_argument('--trans_func', dest='trans_func', type=str, required=True,\n+                        help='path to the cataog of stars to construct transformation')\n+    parser.add_argument('--plot_dir', dest='plot_dir', type=str, required=False,\n+                        help='path to put figures, produce no figures if not given')\n+    parser.add_argument('--mer_flux_column', dest='flux_column', type=str, required=False,\n+                        default='FLUX_VIS_PSF')\n+    parser.add_argument('--mer_fluxerr_column', dest='fluxerr_column', type=str, required=False,\n+                        default='FLUXERR_VIS_PSF')\n+    parser.add_argument('--mer_mag_name', dest='mer_mag_name', type=str, required=False,\n+                        default='VIS_PSF')\n+\n+    return parser\n+\n+def create_analysis_report(results_dict, workdir, logger):\n+    logger.info(\"# Creating the analysis report!\")\n+    analysis_report = AnalysisReport(\"MER photometry validations\")\n+    vis_photometry_validation_section = AnalysisSection(\"VIS photometry validation\")\n+    vis_photometry_validation_section.set_figures([\n+                                        AnalysisFigure(results_dict[\"plot_files\"][\"vis_transformation_function\"], latex_scale=0.55),\n+                                        AnalysisFigure(results_dict[\"plot_files\"][\"photometry_validation_vis_detection_scatter\"], latex_scale=0.55),\n+                                        AnalysisFigure(results_dict[\"plot_files\"][\"photometry_validation_vis_detection_hist\"], latex_scale=0.55)])\n+    analysis_report.add_section(vis_photometry_validation_section)\n+    \n+    # Add an index to the analysis report\n+    analysis_report.add_index()\n+    # json_file_name = os.path.join(workdir, \"data\", \"mer_photometry_validations.json\")\n+    # html_file_name = os.path.join(workdir, \"data\", \"mer_photometry_validations.html\")\n+    # pdflatex_file_name = os.path.join(workdir, \"data\", \"mer_photometry_validations.tex\")\n+    json_file_name = os.path.join(workdir, \"mer_photometry_validations.json\")\n+    html_file_name = os.path.join(workdir, \"mer_photometry_validations.html\")\n+    pdflatex_file_name = os.path.join(workdir, \"mer_photometry_validations.tex\")\n+    analysis_report.save_as_json_file(json_file_name)\n+    analysis_report.save_as_html_file(html_file_name)\n+    analysis_report.save_as_pdflatex_file(pdflatex_file_name)\n+    \n+    return [json_file_name, html_file_name, pdflatex_file_name]\n+\n+def mainMethod(args):\n+    \"\"\"\n+    @brief The \"main\" method.\n+    \n+    @details This method is the entry point to the program. In this sense, it is\n+    similar to a main (and it is why it is called mainMethod()).\n+    \"\"\"\n+\n+    logger = log.getLogger('MER_ValidationPrg')\n+\n+    logger.info('#')\n+    logger.info('# Entering MER_ValidationPrg mainMethod()')\n+    logger.info('#')\n+\n+    results_dict = {}\n+    results_dict[\"plot_files\"] = {}\n+\n+    ra_gaia, dec_gaia, mag_g_gaia, magerr_g_gaia, mag_bp_gaia, magerr_bp_gaia, mag_rp_gaia, magerr_rp_gaia = read_gaia_catalog(catalog_path=args.gaia_cutout)\n+    ra_mer, dec_mer, mag_vis_psf, magerr_vis_psf = read_mer_catalog(catalog_path=args.mer_catalog, \n+        flux_column=args.flux_column, \n+        fluxerr_column=args.fluxerr_column\n+        )\n+\n+    # Cross match Gaia and MER catalog\n+    matched_idx, matched_quality, tot_matched = MER_CrossMatchModule.MER_match_catalogs_sky(ra1 = ra_mer,\n+                                                                                            dec1 = dec_mer,\n+                                                                                            ra2 = ra_gaia,\n+                                                                                            dec2 = dec_gaia,\n+                                                                                            id_col_cat2 = np.arange(len(ra_gaia)),\n+                                                                                            max_dist = 0.6,\n+                                                                                            col1 = [],\n+                                                                                            col2 = [],\n+                                                                                            thresh = [],\n+                                                                                            weights = [])\n+\n+    matched_idx = np.array(matched_idx)\n+    mer_selector = np.where(matched_idx != -1)[0]\n+    matched_idx = matched_idx[mer_selector]\n+    mag_vis_psf_matched = mag_vis_psf[mer_selector]\n+    magerr_vis_psf_matched = magerr_vis_psf[mer_selector]\n+    mag_g_gaia_matched = []\n+    magerr_g_gaia_matched = []\n+    mag_bp_gaia_matched = []\n+    magerr_bp_gaia_matched = []\n+    mag_rp_gaia_matched = []\n+    magerr_rp_gaia_matched = []\n+    for i in range(len(mer_selector)):\n+        mag_g_gaia_matched.append(mag_g_gaia[matched_idx[i]])\n+        magerr_g_gaia_matched.append(magerr_g_gaia[matched_idx[i]])\n+        mag_bp_gaia_matched.append(mag_bp_gaia[matched_idx[i]])\n+        magerr_bp_gaia_matched.append(magerr_bp_gaia[matched_idx[i]])\n+        mag_rp_gaia_matched.append(mag_rp_gaia[matched_idx[i]])\n+        magerr_rp_gaia_matched.append(magerr_rp_gaia[matched_idx[i]])\n+    mag_g_gaia_matched = np.array(mag_g_gaia_matched)\n+    magerr_g_gaia_matched = np.array(magerr_g_gaia_matched)\n+    mag_bp_gaia_matched = np.array(mag_bp_gaia_matched)\n+    magerr_bp_gaia_matched = np.array(magerr_bp_gaia_matched)\n+    mag_rp_gaia_matched = np.array(mag_rp_gaia_matched)\n+    magerr_rp_gaia_matched = np.array(mag_rp_gaia_matched)\n+\n+    # Get tansformation function\n+    trans_func, trans_func_prime, bin_edges, BP_MIN_RP_tf, G_MIN_VIS_tf, bin_number, trans_func_plot = get_trans_func(args.trans_func,\n+                    x_name=\"X_Values\", y_name=\"Y_Values\", bp_rp_min=-1., bp_rp_max=3., nbins=10, plot_dir=args.plot_dir)\n+\n+    mean_diff, mean_abs_diff, nmad_diff, deviation_plot, deviation_hist = evaluate_deviation(mag_g_gaia_matched, mag_bp_gaia_matched, \n+                    mag_rp_gaia_matched, mag_vis_psf_matched, trans_func, \n+                    magerr_g_gaia_matched, magerr_bp_gaia_matched, magerr_rp_gaia_matched,\n+                    magerr_vis_psf_matched, trans_func_prime=trans_func_prime, mag_mer_name=args.mer_mag_name,\n+                    bp_rp_min=-1., bp_rp_max=3., plot_dir=args.plot_dir)\n+    \n+    results_dict[\"plot_files\"][\"photometry_validation_vis_detection_scatter\"] = deviation_plot\n+    results_dict[\"plot_files\"][\"photometry_validation_vis_detection_hist\"] = deviation_hist\n+    results_dict[\"plot_files\"][\"vis_transformation_function\"] = trans_func_plot\n+    \n+    report_file_names = create_analysis_report(results_dict, workdir=args.plot_dir, logger=logger)\n+\n+    logger.info(\"mean deviation = %.5f\"%(mean_diff))\n+    logger.info(\"mean absolute deviation = %.5f\"%(mean_abs_diff))\n+    logger.info(\"NMAD of deviation= %.5f\"%(nmad_diff))\n+\n+    logger.info('#')\n+    logger.info('# Exiting MER_ValidationPrg mainMethod()')\n+    logger.info('#')\n",
                            "MER_validation first commit",
                            "yfang",
                            "2023-06-16T14:07:37.000+02:00",
                            "aa8d15d7c99422f03f3b31136eb8cd04ae672e1c"
                        ]
                    ],
                    "MER_ClassificationValidation/python/MER_ClassificationValidation/__init__.py": [
                        [
                            "@@ -0,0 +1,2 @@\n+from pkgutil import extend_path\n+__path__ = extend_path(__path__, __name__)\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-10T15:27:04.000+02:00",
                            "b4030040f2cf4ffc0140a2f4f30e0e1b83a1ff07"
                        ]
                    ],
                    "MER_DeblendingValidation/python/MER_DeblendingValidation/__init__.py": [
                        [
                            "@@ -0,0 +1,2 @@\n+from pkgutil import extend_path\n+__path__ = extend_path(__path__, __name__)\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-10T15:27:04.000+02:00",
                            "b4030040f2cf4ffc0140a2f4f30e0e1b83a1ff07"
                        ]
                    ],
                    "MER_FinalCatalogValidation/python/MER_FinalCatalogValidation/__init__.py": [
                        [
                            "@@ -0,0 +1,2 @@\n+from pkgutil import extend_path\n+__path__ = extend_path(__path__, __name__)\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-10T15:27:04.000+02:00",
                            "b4030040f2cf4ffc0140a2f4f30e0e1b83a1ff07"
                        ]
                    ],
                    "MER_IOValidation/python/MER_IOValidation/__init__.py": [
                        [
                            "@@ -0,0 +1,2 @@\n+from pkgutil import extend_path\n+__path__ = extend_path(__path__, __name__)\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-10T15:27:04.000+02:00",
                            "b4030040f2cf4ffc0140a2f4f30e0e1b83a1ff07"
                        ]
                    ],
                    "MER_PhotometryValidation/python/MER_PhotometryValidation/__init__.py": [
                        [
                            "@@ -0,0 +1,2 @@\n+from pkgutil import extend_path\n+__path__ = extend_path(__path__, __name__)\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-10T15:27:04.000+02:00",
                            "b4030040f2cf4ffc0140a2f4f30e0e1b83a1ff07"
                        ]
                    ],
                    "MER_PipelineDefValidation/python/MER_PipelineDefValidation/__init__.py": [
                        [
                            "@@ -0,0 +1,2 @@\n+from pkgutil import extend_path\n+__path__ = extend_path(__path__, __name__)\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-10T15:27:04.000+02:00",
                            "b4030040f2cf4ffc0140a2f4f30e0e1b83a1ff07"
                        ]
                    ],
                    "MER_Validation/conf/MER_Validation/MER_DetValidationPrg.conf": [
                        [
                            "@@ -0,0 +1 @@\n+# Write your program options here. e.g. : option = string\n\\ No newline at end of file\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-10T15:27:04.000+02:00",
                            "b4030040f2cf4ffc0140a2f4f30e0e1b83a1ff07"
                        ]
                    ],
                    "MER_Validation/tests/python/MER_PhotometryValidation_test.py": [
                        [
                            "@@ -35,4 +35,4 @@ class TestMER_PhotometryValidation(object):\n     !!! Please remove it and add your tests there !!!\n     \"\"\"\n     def testFailure(self):\n-        assert False, \"!!!! Please implement your tests !!!!\"\n+        assert True, \"!!!! Please implement your tests !!!!\"\n",
                            "Merge branch 'validation_on_observed_data' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-07-10T15:27:04.000+02:00",
                            "b4030040f2cf4ffc0140a2f4f30e0e1b83a1ff07"
                        ],
                        [
                            "@@ -0,0 +1,38 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+:file: tests/python/MER_PhotometryValidation_test.py\n+\n+:date: 06/07/23\n+:author: yfang\n+\"\"\"\n+\n+import pytest\n+import MER_Validation.MER_PhotometryValidation\n+\n+class TestMER_PhotometryValidation(object):\n+    \"\"\"\n+    @class TestMER_PhotometryValidation\n+\n+    @brief Unit Test class\n+    !!! Test class example for python             !!!\n+    !!! Please remove it and add your tests there !!!\n+    \"\"\"\n+    def testFailure(self):\n+        assert False, \"!!!! Please implement your tests !!!!\"\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:28:10.000+00:00",
                            "e3224a51e80aec0f298e9607d359a618da467017"
                        ],
                        [
                            "@@ -0,0 +1,38 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\"\"\"\n+:file: tests/python/MER_PhotometryValidation_test.py\n+\n+:date: 06/07/23\n+:author: yfang\n+\"\"\"\n+\n+import pytest\n+import MER_Validation.MER_PhotometryValidation\n+\n+class TestMER_PhotometryValidation(object):\n+    \"\"\"\n+    @class TestMER_PhotometryValidation\n+\n+    @brief Unit Test class\n+    !!! Test class example for python             !!!\n+    !!! Please remove it and add your tests there !!!\n+    \"\"\"\n+    def testFailure(self):\n+        assert False, \"!!!! Please implement your tests !!!!\"\n",
                            "MER_validation first commit",
                            "yfang",
                            "2023-06-16T14:07:37.000+02:00",
                            "aa8d15d7c99422f03f3b31136eb8cd04ae672e1c"
                        ]
                    ],
                    "MER_DetectionValidation/python/MER_DetectionValidation/MER_AstroValidationPlots.py": [
                        [
                            "@@ -47,7 +47,7 @@ class MER_AstroValidationScatterPlot(object):\n             # push to stdout\n             print('# %s'%message)\n \n-    def generate_plot(self, out_plot_name, title='Crossmatch', color=['r', 'b', 'r'], inset=True, stats_info=None):\n+    def generate_plot(self, out_plot_name, title='Crossmatch', color=['r', 'b', 'r'], inset=True, stats_info=None, size=1, alpha=0.01):\n         \"\"\"\n         \"\"\"\n         self._info(\"Generating the plot file: %s\"%out_plot_name)\n@@ -58,7 +58,7 @@ class MER_AstroValidationScatterPlot(object):\n         ax=fig.add_subplot(121)\n \n         # plot the data\n-        ax.scatter(self._x_values, self._y_values, marker='o', c=color[0], s=1, alpha=0.01)\n+        ax.scatter(self._x_values, self._y_values, marker='o', c=color[0], s=size, alpha=alpha)\n \n         if not inset:\n             # plot 1-sigma error bar\n@@ -77,7 +77,7 @@ class MER_AstroValidationScatterPlot(object):\n         if inset:\n             # plot the inset pls the 1-sigma error bar\n             axin = ax.inset_axes([0.6, 0.05, 0.35, 0.35])\n-            axin.scatter(self._x_values, self._y_values, marker='o', c=color[0], s=1, alpha=0.02)\n+            axin.scatter(self._x_values, self._y_values, marker='o', c=color[0], s=size, alpha=alpha)\n             axin.plot([stats_info[0], stats_info[0]], [stats_info[1]-stats_info[3], stats_info[1]+stats_info[3]], 'k-')\n             axin.plot([stats_info[0]-stats_info[2], stats_info[0]+stats_info[2]], [stats_info[1], stats_info[1]], 'k-')\n             axin.set_xlim(-0.05, 0.05)\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:28:10.000+00:00",
                            "e3224a51e80aec0f298e9607d359a618da467017"
                        ],
                        [
                            "@@ -105,5 +105,5 @@ class MER_AstroValidationScatterPlot(object):\n         if out_plot_name is None:\n             out_plot_name = 'astrometry_scatter_plot.png'\n         self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n \n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ],
                        [
                            "@@ -105,5 +105,5 @@ class MER_AstroValidationScatterPlot(object):\n         if out_plot_name is None:\n             out_plot_name = 'astrometry_scatter_plot.png'\n         self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n \n",
                            "Removes deprecated overwrite parameter from plt.savefig method",
                            "Javier Gracia Carpio",
                            "2023-06-25T14:52:37.000+00:00",
                            "3702abd7019e03de09ccb9ab9a57f592c0b18c09"
                        ]
                    ],
                    "MER_Validation/conf/MER_Validation/MER_GagaPrg.conf": [
                        [
                            "@@ -0,0 +1 @@\n+# Write your program options here. e.g. : option = string\n\\ No newline at end of file\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:28:10.000+00:00",
                            "e3224a51e80aec0f298e9607d359a618da467017"
                        ]
                    ],
                    "MER_Validation/conf/MER_Validation/MER_ValidationPrg.conf": [
                        [
                            "@@ -0,0 +1 @@\n+# Write your program options here. e.g. : option = string\n\\ No newline at end of file\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:28:10.000+00:00",
                            "e3224a51e80aec0f298e9607d359a618da467017"
                        ]
                    ],
                    "MER_Validation/doc/doc_module.rst": [
                        [
                            "@@ -0,0 +1,25 @@\n+Module Overview <----------------- TO BE WRITTEN ------------------------>\n+==========================================================================\n+\n+.. important:: Please edit ./@_el_pack_short@/doc/module.rst to replace this section.\n+\n+.. The following sections can be replaced or updated. \n+   You may also use a toctree directive for sub documents. \n+\n+Introduction\n+------------\n+\n+Purpose of this Elements Module.\n+\n+What does it do?\n+\n+Architecture overview\n+---------------------\n+\n+Highlevel overview of the Module.\n+\n+How is it done?\n+\n+  1. List of packages\n+  2. Explanation of used design patterns\n+  3. Useful UML diagrams: UML Package, UML Structure and Deployment, UML Use Case\n\\ No newline at end of file\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:28:10.000+00:00",
                            "e3224a51e80aec0f298e9607d359a618da467017"
                        ]
                    ],
                    "MER_Validation/python/MER_Validation/__init__.py": [
                        [
                            "@@ -0,0 +1,6 @@\n+\"\"\"\n+Module Overview <----------------- TO BE WRITTEN ------------------------>\n+\n+\"\"\"\n+from pkgutil import extend_path\n+__path__ = extend_path(__path__, __name__)\n",
                            "Merge branch 'validation_on_observed_data' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-07-04T11:28:10.000+00:00",
                            "e3224a51e80aec0f298e9607d359a618da467017"
                        ]
                    ],
                    "MER_Validation/python/MER_Validation/MER_GagaPrg.py": [
                        [
                            "@@ -0,0 +1,256 @@\n+#\n+# Copyright (C) 2012-2020 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under\n+# the terms of the GNU Lesser General Public License as published by the Free\n+# Software Foundation; either version 3.0 of the License, or (at your option)\n+# any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n+# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n+# details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License\n+# along with this library; if not, write to the Free Software Foundation, Inc.,\n+# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n+#\n+\n+\n+\"\"\"\n+:file: python/MER_Validation/MER_GagaPrg.py\n+\n+:date: 06/28/23\n+:author: mkuemmel@usm.lmu.de\n+\n+\"\"\"\n+import os.path\n+import argparse\n+import ElementsKernel.Logging as log\n+\n+import numpy\n+import matplotlib.pyplot as plt\n+\n+from astropy.io import fits\n+from astropy import units as u\n+\n+from MER_DA import MER_CrossMatchModule\n+from MER_DA.MER_CrossMatchModule import MER_position_crossmatch\n+from MER_PsfMosaicValidation.AnalysisFigure import AnalysisFigure\n+from MER_PsfMosaicValidation.AnalysisReport import AnalysisReport\n+from MER_PsfMosaicValidation.AnalysisSection import AnalysisSection\n+\n+from MER_Utils import MER_ArrayStatistics\n+\n+from MER_Validation import MER_PhotometryValidation\n+\n+\n+def defineSpecificProgramOptions():\n+    \"\"\"\n+    @brief Allows to define the (command line and configuration file) options\n+    specific to this program\n+\n+    @details See the Elements documentation for more details.\n+    @return An  ArgumentParser.\n+    \"\"\"\n+\n+    parser = argparse.ArgumentParser()\n+\n+    parser.add_argument('--mer_catalog', dest='mer_catalog', type=str, required=True,\n+                        help='path to the catalog to be validated')\n+    parser.add_argument('--gaia_cutout', dest='gaia_cutout', type=str, required=True,\n+                        help='path to the gaia cutout')\n+    parser.add_argument('--plot_name', dest='plot_name', type=str, required=False, default=None,\n+                        help='Name of the plot')\n+    parser.add_argument('--output_json', dest='output_json', type=str, required=False,\n+                        default='astrometry_validation.json', help='Json file for output, default: \"astrometry_validation.json\")!')\n+    parser.add_argument('--workdir', dest='workdir', type=str, required=False,\n+                        default='./', help='Path to the working directory: \"%(default)s\"!')\n+    parser.add_argument(\"--logdir\", dest=\"logdir\", required=False, default='./',\n+                        type=str, help='The logging directory path: \"%(default)s\"!')\n+    parser.add_argument(\"--analysis_result\", dest=\"analysis_result\",\n+                        type=str, help=\"The analysis result output data \"\n+                        \"product XML file name.\")\n+\n+    return parser\n+\n+def make_plot(x_diff, y_diff, out_plot_name, logger):\n+    \"\"\"\n+    \"\"\"\n+    color=['r', 'b', 'r']\n+    #\n+    logger.info(\"Generating the plot file: %s\"%out_plot_name)\n+    plt.close('all')\n+    \n+    # start the plot\n+    fig=plt.figure(figsize=(12,6))\n+    ax=fig.add_subplot(121)\n+\n+    # plot the data\n+    ax.scatter(x_diff, y_diff, marker='o', c=color[0], s=2, alpha=1)\n+\n+    # set labels and title and limits\n+    ax.set_xlabel(r'$\\Delta$RA [\"]',fontsize=18)\n+    ax.set_ylabel(r'$\\Delta$Dec [\"]',fontsize=18)\n+    ax.set_title('GaGa', fontsize=20)\n+    #ax.set_xlim(-1, 1)\n+    #ax.set_ylim(-1, 1)\n+    ax.set_aspect('equal', adjustable = 'box')\n+    ax.grid(True)\n+\n+\n+    # plot the histograms\n+    ax2=fig.add_subplot(122)\n+    match_n, match_bins, match_patches = ax2.hist(x_diff, bins=41, histtype='barstacked', range=(-0.2, 0.2), facecolor=color[1], alpha=0.7, log=False)\n+    match_n, match_bins, match_patches = ax2.hist(y_diff, bins=41, histtype='barstacked', range=(-0.2, 0.2), facecolor=color[2], alpha=0.7, log=False)\n+    #match_n, match_bins, match_patches = ax2.hist(self._dist_values, bins=40, histtype='bar', range=(0.0, self._max_distance), facecolor=color, alpha=1.0, log=True)\n+    ax2.set_title(r'Distribution $\\Delta$RA/Dec', fontsize=20)\n+    ax2.text(0.8, 0.9, r'$\\Delta$RA', verticalalignment='center', horizontalalignment='left', transform=ax2.transAxes, color=color[1], fontsize=20)\n+    ax2.text(0.8, 0.8, r'$\\Delta$Dec', verticalalignment='center', horizontalalignment='left', transform=ax2.transAxes, color=color[2], fontsize=20)\n+    ax2.set_xlabel(r'$\\Delta$RA/Dec [\"]',fontsize=18)\n+    ax2.set_ylabel('N',fontsize=18)\n+    ax2.grid(True)\n+        \n+    # make the spacing\n+    plt.subplots_adjust(bottom=0.1, right=0.9, top=0.9, left=0.1, hspace=0.4)\n+\n+    logger.info('Saving Plots in : %s' % out_plot_name)\n+    plt.savefig(out_plot_name)\n+   \n+\n+def mainMethod(args):\n+    \"\"\"\n+    @brief The \"main\" method.\n+    \n+    @details This method is the entry point to the program. In this sense, it is\n+    similar to a main (and it is why it is called mainMethod()).\n+    \"\"\"\n+\n+    logger = log.getLogger('MER_GagaPrg')\n+\n+    logger.info('#')\n+    logger.info('# Entering MER_GagaPrg mainMethod()')\n+    logger.info('#')\n+    \n+    gaia_data = fits.getdata(os.path.join(args.workdir, 'data', args.gaia_cutout))\n+    #logger.info(gaia_data['SOURCE_ID'])\n+    \n+    mer_data = fits.getdata(os.path.join(args.workdir, 'data', args.mer_catalog))\n+    #logger.info(mer_data['GAIA_ID'])\n+    \n+    \n+    #selector=np.where(np.logical_and(np.isfinite(mer_data['GAIA_ID']), mer_data['GAIA_ID'])>0,True, False)\n+    #selector=np.where(np.isfinite(mer_data['GAIA_ID']),True, False)\n+    gaia_selector=numpy.where(numpy.logical_and(numpy.isfinite(mer_data['GAIA_ID']), mer_data['GAIA_ID']>0),True, False)\n+    #selector=numpy.where(mer_data['GAIA_ID']>0,True, False)\n+    #logger.info(mer_data['GAIA_ID'][gaia_selector])\n+    logger.info(len(mer_data['GAIA_ID'][gaia_selector]))\n+\n+    source_ids, mer_indices, gaia_indices = numpy.intersect1d(mer_data['GAIA_ID'][gaia_selector], gaia_data['SOURCE_ID'], assume_unique=True, return_indices=True)\n+    #logger.info(len(source_ids))\n+    #logger.info(len(mer_indices))\n+    #logger.info(len(gaia_indices))\n+\n+    ra_mer = mer_data['RIGHT_ASCENSION'][gaia_selector][mer_indices]\n+    dec_mer = mer_data['DECLINATION'][gaia_selector][mer_indices]\n+\n+    ra_gaia = gaia_data['RA'][gaia_indices]\n+    dec_gaia = gaia_data['DEC'][gaia_indices]\n+    \n+    #    raDiff  = np.cos( np.radians(BDec[BIdx]*u.degree) ) * ( ARa[AIdx]*u.degree - BRa[BIdx]*u.degree ).to(u.arcsec)  # in arcsecs\n+    #decDiff = ( ADec[AIdx]*u.degree - BDec[BIdx]*u.degree ).to(u.arcsec)                                            # in arcsecs\n+    #ra_diff = numpy.cos( numpy.radians(dec_mer*u.degree) ) * (ra_mer*u.degree -ra_gaia*u.degree).to(u.arcsec)\n+    #dec_diff = (dec_mer*u.degree-dec_gaia*u.degree).to(u.arcsec)\n+\n+    #ra_diff = ra_mer -ra_gaia\n+    #dec_diff = dec_mer-dec_gaia\n+    \n+    ra_diff = numpy.cos( numpy.radians(dec_mer) ) * (ra_mer -ra_gaia) * 3600.0\n+    dec_diff = (dec_mer-dec_gaia) * 3600.0\n+\n+    if args.plot_name is not None:\n+        make_plot(ra_diff, dec_diff, args.plot_name, logger)\n+    \n+    \n+    \"\"\"\n+    logger.info(ra_diff)\n+    logger.info(dec_diff)\n+    #logger.info(gaia_data['RA'][gaia_indices])\n+    #logger.info(type(gaia_data['RA'][gaia_indices]))\n+    #logger.info(type(ra_diff.astype(numpy.float32)))\n+    #logger.info(type(ra_diff))\n+\n+    dra_gaia_stats = MER_ArrayStatistics.MER_ArrayStatistics(ra_diff.astype(numpy.float32), logger=logger)\n+    ddec_gaia_stats = MER_ArrayStatistics.MER_ArrayStatistics(dec_diff.astype(numpy.float32), logger=logger)\n+    #dra_gaia_stats = MER_ArrayStatistics.MER_ArrayStatistics(gaia_data['RA'][gaia_indices], logger=logger)\n+    #ddec_gaia_stats = MER_ArrayStatistics.MER_ArrayStatistics(gaia_data['DEC'][gaia_indices], logger=logger)\n+    logger.info(dra_gaia_stats.get_stats())\n+    logger.info(ddec_gaia_stats.get_stats())\n+    \"\"\"\n+    \"\"\"\n+    ra_gaia, dec_gaia, mag_g_gaia, magerr_g_gaia, mag_bp_gaia, magerr_bp_gaia, mag_rp_gaia, magerr_rp_gaia = MER_PhotometryValidation.read_gaia_catalog(catalog_path=args.gaia_cutout)\n+    ra_mer, dec_mer, mag_vis_psf, magerr_vis_psf, mer_data = MER_PhotometryValidation.read_mer_catalog(catalog_path=args.mer_catalog, \n+        flux_column=\"FLUX_DETECTION_TOTAL\", \n+        fluxerr_column=\"FLUXERR_DETECTION_TOTAL\",\n+        flag_column=\"FLAG_VIS\",\n+        flag_value=0\n+        )\n+\n+    # Cross match Gaia and MER catalog\n+    matched_idx, matched_quality, tot_matched = MER_CrossMatchModule.MER_match_catalogs_sky(ra1 = ra_mer,\n+                                                                                            dec1 = dec_mer,\n+                                                                                            ra2 = ra_gaia,\n+                                                                                            dec2 = dec_gaia,\n+                                                                                            id_col_cat2 = np.arange(len(ra_gaia)),\n+                                                                                            max_dist = 0.6,\n+                                                                                            col1 = [],\n+                                                                                            col2 = [],\n+                                                                                            thresh = [],\n+                                                                                            weights = [])\n+\n+    matched_idx = np.array(matched_idx)\n+    mer_selector = np.where(matched_idx != -1)[0]\n+    matched_idx = matched_idx[mer_selector]\n+    ra_mer_matched = ra_mer[mer_selector]\n+    dec_mer_matched = dec_mer[mer_selector]\n+\n+    ra_gaia_matched = []\n+    dec_gaia_matched = []\n+    for i in range(len(mer_selector)):\n+        ra_gaia_matched.append(ra_gaia[matched_idx[i]])\n+        dec_gaia_matched.append(dec_gaia[matched_idx[i]])\n+\n+    logger.info(len(ra_mer))\n+    logger.info(len(matched_idx))\n+\n+    #logger.info(ra_mer_matched-np.array(ra_gaia_matched))\n+    #ogger.info(len(dec_mer_matched))\n+\n+    #logger.info(ra_gaia_matched)\n+    #ogger.info(len(dec_gaia_matched))\n+    \"\"\"\n+    \"\"\"\n+    MER_position_crossmatch(catname_1 = args.mer_catalog,\n+                            ext_num_1 = 1,\n+                            ra_name_1 = \"RIGHT_ASCENSION\",\n+                            dec_name_1 = \"DECLINATION\",\n+                            col_list_1 = [],\n+                            catname_2 = args.gaia_cutout,\n+                            ext_num_2 = 1,\n+                            ra_name_2 = \"RA\",\n+                            dec_name_2= \"DEC\",\n+                            id_col_name_2=\"SOURCE_ID\",\n+                            col_list_2=[],\n+                            max_separation=0.3,\n+                            other_thresholds=[],\n+                            weights=[],\n+                            output_path = args.mer_catalog,\n+                            matched_id_outputname = \"GAIA_ID\",\n+                            matched_quality_outputname = \"GAIA_MATCH_QUALITY\",\n+                            logger=logger)\n+    \n+    \"\"\"\n+\n+    logger.info('#')\n+    logger.info('# Exiting MER_GagaPrg mainMethod()')\n+    logger.info('#')\n",
                            "Added astrometric validation",
                            "Martin Kuemmel",
                            "2023-06-30T13:43:12.000+02:00",
                            "dd8b105bbc80fc2f67a5da64e02185d377fabfd5"
                        ]
                    ],
                    ".jenkinsFile": [
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\n-@Library('integration-library@release-9') _\n-pipelineElements(artifactId:\"MER_Validation\", component:'eden.3.0')\n+@Library(value='integration-library@release-10') _\n+pipelineElements(name:\"MER_Validation\", component:'eden.3.1')\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_BackgroundValidation/python/MER_BackgroundValidation/MER_BackgroundValidationModule.py": [
                        [
                            "@@ -34,7 +34,7 @@ from   scipy import stats\n import matplotlib.gridspec as gridspec\n from   mpl_toolkits.axes_grid1 import make_axes_locatable\n from   matplotlib.axes import Axes\n-from   scipy.stats import median_absolute_deviation\n+from   scipy.stats import median_abs_deviation\n from numpy import format_float_scientific\n #from scipy.ndimage import zoom\n \n@@ -227,14 +227,14 @@ def create_analysis_report(mosaics, bright_star_mask_polygons, final_catalog_pat\n         flux_ratio = [flux_ratio[xx] for xx in SUBSET]\n         mags   = [mags[xx] for xx in SUBSET]\n         median = np.median(flux_ratio)                                              \n-        NMAD   = 1.4826 * median_absolute_deviation(flux_ratio)                     \n+        NMAD   = 1.4826 * median_abs_deviation(flux_ratio)                     \n         vmin   = median - 5 * NMAD                                                  \n         vmax   = median + 5 * NMAD     \n         bins   = [16, 18, 19, 20, 21, 21.5, 22, 22.5, 23, 23.5, 24, 24.5, 25, 27]\n         flux_ratio_median,edges,_   = np.array(stats.binned_statistic(\n             mags, flux_ratio, statistic = 'median', bins = bins, range = (16, 27)))\n         flux_ratio_nmad,_,_   = np.array(stats.binned_statistic(\n-            mags, flux_ratio, statistic = median_absolute_deviation, bins = bins, range = (16, 27)))\n+            mags, flux_ratio, statistic = median_abs_deviation, bins = bins, range = (16, 27)))\n         flux_ratio_counts,_,_   = np.array(stats.binned_statistic(\n             mags, flux_ratio, statistic = 'count', bins = bins, range = (16, 27)))\n         flux_ratio_nmad *= 1.4826\n@@ -320,7 +320,7 @@ def get_hist_obj(sample_data, sample_flags, sample_rms, npixels, logger=None):\n     if len(histdata) > 0:\n         mode   = stats.mode(histdata)[0][0]\n         std    = np.std(histdata)\n-        NMAD   = 1.4826 * median_absolute_deviation(histdata)\n+        NMAD   = 1.4826 * median_abs_deviation(histdata)\n \n         vmin   = median - 5 * NMAD\n         vmax   = median + 5 * NMAD\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ],
                        [
                            "@@ -227,14 +227,14 @@ def create_analysis_report(mosaics, bright_star_mask_polygons, final_catalog_pat\n         flux_ratio = [flux_ratio[xx] for xx in SUBSET]\n         mags   = [mags[xx] for xx in SUBSET]\n         median = np.median(flux_ratio)                                              \n-        NMAD   = 1.4826 * median_absolute_deviation(flux_ratio)                     \n+        NMAD   = 1.4826 * median_abs_deviation(flux_ratio)                     \n         vmin   = median - 5 * NMAD                                                  \n         vmax   = median + 5 * NMAD     \n         bins   = [16, 18, 19, 20, 21, 21.5, 22, 22.5, 23, 23.5, 24, 24.5, 25, 27]\n         flux_ratio_median,edges,_   = np.array(stats.binned_statistic(\n             mags, flux_ratio, statistic = 'median', bins = bins, range = (16, 27)))\n         flux_ratio_nmad,_,_   = np.array(stats.binned_statistic(\n-            mags, flux_ratio, statistic = median_absolute_deviation, bins = bins, range = (16, 27)))\n+            mags, flux_ratio, statistic = median_abs_deviation, bins = bins, range = (16, 27)))\n         flux_ratio_counts,_,_   = np.array(stats.binned_statistic(\n             mags, flux_ratio, statistic = 'count', bins = bins, range = (16, 27)))\n         flux_ratio_nmad *= 1.4826\n@@ -320,7 +320,7 @@ def get_hist_obj(sample_data, sample_flags, sample_rms, npixels, logger=None):\n     if len(histdata) > 0:\n         mode   = stats.mode(histdata)[0][0]\n         std    = np.std(histdata)\n-        NMAD   = 1.4826 * median_absolute_deviation(histdata)\n+        NMAD   = 1.4826 * median_abs_deviation(histdata)\n \n         vmin   = median - 5 * NMAD\n         vmax   = median + 5 * NMAD\n",
                            "Fixes small bug",
                            "Javier Gracia Carpio",
                            "2023-06-27T17:29:11.000+00:00",
                            "1e0d1b65c2109bb09713177df68a9a85e925d72a"
                        ],
                        [
                            "@@ -34,7 +34,7 @@ from   scipy import stats\n import matplotlib.gridspec as gridspec\n from   mpl_toolkits.axes_grid1 import make_axes_locatable\n from   matplotlib.axes import Axes\n-from   scipy.stats import median_absolute_deviation\n+from   scipy.stats import median_abs_deviation\n from numpy import format_float_scientific\n #from scipy.ndimage import zoom\n \n",
                            "Fixes import from scipy",
                            "Javier Gracia Carpio",
                            "2023-06-24T23:07:05.000+00:00",
                            "ad6181c826f529750845c1484d5e71fdabe92724"
                        ],
                        [
                            "@@ -124,7 +124,7 @@ def create_analysis_report(mosaics, bright_star_mask_polygons, final_catalog_pat\n         del data\n \n         sample_bck_data  = get_sampled_data(bck_data,  100)\n-        bck_hist     = get_hist_obj(sample_bck_data,    sample_flags, sample_rms, npixels)        \n+        bck_hist     = get_hist_obj(sample_bck_data,    sample_flags, sample_rms, npixels, logger)        \n         del sample_bck_data\n \n         plot_map(zoomed_bck, bck_hist, f_ax1, \"Background\", fig, image_downsampling_factor)\n@@ -165,7 +165,7 @@ def create_analysis_report(mosaics, bright_star_mask_polygons, final_catalog_pat\n         #zoomed_bcksub = zoom(data, 0.5)\n         sample_bcksub_data  = get_sampled_data(data, 100)\n         del data\n-        bcksub_hist     = get_hist_obj(sample_bcksub_data, sample_flags, sample_rms, npixels)\n+        bcksub_hist     = get_hist_obj(sample_bcksub_data, sample_flags, sample_rms, npixels, logger)\n         del sample_bcksub_data\n         del sample_flags\n         del sample_rms\n@@ -183,7 +183,7 @@ def create_analysis_report(mosaics, bright_star_mask_polygons, final_catalog_pat\n \n         del zoomed_bcksub\n         plt.close('all')         \n-        plot_hists(bck_hist, bcksub_hist,  figsdir, filter_name, hist_png)\n+        plot_hists(bck_hist, bcksub_hist,  figsdir, filter_name, hist_png, logger)\n \n         del bck_hist['histdata']\n         del bcksub_hist['histdata']\n@@ -306,19 +306,32 @@ def get_sampled_data(data, sample_rate = 100, logger=None):\n                      for x in range(0, len(sub_data),    sample_rate) \n                      for y in range(0, len(sub_data[x]), sample_rate)])    \n \n-def get_hist_obj(sample_data, sample_flags, sample_rms, npixels):\n+def get_hist_obj(sample_data, sample_flags, sample_rms, npixels, logger=None):\n                  \n     subset = np.where(np.logical_and(sample_flags == 0, sample_rms < 1e10 ) )[0]\n     npix_sampled = len(subset)\n     histdata   = sample_data[subset]\n     median = np.median(histdata)\n     mean   = np.mean(histdata)\n-    mode   = stats.mode(histdata)[0][0]\n-    std    = np.std(histdata)\n-    NMAD   = 1.4826 * median_absolute_deviation(histdata)\n-\n-    vmin   = median - 5 * NMAD\n-    vmax   = median + 5 * NMAD\n+    #if logger is not None:\n+    #    logger.info(str(histdata))\n+    #    logger.info(npixels)\n+    \n+    if len(histdata) > 0:\n+        mode   = stats.mode(histdata)[0][0]\n+        std    = np.std(histdata)\n+        NMAD   = 1.4826 * median_absolute_deviation(histdata)\n+\n+        vmin   = median - 5 * NMAD\n+        vmax   = median + 5 * NMAD\n+\n+    else:\n+        logger.warning('# Generating a dummy statistics with *no* pixels!')\n+        mode = np.nan\n+        std = np.nan\n+        NMAD = np.nan\n+        vmin   = -1.\n+        vmax   = 1.\n \n     hist_obj = {}\n     hist_obj['histdata'] = np.clip(histdata, vmin, vmax)\n@@ -363,16 +376,20 @@ def plot_mask(polygon_list, wcs, ax, image_downsampling_factor):\n         polygon_pix = astropy.wcs.utils.skycoord_to_pixel(coords_polygon, wcs)\n         ax.plot(polygon_pix[0]/image_downsampling_factor, polygon_pix[1]/image_downsampling_factor, '-', color='blue')\n \n-def plot_hist(hist, ax, title_prefix):\n+def plot_hist(hist, ax, title_prefix, logger=None):\n     # Plot the background hist on the bottom-left\n     title  = '%s' % title_prefix    \n     histo, bin_edges = np.histogram(hist['histdata'],\n                                     bins  = 200, \n                                     range = (hist['vmin'], hist['vmax']),)\n \n-    histo = float(hist['number of pixels']) / hist['number of sampled pixels'] * np.array(histo, dtype = float)\n-    ax.plot((bin_edges[1:] + bin_edges[:-1]) / 2, histo,\n-        linewidth = 2, ds = 'steps-mid',)\n+    if hist['number of sampled pixels'] > 0:\n+        histo = float(hist['number of pixels']) / hist['number of sampled pixels'] * np.array(histo, dtype = float)\n+        ax.plot((bin_edges[1:] + bin_edges[:-1]) / 2, histo,\n+                linewidth = 2, ds = 'steps-mid',)\n+    else:\n+        if logger is not None:\n+            logger.warning('# No pixels available for the histogram!')\n \n     ax.set_xlabel('Flux')\n     ax.set_ylabel('#')\n@@ -381,7 +398,7 @@ def plot_hist(hist, ax, title_prefix):\n     ax.set_title(title)\n \n     \n-def plot_hists(hist1, hist2, figsdir, filter_name, file_name):\n+def plot_hists(hist1, hist2, figsdir, filter_name, file_name, logger=None):\n     \"\"\"Creates  analysis plot.\n \n     Parameters\n@@ -393,8 +410,8 @@ def plot_hists(hist1, hist2, figsdir, filter_name, file_name):\n     f_ax1  = fig.add_subplot(spec2[0, 0])\n     f_ax2  = fig.add_subplot(spec2[0, 1])\n     plt.suptitle(\"Flux distribution\")\n-    plot_hist(hist1, f_ax1, \"Background\")\n-    plot_hist(hist2, f_ax2, \"Background-subtracted mosaic\")\n+    plot_hist(hist1, f_ax1, \"Background\", logger)\n+    plot_hist(hist2, f_ax2, \"Background-subtracted mosaic\", logger)\n     plt.savefig(file_name)\n \n \n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-06-16T14:11:46.000+02:00",
                            "504febbf2c08fe2012b74d4f6aae5c5693624ea2"
                        ]
                    ],
                    "MER_BackgroundValidation/tests/python/MER_BackgroundValidationModule_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 11/11/20\n Author: thomv\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_BackgroundValidation.MER_BackgroundValidationModule\n \n class TestMER_BackgroundValidationModule(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_ClassificationValidation/python/MER_ClassificationValidation/MER_ClassificationMakeProbaCubeUtils.py": [
                        [
                            "@@ -124,7 +124,7 @@ def write_proba_cube( filename, cube,\n     date_now = datetime.datetime.now()\n     current_date = date_now.isoformat()[:16]+':00.00Z'\n \n-    fits.writeto(filename,cube,clobber=True)\n+    fits.writeto(filename,cube,overwrite=True)\n     \n     hdu=fits.open(filename,'update')\n     hdu0=hdu[0]\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_ClassificationValidation/python/MER_ClassificationValidation/MER_ClassificationValidationPrg.py": [
                        [
                            "@@ -298,9 +298,9 @@ def mainMethod(args):\n \n     tile_latitude = np.nanmean(output_cat['GLAT'])\n \n-    xmatch_out = get_temp_filepath('_xmatch.fits')\n-    logger.info('CREATING %s ' % xmatch_out)\n-    fits.write(xmatch_out, output_cat,clobber=True)\n+    #xmatch_out = get_temp_filepath('_xmatch.fits')\n+    #logger.info('CREATING %s ' % xmatch_out)\n+    #fits.write(xmatch_out, output_cat, clobber=True)\n     \n     # start the dict for the results\n     results_dict = {}\n@@ -373,7 +373,7 @@ def mainMethod(args):\n     plt.ylabel('$\\mu_{max}$ - Mag')\n     plt.legend()\n     plt.title('NIR-only and VIS+NIR detections')\n-    plt.savefig(mumax_mag_dict['mumax_mag_plot_VIS_NIR'], overwrite=True)\n+    plt.savefig(mumax_mag_dict['mumax_mag_plot_VIS_NIR'])\n     \n     png_name = (final_catalog.get_data()).split(\".fits\")[0] + '_mumax_mag_NIR.png'\n     mumax_mag_dict['mumax_mag_plot_NIR'] = os.path.join(figsdir, png_name)\n@@ -389,7 +389,7 @@ def mainMethod(args):\n     plt.ylabel('$\\mu_{max}$ - Mag')\n     plt.legend()\n     plt.title('NIR detections (stars, galaxies, spurious)')\n-    plt.savefig(mumax_mag_dict['mumax_mag_plot_NIR'], overwrite=True)\n+    plt.savefig(mumax_mag_dict['mumax_mag_plot_NIR'])\n     \n     png_name = (final_catalog.get_data()).split(\".fits\")[0] + '_mumax_mag_VIS.png'\n     mumax_mag_dict['mumax_mag_plot_VIS'] = os.path.join(figsdir, png_name)\n@@ -404,7 +404,7 @@ def mainMethod(args):\n     plt.ylabel('$\\mu_{max}$ - Mag')\n     plt.legend()\n     plt.title('VIS detections (stars, galaxies, spurious)')\n-    plt.savefig(mumax_mag_dict['mumax_mag_plot_VIS'], overwrite=True)\n+    plt.savefig(mumax_mag_dict['mumax_mag_plot_VIS'])\n \n     png_name = (final_catalog.get_data()).split(\".fits\")[0] + '_mumax_mag_flag.png'\n     mumax_mag_dict['mumax_mag_plot_flag'] = os.path.join(figsdir, png_name)\n@@ -420,7 +420,7 @@ def mainMethod(args):\n     plt.ylabel('$\\mu_{max}$ - Mag')\n     plt.legend()\n     plt.title('POINT_LIKE_FLAG')\n-    plt.savefig(mumax_mag_dict['mumax_mag_plot_flag'], overwrite=True)\n+    plt.savefig(mumax_mag_dict['mumax_mag_plot_flag'])\n \n \n     png_name = (final_catalog.get_data()).split(\".fits\")[0] + '_mumax_mag_cube.png'\n@@ -459,7 +459,7 @@ def mainMethod(args):\n     plt.legend()\n \n     plt.title('Probability cube and contours, VIS detections with DET_QUALITY_FLAG=0')\n-    plt.savefig(mumax_mag_dict['mumax_mag_plot_cube'], overwrite=True)\n+    plt.savefig(mumax_mag_dict['mumax_mag_plot_cube'])\n \n \n     proba_dict = {}\n@@ -562,7 +562,7 @@ def mainMethod(args):\n     plt.ylabel('Fraction of star or galaxy / Mag bin (in %)')\n     plt.legend()\n     plt.title('Fraction of VIS objects which Point-Like probability is > 0.5 or < 0.5')\n-    plt.savefig(proba_dict['pointlike_prob'], overwrite=True)\n+    plt.savefig(proba_dict['pointlike_prob'])\n \n \n     \n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ],
                        [
                            "@@ -298,9 +298,9 @@ def mainMethod(args):\n \n     tile_latitude = np.nanmean(output_cat['GLAT'])\n \n-    xmatch_out = get_temp_filepath('_xmatch.fits')\n-    logger.info('CREATING %s ' % xmatch_out)\n-    fits.write(xmatch_out, output_cat, clobber=True)\n+    #xmatch_out = get_temp_filepath('_xmatch.fits')\n+    #logger.info('CREATING %s ' % xmatch_out)\n+    #fits.write(xmatch_out, output_cat, clobber=True)\n     \n     # start the dict for the results\n     results_dict = {}\n",
                            "Avoid writing files in /tmp",
                            "Javier Gracia Carpio",
                            "2023-06-27T20:33:53.000+00:00",
                            "b9e9dee17df1134fea5409f81f2d23525fd356e1"
                        ],
                        [
                            "@@ -300,7 +300,7 @@ def mainMethod(args):\n \n     xmatch_out = get_temp_filepath('_xmatch.fits')\n     logger.info('CREATING %s ' % xmatch_out)\n-    fits.write(xmatch_out, output_cat, overwrite=True)\n+    fits.write(xmatch_out, output_cat, clobber=True)\n     \n     # start the dict for the results\n     results_dict = {}\n",
                            "Use clobber for fitsio",
                            "Javier Gracia Carpio",
                            "2023-06-27T17:06:56.000+00:00",
                            "842b3edde7b35d82192b2a11cac47d42467c97a4"
                        ],
                        [
                            "@@ -373,7 +373,7 @@ def mainMethod(args):\n     plt.ylabel('$\\mu_{max}$ - Mag')\n     plt.legend()\n     plt.title('NIR-only and VIS+NIR detections')\n-    plt.savefig(mumax_mag_dict['mumax_mag_plot_VIS_NIR'], overwrite=True)\n+    plt.savefig(mumax_mag_dict['mumax_mag_plot_VIS_NIR'])\n     \n     png_name = (final_catalog.get_data()).split(\".fits\")[0] + '_mumax_mag_NIR.png'\n     mumax_mag_dict['mumax_mag_plot_NIR'] = os.path.join(figsdir, png_name)\n@@ -389,7 +389,7 @@ def mainMethod(args):\n     plt.ylabel('$\\mu_{max}$ - Mag')\n     plt.legend()\n     plt.title('NIR detections (stars, galaxies, spurious)')\n-    plt.savefig(mumax_mag_dict['mumax_mag_plot_NIR'], overwrite=True)\n+    plt.savefig(mumax_mag_dict['mumax_mag_plot_NIR'])\n     \n     png_name = (final_catalog.get_data()).split(\".fits\")[0] + '_mumax_mag_VIS.png'\n     mumax_mag_dict['mumax_mag_plot_VIS'] = os.path.join(figsdir, png_name)\n@@ -404,7 +404,7 @@ def mainMethod(args):\n     plt.ylabel('$\\mu_{max}$ - Mag')\n     plt.legend()\n     plt.title('VIS detections (stars, galaxies, spurious)')\n-    plt.savefig(mumax_mag_dict['mumax_mag_plot_VIS'], overwrite=True)\n+    plt.savefig(mumax_mag_dict['mumax_mag_plot_VIS'])\n \n     png_name = (final_catalog.get_data()).split(\".fits\")[0] + '_mumax_mag_flag.png'\n     mumax_mag_dict['mumax_mag_plot_flag'] = os.path.join(figsdir, png_name)\n@@ -420,7 +420,7 @@ def mainMethod(args):\n     plt.ylabel('$\\mu_{max}$ - Mag')\n     plt.legend()\n     plt.title('POINT_LIKE_FLAG')\n-    plt.savefig(mumax_mag_dict['mumax_mag_plot_flag'], overwrite=True)\n+    plt.savefig(mumax_mag_dict['mumax_mag_plot_flag'])\n \n \n     png_name = (final_catalog.get_data()).split(\".fits\")[0] + '_mumax_mag_cube.png'\n@@ -459,7 +459,7 @@ def mainMethod(args):\n     plt.legend()\n \n     plt.title('Probability cube and contours, VIS detections with DET_QUALITY_FLAG=0')\n-    plt.savefig(mumax_mag_dict['mumax_mag_plot_cube'], overwrite=True)\n+    plt.savefig(mumax_mag_dict['mumax_mag_plot_cube'])\n \n \n     proba_dict = {}\n@@ -562,7 +562,7 @@ def mainMethod(args):\n     plt.ylabel('Fraction of star or galaxy / Mag bin (in %)')\n     plt.legend()\n     plt.title('Fraction of VIS objects which Point-Like probability is > 0.5 or < 0.5')\n-    plt.savefig(proba_dict['pointlike_prob'], overwrite=True)\n+    plt.savefig(proba_dict['pointlike_prob'])\n \n \n     \n",
                            "Removes deprecated overwrite parameter from plt.savefig method",
                            "Javier Gracia Carpio",
                            "2023-06-25T14:52:37.000+00:00",
                            "3702abd7019e03de09ccb9ab9a57f592c0b18c09"
                        ],
                        [
                            "@@ -300,7 +300,7 @@ def mainMethod(args):\n \n     xmatch_out = get_temp_filepath('_xmatch.fits')\n     logger.info('CREATING %s ' % xmatch_out)\n-    fits.write(xmatch_out, output_cat,clobber=True)\n+    fits.write(xmatch_out, output_cat, overwrite=True)\n     \n     # start the dict for the results\n     results_dict = {}\n",
                            "Fixes small issues",
                            "Javier Gracia Carpio",
                            "2023-06-25T13:56:34.000+00:00",
                            "204ce9d35926e49c0f819fb8ff0855f445b9cdf4"
                        ]
                    ],
                    "MER_ClassificationValidation/tests/python/MER_FindStarGalSpurious_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 03/22/19\n Author: esoubrie\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_ClassificationValidation.MER_ClassificationStarGalMatch as sgval\n \n class TestMER_FindStarGalInAuxdir(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_DeblendingValidation/tests/python/MER_CheckSegmapUtils_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 01/31/19\n Author: mkuemmel\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DeblendingValidation.MER_CheckSegmapUtils as csu\n \n class TestMER_DensityPlot(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_DetectionValidation/python/MER_DetectionValidation/MER_CatalogPlot.py": [
                        [
                            "@@ -99,4 +99,4 @@ class MER_CatalogPlot(object):\n         if out_plot_name is None:\n             out_plot_name = 'histo_plot.png'\n         self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_DetectionValidation/python/MER_DetectionValidation/MER_CrossmatchBarPlot.py": [
                        [
                            "@@ -147,4 +147,4 @@ class MER_CrossmatchBarPlot(object):\n         if out_plot_name is None:\n             out_plot_name = 'crossmatch_plot.png'\n         self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_DetectionValidation/python/MER_DetectionValidation/MER_HPViewTestPrg.py": [
                        [
                            "@@ -74,17 +74,17 @@ def mainMethod(args):\n     #wmap_map_I = healpy.read_map('wmap_band_iqumap_r9_7yr_W_v4_udgraded32.fits')\n     #healpy.mollview(wmap_map_I, coord=['G','E'], title='Histogram equalized Ecliptic', unit='mK', norm='hist', min=-1,max=1, xsize=2000)\n     #healpy.graticule()\n-    #plt.savefig('hp.png', overwrite=True)\n+    #plt.savefig('hp.png')\n \n     #wmap_map_I = healpy.read_map('wmap_band_iqumap_r9_7yr_W_v4_udgraded32.fits')\n     #healpy.mollview(wmap_map_I, coord=['G','C'], title='Histogram equalized Ecliptic', unit='mK', norm='hist', min=-1,max=1, xsize=2000)\n     #healpy.graticule()\n-    #plt.savefig('hp.png', overwrite=True)\n+    #plt.savefig('hp.png')\n \n     mer_map = healpy.read_map('bmapII.fits', nest=True, partial=True, verbose=True)\n     healpy.mollview(mer_map, coord='C', title='Healpix density map', nest=True, xsize=2000)\n     healpy.graticule()\n-    plt.savefig('hp.png', overwrite=True)\n+    plt.savefig('hp.png')\n \n \n     #NSIDE = healpy.order2nside(8)\n@@ -92,7 +92,7 @@ def mainMethod(args):\n     #healpy.mollview(m, title=\"Mollview image RING\")\n     #healpy.fitsfunc.write_map('map_part.fits', m, partial=True) \n     #healpy.fitsfunc.write_map('map.fits', m) \n-    #plt.savefig('hp.png', overwrite=True)\n+    #plt.savefig('hp.png')\n \n     logger.info('#')\n     logger.info('# Exiting MER_HPViewTestPrg mainMethod()')\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_DetectionValidation/python/MER_DetectionValidation/MER_HistoPlot.py": [
                        [
                            "@@ -256,7 +256,7 @@ class MER_CrossmatchHistoPlot(MER_HistoPlot):\n         if out_plot_name is None:\n             out_plot_name = 'histo_plot.png'\n         self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n \n class MER_DetectionHistoPlot(MER_HistoPlot):\n     \"\"\"\n@@ -335,7 +335,7 @@ class MER_DetectionHistoPlot(MER_HistoPlot):\n         if out_plot_name is None:\n             out_plot_name = 'dethisto_plot.png'\n         self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n \n \n class MER_CrossmatchSNRHistoPlot(MER_HistoPlot):\n@@ -406,7 +406,7 @@ class MER_CrossmatchSNRHistoPlot(MER_HistoPlot):\n         if out_plot_name is None:\n             out_plot_name = 'histo_snr_plot.png'\n         self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n \n \n class MER_CrossmatchFractionHistoPlot(MER_HistoPlot):\n@@ -568,4 +568,4 @@ class MER_CrossmatchFractionHistoPlot(MER_HistoPlot):\n         if out_plot_name is None:\n             out_plot_name = 'histo_fraction_plot.png'\n         self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True, dpi=150)\n+        plt.savefig(out_plot_name, dpi=150)\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ],
                        [
                            "@@ -568,4 +568,4 @@ class MER_CrossmatchFractionHistoPlot(MER_HistoPlot):\n         if out_plot_name is None:\n             out_plot_name = 'histo_fraction_plot.png'\n         self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True, dpi=150)\n+        plt.savefig(out_plot_name, dpi=150)\n",
                            "Fixes another overwrite...",
                            "Javier Gracia Carpio",
                            "2023-06-27T18:02:10.000+00:00",
                            "b7dfd2549d17e75c554f49bf2e71f2dd7a3713fc"
                        ],
                        [
                            "@@ -256,7 +256,7 @@ class MER_CrossmatchHistoPlot(MER_HistoPlot):\n         if out_plot_name is None:\n             out_plot_name = 'histo_plot.png'\n         self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n \n class MER_DetectionHistoPlot(MER_HistoPlot):\n     \"\"\"\n@@ -335,7 +335,7 @@ class MER_DetectionHistoPlot(MER_HistoPlot):\n         if out_plot_name is None:\n             out_plot_name = 'dethisto_plot.png'\n         self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n \n \n class MER_CrossmatchSNRHistoPlot(MER_HistoPlot):\n@@ -406,7 +406,7 @@ class MER_CrossmatchSNRHistoPlot(MER_HistoPlot):\n         if out_plot_name is None:\n             out_plot_name = 'histo_snr_plot.png'\n         self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n \n \n class MER_CrossmatchFractionHistoPlot(MER_HistoPlot):\n",
                            "Removes deprecated overwrite parameter from plt.savefig method",
                            "Javier Gracia Carpio",
                            "2023-06-25T14:52:37.000+00:00",
                            "3702abd7019e03de09ccb9ab9a57f592c0b18c09"
                        ]
                    ],
                    "MER_DetectionValidation/python/MER_DetectionValidation/MER_SpuriousDetectionValidation.py": [
                        [
                            "@@ -137,7 +137,7 @@ class MER_SpuriousDetectionValidation(object):\n         if out_plot_name is None:\n             out_plot_name = 'spurious_plot.png'\n         self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n \n     def get_reliability(self):\n         \"\"\"Compute the fraction of spurious detections amongst galaxies, stars and false positives\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_DetectionValidation/tests/python/MER_AstroValidationGenerator_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 09/09/20\n Author: user\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DetectionValidation.MER_AstroValidationGenerator\n \n class TestMER_AstroValidationGenerator(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_DetectionValidation/tests/python/MER_AstroValidationPlots_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 09/09/20\n Author: user\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DetectionValidation.MER_AstroValidationPlots\n \n class TestMER_AstroValidationPlots(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_DetectionValidation/tests/python/MER_CatalogPlot_test.py": [
                        [
                            "@@ -23,7 +23,7 @@\n :author: mkuemmel@usm.lmu.de\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DetectionValidation.MER_CatalogPlot\n \n class TestMER_CatalogPlot(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_DetectionValidation/tests/python/MER_CrossmatchBarPlot_test.py": [
                        [
                            "@@ -23,7 +23,7 @@\n :author: mkuemmel@usm.lmu.de\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DetectionValidation.MER_CrossmatchBarPlot\n \n class TestMER_CrossmatchBarPlot(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_DetectionValidation/tests/python/MER_DensityPlot_test.py": [
                        [
                            "@@ -23,12 +23,7 @@ Created on: 01/31/19\n Author: mkuemmel\n \"\"\"\n \n-from __future__ import division, print_function\n-import sys\n-if sys.version_info[0] < 3:\n-    from future_builtins import *\n-\n-import py.test\n+import pytest\n import MER_DetectionValidation.MER_DensityPlot\n \n class TestMER_DensityPlot(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_DetectionValidation/tests/python/MER_HealpixPlot_test.py": [
                        [
                            "@@ -23,12 +23,7 @@ Created on: 02/01/19\n Author: mkuemmel\n \"\"\"\n \n-from __future__ import division, print_function\n-import sys\n-if sys.version_info[0] < 3:\n-    from future_builtins import *\n-\n-import py.test\n+import pytest\n import MER_DetectionValidation.MER_HealpixPlot\n \n class TestMER_HealpixPlot(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_DetectionValidation/tests/python/MER_HistoPlot_test.py": [
                        [
                            "@@ -23,12 +23,7 @@ Created on: 01/28/19\n Author: mkuemmel\n \"\"\"\n \n-from __future__ import division, print_function\n-import sys\n-if sys.version_info[0] < 3:\n-    from future_builtins import *\n-\n-import py.test\n+import pytest\n import MER_DetectionValidation.MER_HistoPlot\n \n class TestMER_HistoPlot(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_DetectionValidation/tests/python/MER_PartitionCheckTable_test.py": [
                        [
                            "@@ -23,12 +23,7 @@ Created on: 12/19/19\n Author: user\n \"\"\"\n \n-from __future__ import division, print_function\n-import sys\n-if sys.version_info[0] < 3:\n-    from future_builtins import *\n-\n-import py.test\n+import pytest\n import MER_DetectionValidation.MER_PartitionCheckTable\n \n class TestMER_PartitionCheckTable(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_DetectionValidation/tests/python/MER_PositionPlot_test.py": [
                        [
                            "@@ -23,12 +23,7 @@ Created on: 01/25/19\n Author: mkuemmel\n \"\"\"\n \n-from __future__ import division, print_function\n-import sys\n-if sys.version_info[0] < 3:\n-    from future_builtins import *\n-\n-import py.test\n+import pytest\n import MER_DetectionValidation.MER_PositionPlot\n \n class TestMER_PositionPlot(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_DetectionValidation/tests/python/MER_QuickPositionPlot_test.py": [
                        [
                            "@@ -23,7 +23,7 @@\n :author: mkuemmel\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DetectionValidation.MER_QuickPositionPlot\n \n class TestMER_QuickPositionPlot(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_DetectionValidation/tests/python/MER_SpuriousDetectionValidation_test.py": [
                        [
                            "@@ -23,7 +23,7 @@\n :author: mkuemmel@usm.lmu.de\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_DetectionValidation.MER_SpuriousDetectionValidation\n \n class TestMER_SpuriousDetectionValidation(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_FinalCatalogValidation/tests/MER_CheckFinalCat_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 09/09/20\n Author: user\n \"\"\"\n \n-import py.test\n+import pytest\n \n class TestMER_CheckFinalCat(object):\n     \"\"\"\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_IOValidation/tests/MER_CheckIO_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 09/09/20\n Author: user\n \"\"\"\n \n-import py.test\n+import pytest\n \n class TestMER_CheckIO(object):\n     \"\"\"\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_MorphologyValidation/python/MER_MorphologyValidation/MER_MorphologyPlotAsymmetryHistogram.py": [
                        [
                            "@@ -296,4 +296,4 @@ class MorphologyPlotAsymmetryHistogram():\n \n         # store the plot\n         # self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_MorphologyValidation/python/MER_MorphologyValidation/MER_MorphologyPlotGiniHistogram.py": [
                        [
                            "@@ -296,4 +296,4 @@ class MorphologyPlotGiniHistogram():\n \n         # store the plot\n         # self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_MorphologyValidation/python/MER_MorphologyValidation/MER_MorphologyPlotM20Histogram.py": [
                        [
                            "@@ -296,4 +296,4 @@ class MorphologyPlotM20Histogram():\n \n         # store the plot\n         # self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_MorphologyValidation/python/MER_MorphologyValidation/MER_MorphologyPlotSmoothnessHistogram.py": [
                        [
                            "@@ -296,4 +296,4 @@ class MorphologyPlotSmoothnessHistogram():\n \n         # store the plot\n         # self._info('Saving Plots in : %s' % out_plot_name)\n-        plt.savefig(out_plot_name, overwrite=True)\n+        plt.savefig(out_plot_name)\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_MorphologyValidation/tests/python/MER_MorphologyValidation_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 10/14/20\n Author: user\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_MorphologyValidation.MER_MorphologyValidationPrg\n \n class TestMER_MorphologyValidation(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_MosaicingValidation/python/MER_MosaicingValidation/MER_NoiseRMSUtils.py": [
                        [
                            "@@ -30,7 +30,6 @@ import json\n import numpy as np\n from astropy.io import fits\n from astropy.stats import sigma_clip\n-from astropy.stats import median_absolute_deviation\n from astropy.stats import mad_std\n from scipy import ndimage\n \n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_MosaicingValidation/tests/python/MER_MosaicingValidation_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 08/25/20\n Author: igorz\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_MosaicingValidation.MER_MosaicingValidation\n \n class TestMER_MosaicingValidation(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_MosaicingValidation/tests/python/MER_NoiseApertureUtils_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 11/30/20\n Author: igorz\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_MosaicingValidation.MER_NoiseApertureUtils\n \n class TestMER_NoiseApertureUtils(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_MosaicingValidation/tests/python/MER_NoiseRMSUtils_test.py": [
                        [
                            "@@ -23,7 +23,7 @@\n :author: igorz\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_MosaicingValidation.MER_NoiseRMSUtils\n \n class TestMER_NoiseRMSUtils(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_PhotometryValidation/python/MER_PhotometryValidation/MER_PhotometryPlotCheck.py": [
                        [
                            "@@ -108,8 +108,6 @@ def mainMethod(args):\n     logger.info('# Entering MER_PhotometryPlotCheck mainMethod()')\n     logger.info('#')\n \n-    band_list = ['ALL']\n-\n     fig_dir = os.path.join(args.workdir, \"data\", \"photometryPlots\")\n     AnalysisUtils.create_directory(fig_dir)\n \n@@ -128,7 +126,7 @@ def mainMethod(args):\n     cat_fits = cat_metadata.get_data()\n \n     # Add all non empty columns to the band list\n-    band_list += create_band_list(args.workdir, cat_fits)\n+    band_list = create_band_list(args.workdir, cat_fits)\n \n     logger.info('# Reading TU_STAR_CATALOG')\n     # read xml data product\n@@ -148,9 +146,14 @@ def mainMethod(args):\n                                     cat_fits,\n                                     tus_fits,\n                                     tug_fits)\n+\n+    # First plot with all the bands\n+    # when band == ALL it uses only the not empty columns\n+    logger.info(f'# Plotting: ALL')\n+    phot_plot_utils.plot(fig_dir, 'ALL', band_list = band_list)\n+    # loop on existing bands\n     for band in band_list:\n         logger.info(f'# Plotting: {band}')\n-        # when band == ALL it uses only the not empty columns\n         phot_plot_utils.plot(fig_dir, band, band_list = band_list)\n \n      # Create the analysis report\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ],
                        [
                            "@@ -40,6 +40,7 @@ from MER_DataModelUtils.FileNaming import mer_filename\n \n from MER_PsfMosaicValidation.AnalysisUtils import AnalysisUtils\n \n+add_nisp_token = lambda col : f'{col}_NISP' if '_' not in col else col\n \n def defineSpecificProgramOptions():\n     \"\"\"\n@@ -88,6 +89,8 @@ def create_band_list(workdir, catalog):\n     # i.e. also TPHOT will be empty\n     aphot = [col for col in fluxes if 'APER' in col]\n     aphot_clean = [col.replace('FLUX_','').replace('_APER','').replace('_EXT_','_') for col in aphot]\n+    # add \"_NISP\" to Y, J, H to allign it with band_list definitions\n+    aphot_clean = [add_nisp_token(col) for col in aphot_clean]\n     real_band_list = [col for col in band_list if col not in aphot_clean]\n \n     return real_band_list\n@@ -145,7 +148,6 @@ def mainMethod(args):\n                                     cat_fits,\n                                     tus_fits,\n                                     tug_fits)\n-\n     for band in band_list:\n         logger.info(f'# Plotting: {band}')\n         # when band == ALL it uses only the not empty columns\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-06-16T14:11:46.000+02:00",
                            "504febbf2c08fe2012b74d4f6aae5c5693624ea2"
                        ]
                    ],
                    "MER_PhotometryValidation/tests/MER_PhotometryPlotCheck_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 09/09/20\n Author: user\n \"\"\"\n \n-import py.test\n+import pytest\n \n class TestMER_PhotometryPlotCheck(object):\n     \"\"\"\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_PipelineDefValidation/tests/MER_CheckPipelineDefinition_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 09/09/20\n Author: user\n \"\"\"\n \n-import py.test\n+import pytest\n \n class TestMER_CheckPipelienDefinition(object):\n     \"\"\"\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_PsfMosaicValidation/notebooks/Euclid_Input_PSFs_Analysis.ipynb": [
                        [
                            "@@ -125,7 +125,7 @@\n     \"        f[i].header[\\\"EXTNAME\\\"] =names[i-1]\\n\",\n     \"        print(ArrayUtils.fit_simple_gauss_2d(f[i].data))\\n\",\n     \"    nir_psf_file_name = os.path.join(workdir, \\\"ronaldoPsf4.fits\\\")\\n\",\n-    \"    f.writeto(nir_psf_file_name, clobber=True)\\n\"\n+    \"    f.writeto(nir_psf_file_name, overwrite=True)\\n\"\n    ]\n   },\n   {\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_Utils/python/MER_Utils/MER_ArrayStatistics.py": [
                        [
                            "@@ -79,7 +79,7 @@ class MER_ArrayStatistics(object):\n                     'min': numpy.nan, 'max': numpy.nan, 'mean': numpy.nan,\n                     'median': numpy.nan, 'std': numpy.nan}\n         # TODO: replace with \"median_abs_deviation()\" from v1.5 on\n-        stats_dict['mad'] = float(stats.median_absolute_deviation(array, axis, nan_policy='omit'))\n+        stats_dict['mad'] = float(stats.median_abs_deviation(array, axis, nan_policy='omit'))\n         \n         # that should be improved!\n         trim_limits = (stats_dict['median']-3.0*stats_dict['std'], stats_dict['median']+3.0*stats_dict['std'])\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_Utils/python/MER_Utils/MER_S2Nplot.py": [
                        [
                            "@@ -171,7 +171,7 @@ def mainMethod(args):\n \n             outplot=os.path.join(args.workdir,args.band+\"_S2N.png\")\n             logger.info('# Saving Plots in : %s'%args.band+\"_S2N.png\")\n-            plt.savefig(outplot,overwrite=True)\n+            plt.savefig(outplot)\n \n     logger.info('#')\n     logger.info('# Exiting MER_S2Nplot')\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_Utils/tests/python/MER_ArrayStatistics_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 09/09/20\n Author: user\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_Utils.MER_ArrayStatistics\n \n class TestMER_ArrayStatistics(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_Utils/tests/python/MER_MakeRestCat_test.py": [
                        [
                            "@@ -23,12 +23,7 @@ Created on: 01/25/19\n Author: mkuemmel\n \"\"\"\n \n-from __future__ import division, print_function\n-import sys\n-if sys.version_info[0] < 3:\n-    from future_builtins import *\n-\n-import py.test\n+import pytest\n import MER_Utils.MER_MakeRestCat\n \n class TestMER_MakeRestCat(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_Utils/tests/python/MER_Regionfile_test.py": [
                        [
                            "@@ -22,7 +22,7 @@ File: tests/python/MER_Regionfile_test.py\n Created on: 01/09/18\n Author: user\n \"\"\"\n-import py.test\n+import pytest\n import MER_Utils.MER_Regionfile\n \n class TestMER_Regionfile(object):\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "Makefile": [
                        [
                            "@@ -44,169 +44,19 @@\n #\n ################################################################################\n \n-# settings\n-CMAKE := cmake\n-CTEST := ctest\n-NINJA := $(shell which ninja-build 2> /dev/null)\n-ifeq ($(NINJA),)\n-  NINJA := $(shell which ninja 2> /dev/null)\n-endif\n-\n-# Looking for the Custom make library\n-\n-CUSTOM_MAKE_LIB := Custom.mk\n-\n-ifneq ($(wildcard $(CURDIR)/make/$(CUSTOM_MAKE_LIB)),)\n-  CUSTOM_MAKE_LIB_FILE := $(CURDIR)/make/$(CUSTOM_MAKE_LIB)\n-else\n-  ifneq ($(CMAKE_PREFIX_PATH),)\n-    PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    CUSTOM_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(CUSTOM_MAKE_LIB) $(dir)/../make/$(CUSTOM_MAKE_LIB)))\n-  endif\n-  CUSTOM_MAKE_LIB_LIST += /usr/share/Elements/make/$(CUSTOM_MAKE_LIB)\n-  CUSTOM_MAKE_LIB_FILE := $(firstword $(CUSTOM_MAKE_LIB_LIST))\n-endif\n-\n-# Looking for the ToolChain\n-\n-TOOLCHAIN_NAME := ElementsToolChain.cmake\n+ELEMENTS_MAKE_LIB := Elements.mk\n \n-ifneq ($(wildcard $(CURDIR)/cmake/$(TOOLCHAIN_NAME)),)\n-  TOOLCHAIN_FILE := $(CURDIR)/cmake/$(TOOLCHAIN_NAME)\n+ifneq ($(wildcard $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)),)\n+  ELEMENTS_MAKE_LIB_FILE := $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)\n else\n   ifneq ($(CMAKE_PREFIX_PATH),)\n     PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    TOOLCHAIN_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/lib*/cmake/ElementsProject/$(TOOLCHAIN_NAME) $(dir)/$(TOOLCHAIN_NAME)))\n-    TOOLCHAIN_FILE := $(firstword $(TOOLCHAIN_LIST))\n+    ELEMENTS_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(ELEMENTS_MAKE_LIB) $(dir)/../make/$(ELEMENTS_MAKE_LIB)))\n   endif\n+  ELEMENTS_MAKE_LIB_LIST += /usr/share/Elements/make/$(ELEMENTS_MAKE_LIB)\n+  ELEMENTS_MAKE_LIB_FILE := $(firstword $(ELEMENTS_MAKE_LIB_LIST))\n endif\n \n-override ALL_CMAKEFLAGS := -Wno-dev --no-warn-unused-cli\n-\n-ifneq ($(TOOLCHAIN_FILE),)\n-  # A toolchain has been found. Lets use it.\n-  override ALL_CMAKEFLAGS += -DCMAKE_TOOLCHAIN_FILE=$(TOOLCHAIN_FILE)\n-endif\n-\n-\n-BUILD_PREFIX_NAME := build\n-\n-override ALL_CMAKEFLAGS += -DUSE_LOCAL_INSTALLAREA=ON -DBUILD_PREFIX_NAME:STRING=$(BUILD_PREFIX_NAME)\n-override ALL_CMAKEFLAGS += -DUSE_VERSIONED_LIBRARIES=OFF\n-\n-ifndef BINARY_TAG\n-  ifdef CMAKECONFIG\n-    BINARY_TAG := ${CMAKECONFIG}\n-  else\n-    ifdef CMTCONFIG\n-      BINARY_TAG := ${CMTCONFIG}\n-    endif\n-  endif\n-endif\n-\n-ifdef BINARY_TAG\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME).$(BINARY_TAG)\n-else\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME)\n-endif\n-BUILDDIR := $(CURDIR)/$(BUILD_SUBDIR)\n-\n-# build tool\n-\n-ifneq ($(USE_NINJA),)\n-  # enable Ninja\n-  override ALL_CMAKEFLAGS += -GNinja\n-  BUILD_CONF_FILE := build.ninja\n-  BUILDFLAGS := $(NINJAFLAGS)\n-  ifneq ($(VERBOSE),)\n-    BUILDFLAGS := -v $(BUILDFLAGS)\n-  endif\n-else\n-  BUILD_CONF_FILE := Makefile\n-endif\n-BUILD_CMD := $(CMAKE) --build $(BUILD_SUBDIR) --target\n-\n-\n-# Use environment variable for extra flags\n-\n-# Replace the \":\" from eclipse variable list to spaces  \n-ifneq ($(EXPAND_FLAGS),)\n-  CMAKEFLAGS := $(subst :-, -,$(CMAKEFLAGS))\n-endif\n-\n-ifneq ($(CMAKEFLAGS),)\n-  override ALL_CMAKEFLAGS += $(CMAKEFLAGS)\n-endif\n-\n-# default target\n-all:\n-\n-# deep clean\n-purge:\n-\t$(RM) -r $(BUILDDIR) $(CURDIR)/InstallArea/$(BINARY_TAG)\n-\tfind $(CURDIR) \"(\" -name \"InstallArea\" -prune -o -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# Remove all the possible directories and the whole InstallArea as well\n-mrproper:\n-\t$(RM) -r $(CURDIR)/build $(CURDIR)/build.* $(CURDIR)/InstallArea\n-\tfind $(CURDIR) \"(\" -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# delegate any target to the build directory (except 'purge')\n-ifneq ($(MAKECMDGOALS),purge)\n-ifneq ($(MAKECMDGOALS),mrproper)\n-%: $(BUILDDIR)/$(BUILD_CONF_FILE) FORCE\n-\t+$(BUILD_CMD) $* -- $(BUILDFLAGS)\n-endif\n-endif\n-\n-# aliases\n-.PHONY: configure tests FORCE\n-ifneq ($(wildcard $(BUILDDIR)/$(BUILD_CONF_FILE)),)\n-configure: rebuild_cache\n-else\n-configure: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-endif\n-\t@ # do not delegate further\n-\n-\n-# This wrapping around the test target is used to ensure the generation of\n-# the XML output from ctest.\n-test: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-\n-# This target ensures that the \"all\" target is called before\n-# running the tests (unlike the \"test\" default target of CMake)\n-tests: all\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-ifeq ($(VERBOSE),)\n-# less verbose install\n-# (emulate the default CMake install target)\n-install: all\n-\tcd $(BUILDDIR) && $(CMAKE) -P cmake_install.cmake | grep -v \"^-- Up-to-date:\"\n-endif\n-\n-# import the library to look for a custom Makefile\n--include $(CUSTOM_MAKE_LIB_FILE)\n-\n-# ensure that the target are always passed to the CMake Makefile\n-FORCE: ;\n-\n-# Makefiles are used as implicit targets in make, but we should not consider\n-# them for delegation.\n-$(MAKEFILE_LIST): ;\n-\n-\n-# trigger CMake configuration\n-$(BUILDDIR)/$(BUILD_CONF_FILE): | $(BUILDDIR)\n-\tcd $(BUILDDIR) && $(CMAKE) $(ALL_CMAKEFLAGS) $(CURDIR)\n+$(info Using the $(ELEMENTS_MAKE_LIB_FILE) make library)\n+include $(ELEMENTS_MAKE_LIB_FILE)\n \n-$(BUILDDIR):\n-\tmkdir -p $(BUILDDIR)\n",
                            "merge to pull develop",
                            "yfang",
                            "2023-06-28T16:28:53.000+02:00",
                            "feaaa8345f10942413e896f84e3f622676b4e0ca"
                        ]
                    ],
                    "MER_MosaicingValidation/python/MER_MosaicingValidation/MER_NoiseStatisticsPairwiseUtils.py": [
                        [
                            "@@ -31,7 +31,7 @@ if sys.version_info[0] < 3:\n import numpy as np\n from astropy.io import fits\n from astropy.stats import sigma_clip\n-from astropy.stats import median_abs_deviation\n+from astropy.stats import median_absolute_deviation\n from astropy.stats import mad_std\n \n def noise_statistics(fitsname, segname, flagname=None, offset_min=1, offset_max=10, \n@@ -98,7 +98,7 @@ def noise_statistics(fitsname, segname, flagname=None, offset_min=1, offset_max=\n             i += 1\n \n         sigma_output[j]   = np.std(sigma_clip(diff, sigma=sigma_cl))/np.sqrt(2)\n-        mad_output[j]     = median_abs_deviation(diff)/np.sqrt(2)\n+        mad_output[j]     = median_absolute_deviation(diff)/np.sqrt(2)\n         mad_std_output[j] = mad_std(diff)/np.sqrt(2)\n \n         mag_output[j] = zp - 2.5*np.log10(sigma_lim*sigma_output[j])\n",
                            "Astropy uses median_absolute_deviation...",
                            "Javier Gracia Carpio",
                            "2023-06-27T17:44:46.000+00:00",
                            "783ad20b240644af8b80603986e284d53eb79b9e"
                        ],
                        [
                            "@@ -31,7 +31,7 @@ if sys.version_info[0] < 3:\n import numpy as np\n from astropy.io import fits\n from astropy.stats import sigma_clip\n-from astropy.stats import median_absolute_deviation\n+from astropy.stats import median_abs_deviation\n from astropy.stats import mad_std\n \n def noise_statistics(fitsname, segname, flagname=None, offset_min=1, offset_max=10, \n@@ -98,7 +98,7 @@ def noise_statistics(fitsname, segname, flagname=None, offset_min=1, offset_max=\n             i += 1\n \n         sigma_output[j]   = np.std(sigma_clip(diff, sigma=sigma_cl))/np.sqrt(2)\n-        mad_output[j]     = median_absolute_deviation(diff)/np.sqrt(2)\n+        mad_output[j]     = median_abs_deviation(diff)/np.sqrt(2)\n         mad_std_output[j] = mad_std(diff)/np.sqrt(2)\n \n         mag_output[j] = zp - 2.5*np.log10(sigma_lim*sigma_output[j])\n",
                            "Corrects more places where median_absolute_deviation is used",
                            "Javier Gracia Carpio",
                            "2023-06-27T17:38:28.000+00:00",
                            "be62009f85707296ce7de1b4a1f7a59dfd5f4496"
                        ]
                    ],
                    "MER_BackgroundValidation/python/MER_BackgroundValidation/MER_BackgroundValidationPrg.py": [
                        [
                            "@@ -29,6 +29,7 @@ import ElementsKernel.Logging as log\n \n import json\n import os\n+import time\n \n from MER_BackgroundValidation import MER_BackgroundValidationModule\n \n@@ -98,6 +99,9 @@ def mainMethod(args):\n     logger.info('# Entering MER_BackgroundValidationPrg mainMethod()')\n     logger.info('#')\n \n+    # Store the start time\n+    start_time = time.time()\n+\n     # print all parameters to the screen\n     print_input_arguments(args, logger)\n \n@@ -176,6 +180,8 @@ def mainMethod(args):\n     \n     analysis_result.save_xml(os.path.join(args.workdir, args.analysis_result))\n \n+    # Print the time spent running the step\n+    logger.info('# Time spend on step: %8ds' % (time.time() - start_time))\n \n     logger.info('#')\n     logger.info('# Exiting MER_BackgroundValidationPrg mainMethod()')\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-06-16T14:11:46.000+02:00",
                            "504febbf2c08fe2012b74d4f6aae5c5693624ea2"
                        ]
                    ],
                    "MER_PsfMosaicValidation/python/MER_PsfMosaicValidation/MER_ExtractTuCatalogs.py": [
                        [
                            "@@ -192,6 +192,10 @@ def select_tu_sources(catalog_file_names, tile, logger):\n             else:\n                 merged_catalog = vstack([merged_catalog, catalog[inside]])\n \n+    # Return None if the catalog was not created\n+    if merged_catalog is None:\n+        return None\n+\n     # Add the (x, y) pixel coordinates columns to the merged catalog\n     add_xy_coordinates_columns(merged_catalog, tile)\n \n@@ -239,9 +243,9 @@ def mainMethod(args):\n \n     # Get the MER tiles and the TU catalog XML file names\n     tile_xml_file_names = glob.glob(args.tiledir + os.sep + \"*.xml\")\n-    tu_star_catalog_xml_file_names = glob.glob(\n+    tu_star_catalog_xml_file_names = [] if args.tustardir is None else glob.glob(\n         args.tustardir + os.sep + \"*.xml\")\n-    tu_galaxy_catalog_xml_file_names = glob.glob(\n+    tu_galaxy_catalog_xml_file_names = [] if args.tugalaxydir is None else glob.glob(\n         args.tugalaxydir + os.sep + \"*.xml\")\n \n     # Get the TU star catalog release and the fits file names\n@@ -280,75 +284,84 @@ def mainMethod(args):\n         logger.info(\"# Selecting the TU stars that fall inside the tile...\")\n         tu_star_catalog = select_tu_sources(\n             tu_star_catalog_fits_file_names, tile, logger)\n-        logger.info(\n-            \"# Found %s TU stars inside the tile\" % len(tu_star_catalog))\n-\n-        # Save the TU star catalog to the output directory\n-        logger.info(\"# Saving the TU star catalog fits file\")\n-        fits_file_name = mer_filename(\n-            \"CAT\", prefix=\"TU-STAR\", instance_id=\"TILE%i-%s\" % (\n-                tile_index, tile_use_case))\n-        tu_star_catalog.write(os.path.join(args.outdir, fits_file_name))\n-\n-        # Create the MER TU star catalog product\n-        tu_star_catalog_product = mer_utils.create_true_universe_star_catalog(\n-            AnalysisUtils.ALL_FILTERS)\n-        tu_star_catalog_product.set_data(fits_file_name)\n-        tu_star_catalog_product.set_tile_index(tile_index)\n-        tu_star_catalog_product.set_release(tu_star_catalog_release)\n-        tu_star_catalog_product.Header.DataSetRelease = args.release\n-        tu_star_catalog_product.Header.ProductId = fits_file_name.replace(\n-            \".fits\", \"\")\n-        tu_star_catalog_product.Data.SpatialCoverage.Polygon = footprint_polygon\n-\n-        if tile_use_case in [\"WIDE\", \"DEEP\"]:\n-            tu_star_catalog_product.Data.CatalogDescription[\n-                0].CatalogOrigin = \"SIMULATED_%s\" % tile_use_case\n+\n+        if tu_star_catalog is None:\n+            logger.info(\"# The tile has no TU stars inside.\")\n         else:\n-            tu_star_catalog_product.Data.CatalogDescription[\n-                0].CatalogOrigin = \"OTHERS\"\n+            logger.info(\n+                \"# Found %s TU stars inside the tile\" % len(tu_star_catalog))\n+\n+            # Save the TU star catalog to the output directory\n+            logger.info(\"# Saving the TU star catalog fits file\")\n+            fits_file_name = mer_filename(\n+                \"CAT\", prefix=\"TU-STAR\", instance_id=\"TILE%i-%s\" % (\n+                    tile_index, tile_use_case))\n+            tu_star_catalog.write(os.path.join(args.outdir, fits_file_name))\n+\n+            # Create the MER TU star catalog product\n+            tu_star_catalog_product = mer_utils.create_true_universe_star_catalog(\n+                AnalysisUtils.ALL_FILTERS)\n+            tu_star_catalog_product.set_data(fits_file_name)\n+            tu_star_catalog_product.set_tile_index(tile_index)\n+            tu_star_catalog_product.set_release(tu_star_catalog_release)\n+            tu_star_catalog_product.Header.DataSetRelease = args.release\n+            tu_star_catalog_product.Header.ProductId = fits_file_name.replace(\n+                \".fits\", \"\")\n+            tu_star_catalog_product.Data.SpatialCoverage.Polygon = footprint_polygon\n+\n+            if tile_use_case in [\"WIDE\", \"DEEP\"]:\n+                tu_star_catalog_product.Data.CatalogDescription[\n+                    0].CatalogOrigin = \"SIMULATED_%s\" % tile_use_case\n+            else:\n+                tu_star_catalog_product.Data.CatalogDescription[\n+                    0].CatalogOrigin = \"OTHERS\"\n \n-        # Save the TU star catalog product to the output directory\n-        logger.info(\"# Saving the TU star catalog XML file\")\n-        tu_star_catalog_product.save_xml(\n-            os.path.join(args.outdir, fits_file_name.replace(\".fits\", \".xml\")))\n+            # Save the TU star catalog product to the output directory\n+            logger.info(\"# Saving the TU star catalog XML file\")\n+            tu_star_catalog_product.save_xml(os.path.join(\n+                args.outdir, fits_file_name.replace(\".fits\", \".xml\")))\n \n         # Select the TU galaxies that fall inside the tile\n         logger.info(\"# Selecting the TU galaxies that fall inside the tile...\")\n         tu_galaxy_catalog = select_tu_sources(\n             tu_galaxy_catalog_fits_file_names, tile, logger)\n-        logger.info(\"# Found %s TU galaxies inside the tile\" % len(\n-            tu_galaxy_catalog))\n-\n-        # Save the TU galaxy catalog to the output directory\n-        logger.info(\"# Saving the TU galaxy catalog fits file\")\n-        fits_file_name = mer_filename(\n-            \"CAT\", prefix=\"TU-GALAXY\", instance_id=\"TILE%i-%s\" % (\n-                tile_index, tile_use_case))\n-        tu_galaxy_catalog.write(os.path.join(args.outdir, fits_file_name))\n-\n-        # Create the MER TU galaxy catalog product\n-        tu_galaxy_catalog_product = mer_utils.create_true_universe_galaxy_catalog(\n-            AnalysisUtils.ALL_FILTERS)\n-        tu_galaxy_catalog_product.set_data(fits_file_name)\n-        tu_galaxy_catalog_product.set_tile_index(tile_index)\n-        tu_galaxy_catalog_product.set_release(tu_galaxy_catalog_release)\n-        tu_galaxy_catalog_product.Header.DataSetRelease = args.release\n-        tu_galaxy_catalog_product.Header.ProductId = fits_file_name.replace(\n-            \".fits\", \"\")\n-        tu_galaxy_catalog_product.Data.SpatialCoverage.Polygon = footprint_polygon\n-\n-        if tile_use_case in [\"DEEP\", \"WIDE\"]:\n-            tu_galaxy_catalog_product.Data.CatalogDescription[\n-                0].CatalogOrigin = \"SIMULATED_%s\" % tile_use_case\n+\n+        if tu_galaxy_catalog is None:\n+            logger.info(\n+                \"# The tile has no TU galaxies inside.\")\n         else:\n-            tu_galaxy_catalog_product.Data.CatalogDescription[\n-                0].CatalogOrigin = \"OTHERS\"\n+            logger.info(\"# Found %s TU galaxies inside the tile\" % len(\n+                tu_galaxy_catalog))\n+\n+            # Save the TU galaxy catalog to the output directory\n+            logger.info(\"# Saving the TU galaxy catalog fits file\")\n+            fits_file_name = mer_filename(\n+                \"CAT\", prefix=\"TU-GALAXY\", instance_id=\"TILE%i-%s\" % (\n+                    tile_index, tile_use_case))\n+            tu_galaxy_catalog.write(os.path.join(args.outdir, fits_file_name))\n+\n+            # Create the MER TU galaxy catalog product\n+            tu_galaxy_catalog_product = mer_utils.create_true_universe_galaxy_catalog(\n+                AnalysisUtils.ALL_FILTERS)\n+            tu_galaxy_catalog_product.set_data(fits_file_name)\n+            tu_galaxy_catalog_product.set_tile_index(tile_index)\n+            tu_galaxy_catalog_product.set_release(tu_galaxy_catalog_release)\n+            tu_galaxy_catalog_product.Header.DataSetRelease = args.release\n+            tu_galaxy_catalog_product.Header.ProductId = fits_file_name.replace(\n+                \".fits\", \"\")\n+            tu_galaxy_catalog_product.Data.SpatialCoverage.Polygon = footprint_polygon\n+\n+            if tile_use_case in [\"DEEP\", \"WIDE\"]:\n+                tu_galaxy_catalog_product.Data.CatalogDescription[\n+                    0].CatalogOrigin = \"SIMULATED_%s\" % tile_use_case\n+            else:\n+                tu_galaxy_catalog_product.Data.CatalogDescription[\n+                    0].CatalogOrigin = \"OTHERS\"\n \n-        # Save the TU galaxy catalog product to the output directory\n-        logger.info(\"# Saving the TU galaxy catalog XML file\")\n-        tu_galaxy_catalog_product.save_xml(\n-            os.path.join(args.outdir, fits_file_name.replace(\".fits\", \".xml\")))\n+            # Save the TU galaxy catalog product to the output directory\n+            logger.info(\"# Saving the TU galaxy catalog XML file\")\n+            tu_galaxy_catalog_product.save_xml(os.path.join(\n+                args.outdir, fits_file_name.replace(\".fits\", \".xml\")))\n \n     logger.info(\"#\")\n     logger.info(\"# Exiting MER_ExtractTuCatalogs mainMethod()\")\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-06-16T14:11:46.000+02:00",
                            "504febbf2c08fe2012b74d4f6aae5c5693624ea2"
                        ]
                    ],
                    "MER_PsfMosaicValidation/python/MER_PsfMosaicValidation/MER_PhotometryAnalysis.py": [
                        [
                            "@@ -27,6 +27,7 @@ import os.path\n import argparse\n import numpy as np\n import matplotlib.pyplot as plt\n+from astropy.table.column import MaskedColumn\n \n import ElementsKernel.Logging as log\n \n@@ -281,7 +282,9 @@ def create_analysis_figures(catalog, filter_name, workdir, figsdir):\n         return None\n \n     # Return None if there are no valid photometry measurements in the catalog\n-    if np.all(np.isnan(catalog[column_names[\"APHOT_FLUX\"]])):\n+    aphot_column = catalog[column_names[\"APHOT_FLUX\"]]\n+\n+    if isinstance(aphot_column, MaskedColumn) and np.all(aphot_column.mask):\n         return None\n \n     # Plot the A-Phot vs. TU photometry comparison\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_Validation into validation_on_observed_data",
                            "yfang",
                            "2023-06-16T14:11:46.000+02:00",
                            "504febbf2c08fe2012b74d4f6aae5c5693624ea2"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "9.1.1",
                        "created_at": "2023-03-08T14:57:05.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.0",
                        "created_at": "2023-07-03T15:17:10.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.1",
                        "created_at": "2023-08-14T13:19:54.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    }
                ]
            },
            "PF-MER/MER_DataModelUtils": {
                "start date": "2023-06-09 09:00",
                "end date": "2023-08-23 15:00",
                "start tag": "> 9.1.0",
                "end tag": "> 10.1.1",
                "count_files_modified": "7",
                "modifications_by_file": {
                    "MER_DataModelUtils/python/MER_DataModelUtils/ArchiveUtils.py": [
                        [
                            "@@ -133,7 +133,7 @@ def get_eas_metadata(query, eas_database, eas_project, logger=None,\n     query += \"&project=\" + eas_project\n \n     # Add the allow array parameter\n-    query += \"&allow_array=TRUE\"\n+    query += \"&allow_array=True\"\n \n     # Replace the + symbol by %2b\n     query = query.replace(\"+\", \"%2b\")\n",
                            "Correct possible typo",
                            "Javier Gracia Carpio",
                            "2023-08-11T14:56:48.000+00:00",
                            "919365d170f7f9535f5eac95973aa4619280a068"
                        ],
                        [
                            "@@ -132,6 +132,9 @@ def get_eas_metadata(query, eas_database, eas_project, logger=None,\n     # Add the EAS project parameter to the query\n     query += \"&project=\" + eas_project\n \n+    # Add the allow array parameter\n+    query += \"&allow_array=TRUE\"\n+\n     # Replace the + symbol by %2b\n     query = query.replace(\"+\", \"%2b\")\n \n",
                            "Adds the allow_array parameter to the EAS queries",
                            "Javier Gracia Carpio",
                            "2023-08-11T13:55:41.000+00:00",
                            "9f0b98f3cd74110396f6eadad6fa4871ade708b4"
                        ],
                        [
                            "@@ -124,17 +124,14 @@ def get_eas_metadata(query, eas_database, eas_project, logger=None,\n                         \"These are the allowed values: EUCLID, TEST.\")\n \n     # Define the EAS address\n-    eas_address = \"https://eas-dps-rest-ops.esac.esa.int\"\n+    eas_address = \"https://eas-dps-cps-ops.esac.esa.int\"\n \n     # Define the EAS service\n-    eas_service = \"/REST?\"\n+    eas_service = \"/COORS?\"\n \n     # Add the EAS project parameter to the query\n     query += \"&project=\" + eas_project\n \n-    # Add the allow array parameter\n-    query += \"&allow_array=TRUE\"\n-\n     # Replace the + symbol by %2b\n     query = query.replace(\"+\", \"%2b\")\n \n",
                            "Go back to COORS",
                            "Javier Gracia Carpio",
                            "2023-08-11T13:48:45.000+00:00",
                            "7cb06e275d92273e118655a19cc92a77f8686525"
                        ],
                        [
                            "@@ -124,14 +124,17 @@ def get_eas_metadata(query, eas_database, eas_project, logger=None,\n                         \"These are the allowed values: EUCLID, TEST.\")\n \n     # Define the EAS address\n-    eas_address = \"https://eas-dps-cps-ops.esac.esa.int\"\n+    eas_address = \"https://eas-dps-rest-ops.esac.esa.int\"\n \n     # Define the EAS service\n-    eas_service = \"/COORS?\"\n+    eas_service = \"/REST?\"\n \n     # Add the EAS project parameter to the query\n     query += \"&project=\" + eas_project\n \n+    # Add the allow array parameter\n+    query += \"&allow_array=TRUE\"\n+\n     # Replace the + symbol by %2b\n     query = query.replace(\"+\", \"%2b\")\n \n",
                            "Use REST service for EAS",
                            "Javier Gracia Carpio",
                            "2023-08-11T13:46:42.000+00:00",
                            "7e5165ab2803cb0aca8a8f2c6adaa0bd1fbf49ef"
                        ],
                        [
                            "@@ -38,6 +38,7 @@ import json\n import base64\n import fnmatch\n import subprocess\n+import time\n from urllib.request import urlopen\n import xml.etree.ElementTree as ElementTree\n from http.client import HTTPSConnection\n@@ -89,7 +90,8 @@ def check_metadata(metadata):\n             \"The EAS query returned an error message:\\n%s\" % metadata)\n \n \n-def get_eas_metadata(query, eas_database, eas_project, logger=None):\n+def get_eas_metadata(query, eas_database, eas_project, logger=None,\n+                     make_asy=False):\n     \"\"\"Returns the metadata information stored in EAS for the given query\n     parameters.\n \n@@ -103,6 +105,8 @@ def get_eas_metadata(query, eas_database, eas_project, logger=None):\n         The EAS project to query (EUCLID or TEST).\n     logger: object, optional\n         The logger instance. Default is None.\n+    make_asy: bool, optional\n+        Make an asynchronous query. Default is False.\n \n     Returns\n     -------\n@@ -132,10 +136,21 @@ def get_eas_metadata(query, eas_database, eas_project, logger=None):\n     query = query.replace(\"+\", \"%2b\")\n \n     # Query the EAS database\n+    url = eas_address + eas_service + query\n+\n     if logger is not None:\n-        logger.info(\"EAS query: %s\", eas_address + eas_service + query)\n-    metadata = urlopen(eas_address + eas_service + query, timeout=600).read(\n-        ).decode(\"utf-8\", \"ignore\")\n+        logger.info(\"EAS query: %s\", url)\n+\n+    if make_asy:\n+        response = json.loads(urlopen(url + \"&make_asy=TRUE\").read())\n+\n+        while response[\"status\"] != \"FINISHED\":\n+            time.sleep(5)\n+            response = json.loads(urlopen(response[\"url\"]).read())\n+\n+        url = response[\"url\"]\n+\n+    metadata = urlopen(url).read().decode(\"utf-8\", \"ignore\")\n \n     # Check that the EAS query returned a valid result\n     check_metadata(metadata)\n@@ -143,7 +158,8 @@ def get_eas_metadata(query, eas_database, eas_project, logger=None):\n     return metadata\n \n \n-def get_ppo_metadata(ppo_id, eas_database, eas_project, logger=None):\n+def get_ppo_metadata(ppo_id, eas_database, eas_project, logger=None,\n+                     make_asy=False):\n     \"\"\"Returns the metadata information stored in EAS for a given PPO data\n     product.\n \n@@ -157,6 +173,8 @@ def get_ppo_metadata(ppo_id, eas_database, eas_project, logger=None):\n         The EAS project to query (EUCLID or TEST).\n     logger: object, optional\n         The logger instance. Default is None.\n+    make_asy: bool, optional\n+        Make an asynchronous query. Default is False.\n \n     Returns\n     -------\n@@ -168,7 +186,8 @@ def get_ppo_metadata(ppo_id, eas_database, eas_project, logger=None):\n     query = \"class_name=PipelineProcessingOrder&Id=\" + ppo_id\n \n     # Get the PPO metadata\n-    ppo_metadata = get_eas_metadata(query, eas_database, eas_project, logger)\n+    ppo_metadata = get_eas_metadata(\n+        query, eas_database, eas_project, logger, make_asy)\n \n     # Raise and exception if the PPO metadata is empty\n     if not \"<ProcessingOrder>\" in ppo_metadata:\n@@ -179,7 +198,7 @@ def get_ppo_metadata(ppo_id, eas_database, eas_project, logger=None):\n \n \n def get_product_metadata(product_class, product_id, eas_database, eas_project,\n-                         query_extension=None, logger=None):\n+                         query_extension=None, logger=None, make_asy=False):\n     \"\"\"Returns the metadata information stored in EAS for a given data product.\n \n     Parameters\n@@ -196,6 +215,8 @@ def get_product_metadata(product_class, product_id, eas_database, eas_project,\n         Some extra parameters to add to the EAS query. Default is None.\n     logger: object, optional\n         The logger instance. Default is None.\n+    make_asy: bool, optional\n+        Make an asynchronous query. Default is False.\n \n     Returns\n     -------\n@@ -210,11 +231,11 @@ def get_product_metadata(product_class, product_id, eas_database, eas_project,\n     if query_extension is not None:\n         query += \"&\" + query_extension\n \n-    return get_eas_metadata(query, eas_database, eas_project, logger)\n+    return get_eas_metadata(query, eas_database, eas_project, logger, make_asy)\n \n \n def get_products_metadata(product_class, query, eas_database, eas_project,\n-                          logger=None):\n+                          logger=None, make_asy=False):\n     \"\"\"Returns the metadata information stored in EAS for a given set of data\n     products.\n \n@@ -230,6 +251,8 @@ def get_products_metadata(product_class, query, eas_database, eas_project,\n         The EAS project to query (EUCLID or TEST).\n     logger: object, optional\n         The logger instance. Default is None.\n+    make_asy: bool, optional\n+        Make an asynchronous query. Default is False.\n \n     Returns\n     -------\n@@ -242,7 +265,8 @@ def get_products_metadata(product_class, query, eas_database, eas_project,\n     query = \"class_name=\" + product_class + \"&\" + query\n \n     # Get the EAS metadata\n-    metadata = get_eas_metadata(query, eas_database, eas_project, logger)\n+    metadata = get_eas_metadata(\n+        query, eas_database, eas_project, logger, make_asy)\n \n     # Extract the metadata for each product\n     products_metadata = []\n@@ -263,7 +287,7 @@ def get_products_metadata(product_class, query, eas_database, eas_project,\n \n \n def get_products_fields(product_class, query, fields, eas_database,\n-                        eas_project, logger=None):\n+                        eas_project, logger=None, make_asy=False):\n     \"\"\"Returns the metadata information stored in EAS for a given set of data\n     products.\n \n@@ -281,6 +305,8 @@ def get_products_fields(product_class, query, fields, eas_database,\n         The EAS project to query (EUCLID or TEST).\n     logger: object, optional\n         The logger instance. Default is None.\n+    make_asy: bool, optional\n+        Make an asynchronous query. Default is False.\n \n     Returns\n     -------\n@@ -293,7 +319,8 @@ def get_products_fields(product_class, query, fields, eas_database,\n     query = \"class_name=\" + product_class + \"&\" + query + \"&fields=\" + fields\n \n     # Get the EAS metadata\n-    metadata = get_eas_metadata(query, eas_database, eas_project, logger)\n+    metadata = get_eas_metadata(\n+        query, eas_database, eas_project, logger, make_asy)\n \n     # Extract the metadata for each product\n     product_metadata = metadata.split(\"\\n\")\n@@ -309,7 +336,7 @@ def get_products_fields(product_class, query, fields, eas_database,\n \n \n def get_products_ids(product_class, query, eas_database, eas_project,\n-                     logger=None):\n+                     logger=None, make_asy=False):\n     \"\"\"Returns the ids of the products stored in EAS for a given query.\n \n     Parameters\n@@ -324,6 +351,8 @@ def get_products_ids(product_class, query, eas_database, eas_project,\n         The EAS project to query (EUCLID, TEST or ANY).\n     logger: object, optional\n         The logger instance. Default is None.\n+    make_asy: bool, optional\n+        Make an asynchronous query. Default is False.\n \n     Returns\n     -------\n@@ -335,13 +364,16 @@ def get_products_ids(product_class, query, eas_database, eas_project,\n \n     if eas_project == \"ANY\":\n         test_product_ids = get_products_fields(\n-            product_class, query, fields, eas_database, \"TEST\", logger)\n+            product_class, query, fields, eas_database, \"TEST\", logger,\n+            make_asy)\n         euclid_product_ids = get_products_fields(\n-            product_class, query, fields, eas_database, \"EUCLID\", logger)\n+            product_class, query, fields, eas_database, \"EUCLID\", logger,\n+            make_asy)\n         return test_product_ids + euclid_product_ids\n \n     return get_products_fields(\n-        product_class, query, fields, eas_database, eas_project, logger)\n+        product_class, query, fields, eas_database, eas_project, logger,\n+        make_asy)\n \n \n def save_metadata(metadata, file_name, output_directory):\n",
                            "Adds the possibility of creating asynchronous queries",
                            "Javier Gracia Carpio",
                            "2023-07-27T10:21:24.000+00:00",
                            "0494f3895119c126b02033e3dad3344161037c45"
                        ],
                        [
                            "@@ -321,7 +321,7 @@ def get_products_ids(product_class, query, eas_database, eas_project,\n     eas_database: str\n         The EAS database to query (DM9.2).\n     eas_project: str\n-        The EAS project to query (EUCLID or TEST).\n+        The EAS project to query (EUCLID, TEST or ANY).\n     logger: object, optional\n         The logger instance. Default is None.\n \n@@ -333,6 +333,13 @@ def get_products_ids(product_class, query, eas_database, eas_project,\n     \"\"\"\n     fields = \"Header.ProductId.LimitedString\"\n \n+    if eas_project == \"ANY\":\n+        test_product_ids = get_products_fields(\n+            product_class, query, fields, eas_database, \"TEST\", logger)\n+        euclid_product_ids = get_products_fields(\n+            product_class, query, fields, eas_database, \"EUCLID\", logger)\n+        return test_product_ids + euclid_product_ids\n+\n     return get_products_fields(\n         product_class, query, fields, eas_database, eas_project, logger)\n \n",
                            "Add the possibility to searh in TEST and EUCLID at the same time",
                            "Javier Gracia Carpio",
                            "2023-07-19T16:44:54.000+00:00",
                            "627355ec552d47f1f5ee8e25aae54916eb2a55aa"
                        ],
                        [
                            "@@ -134,8 +134,8 @@ def get_eas_metadata(query, eas_database, eas_project, logger=None):\n     # Query the EAS database\n     if logger is not None:\n         logger.info(\"EAS query: %s\", eas_address + eas_service + query)\n-    metadata = urlopen(eas_address + eas_service + query).read().decode(\n-        \"utf-8\", \"ignore\")\n+    metadata = urlopen(eas_address + eas_service + query, timeout=600).read(\n+        ).decode(\"utf-8\", \"ignore\")\n \n     # Check that the EAS query returned a valid result\n     check_metadata(metadata)\n",
                            "Increase timeout time",
                            "Javier Gracia Carpio",
                            "2023-07-19T12:26:47.000+00:00",
                            "1fb50f83d07741cfddb47ef93e75b7cfd642734b"
                        ],
                        [
                            "@@ -89,7 +89,7 @@ def check_metadata(metadata):\n             \"The EAS query returned an error message:\\n%s\" % metadata)\n \n \n-def get_eas_metadata(query, eas_database, eas_project):\n+def get_eas_metadata(query, eas_database, eas_project, logger=None):\n     \"\"\"Returns the metadata information stored in EAS for the given query\n     parameters.\n \n@@ -101,6 +101,8 @@ def get_eas_metadata(query, eas_database, eas_project):\n         The EAS database to query (DM9.2).\n     eas_project: str\n         The EAS project to query (EUCLID or TEST).\n+    logger: object, optional\n+        The logger instance. Default is None.\n \n     Returns\n     -------\n@@ -130,6 +132,8 @@ def get_eas_metadata(query, eas_database, eas_project):\n     query = query.replace(\"+\", \"%2b\")\n \n     # Query the EAS database\n+    if logger is not None:\n+        logger.info(\"EAS query: %s\", eas_address + eas_service + query)\n     metadata = urlopen(eas_address + eas_service + query).read().decode(\n         \"utf-8\", \"ignore\")\n \n@@ -139,7 +143,7 @@ def get_eas_metadata(query, eas_database, eas_project):\n     return metadata\n \n \n-def get_ppo_metadata(ppo_id, eas_database, eas_project):\n+def get_ppo_metadata(ppo_id, eas_database, eas_project, logger=None):\n     \"\"\"Returns the metadata information stored in EAS for a given PPO data\n     product.\n \n@@ -151,6 +155,8 @@ def get_ppo_metadata(ppo_id, eas_database, eas_project):\n         The EAS database to query (DM9.2).\n     eas_project: str\n         The EAS project to query (EUCLID or TEST).\n+    logger: object, optional\n+        The logger instance. Default is None.\n \n     Returns\n     -------\n@@ -162,7 +168,7 @@ def get_ppo_metadata(ppo_id, eas_database, eas_project):\n     query = \"class_name=PipelineProcessingOrder&Id=\" + ppo_id\n \n     # Get the PPO metadata\n-    ppo_metadata = get_eas_metadata(query, eas_database, eas_project)\n+    ppo_metadata = get_eas_metadata(query, eas_database, eas_project, logger)\n \n     # Raise and exception if the PPO metadata is empty\n     if not \"<ProcessingOrder>\" in ppo_metadata:\n@@ -173,7 +179,7 @@ def get_ppo_metadata(ppo_id, eas_database, eas_project):\n \n \n def get_product_metadata(product_class, product_id, eas_database, eas_project,\n-                         query_extension=None):\n+                         query_extension=None, logger=None):\n     \"\"\"Returns the metadata information stored in EAS for a given data product.\n \n     Parameters\n@@ -188,6 +194,8 @@ def get_product_metadata(product_class, product_id, eas_database, eas_project,\n         The EAS project to query (EUCLID or TEST).\n     query_extension: str, optional\n         Some extra parameters to add to the EAS query. Default is None.\n+    logger: object, optional\n+        The logger instance. Default is None.\n \n     Returns\n     -------\n@@ -202,10 +210,11 @@ def get_product_metadata(product_class, product_id, eas_database, eas_project,\n     if query_extension is not None:\n         query += \"&\" + query_extension\n \n-    return get_eas_metadata(query, eas_database, eas_project)\n+    return get_eas_metadata(query, eas_database, eas_project, logger)\n \n \n-def get_products_metadata(product_class, query, eas_database, eas_project):\n+def get_products_metadata(product_class, query, eas_database, eas_project,\n+                          logger=None):\n     \"\"\"Returns the metadata information stored in EAS for a given set of data\n     products.\n \n@@ -219,6 +228,8 @@ def get_products_metadata(product_class, query, eas_database, eas_project):\n         The EAS database to query (DM9.2).\n     eas_project: str\n         The EAS project to query (EUCLID or TEST).\n+    logger: object, optional\n+        The logger instance. Default is None.\n \n     Returns\n     -------\n@@ -231,7 +242,7 @@ def get_products_metadata(product_class, query, eas_database, eas_project):\n     query = \"class_name=\" + product_class + \"&\" + query\n \n     # Get the EAS metadata\n-    metadata = get_eas_metadata(query, eas_database, eas_project)\n+    metadata = get_eas_metadata(query, eas_database, eas_project, logger)\n \n     # Extract the metadata for each product\n     products_metadata = []\n@@ -252,7 +263,7 @@ def get_products_metadata(product_class, query, eas_database, eas_project):\n \n \n def get_products_fields(product_class, query, fields, eas_database,\n-                        eas_project):\n+                        eas_project, logger=None):\n     \"\"\"Returns the metadata information stored in EAS for a given set of data\n     products.\n \n@@ -268,6 +279,8 @@ def get_products_fields(product_class, query, fields, eas_database,\n         The EAS database to query (DM9.2).\n     eas_project: str\n         The EAS project to query (EUCLID or TEST).\n+    logger: object, optional\n+        The logger instance. Default is None.\n \n     Returns\n     -------\n@@ -280,7 +293,7 @@ def get_products_fields(product_class, query, fields, eas_database,\n     query = \"class_name=\" + product_class + \"&\" + query + \"&fields=\" + fields\n \n     # Get the EAS metadata\n-    metadata = get_eas_metadata(query, eas_database, eas_project)\n+    metadata = get_eas_metadata(query, eas_database, eas_project, logger)\n \n     # Extract the metadata for each product\n     product_metadata = metadata.split(\"\\n\")\n@@ -295,7 +308,8 @@ def get_products_fields(product_class, query, fields, eas_database,\n     return sorted(product_metadata)\n \n \n-def get_products_ids(product_class, query, eas_database, eas_project):\n+def get_products_ids(product_class, query, eas_database, eas_project,\n+                     logger=None):\n     \"\"\"Returns the ids of the products stored in EAS for a given query.\n \n     Parameters\n@@ -308,6 +322,8 @@ def get_products_ids(product_class, query, eas_database, eas_project):\n         The EAS database to query (DM9.2).\n     eas_project: str\n         The EAS project to query (EUCLID or TEST).\n+    logger: object, optional\n+        The logger instance. Default is None.\n \n     Returns\n     -------\n@@ -318,7 +334,7 @@ def get_products_ids(product_class, query, eas_database, eas_project):\n     fields = \"Header.ProductId.LimitedString\"\n \n     return get_products_fields(\n-        product_class, query, fields, eas_database, eas_project)\n+        product_class, query, fields, eas_database, eas_project, logger)\n \n \n def save_metadata(metadata, file_name, output_directory):\n",
                            "Pass logger to print the query information",
                            "Javier Gracia Carpio",
                            "2023-07-18T12:12:48.000+00:00",
                            "67a77b6be9aa2e71087a7bb5d2ac12ee1e76a63a"
                        ],
                        [
                            "@@ -98,7 +98,7 @@ def get_eas_metadata(query, eas_database, eas_project):\n     query: str\n         The EAS query parameters.\n     eas_database: str\n-        The EAS database to query (DM9.1).\n+        The EAS database to query (DM9.2).\n     eas_project: str\n         The EAS project to query (EUCLID or TEST).\n \n@@ -109,9 +109,9 @@ def get_eas_metadata(query, eas_database, eas_project):\n \n     \"\"\"\n     # Check that the input parameters are valid\n-    if not eas_database in [\"DM9.1\"]:\n+    if not eas_database in [\"DM9.2\"]:\n         raise Exception(\"The EAS database parameter is not valid.\\n\"\n-                        \"These are the allowed values: DM9.1\")\n+                        \"These are the allowed values: DM9.2\")\n \n     if not eas_project in [\"EUCLID\", \"TEST\"]:\n         raise Exception(\"The EAS project parameter is not valid.\\n\"\n@@ -148,7 +148,7 @@ def get_ppo_metadata(ppo_id, eas_database, eas_project):\n     ppo_id: str\n         The PPO id.\n     eas_database: str\n-        The EAS database to query (DM9.1).\n+        The EAS database to query (DM9.2).\n     eas_project: str\n         The EAS project to query (EUCLID or TEST).\n \n@@ -183,7 +183,7 @@ def get_product_metadata(product_class, product_id, eas_database, eas_project,\n     product_id: str\n         The product id.\n     eas_database: str\n-        The EAS database to query (DM9.1).\n+        The EAS database to query (DM9.2).\n     eas_project: str\n         The EAS project to query (EUCLID or TEST).\n     query_extension: str, optional\n@@ -216,7 +216,7 @@ def get_products_metadata(product_class, query, eas_database, eas_project):\n     query: str\n         The EAS query parameters.\n     eas_database: str\n-        The EAS database to query (DM9.1).\n+        The EAS database to query (DM9.2).\n     eas_project: str\n         The EAS project to query (EUCLID or TEST).\n \n@@ -265,7 +265,7 @@ def get_products_fields(product_class, query, fields, eas_database,\n     fields: str\n         The product metadata elements to return.\n     eas_database: str\n-        The EAS database to query (DM9.1).\n+        The EAS database to query (DM9.2).\n     eas_project: str\n         The EAS project to query (EUCLID or TEST).\n \n@@ -305,7 +305,7 @@ def get_products_ids(product_class, query, eas_database, eas_project):\n     query: str\n         The EAS query parameters.\n     eas_database: str\n-        The EAS database to query (DM9.1).\n+        The EAS database to query (DM9.2).\n     eas_project: str\n         The EAS project to query (EUCLID or TEST).\n \n@@ -384,7 +384,7 @@ def download_product_data_files(metadata, output_directory, user_information,\n     user_information: dict\n         A python dictionary with the Euclid user name and password.\n     dss_instance: str\n-        The DSS instance to query (DM9.1).\n+        The DSS instance to query (DM9.2).\n     logger: object, optional\n         A logger instance where the download information will be printed.\n         Default is None.\n@@ -455,7 +455,7 @@ def download_dss_file(file_name, output_directory, user_information,\n     user_information: dict\n         A python dictionary with the Euclid user name and password.\n     dss_instance: str\n-        The DSS instance to query (DM9.1).\n+        The DSS instance to query (DM9.2).\n     use_wget: bool, optional\n         If True, the file will be downloaded using the wget program. Default is\n         False.\n@@ -482,7 +482,7 @@ def download_dss_file_with_http(file_name, output_directory, user_information,\n     user_information: dict\n         A python dictionary with the Euclid user name and password.\n     dss_instance: str\n-        The DSS instance to query (DM9.1).\n+        The DSS instance to query (DM9.2).\n \n     \"\"\"\n     # Define the DSS address\n@@ -545,7 +545,7 @@ def download_dss_file_with_wget(file_name, output_directory, user_information,\n     user_information: dict\n         A python dictionary with the Euclid user name and password.\n     dss_instance: str\n-        The DSS instance to query (DM9.1).\n+        The DSS instance to query (DM9.2).\n \n     \"\"\"\n     # Define the DSS address\n",
                            "Missing bits for the DM9.2 update",
                            "Javier Gracia Carpio",
                            "2023-06-22T12:05:44.000+00:00",
                            "362d869524c7d6bdcbb847627ea85b3746372c58"
                        ]
                    ],
                    "CMakeLists.txt": [
                        [
                            "@@ -14,4 +14,4 @@ find_package(ElementsProject)\n \n elements_project(MER_DataModelUtils 10.2 USE Elements 6.2.1\n                                              ST_DataModel 9.2.0\n-                                             ST_DataModelTools 9.2.1)\n+                                             ST_DataModelTools 9.2.2)\n",
                            "Merge branch 'develop' of git@gitlab.euclid-sgs.uk:PF-MER/MER_DataModelUtils.git into develop",
                            "Javier Gracia Carpio",
                            "2023-08-11T13:46:55.000+00:00",
                            "38b8a321e58ed7a3010f1be32ac82fa84113abb6"
                        ],
                        [
                            "@@ -12,6 +12,6 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_DataModelUtils 10.1 USE Elements 6.2.1\n+elements_project(MER_DataModelUtils 10.2 USE Elements 6.2.1\n                                              ST_DataModel 9.2.0\n                                              ST_DataModelTools 9.2.1)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-07-03T11:54:04.000+00:00",
                            "c3c86326a48e58b04d899bea0c67df0445613608"
                        ],
                        [
                            "@@ -12,6 +12,6 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_DataModelUtils 10.0 USE Elements 6.1.1\n-                                             ST_DataModel 9.1.5\n-                                             ST_DataModelTools 9.1.2)\n+elements_project(MER_DataModelUtils 10.1 USE Elements 6.2.1\n+                                             ST_DataModel 9.2.0\n+                                             ST_DataModelTools 9.2.1)\n",
                            "Migrate to DM9.2 and EDEN 3.1",
                            "Javier Gracia Carpio",
                            "2023-06-22T09:21:20.000+00:00",
                            "9ed60eaa2caa15ec380a66e8d70a644e2bda58c4"
                        ]
                    ],
                    "MER_DataModelUtils/python/MER_DataModelUtils/FileNaming.py": [
                        [
                            "@@ -92,7 +92,7 @@ VALIDATION_PREFIXES = [\n     \"PSF\",\n     \"MER-STAR-PSF\",\n     \"TU-STAR-PSF\",\n-    \"GAIA-STAR-PSF\",\n+    \"GAIA-PSF\",\n     \"CROSSMATCH\",\n     \"PHOTOMETRY\",\n     \"DETECTION\",\n",
                            "Renames prefix",
                            "Javier Gracia Carpio",
                            "2023-08-10T16:17:31.000+00:00",
                            "957257c2a48f1ae68fd3c1063afa3474e078f4c6"
                        ],
                        [
                            "@@ -92,6 +92,7 @@ VALIDATION_PREFIXES = [\n     \"PSF\",\n     \"MER-STAR-PSF\",\n     \"TU-STAR-PSF\",\n+    \"GAIA-STAR-PSF\",\n     \"CROSSMATCH\",\n     \"PHOTOMETRY\",\n     \"DETECTION\",\n",
                            "Add a new validation prefix",
                            "Javier Gracia Carpio",
                            "2023-08-10T16:03:51.000+00:00",
                            "8848ac732eeba0b0bdaacfb3fa5aa734442216de"
                        ],
                        [
                            "@@ -301,7 +301,7 @@ def mer_filename(product, prefix=None, filter1=None, filter2=None, ext=\"fits\",\n \n \n def euclid_filename(processing_function, data_product_type, extension,\n-                    instance_id=\"\", release=None):\n+                    instance_id=\"\", release=\"00.00\"):\n     \"\"\"Returns a file name that follows the Euclid naming conventions.\n \n     Parameters\n@@ -315,7 +315,7 @@ def euclid_filename(processing_function, data_product_type, extension,\n     instance_id: str, optional\n         The product instance ID. Default is an empty string.\n     release: str, optional\n-        The product release number. Default is None\n+        The product release number. Default is 00.00\n \n     Returns\n     -------\n@@ -327,5 +327,5 @@ def euclid_filename(processing_function, data_product_type, extension,\n         processing_function=processing_function.upper(),\n         type_name=data_product_type.upper(),\n         instance_id=instance_id.upper(),\n-        release=release,\n+        release=release.upper(),\n         extension=extension.lower())\n",
                            "Undo previous change",
                            "Javier Gracia Carpio",
                            "2023-06-25T14:39:38.000+00:00",
                            "d62b2f99a16e054f20cd993c76fe43cc34f37ae1"
                        ],
                        [
                            "@@ -301,7 +301,7 @@ def mer_filename(product, prefix=None, filter1=None, filter2=None, ext=\"fits\",\n \n \n def euclid_filename(processing_function, data_product_type, extension,\n-                    instance_id=\"\", release=\"00.00\"):\n+                    instance_id=\"\", release=None):\n     \"\"\"Returns a file name that follows the Euclid naming conventions.\n \n     Parameters\n@@ -315,7 +315,7 @@ def euclid_filename(processing_function, data_product_type, extension,\n     instance_id: str, optional\n         The product instance ID. Default is an empty string.\n     release: str, optional\n-        The product release number. Default is 00.00\n+        The product release number. Default is None\n \n     Returns\n     -------\n@@ -327,5 +327,5 @@ def euclid_filename(processing_function, data_product_type, extension,\n         processing_function=processing_function.upper(),\n         type_name=data_product_type.upper(),\n         instance_id=instance_id.upper(),\n-        release=release.upper(),\n+        release=release,\n         extension=extension.lower())\n",
                            "Changes default for release parameter",
                            "Javier Gracia Carpio",
                            "2023-06-25T14:17:48.000+00:00",
                            "6a7a1d5c12bccd6b4925d58f85bac91f7a9b7df9"
                        ]
                    ],
                    "MER_DataModelUtils/python/MER_DataModelUtils/MerDmUtils.py": [
                        [
                            "@@ -2219,7 +2219,7 @@ def __set_morphology_catalog(self, file_name):\n             mer_dict.merFinalMorphologyCatalogFitsFile, file_name,\n             \"mer.finalMorphologyCatalog\", \"0.1\")\n         self.Data.CatalogDescription.append(dm_utils.create_catalog_description(\n-            \"Mer-Morphology-Catalog\",\n+            \"Mer-Final-Morphology-Catalog\",\n             \"Data.MorphologyCatalogStorage.DataContainer.FileName\"))\n     else:\n         self.Data.MorphologyCatalogStorage.DataContainer.FileName = file_name\n@@ -2295,9 +2295,9 @@ def __set_deep_field_photometry_catalog(self, file_name):\n         self.Data.DeepFieldPhotometryCatalogStorage = dm_utils.create_fits_storage(\n             mer_dict.merDeepFieldPhotometryCatalogFitsFile, file_name,\n             \"mer.deepFieldPhotometryCatalog\", \"0.2\")\n-        # self.Data.CatalogDescription.append(dm_utils.create_catalog_description(\n-        #    \"Mer-Deep-Field-Photometry-Catalog\",\n-        #    \"Data.DeepFieldPhotometryCatalogStorage.DataContainer.FileName\"))\n+        self.Data.CatalogDescription.append(dm_utils.create_catalog_description(\n+           \"Mer-Deep-Field-Photometry-Catalog\",\n+           \"Data.DeepFieldPhotometryCatalogStorage.DataContainer.FileName\"))\n     else:\n         self.Data.DeepFieldPhotometryCatalogStorage.DataContainer.FileName = file_name\n \n",
                            "Uses better catalog ids",
                            "Javier Gracia Carpio",
                            "2023-06-28T12:21:27.000+00:00",
                            "1352dd4d34af8a5c2cb5353bd38c49dd0ec5e574"
                        ],
                        [
                            "@@ -1274,6 +1274,9 @@ def __add_mer_extra_functionality(dp_binding_class):\n     if hasattr(data_element, \"BackgroundStorage\"):\n         dp_binding_class.set_background_map = __set_background_map\n         dp_binding_class.get_background_map = __get_background_map\n+    if hasattr(data_element, \"BrightStarMasksStorage\"):\n+        dp_binding_class.set_bright_star_masks = __set_bright_star_masks\n+        dp_binding_class.get_bright_star_masks = __get_bright_star_masks\n     if hasattr(data_element, \"ConvolutionKernelStorage\"):\n         dp_binding_class.set_convolution_kernel = __set_convolution_kernel\n         dp_binding_class.get_convolution_kernel = __get_convolution_kernel\n@@ -2133,6 +2136,38 @@ def __get_background_map(self):\n     return self.Data.BackgroundStorage.DataContainer.FileName\n \n \n+def __set_bright_star_masks(self, file_name):\n+    \"\"\"Sets the bright star masks file name.\n+\n+    Parameters\n+    ----------\n+    file_name: str\n+        The file name.\n+\n+    \"\"\"\n+    if self.Data.BrightStarMasksStorage is None:\n+        masks_container = dm_utils.create_data_container(file_name)\n+        self.Data.BrightStarMasksStorage = mer_dict.merBrightStarMasksFile()\n+        self.Data.BrightStarMasksStorage.DataContainer = masks_container\n+    else:\n+        self.Data.BrightStarMasksStorage.DataContainer.FileName = file_name\n+\n+\n+def __get_bright_star_masks(self):\n+    \"\"\"Returns the bright star masks file name.\n+\n+    Returns\n+    -------\n+    str\n+        The bright star masks file name.\n+\n+    \"\"\"\n+    if self.Data.BrightStarMasksStorage is None:\n+        return None\n+\n+    return self.Data.BrightStarMasksStorage.DataContainer.FileName\n+\n+\n def __set_convolution_kernel(self, file_name):\n     \"\"\"Sets the convolution kernel file name.\n \n@@ -2260,7 +2295,7 @@ def __set_deep_field_photometry_catalog(self, file_name):\n         self.Data.DeepFieldPhotometryCatalogStorage = dm_utils.create_fits_storage(\n             mer_dict.merDeepFieldPhotometryCatalogFitsFile, file_name,\n             \"mer.deepFieldPhotometryCatalog\", \"0.2\")\n-        #self.Data.CatalogDescription.append(dm_utils.create_catalog_description(\n+        # self.Data.CatalogDescription.append(dm_utils.create_catalog_description(\n         #    \"Mer-Deep-Field-Photometry-Catalog\",\n         #    \"Data.DeepFieldPhotometryCatalogStorage.DataContainer.FileName\"))\n     else:\n",
                            "Adds a method for the bright star masks container",
                            "Javier Gracia Carpio",
                            "2023-06-28T12:02:51.000+00:00",
                            "e9b2b5137980992a5d651112e1cc94a05beccd42"
                        ],
                        [
                            "@@ -611,7 +611,7 @@ def create_true_universe_galaxy_catalog(filter_names):\n     # Add the DataStorage\n     dp.Data.DataStorage = dm_utils.create_fits_storage(\n         mer_dict.merTrueUniverseGalaxyCatalogFitsFile, \"catalog.fits\",\n-        \"sim.galaxyCatalog\", \"0.4\")\n+        \"sim.galaxyCatalog\", \"0.5\")\n \n     return dp\n \n",
                            "Missing bits for the DM9.2 update",
                            "Javier Gracia Carpio",
                            "2023-06-22T12:05:44.000+00:00",
                            "362d869524c7d6bdcbb847627ea85b3746372c58"
                        ]
                    ],
                    "MER_DataModelUtils/tests/python/MerDmUtils_test.py": [
                        [
                            "@@ -652,6 +652,20 @@ class TestMerDmUtils(object):\n         # Check that we recover the given file name\n         assert bks_mosaic.get_background_map() == file_name\n \n+    def test_mosaic_bright_star_masks_methods(self):\n+        # Create the mosaic\n+        mosaic = get_mer_product(\"mosaic\")\n+\n+        # Check that by default there is no bright star masks\n+        assert mosaic.get_bright_star_masks() is None\n+\n+        # Set the bright star masks file name\n+        file_name = \"myBrightStarMasks.json\"\n+        mosaic.set_bright_star_masks(file_name)\n+\n+        # Check that we recover the given file name\n+        assert mosaic.get_bright_star_masks() == file_name\n+\n     def test_segmentation_map_convolution_kernel_methods(self):\n         # Create the segmentation map\n         segmentation_map = get_mer_product(\"segmentation_map\")\n",
                            "Adds a method for the bright star masks container",
                            "Javier Gracia Carpio",
                            "2023-06-28T12:02:51.000+00:00",
                            "e9b2b5137980992a5d651112e1cc94a05beccd42"
                        ]
                    ],
                    ".jenkinsFile": [
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\n-@Library('integration-library@release-9') _\n-pipelineElements(artifactId:\"MER_DataModelUtils\", component:'eden.3.0')\n+@Library(value='integration-library@release-10') _\n+pipelineElements(name:\"MER_DataModelUtils\", component:'eden.3.1')\n",
                            "Migrate to DM9.2 and EDEN 3.1",
                            "Javier Gracia Carpio",
                            "2023-06-22T09:21:20.000+00:00",
                            "9ed60eaa2caa15ec380a66e8d70a644e2bda58c4"
                        ]
                    ],
                    "Makefile": [
                        [
                            "@@ -44,169 +44,19 @@\n #\n ################################################################################\n \n-# settings\n-CMAKE := cmake\n-CTEST := ctest\n-NINJA := $(shell which ninja-build 2> /dev/null)\n-ifeq ($(NINJA),)\n-  NINJA := $(shell which ninja 2> /dev/null)\n-endif\n-\n-# Looking for the Custom make library\n-\n-CUSTOM_MAKE_LIB := Custom.mk\n-\n-ifneq ($(wildcard $(CURDIR)/make/$(CUSTOM_MAKE_LIB)),)\n-  CUSTOM_MAKE_LIB_FILE := $(CURDIR)/make/$(CUSTOM_MAKE_LIB)\n-else\n-  ifneq ($(CMAKE_PREFIX_PATH),)\n-    PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    CUSTOM_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(CUSTOM_MAKE_LIB) $(dir)/../make/$(CUSTOM_MAKE_LIB)))\n-  endif\n-  CUSTOM_MAKE_LIB_LIST += /usr/share/Elements/make/$(CUSTOM_MAKE_LIB)\n-  CUSTOM_MAKE_LIB_FILE := $(firstword $(CUSTOM_MAKE_LIB_LIST))\n-endif\n-\n-# Looking for the ToolChain\n-\n-TOOLCHAIN_NAME := ElementsToolChain.cmake\n+ELEMENTS_MAKE_LIB := Elements.mk\n \n-ifneq ($(wildcard $(CURDIR)/cmake/$(TOOLCHAIN_NAME)),)\n-  TOOLCHAIN_FILE := $(CURDIR)/cmake/$(TOOLCHAIN_NAME)\n+ifneq ($(wildcard $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)),)\n+  ELEMENTS_MAKE_LIB_FILE := $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)\n else\n   ifneq ($(CMAKE_PREFIX_PATH),)\n     PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    TOOLCHAIN_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/lib*/cmake/ElementsProject/$(TOOLCHAIN_NAME) $(dir)/$(TOOLCHAIN_NAME)))\n-    TOOLCHAIN_FILE := $(firstword $(TOOLCHAIN_LIST))\n+    ELEMENTS_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(ELEMENTS_MAKE_LIB) $(dir)/../make/$(ELEMENTS_MAKE_LIB)))\n   endif\n+  ELEMENTS_MAKE_LIB_LIST += /usr/share/Elements/make/$(ELEMENTS_MAKE_LIB)\n+  ELEMENTS_MAKE_LIB_FILE := $(firstword $(ELEMENTS_MAKE_LIB_LIST))\n endif\n \n-override ALL_CMAKEFLAGS := -Wno-dev --no-warn-unused-cli\n-\n-ifneq ($(TOOLCHAIN_FILE),)\n-  # A toolchain has been found. Lets use it.\n-  override ALL_CMAKEFLAGS += -DCMAKE_TOOLCHAIN_FILE=$(TOOLCHAIN_FILE)\n-endif\n-\n-\n-BUILD_PREFIX_NAME := build\n-\n-override ALL_CMAKEFLAGS += -DUSE_LOCAL_INSTALLAREA=ON -DBUILD_PREFIX_NAME:STRING=$(BUILD_PREFIX_NAME)\n-override ALL_CMAKEFLAGS += -DUSE_VERSIONED_LIBRARIES=OFF\n-\n-ifndef BINARY_TAG\n-  ifdef CMAKECONFIG\n-    BINARY_TAG := ${CMAKECONFIG}\n-  else\n-    ifdef CMTCONFIG\n-      BINARY_TAG := ${CMTCONFIG}\n-    endif\n-  endif\n-endif\n-\n-ifdef BINARY_TAG\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME).$(BINARY_TAG)\n-else\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME)\n-endif\n-BUILDDIR := $(CURDIR)/$(BUILD_SUBDIR)\n-\n-# build tool\n-\n-ifneq ($(USE_NINJA),)\n-  # enable Ninja\n-  override ALL_CMAKEFLAGS += -GNinja\n-  BUILD_CONF_FILE := build.ninja\n-  BUILDFLAGS := $(NINJAFLAGS)\n-  ifneq ($(VERBOSE),)\n-    BUILDFLAGS := -v $(BUILDFLAGS)\n-  endif\n-else\n-  BUILD_CONF_FILE := Makefile\n-endif\n-BUILD_CMD := $(CMAKE) --build $(BUILD_SUBDIR) --target\n-\n-\n-# Use environment variable for extra flags\n-\n-# Replace the \":\" from eclipse variable list to spaces  \n-ifneq ($(EXPAND_FLAGS),)\n-  CMAKEFLAGS := $(subst :-, -,$(CMAKEFLAGS))\n-endif\n-\n-ifneq ($(CMAKEFLAGS),)\n-  override ALL_CMAKEFLAGS += $(CMAKEFLAGS)\n-endif\n-\n-# default target\n-all:\n-\n-# deep clean\n-purge:\n-\t$(RM) -r $(BUILDDIR) $(CURDIR)/InstallArea/$(BINARY_TAG)\n-\tfind $(CURDIR) \"(\" -name \"InstallArea\" -prune -o -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# Remove all the possible directories and the whole InstallArea as well\n-mrproper:\n-\t$(RM) -r $(CURDIR)/build $(CURDIR)/build.* $(CURDIR)/InstallArea\n-\tfind $(CURDIR) \"(\" -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# delegate any target to the build directory (except 'purge')\n-ifneq ($(MAKECMDGOALS),purge)\n-ifneq ($(MAKECMDGOALS),mrproper)\n-%: $(BUILDDIR)/$(BUILD_CONF_FILE) FORCE\n-\t+$(BUILD_CMD) $* -- $(BUILDFLAGS)\n-endif\n-endif\n-\n-# aliases\n-.PHONY: configure tests FORCE\n-ifneq ($(wildcard $(BUILDDIR)/$(BUILD_CONF_FILE)),)\n-configure: rebuild_cache\n-else\n-configure: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-endif\n-\t@ # do not delegate further\n-\n-\n-# This wrapping around the test target is used to ensure the generation of\n-# the XML output from ctest.\n-test: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-\n-# This target ensures that the \"all\" target is called before\n-# running the tests (unlike the \"test\" default target of CMake)\n-tests: all\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-ifeq ($(VERBOSE),)\n-# less verbose install\n-# (emulate the default CMake install target)\n-install: all\n-\tcd $(BUILDDIR) && $(CMAKE) -P cmake_install.cmake | grep -v \"^-- Up-to-date:\"\n-endif\n-\n-# import the library to look for a custom Makefile\n--include $(CUSTOM_MAKE_LIB_FILE)\n-\n-# ensure that the target are always passed to the CMake Makefile\n-FORCE: ;\n-\n-# Makefiles are used as implicit targets in make, but we should not consider\n-# them for delegation.\n-$(MAKEFILE_LIST): ;\n-\n-\n-# trigger CMake configuration\n-$(BUILDDIR)/$(BUILD_CONF_FILE): | $(BUILDDIR)\n-\tcd $(BUILDDIR) && $(CMAKE) $(ALL_CMAKEFLAGS) $(CURDIR)\n+$(info Using the $(ELEMENTS_MAKE_LIB_FILE) make library)\n+include $(ELEMENTS_MAKE_LIB_FILE)\n \n-$(BUILDDIR):\n-\tmkdir -p $(BUILDDIR)\n",
                            "Migrate to DM9.2 and EDEN 3.1",
                            "Javier Gracia Carpio",
                            "2023-06-22T09:21:20.000+00:00",
                            "9ed60eaa2caa15ec380a66e8d70a644e2bda58c4"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "9.1.0",
                        "created_at": "2023-03-06T14:17:55.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.0",
                        "created_at": "2023-07-03T11:49:08.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.1",
                        "created_at": "2023-08-14T11:52:49.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    }
                ]
            },
            "PF-MER/MER_Classification": {
                "start date": "2023-06-09 09:00",
                "end date": "2023-08-23 15:00",
                "start tag": "> 9.1.0",
                "end tag": "> 10.1.1",
                "count_files_modified": "3",
                "modifications_by_file": {
                    "CMakeLists.txt": [
                        [
                            "@@ -13,5 +13,5 @@ find_package(ElementsProject)\n #===============================================================================\n \n elements_project(MER_Classification 10.2 USE Elements 6.2.1\n-                                            EL_Utils 1.4.2\n+                                            EL_Utils 1.5.1\n                                             MER_DataModelUtils 10.2)\n",
                            "Use new EL_Utils",
                            "Javier Gracia Carpio",
                            "2023-08-14T15:27:00.000+00:00",
                            "af8c97a06b732f4adfccfb55081b600e585845eb"
                        ],
                        [
                            "@@ -13,5 +13,5 @@ find_package(ElementsProject)\n #===============================================================================\n \n elements_project(MER_Classification 10.2 USE Elements 6.2.1\n-                                            EL_Utils 1.4.1\n+                                            EL_Utils 1.4.2\n                                             MER_DataModelUtils 10.2)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-08-11T12:56:01.000+00:00",
                            "4ef5f1a98388d0486f8cb432ba08e06a3458c70d"
                        ],
                        [
                            "@@ -12,6 +12,6 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.8)\n #===============================================================================\n \n-elements_project(MER_Classification 10.1 USE Elements 6.2.1\n+elements_project(MER_Classification 10.2 USE Elements 6.2.1\n                                             EL_Utils 1.4.1\n-                                            MER_DataModelUtils 10.1)\n+                                            MER_DataModelUtils 10.2)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-07-03T12:19:18.000+00:00",
                            "ca3959d894d04cee3c318b6cf309ba3888c4a48f"
                        ],
                        [
                            "@@ -12,6 +12,6 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.8)\n #===============================================================================\n \n-elements_project(MER_Classification 10.0 USE Elements 6.2.1\n+elements_project(MER_Classification 10.1 USE Elements 6.2.1\n                                             EL_Utils 1.4.1\n                                             MER_DataModelUtils 10.1)\n",
                            "Increase project version to 10.1",
                            "Elie Soubrie",
                            "2023-06-22T14:12:42.000+00:00",
                            "2060c8e7a6ea2472c9cf9090d2fbade4eb4d98a6"
                        ],
                        [
                            "@@ -12,6 +12,6 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.8)\n #===============================================================================\n \n-elements_project(MER_Classification 10.0 USE Elements 6.1.1\n-                                            EL_Utils 1.3.1\n-                                            MER_DataModelUtils 10.0)\n+elements_project(MER_Classification 10.0 USE Elements 6.2.1\n+                                            EL_Utils 1.4.1\n+                                            MER_DataModelUtils 10.1)\n",
                            "Migrate to DM9.2 and EDEN 3.1",
                            "Elie Soubrie",
                            "2023-06-22T13:57:18.000+00:00",
                            "a56460723c851bc7b7daaddc733f1217f8576993"
                        ]
                    ],
                    ".jenkinsFile": [
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\n-@Library('integration-library@release-9') _\n-pipelineElements(artifactId:\"MER_Classification\", component:'eden.3.0')\n+@Library(value='integration-library@release-10') _\n+pipelineElements(name:\"MER_Classification\", component:'eden.3.1')\n",
                            "Migrate to DM9.2 and EDEN 3.1",
                            "Elie Soubrie",
                            "2023-06-22T13:57:18.000+00:00",
                            "a56460723c851bc7b7daaddc733f1217f8576993"
                        ]
                    ],
                    "Makefile": [
                        [
                            "@@ -44,169 +44,19 @@\n #\n ################################################################################\n \n-# settings\n-CMAKE := cmake\n-CTEST := ctest\n-NINJA := $(shell which ninja-build 2> /dev/null)\n-ifeq ($(NINJA),)\n-  NINJA := $(shell which ninja 2> /dev/null)\n-endif\n-\n-# Looking for the Custom make library\n-\n-CUSTOM_MAKE_LIB := Custom.mk\n-\n-ifneq ($(wildcard $(CURDIR)/make/$(CUSTOM_MAKE_LIB)),)\n-  CUSTOM_MAKE_LIB_FILE := $(CURDIR)/make/$(CUSTOM_MAKE_LIB)\n-else\n-  ifneq ($(CMAKE_PREFIX_PATH),)\n-    PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    CUSTOM_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(CUSTOM_MAKE_LIB) $(dir)/../make/$(CUSTOM_MAKE_LIB)))\n-  endif\n-  CUSTOM_MAKE_LIB_LIST += /usr/share/Elements/make/$(CUSTOM_MAKE_LIB)\n-  CUSTOM_MAKE_LIB_FILE := $(firstword $(CUSTOM_MAKE_LIB_LIST))\n-endif\n-\n-# Looking for the ToolChain\n-\n-TOOLCHAIN_NAME := ElementsToolChain.cmake\n+ELEMENTS_MAKE_LIB := Elements.mk\n \n-ifneq ($(wildcard $(CURDIR)/cmake/$(TOOLCHAIN_NAME)),)\n-  TOOLCHAIN_FILE := $(CURDIR)/cmake/$(TOOLCHAIN_NAME)\n+ifneq ($(wildcard $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)),)\n+  ELEMENTS_MAKE_LIB_FILE := $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)\n else\n   ifneq ($(CMAKE_PREFIX_PATH),)\n     PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    TOOLCHAIN_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/lib*/cmake/ElementsProject/$(TOOLCHAIN_NAME) $(dir)/$(TOOLCHAIN_NAME)))\n-    TOOLCHAIN_FILE := $(firstword $(TOOLCHAIN_LIST))\n+    ELEMENTS_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(ELEMENTS_MAKE_LIB) $(dir)/../make/$(ELEMENTS_MAKE_LIB)))\n   endif\n+  ELEMENTS_MAKE_LIB_LIST += /usr/share/Elements/make/$(ELEMENTS_MAKE_LIB)\n+  ELEMENTS_MAKE_LIB_FILE := $(firstword $(ELEMENTS_MAKE_LIB_LIST))\n endif\n \n-override ALL_CMAKEFLAGS := -Wno-dev --no-warn-unused-cli\n-\n-ifneq ($(TOOLCHAIN_FILE),)\n-  # A toolchain has been found. Lets use it.\n-  override ALL_CMAKEFLAGS += -DCMAKE_TOOLCHAIN_FILE=$(TOOLCHAIN_FILE)\n-endif\n-\n-\n-BUILD_PREFIX_NAME := build\n-\n-override ALL_CMAKEFLAGS += -DUSE_LOCAL_INSTALLAREA=ON -DBUILD_PREFIX_NAME:STRING=$(BUILD_PREFIX_NAME)\n-override ALL_CMAKEFLAGS += -DUSE_VERSIONED_LIBRARIES=OFF\n-\n-ifndef BINARY_TAG\n-  ifdef CMAKECONFIG\n-    BINARY_TAG := ${CMAKECONFIG}\n-  else\n-    ifdef CMTCONFIG\n-      BINARY_TAG := ${CMTCONFIG}\n-    endif\n-  endif\n-endif\n-\n-ifdef BINARY_TAG\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME).$(BINARY_TAG)\n-else\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME)\n-endif\n-BUILDDIR := $(CURDIR)/$(BUILD_SUBDIR)\n-\n-# build tool\n-\n-ifneq ($(USE_NINJA),)\n-  # enable Ninja\n-  override ALL_CMAKEFLAGS += -GNinja\n-  BUILD_CONF_FILE := build.ninja\n-  BUILDFLAGS := $(NINJAFLAGS)\n-  ifneq ($(VERBOSE),)\n-    BUILDFLAGS := -v $(BUILDFLAGS)\n-  endif\n-else\n-  BUILD_CONF_FILE := Makefile\n-endif\n-BUILD_CMD := $(CMAKE) --build $(BUILD_SUBDIR) --target\n-\n-\n-# Use environment variable for extra flags\n-\n-# Replace the \":\" from eclipse variable list to spaces  \n-ifneq ($(EXPAND_FLAGS),)\n-  CMAKEFLAGS := $(subst :-, -,$(CMAKEFLAGS))\n-endif\n-\n-ifneq ($(CMAKEFLAGS),)\n-  override ALL_CMAKEFLAGS += $(CMAKEFLAGS)\n-endif\n-\n-# default target\n-all:\n-\n-# deep clean\n-purge:\n-\t$(RM) -r $(BUILDDIR) $(CURDIR)/InstallArea/$(BINARY_TAG)\n-\tfind $(CURDIR) \"(\" -name \"InstallArea\" -prune -o -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# Remove all the possible directories and the whole InstallArea as well\n-mrproper:\n-\t$(RM) -r $(CURDIR)/build $(CURDIR)/build.* $(CURDIR)/InstallArea\n-\tfind $(CURDIR) \"(\" -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# delegate any target to the build directory (except 'purge')\n-ifneq ($(MAKECMDGOALS),purge)\n-ifneq ($(MAKECMDGOALS),mrproper)\n-%: $(BUILDDIR)/$(BUILD_CONF_FILE) FORCE\n-\t+$(BUILD_CMD) $* -- $(BUILDFLAGS)\n-endif\n-endif\n-\n-# aliases\n-.PHONY: configure tests FORCE\n-ifneq ($(wildcard $(BUILDDIR)/$(BUILD_CONF_FILE)),)\n-configure: rebuild_cache\n-else\n-configure: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-endif\n-\t@ # do not delegate further\n-\n-\n-# This wrapping around the test target is used to ensure the generation of\n-# the XML output from ctest.\n-test: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-\n-# This target ensures that the \"all\" target is called before\n-# running the tests (unlike the \"test\" default target of CMake)\n-tests: all\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-ifeq ($(VERBOSE),)\n-# less verbose install\n-# (emulate the default CMake install target)\n-install: all\n-\tcd $(BUILDDIR) && $(CMAKE) -P cmake_install.cmake | grep -v \"^-- Up-to-date:\"\n-endif\n-\n-# import the library to look for a custom Makefile\n--include $(CUSTOM_MAKE_LIB_FILE)\n-\n-# ensure that the target are always passed to the CMake Makefile\n-FORCE: ;\n-\n-# Makefiles are used as implicit targets in make, but we should not consider\n-# them for delegation.\n-$(MAKEFILE_LIST): ;\n-\n-\n-# trigger CMake configuration\n-$(BUILDDIR)/$(BUILD_CONF_FILE): | $(BUILDDIR)\n-\tcd $(BUILDDIR) && $(CMAKE) $(ALL_CMAKEFLAGS) $(CURDIR)\n+$(info Using the $(ELEMENTS_MAKE_LIB_FILE) make library)\n+include $(ELEMENTS_MAKE_LIB_FILE)\n \n-$(BUILDDIR):\n-\tmkdir -p $(BUILDDIR)\n",
                            "Migrate to DM9.2 and EDEN 3.1",
                            "Elie Soubrie",
                            "2023-06-22T13:57:18.000+00:00",
                            "a56460723c851bc7b7daaddc733f1217f8576993"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "9.1.0",
                        "created_at": "2023-03-06T15:04:57.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.0",
                        "created_at": "2023-07-03T12:18:39.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.1",
                        "created_at": "2023-08-14T12:04:34.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    }
                ]
            },
            "PF-MER/MER_PSFHomogenization": {
                "start date": "2023-06-09 09:00",
                "end date": "2023-08-23 15:00",
                "start tag": "> 9.1.0",
                "end tag": "> 10.1.1",
                "count_files_modified": "3",
                "modifications_by_file": {
                    "CMakeLists.txt": [
                        [
                            "@@ -12,6 +12,6 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.8)\n #===============================================================================\n \n-elements_project(MER_PSFHomogenization 10.1 USE Elements 6.2.1\n-                                               MER_PsfMosaic 10.1\n-                                               MER_DataModelUtils 10.1)\n+elements_project(MER_PSFHomogenization 10.2 USE Elements 6.2.1\n+                                               MER_PsfMosaic 10.2\n+                                               MER_DataModelUtils 10.2)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-07-03T13:37:11.000+00:00",
                            "02347bc020d54e9813ba5baacccdd8b31ff0d581"
                        ],
                        [
                            "@@ -12,6 +12,6 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.8)\n #===============================================================================\n \n-elements_project(MER_PSFHomogenization 10.0 USE Elements 6.1.1\n-                                               MER_PsfMosaic 10.0\n-                                               MER_DataModelUtils 10.0)\n+elements_project(MER_PSFHomogenization 10.1 USE Elements 6.2.1\n+                                               MER_PsfMosaic 10.1\n+                                               MER_DataModelUtils 10.1)\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:30:30.000+00:00",
                            "e6a01d7e75b428a96bbe9250a61389ac94566c99"
                        ]
                    ],
                    ".jenkinsFile": [
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\n-@Library('integration-library@release-9') _\n-pipelineElements(artifactId:\"MER_PSFHomogenization\", component:'eden.3.0', repository:'eden.3.0')\n+@Library(value='integration-library@release-10') _\n+pipelineElements(name:\"MER_PSFHomogenization\", component:'eden.3.1')\n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:30:30.000+00:00",
                            "e6a01d7e75b428a96bbe9250a61389ac94566c99"
                        ]
                    ],
                    "Makefile": [
                        [
                            "@@ -44,170 +44,19 @@\n #\n ################################################################################\n \n-# settings\n-CMAKE := cmake\n-CTEST := ctest\n-NINJA := $(shell which ninja-build 2> /dev/null)\n-ifeq ($(NINJA),)\n-  NINJA := $(shell which ninja 2> /dev/null)\n-endif\n-\n-# Looking for the Custom make library\n-\n-CUSTOM_MAKE_LIB := Custom.mk\n-\n-ifneq ($(wildcard $(CURDIR)/make/$(CUSTOM_MAKE_LIB)),)\n-  CUSTOM_MAKE_LIB_FILE := $(CURDIR)/make/$(CUSTOM_MAKE_LIB)\n-else\n-  ifneq ($(CMAKE_PREFIX_PATH),)\n-    PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    CUSTOM_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(CUSTOM_MAKE_LIB) $(dir)/../make/$(CUSTOM_MAKE_LIB)))\n-  endif\n-  CUSTOM_MAKE_LIB_LIST += /usr/share/Elements/make/$(CUSTOM_MAKE_LIB)\n-  CUSTOM_MAKE_LIB_FILE := $(firstword $(CUSTOM_MAKE_LIB_LIST))\n-endif\n-\n-# Looking for the ToolChain\n-\n-TOOLCHAIN_NAME := ElementsToolChain.cmake\n+ELEMENTS_MAKE_LIB := Elements.mk\n \n-ifneq ($(wildcard $(CURDIR)/cmake/$(TOOLCHAIN_NAME)),)\n-  TOOLCHAIN_FILE := $(CURDIR)/cmake/$(TOOLCHAIN_NAME)\n+ifneq ($(wildcard $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)),)\n+  ELEMENTS_MAKE_LIB_FILE := $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)\n else\n   ifneq ($(CMAKE_PREFIX_PATH),)\n     PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    TOOLCHAIN_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/lib*/cmake/ElementsProject/$(TOOLCHAIN_NAME) $(dir)/$(TOOLCHAIN_NAME)))\n-    TOOLCHAIN_FILE := $(firstword $(TOOLCHAIN_LIST))\n-  endif\n-endif\n-\n-override ALL_CMAKEFLAGS := -Wno-dev --no-warn-unused-cli\n-\n-ifneq ($(TOOLCHAIN_FILE),)\n-  # A toolchain has been found. Lets use it.\n-  override ALL_CMAKEFLAGS += -DCMAKE_TOOLCHAIN_FILE=$(TOOLCHAIN_FILE)\n-endif\n-\n-\n-BUILD_PREFIX_NAME := build\n-\n-override ALL_CMAKEFLAGS += -DUSE_LOCAL_INSTALLAREA=ON -DBUILD_PREFIX_NAME:STRING=$(BUILD_PREFIX_NAME)\n-override ALL_CMAKEFLAGS += -DUSE_VERSIONED_LIBRARIES=OFF\n-\n-ifndef BINARY_TAG\n-  ifdef CMAKECONFIG\n-    BINARY_TAG := ${CMAKECONFIG}\n-  else\n-    ifdef CMTCONFIG\n-      BINARY_TAG := ${CMTCONFIG}\n-    endif\n-  endif\n-endif\n-\n-ifdef BINARY_TAG\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME).$(BINARY_TAG)\n-else\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME)\n-endif\n-BUILDDIR := $(CURDIR)/$(BUILD_SUBDIR)\n-\n-# build tool\n-\n-ifneq ($(USE_NINJA),)\n-  # enable Ninja\n-  override ALL_CMAKEFLAGS += -GNinja\n-  BUILD_CONF_FILE := build.ninja\n-  BUILDFLAGS := $(NINJAFLAGS)\n-  ifneq ($(VERBOSE),)\n-    BUILDFLAGS := -v $(BUILDFLAGS)\n+    ELEMENTS_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(ELEMENTS_MAKE_LIB) $(dir)/../make/$(ELEMENTS_MAKE_LIB)))\n   endif\n-else\n-  BUILD_CONF_FILE := Makefile\n-endif\n-BUILD_CMD := $(CMAKE) --build $(BUILD_SUBDIR) --target\n-\n-\n-# Use environment variable for extra flags\n-\n-# Replace the \":\" from eclipse variable list to spaces  \n-ifneq ($(EXPAND_FLAGS),)\n-  CMAKEFLAGS := $(subst :-, -,$(CMAKEFLAGS))\n-endif\n-\n-ifneq ($(CMAKEFLAGS),)\n-  override ALL_CMAKEFLAGS += $(CMAKEFLAGS)\n+  ELEMENTS_MAKE_LIB_LIST += /usr/share/Elements/make/$(ELEMENTS_MAKE_LIB)\n+  ELEMENTS_MAKE_LIB_FILE := $(firstword $(ELEMENTS_MAKE_LIB_LIST))\n endif\n \n-# default target\n-all:\n-\n-# deep clean\n-purge:\n-\t$(RM) -r $(BUILDDIR) $(CURDIR)/InstallArea/$(BINARY_TAG)\n-\tfind $(CURDIR) \"(\" -name \"InstallArea\" -prune -o -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# Remove all the possible directories and the whole InstallArea as well\n-mrproper:\n-\t$(RM) -r $(CURDIR)/build $(CURDIR)/build.* $(CURDIR)/InstallArea\n-\tfind $(CURDIR) \"(\" -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# delegate any target to the build directory (except 'purge')\n-ifneq ($(MAKECMDGOALS),purge)\n-ifneq ($(MAKECMDGOALS),mrproper)\n-%: $(BUILDDIR)/$(BUILD_CONF_FILE) FORCE\n-\t+$(BUILD_CMD) $* -- $(BUILDFLAGS)\n-endif\n-endif\n-\n-# aliases\n-.PHONY: configure tests FORCE\n-ifneq ($(wildcard $(BUILDDIR)/$(BUILD_CONF_FILE)),)\n-configure: rebuild_cache\n-else\n-configure: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-endif\n-\t@ # do not delegate further\n-\n-\n-# This wrapping around the test target is used to ensure the generation of\n-# the XML output from ctest.\n-test: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-\n-# This target ensures that the \"all\" target is called before\n-# running the tests (unlike the \"test\" default target of CMake)\n-tests: all\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-ifeq ($(VERBOSE),)\n-# less verbose install\n-# (emulate the default CMake install target)\n-install: all\n-\tcd $(BUILDDIR) && $(CMAKE) -P cmake_install.cmake | grep -v \"^-- Up-to-date:\"\n-endif\n-\n-# import the library to look for a custom Makefile\n--include $(CUSTOM_MAKE_LIB_FILE)\n-\n-# ensure that the target are always passed to the CMake Makefile\n-FORCE: ;\n-\n-# Makefiles are used as implicit targets in make, but we should not consider\n-# them for delegation.\n-$(MAKEFILE_LIST): ;\n-\n-\n-# trigger CMake configuration\n-$(BUILDDIR)/$(BUILD_CONF_FILE): | $(BUILDDIR)\n-\tcd $(BUILDDIR) && $(CMAKE) $(ALL_CMAKEFLAGS) $(CURDIR)\n-\n-$(BUILDDIR):\n-\tmkdir -p $(BUILDDIR)\n+$(info Using the $(ELEMENTS_MAKE_LIB_FILE) make library)\n+include $(ELEMENTS_MAKE_LIB_FILE)\n \n",
                            "Updates to latest DM and EDEN3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:30:30.000+00:00",
                            "e6a01d7e75b428a96bbe9250a61389ac94566c99"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "9.1.0",
                        "created_at": "2023-03-07T10:31:33.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.0",
                        "created_at": "2023-07-03T13:36:41.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.1",
                        "created_at": "2023-08-14T12:35:52.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    }
                ]
            },
            "PF-MER/MER_Background": {
                "start date": "2023-06-09 09:00",
                "end date": "2023-08-23 15:00",
                "start tag": "> 9.1.0",
                "end tag": "> 10.1.1",
                "count_files_modified": "6",
                "modifications_by_file": {
                    "CMakeLists.txt": [
                        [
                            "@@ -11,8 +11,8 @@ find_package(ElementsProject)\n # Declare project name and version\n #===============================================================================\n \n-elements_project(MER_Background 10.1 USE Elements 6.2.1\n-                                        MER_DataModelUtils 10.1\n-                                        EL_Background 10.1\n-                                        MER_DA 10.1\n-                                        MER_Mosaicing 10.1)\n+elements_project(MER_Background 10.2 USE Elements 6.2.1\n+                                        MER_DataModelUtils 10.2\n+                                        EL_Background 10.2\n+                                        MER_DA 10.2\n+                                        MER_Mosaicing 10.2)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-07-03T15:25:45.000+00:00",
                            "40f5c40dfe9cf4a84cbe1c4d0d717f0a7f99b426"
                        ],
                        [
                            "@@ -11,8 +11,8 @@ find_package(ElementsProject)\n # Declare project name and version\n #===============================================================================\n \n-elements_project(MER_Background 10.0 USE Elements 6.1.1\n-                                        MER_DataModelUtils 10.0\n-                                        EL_Background 10.0\n-                                        MER_DA 10.0\n-                                        MER_Mosaicing 10.0)\n+elements_project(MER_Background 10.1 USE Elements 6.2.1\n+                                        MER_DataModelUtils 10.1\n+                                        EL_Background 10.1\n+                                        MER_DA 10.1\n+                                        MER_Mosaicing 10.1)\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:38:58.000+00:00",
                            "f6558a0558faff4f34522425e3aa3b3b2d4b3c35"
                        ]
                    ],
                    "MER_Background/python/MER_Background/MER_BackgroundPrg.py": [
                        [
                            "@@ -118,7 +118,7 @@ def mainMethod(args):\n     rms_fits_file_name = mosaic.get_rms()\n     flag_fits_file_name = mosaic.get_flag()\n     filter_transmission_fits_file_name = mosaic.get_filter_transmission()\n-    star_masks_file_name = mosaic.get_extra_file(\"STAR-MASKS\")\n+    star_masks_file_name = mosaic.get_bright_star_masks()\n \n     # Define the background-subtracted mosaic file names\n     background_map_file_name = mer_filename(\n@@ -161,7 +161,7 @@ def mainMethod(args):\n         bks_mosaic.set_filter_transmission(filter_transmission_fits_file_name)\n     \n     if star_masks_file_name is not None:\n-        bks_mosaic.add_extra_file(\"STAR-MASKS\", star_masks_file_name)\n+        bks_mosaic.set_bright_star_masks(star_masks_file_name)\n     \n     # Set the zero point\n     bks_mosaic.set_zero_point(mosaic.get_zero_point())\n",
                            "Use new getter method",
                            "Javier Gracia Carpio",
                            "2023-06-28T12:13:46.000+00:00",
                            "71731e3b52bfe5a5e608e55d622b4b735615d00d"
                        ]
                    ],
                    ".pydevproject": [
                        [
                            "@@ -1,8 +1,11 @@\n <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n <?eclipse-pydev version=\"1.0\"?><pydev_project>\n+        \n     \n     <pydev_property name=\"org.python.pydev.PYTHON_PROJECT_INTERPRETER\">Default</pydev_property>\n+        \n     \n-    <pydev_property name=\"org.python.pydev.PYTHON_PROJECT_VERSION\">python 2.7</pydev_property>\n-    \n+    <pydev_property name=\"org.python.pydev.PYTHON_PROJECT_VERSION\">python interpreter</pydev_property>\n+        \n+\n </pydev_project>\n",
                            "Fixes import",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:45:24.000+00:00",
                            "3a445ea811db1f0712a0111d3de3593be29cd0df"
                        ]
                    ],
                    "MER_Background/tests/python/MER_BackgroundPrg_test.py": [
                        [
                            "@@ -24,7 +24,7 @@ Author: user\n \"\"\"\n \n \n-import py.test\n+import pytest\n import MER_Background.MER_BackgroundPrg\n \n class TestMER_BackgroundPrg(object):\n",
                            "Fixes import",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:45:24.000+00:00",
                            "3a445ea811db1f0712a0111d3de3593be29cd0df"
                        ]
                    ],
                    ".jenkinsFile": [
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\n-@Library('integration-library@release-9') _\n-pipelineElements(artifactId:\"MER_Background\", component:'eden.3.0')\n+@Library(value='integration-library@release-10') _\n+pipelineElements(name:\"MER_Background\", component:'eden.3.1')\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:38:58.000+00:00",
                            "f6558a0558faff4f34522425e3aa3b3b2d4b3c35"
                        ]
                    ],
                    "Makefile": [
                        [
                            "@@ -44,169 +44,19 @@\n #\n ################################################################################\n \n-# settings\n-CMAKE := cmake\n-CTEST := ctest\n-NINJA := $(shell which ninja-build 2> /dev/null)\n-ifeq ($(NINJA),)\n-  NINJA := $(shell which ninja 2> /dev/null)\n-endif\n-\n-# Looking for the Custom make library\n-\n-CUSTOM_MAKE_LIB := Custom.mk\n-\n-ifneq ($(wildcard $(CURDIR)/make/$(CUSTOM_MAKE_LIB)),)\n-  CUSTOM_MAKE_LIB_FILE := $(CURDIR)/make/$(CUSTOM_MAKE_LIB)\n-else\n-  ifneq ($(CMAKE_PREFIX_PATH),)\n-    PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    CUSTOM_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(CUSTOM_MAKE_LIB) $(dir)/../make/$(CUSTOM_MAKE_LIB)))\n-  endif\n-  CUSTOM_MAKE_LIB_LIST += /usr/share/Elements/make/$(CUSTOM_MAKE_LIB)\n-  CUSTOM_MAKE_LIB_FILE := $(firstword $(CUSTOM_MAKE_LIB_LIST))\n-endif\n-\n-# Looking for the ToolChain\n-\n-TOOLCHAIN_NAME := ElementsToolChain.cmake\n+ELEMENTS_MAKE_LIB := Elements.mk\n \n-ifneq ($(wildcard $(CURDIR)/cmake/$(TOOLCHAIN_NAME)),)\n-  TOOLCHAIN_FILE := $(CURDIR)/cmake/$(TOOLCHAIN_NAME)\n+ifneq ($(wildcard $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)),)\n+  ELEMENTS_MAKE_LIB_FILE := $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)\n else\n   ifneq ($(CMAKE_PREFIX_PATH),)\n     PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    TOOLCHAIN_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/lib*/cmake/ElementsProject/$(TOOLCHAIN_NAME) $(dir)/$(TOOLCHAIN_NAME)))\n-    TOOLCHAIN_FILE := $(firstword $(TOOLCHAIN_LIST))\n+    ELEMENTS_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(ELEMENTS_MAKE_LIB) $(dir)/../make/$(ELEMENTS_MAKE_LIB)))\n   endif\n+  ELEMENTS_MAKE_LIB_LIST += /usr/share/Elements/make/$(ELEMENTS_MAKE_LIB)\n+  ELEMENTS_MAKE_LIB_FILE := $(firstword $(ELEMENTS_MAKE_LIB_LIST))\n endif\n \n-override ALL_CMAKEFLAGS := -Wno-dev --no-warn-unused-cli\n-\n-ifneq ($(TOOLCHAIN_FILE),)\n-  # A toolchain has been found. Lets use it.\n-  override ALL_CMAKEFLAGS += -DCMAKE_TOOLCHAIN_FILE=$(TOOLCHAIN_FILE)\n-endif\n-\n-\n-BUILD_PREFIX_NAME := build\n-\n-override ALL_CMAKEFLAGS += -DUSE_LOCAL_INSTALLAREA=ON -DBUILD_PREFIX_NAME:STRING=$(BUILD_PREFIX_NAME)\n-override ALL_CMAKEFLAGS += -DUSE_VERSIONED_LIBRARIES=OFF\n-\n-ifndef BINARY_TAG\n-  ifdef CMAKECONFIG\n-    BINARY_TAG := ${CMAKECONFIG}\n-  else\n-    ifdef CMTCONFIG\n-      BINARY_TAG := ${CMTCONFIG}\n-    endif\n-  endif\n-endif\n-\n-ifdef BINARY_TAG\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME).$(BINARY_TAG)\n-else\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME)\n-endif\n-BUILDDIR := $(CURDIR)/$(BUILD_SUBDIR)\n-\n-# build tool\n-\n-ifneq ($(USE_NINJA),)\n-  # enable Ninja\n-  override ALL_CMAKEFLAGS += -GNinja\n-  BUILD_CONF_FILE := build.ninja\n-  BUILDFLAGS := $(NINJAFLAGS)\n-  ifneq ($(VERBOSE),)\n-    BUILDFLAGS := -v $(BUILDFLAGS)\n-  endif\n-else\n-  BUILD_CONF_FILE := Makefile\n-endif\n-BUILD_CMD := $(CMAKE) --build $(BUILD_SUBDIR) --target\n-\n-\n-# Use environment variable for extra flags\n-\n-# Replace the \":\" from eclipse variable list to spaces  \n-ifneq ($(EXPAND_FLAGS),)\n-  CMAKEFLAGS := $(subst :-, -,$(CMAKEFLAGS))\n-endif\n-\n-ifneq ($(CMAKEFLAGS),)\n-  override ALL_CMAKEFLAGS += $(CMAKEFLAGS)\n-endif\n-\n-# default target\n-all:\n-\n-# deep clean\n-purge:\n-\t$(RM) -r $(BUILDDIR) $(CURDIR)/InstallArea/$(BINARY_TAG)\n-\tfind $(CURDIR) \"(\" -name \"InstallArea\" -prune -o -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# Remove all the possible directories and the whole InstallArea as well\n-mrproper:\n-\t$(RM) -r $(CURDIR)/build $(CURDIR)/build.* $(CURDIR)/InstallArea\n-\tfind $(CURDIR) \"(\" -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# delegate any target to the build directory (except 'purge')\n-ifneq ($(MAKECMDGOALS),purge)\n-ifneq ($(MAKECMDGOALS),mrproper)\n-%: $(BUILDDIR)/$(BUILD_CONF_FILE) FORCE\n-\t+$(BUILD_CMD) $* -- $(BUILDFLAGS)\n-endif\n-endif\n-\n-# aliases\n-.PHONY: configure tests FORCE\n-ifneq ($(wildcard $(BUILDDIR)/$(BUILD_CONF_FILE)),)\n-configure: rebuild_cache\n-else\n-configure: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-endif\n-\t@ # do not delegate further\n-\n-\n-# This wrapping around the test target is used to ensure the generation of\n-# the XML output from ctest.\n-test: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-\n-# This target ensures that the \"all\" target is called before\n-# running the tests (unlike the \"test\" default target of CMake)\n-tests: all\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-ifeq ($(VERBOSE),)\n-# less verbose install\n-# (emulate the default CMake install target)\n-install: all\n-\tcd $(BUILDDIR) && $(CMAKE) -P cmake_install.cmake | grep -v \"^-- Up-to-date:\"\n-endif\n-\n-# import the library to look for a custom Makefile\n--include $(CUSTOM_MAKE_LIB_FILE)\n-\n-# ensure that the target are always passed to the CMake Makefile\n-FORCE: ;\n-\n-# Makefiles are used as implicit targets in make, but we should not consider\n-# them for delegation.\n-$(MAKEFILE_LIST): ;\n-\n-\n-# trigger CMake configuration\n-$(BUILDDIR)/$(BUILD_CONF_FILE): | $(BUILDDIR)\n-\tcd $(BUILDDIR) && $(CMAKE) $(ALL_CMAKEFLAGS) $(CURDIR)\n+$(info Using the $(ELEMENTS_MAKE_LIB_FILE) make library)\n+include $(ELEMENTS_MAKE_LIB_FILE)\n \n-$(BUILDDIR):\n-\tmkdir -p $(BUILDDIR)\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:38:58.000+00:00",
                            "f6558a0558faff4f34522425e3aa3b3b2d4b3c35"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "9.1.0",
                        "created_at": "2023-03-07T13:34:28.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.0",
                        "created_at": "2023-07-03T15:12:07.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.1",
                        "created_at": "2023-08-14T12:43:32.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    }
                ]
            },
            "PF-MER/MER_Photometry": {
                "start date": "2023-06-09 09:00",
                "end date": "2023-08-23 15:00",
                "start tag": "> 9.1.0",
                "end tag": "> 10.1.1",
                "count_files_modified": "20",
                "modifications_by_file": {
                    "CMakeLists.txt": [
                        [
                            "@@ -12,4 +12,4 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_Photometry 10.2 USE Elements 6.2.1 ST_DataModel 9.2.0 ST_DataModelTools 9.2.1 ST_FitsDataModel 9.2.0)\n+elements_project(MER_Photometry 10.2 USE Elements 6.2.1 ST_DataModel 9.2.0 ST_DataModelTools 9.2.2 ST_FitsDataModel 9.2.0)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-08-11T13:02:12.000+00:00",
                            "89920b812d64aed6e29da9a81eacdef0beac59d7"
                        ],
                        [
                            "@@ -12,4 +12,4 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_Photometry 10.1 USE Elements 6.2.1 ST_DataModel 9.2.0 ST_DataModelTools 9.2.1 ST_FitsDataModel 9.2.0)\n+elements_project(MER_Photometry 10.2 USE Elements 6.2.1 ST_DataModel 9.2.0 ST_DataModelTools 9.2.1 ST_FitsDataModel 9.2.0)\n",
                            "Bumped Version",
                            "Samuele Galeotta",
                            "2023-07-03T21:12:02.000+02:00",
                            "c673245a17812ff64ecaa7d88a8c63032f490d8e"
                        ],
                        [
                            "@@ -12,4 +12,4 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_Photometry 10.0 USE Elements 6.1.1 ST_DataModel 9.1.5 ST_DataModelTools 9.1.2 ST_FitsDataModel 9.1.3)\n+elements_project(MER_Photometry 10.1 USE Elements 6.2.1 ST_DataModel 9.2.0 ST_DataModelTools 9.2.1 ST_FitsDataModel 9.2.0)\n",
                            "DataModel update for launch + fixed data model unit tests",
                            "Samuele Galeotta",
                            "2023-06-23T16:08:42.000+02:00",
                            "ffcdf15aae04da9be6bbae90c122fcdec9d49a58"
                        ]
                    ],
                    ".gitignore": [
                        [
                            "@@ -6,6 +6,5 @@ InstallArea\n /.project\n /.pydevproject\n *pyc\n-TPhot/tests/data/create_cut_test.h5\n-TPhot/tests/data/create_mod_test.h5\n+MER_TPhot/tests/data/ocov.fits\n Testing/\n\\ No newline at end of file\n",
                            "Bugs in unit tests for fitter and stats catalog",
                            "Samuele Galeotta",
                            "2023-07-03T17:20:38.000+02:00",
                            "7bd5d9d248f8c1afb88240c2089bce15defa40a7"
                        ]
                    ],
                    "MER_TPhot/src/lib/TPhotStatsCatalog.cpp": [
                        [
                            "@@ -48,90 +48,88 @@ namespace MER_TPhot {\n     }\n     \n   void TPhotStatsCatalog::computeAndStoreSourceStats(TPhotOutputCatalog& fitCatalog, int fitIndex, TPhotInternalCatalog& detectionCatalog,  int detIndex, int modIndex, Eigen::MatrixXd& residualsView, double resXMin, double resYMin){\n-        m_sourceId.push_back(fitCatalog.getSourceId()[fitIndex]);\n-        m_xCenter.push_back(fitCatalog.getXCenter()[fitIndex]);\n-        m_yCenter.push_back(fitCatalog.getYCenter()[fitIndex]);\n+    m_sourceId.push_back(fitCatalog.getSourceId()[fitIndex]);\n+    m_xCenter.push_back(fitCatalog.getXCenter()[fitIndex]);\n+    m_yCenter.push_back(fitCatalog.getYCenter()[fitIndex]);\n \n-        int startI = detectionCatalog.getYMinImage()[detIndex];\n-        int startJ = detectionCatalog.getXMinImage()[detIndex];\n-        int endI = detectionCatalog.getYMaxImage()[detIndex];\n-        int endJ = detectionCatalog.getXMaxImage()[detIndex];\n-        \n-        m_xMinImage.push_back(startJ);\n-        m_xMaxImage.push_back(endJ);\n-        m_yMinImage.push_back(startI);\n-        m_yMaxImage.push_back(endI);\n-\n-        m_fitQuantity.push_back(fitCatalog.getFitQuantity()[fitIndex]);\n-        m_fitQuantityError.push_back(fitCatalog.getFitQuantityErr()[fitIndex]);\n+    int startI = detectionCatalog.getYMinImage()[detIndex];\n+    int startJ = detectionCatalog.getXMinImage()[detIndex];\n+    int endI = detectionCatalog.getYMaxImage()[detIndex];\n+    int endJ = detectionCatalog.getXMaxImage()[detIndex];\n+    \n+    m_xMinImage.push_back(startJ);\n+    m_xMaxImage.push_back(endJ);\n+    m_yMinImage.push_back(startI);\n+    m_yMaxImage.push_back(endI);\n \n-        // Parameters for thresholds\n-        double fwhm3 = 0.;\n-        Eigen::MatrixXd pixelsMod;\n-\tdouble modXMin, modYMin;\n-        if (m_saveRam){\n-            std::stringstream groupIdStream;\n-            groupIdStream << fitCatalog.getSourceId()[fitIndex];\n-            std::string groupName = \"/mod-\"+groupIdStream.str();\n-            fwhm3 = 3*m_modFile->getAttribute<double>(groupName, std::string(\"FWHM\"));\n-            m_modFile->readGroup(groupName, pixelsMod);\n-\t    modXMin = m_modFile->getAttribute<double>(groupName, std::string(\"X_MIN\"));\n-\t    modYMin = m_modFile->getAttribute<double>(groupName, std::string(\"Y_MIN\"));\n-        } else {\n-            fwhm3 = 3*(*m_modList)[modIndex].getFWHM();\n+    m_fitQuantity.push_back(fitCatalog.getFitQuantity()[fitIndex]);\n+    m_fitQuantityError.push_back(fitCatalog.getFitQuantityErr()[fitIndex]);\n+    \n+    // Parameters for thresholds\n+    double fwhm3 = 0.;\n+    Eigen::MatrixXd pixelsMod;\n+    double modXMin, modYMin;\n+    if (m_saveRam){\n+      std::stringstream groupIdStream;\n+      groupIdStream << fitCatalog.getSourceId()[fitIndex];\n+      std::string groupName = \"/mod-\"+groupIdStream.str();\n+      fwhm3 = 3*m_modFile->getAttribute<double>(groupName, std::string(\"FWHM\"));\n+      m_modFile->readGroup(groupName, pixelsMod);\n+      modXMin = m_modFile->getAttribute<double>(groupName, std::string(\"X_MIN\"));\n+      modYMin = m_modFile->getAttribute<double>(groupName, std::string(\"Y_MIN\"));\n+    } else {\n+      fwhm3 = 3*(*m_modList)[modIndex].getFWHM();\n \t    modXMin = (*m_modList)[modIndex].getXMin();\n \t    modYMin = (*m_modList)[modIndex].getYMin();\n-            pixelsMod = (*m_modList)[modIndex].getMod();\n-        }\n-        double inOutThreshold = m_thresholdLevel*pixelsMod.maxCoeff();\n-        double fwhmThreshold = std::pow(fwhm3/0.1, 2); // 0.1 temporary hard code of the pixel size\n-        int xCenter = (endJ-startJ+1)/2;\n-        int yCenter = (endI-startI+1)/2;\n-        // Create residual map view and create stats\n-        MER_TPhot::BasicStats stats;\n-\n-        for (int i=0; i<residualsView.rows(); i++) {\n-            for (int j=0; j<residualsView.cols(); j++) {\n-                if ( std::pow((xCenter-j),2) + std::pow((yCenter-i),2) <= fwhmThreshold) {\n-                    stats.push(residualsView(i,j), true);\n-                } else {\n-                    stats.push(residualsView(i,j), false);\n-                }\n-            }\n+      pixelsMod = (*m_modList)[modIndex].getMod();\n+    }\n+    double inOutThreshold = m_thresholdLevel*pixelsMod.maxCoeff();\n+    double fwhmThreshold = std::pow(fwhm3/0.1, 2); // 0.1 temporary hard code of the pixel size\n+    int xCenter = (endJ-startJ+1)/2;\n+    int yCenter = (endI-startI+1)/2;\n+    // Create residual map view and create stats\n+    \n+    MER_TPhot::BasicStats stats;\n+    for (int i=0; i<residualsView.rows(); i++) {\n+      for (int j=0; j<residualsView.cols(); j++) {\n+        if ( std::pow((xCenter-j),2) + std::pow((yCenter-i),2) <= fwhmThreshold) {\n+          stats.push(residualsView(i,j), true);\n+        } else {\n+          stats.push(residualsView(i,j), false);\n         }\n-        m_sum3FW.push_back(stats.getFWHMThreshold());\n-        m_sum.push_back(stats.sum());\n-        m_mean.push_back(stats.mean());\n-        m_median.push_back(stats.median());\n-        m_stdDeviation.push_back(stats.standardDeviation());\n-        m_kurtosis.push_back(stats.kurtosis());\n-        // Create views with data greater or smaller than the threshold\n-        MER_TPhot::BasicStats statsL;\n-        MER_TPhot::BasicStats statsG;\n-\n-        for (int i=0; i<pixelsMod.rows(); i++) {\n-            for (int j=0; j<pixelsMod.cols(); j++) {\n-                if (pixelsMod(i,j)>inOutThreshold) {\n-\t\t  statsG.push(residualsView(i+static_cast<int>(modYMin-resYMin),j+static_cast<int>(modXMin-resXMin)), false);\n-\t\t  \n-                } else {\n-\t\t  statsL.push(residualsView(i+static_cast<int>(modYMin-resYMin),j+static_cast<int>(modXMin-resXMin)), false);\n-                }\n-            }\n+      }\n+    }\n+    m_sum3FW.push_back(stats.getFWHMThreshold());\n+    m_sum.push_back(stats.sum());\n+    m_mean.push_back(stats.mean());\n+    m_median.push_back(stats.median());\n+    m_stdDeviation.push_back(stats.standardDeviation());\n+    m_kurtosis.push_back(stats.kurtosis());\n+    \n+    // Create views with data greater or smaller than the threshold\n+    MER_TPhot::BasicStats statsL;\n+    MER_TPhot::BasicStats statsG;    \n+    for (int i=0; i<pixelsMod.rows(); i++) {\n+      for (int j=0; j<pixelsMod.cols(); j++) {\n+        if (pixelsMod(i,j)>inOutThreshold) {\n+          statsG.push(residualsView(i+static_cast<int>(modYMin-resYMin),j+static_cast<int>(modXMin-resXMin)), false);\n+        } else {\n+          statsL.push(residualsView(i+static_cast<int>(modYMin-resYMin),j+static_cast<int>(modXMin-resXMin)), false);\n         }\n-        m_sumInside.push_back(statsG.sum());\n-        m_meanInside.push_back(statsG.mean());\n-        m_medianInside.push_back(statsG.median());\n-        m_stdDeviationInside.push_back(statsG.standardDeviation());\n-        m_kurtosisInside.push_back(statsG.kurtosis());\n-\n-        m_sumOutside.push_back(statsL.sum());\n-        m_meanOutside.push_back(statsL.mean());\n-        m_medianOutside.push_back(statsL.median());\n-        m_stdDeviationOutside.push_back(statsL.standardDeviation());\n-        m_kurtosisOutside.push_back(statsL.kurtosis());\n-\n+      }\n     }\n+    m_sumInside.push_back(statsG.sum());\n+    m_meanInside.push_back(statsG.mean());\n+    m_medianInside.push_back(statsG.median());\n+    m_stdDeviationInside.push_back(statsG.standardDeviation());\n+    m_kurtosisInside.push_back(statsG.kurtosis());\n+    \n+    m_sumOutside.push_back(statsL.sum());\n+    m_meanOutside.push_back(statsL.mean());\n+    m_medianOutside.push_back(statsL.median());\n+    m_stdDeviationOutside.push_back(statsL.standardDeviation());\n+    m_kurtosisOutside.push_back(statsL.kurtosis());\n+  }\n     \n     void TPhotStatsCatalog::write(std::string& fileName){\n         // Open file\n",
                            "Bugs in unit tests for fitter and stats catalog",
                            "Samuele Galeotta",
                            "2023-07-03T17:20:38.000+02:00",
                            "7bd5d9d248f8c1afb88240c2089bce15defa40a7"
                        ]
                    ],
                    "MER_TPhot/tests/data/create_cut_test.h5": [
                        [
                            "Binary files a/MER_TPhot/tests/data/create_cut_test.h5 and b/MER_TPhot/tests/data/create_cut_test.h5 differ\n",
                            "Bugs in unit tests for fitter and stats catalog",
                            "Samuele Galeotta",
                            "2023-07-03T17:20:38.000+02:00",
                            "7bd5d9d248f8c1afb88240c2089bce15defa40a7"
                        ]
                    ],
                    "MER_TPhot/tests/data/create_mod_test.h5": [
                        [
                            "Binary files a/MER_TPhot/tests/data/create_mod_test.h5 and b/MER_TPhot/tests/data/create_mod_test.h5 differ\n",
                            "Bugs in unit tests for fitter and stats catalog",
                            "Samuele Galeotta",
                            "2023-07-03T17:20:38.000+02:00",
                            "7bd5d9d248f8c1afb88240c2089bce15defa40a7"
                        ]
                    ],
                    "MER_TPhot/tests/src/Fitter_test.cpp": [
                        [
                            "@@ -158,7 +158,7 @@ BOOST_AUTO_TEST_CASE( test_buildLinearSystem ) {\n   \n   int cellXL = 5;\n   int cellYL = 5; \n-  Eigen::MatrixXd lowResPixels = Eigen::MatrixXd::Zero(cellYDim, cellXDim);\n+  Eigen::MatrixXd lowResPixels = Eigen::MatrixXd::Zero(2*cellYDim, 2*cellXDim);\n   \n   try{\n     MER_TPhot::Fitter fitter;\n",
                            "Bugs in unit tests for fitter and stats catalog",
                            "Samuele Galeotta",
                            "2023-07-03T17:20:38.000+02:00",
                            "7bd5d9d248f8c1afb88240c2089bce15defa40a7"
                        ]
                    ],
                    "MER_TPhot/tests/src/TPhotStatsCatalog_test.cpp": [
                        [
                            "@@ -43,7 +43,9 @@ BOOST_AUTO_TEST_CASE( test_TPhotStatsCatalog) {\n         BOOST_FAIL(\"Failed initialization\");\n       }\n }\n+\n //-----------------------------------------------------------------------------\n+\n BOOST_AUTO_TEST_CASE( test_initializeMod ) {\n  \n   std::shared_ptr<std::vector<MER_TPhot::SingleMod> > modList = std::make_shared<std::vector<MER_TPhot::SingleMod> >();\n@@ -56,7 +58,9 @@ BOOST_AUTO_TEST_CASE( test_initializeMod ) {\n   }\n   BOOST_CHECK(true);\n }\n+\n //-----------------------------------------------------------------------------\n+\n BOOST_AUTO_TEST_CASE( test_initializeMod2 ) {\n   std::shared_ptr<MER_TPhot::Hdf5Object > modFile = std::make_shared<MER_TPhot::Hdf5Object >();\n   try{\n@@ -68,8 +72,9 @@ BOOST_AUTO_TEST_CASE( test_initializeMod2 ) {\n   }\n   BOOST_CHECK(true);\n }\n- \n+\n //-----------------------------------------------------------------------------\n+\n BOOST_AUTO_TEST_CASE( test_write) {\n \n   try\n@@ -86,7 +91,9 @@ BOOST_AUTO_TEST_CASE( test_write) {\n   \n   BOOST_CHECK(true);\n }\n+\n //-----------------------------------------------------------------------------\n+\n BOOST_AUTO_TEST_CASE( test_reset) {\n \n   try\n@@ -100,7 +107,9 @@ BOOST_AUTO_TEST_CASE( test_reset) {\n       }\n   BOOST_CHECK(true);\n }\n+\n //-----------------------------------------------------------------------------\n+\n BOOST_AUTO_TEST_CASE( test_sortBySourceId) {\n \n   try\n@@ -116,7 +125,9 @@ BOOST_AUTO_TEST_CASE( test_sortBySourceId) {\n   \n   BOOST_CHECK(true);\n }\n+\n //-----------------------------------------------------------------------------\n+\n BOOST_AUTO_TEST_CASE( test_sortBySourceId2) {\n \n   try\n@@ -136,7 +147,9 @@ BOOST_AUTO_TEST_CASE( test_sortBySourceId2) {\n \n //-----------------------------------------------------------------------------\n BOOST_AUTO_TEST_CASE( test_computeAndStoreSourceStats) {\n-\n+  AstroDeep::LogLevels loggingLevel = AstroDeep::DEBUG;\n+  logger.setLogLevel(loggingLevel);\n+  \n   try\n       {\n       MER_TPhot::TPhotOutputCatalog fitCatalog; \n@@ -145,8 +158,8 @@ BOOST_AUTO_TEST_CASE( test_computeAndStoreSourceStats) {\n       int detIndex = 0; \n       int modIndex = 0; \n       Eigen::MatrixXd residualsView = Eigen::MatrixXd::Zero(10, 10) ;\n-      double resXMin = 0.0;\n-      double resYMin = 0.0;\n+      double resXMin = 1.0;\n+      double resYMin = 1.0;\n \n       fitCatalog.setSourceId(0);\n       fitCatalog.setXCenter(5);\n@@ -165,8 +178,7 @@ BOOST_AUTO_TEST_CASE( test_computeAndStoreSourceStats) {\n       std::shared_ptr<MER_TPhot::Hdf5Object > modFile = std::make_shared<MER_TPhot::Hdf5Object >(hdf5);\n       MER_TPhot::TPhotStatsCatalog catalog;\n       catalog.initializeMod(modFile);\n-      catalog.computeAndStoreSourceStats(fitCatalog, fitIndex, detectionCatalog, detIndex, modIndex, residualsView, resXMin, resYMin);\n-    \n+      catalog.computeAndStoreSourceStats(fitCatalog, fitIndex, detectionCatalog, detIndex, modIndex, residualsView, resXMin, resYMin);    \n       }\n   catch (...)\n       {\n",
                            "Bugs in unit tests for fitter and stats catalog",
                            "Samuele Galeotta",
                            "2023-07-03T17:20:38.000+02:00",
                            "7bd5d9d248f8c1afb88240c2089bce15defa40a7"
                        ]
                    ],
                    ".jenkinsFile": [
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\r\n-@Library('integration-library@release-9') _\r\n-pipelineElements(artifactId:\"MER_Photometry\", component:'eden.3.1', repository:'eden.3.1')\n\\ No newline at end of file\n+@Library(value='integration-library@release-10') _\r\n+pipelineElements(name:\"MER_Photometry\", component:'eden.3.1')\n\\ No newline at end of file\n",
                            "Wrong jenkins file",
                            "Samuele Galeotta",
                            "2023-06-23T16:12:26.000+02:00",
                            "db547d3a4435a892323fb87280717ed5c3444981"
                        ],
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\r\n @Library('integration-library@release-9') _\r\n-pipelineElements(artifactId:\"MER_Photometry\", component:'eden.3.0', repository:'eden.3.0')\n\\ No newline at end of file\n+pipelineElements(artifactId:\"MER_Photometry\", component:'eden.3.1', repository:'eden.3.1')\n\\ No newline at end of file\n",
                            "DataModel update for launch + fixed data model unit tests",
                            "Samuele Galeotta",
                            "2023-06-23T16:08:42.000+02:00",
                            "ffcdf15aae04da9be6bbae90c122fcdec9d49a58"
                        ]
                    ],
                    "MER_APhot/MER_APhot/SingleSource.h": [
                        [
                            "@@ -435,12 +435,6 @@ private:\n \n   /**\n    * @brief Compute subgrid\n-   * @param ii Pixel index in the mosaic in Y dimension\n-   * @param jj Pixel index in the mosaic in X dimension\n-   * @param xm Distance from the center of the source in Y dimension\n-   * @param ym Distance from the center of the source in X dimension\n-   * @param x0 X pixel of the center of the source\n-   * @param y0 Y pixel of the center of the source\n    * @param R2 Radius limit\n    * @param aa Axis of the ellipse\n    * @param bb Axis of the ellipse \n@@ -448,7 +442,7 @@ private:\n    * @param sinPPAA Angle of the ellipse\n    * @return\n    */\n-  float m_subgrid(int ii, int jj, float xm, float ym, float x0, float y0, double R2, float aa, float bb, double cosPPAA, double sinPPAA);\n+  float m_subgrid(float dx, float dy, double R2, float aa, float bb, double cosPPAA, double sinPPAA);\n \n   /**\n    * @brief Flag RMS limit\n",
                            "DataModel update for launch + fixed data model unit tests",
                            "Samuele Galeotta",
                            "2023-06-23T16:08:42.000+02:00",
                            "ffcdf15aae04da9be6bbae90c122fcdec9d49a58"
                        ]
                    ],
                    "MER_APhot/src/lib/SingleSource.cpp": [
                        [
                            "@@ -648,7 +648,7 @@ namespace MER_APhot {\n     m_pixMax = 0;\n \n     // Position angle stuff\n-    double PA=degToRad(m_theta*57.2958);\n+    double PA=m_theta;\n     double cosPA=cosl(PA);\n     double sinPA=sinl(PA);\n \n@@ -702,7 +702,7 @@ namespace MER_APhot {\n                   x1=(xa-xCatalog)*cosPA+(ya-yCatalog)*sinPA;\n                   y1=-(xa-xCatalog)*sinPA+(ya-yCatalog)*cosPA;\n                   if (((x1*x1)/(aaa*aaa) + (y1*y1)/(bbb*bbb)) >= 1.0) {\n-                    facarea=m_subgrid(i,j,x-0.5,y-0.5,xCatalog,yCatalog,R2,aaa,bbb,cosPA,sinPA);\n+                    facarea=m_subgrid(x-0.5-xCatalog,y-0.5-yCatalog,R2,aaa,bbb,cosPA,sinPA);\n                   }                  \n                   if (m_cutMosaic(i,j)-m_muMax>0.0001) {\n                     m_muMax = m_cutMosaic(i,j);\n@@ -829,7 +829,7 @@ namespace MER_APhot {\n                   keepPix=false;\n                 }\telse if ((xa-xCatalog)*(xa-xCatalog)+(ya-yCatalog)*(ya-yCatalog)>=R2){\n                   // Now check if it's (not) totally inside R\n-                  facarea=m_subgrid(i,j,x-0.5,y-0.5,xCatalog,yCatalog,R2,-1.,0.,0.,0.);\n+                  facarea=m_subgrid(x-0.5-xCatalog,y-0.5-yCatalog,R2,-1.,0.,0.,0.);\n                 } else {\n                   // well it seems it's inside\n                   if (m_cutMosaic(i,j)-m_muMax>0.0001) {\n@@ -910,19 +910,7 @@ namespace MER_APhot {\n   }\n \n   /// Compute subgrid\n-  float SingleSource::m_subgrid(int ii, int jj, float xm, float ym, float x0, float y0, double R2, float aa, float bb, double cosPPAA, double sinPPAA){\n-    Eigen::MatrixXd fff = Eigen::MatrixXd::Zero(m_binSubpix, m_binSubpix);\n-    double dx=xm-x0;\n-    double dy=ym-y0;\n-\n-    double ffftot=0.0;\n-    for (int iii=0;iii<m_binSubpix;iii++) {\n-      for (int jjj=0;jjj<m_binSubpix;jjj++) {\n-        fff(iii,jjj)=m_cutMosaic(ii,jj)/(m_binSubpix*m_binSubpix);\n-        ffftot+=fff(iii,jjj);\n-      }\n-    }\n-\n+  float SingleSource::m_subgrid(float dx, float dy, double R2, float aa, float bb, double cosPPAA, double sinPPAA){\n     // Then, only include subpixels within radius\n     double sfacarea=0.0;\n     if (aa<0.0) {\n@@ -931,7 +919,7 @@ namespace MER_APhot {\n           double dsx=dx+((float)jjj+0.5)*m_dSubpix;\n           double dsy=dy+((float)iii+0.5)*m_dSubpix;\n           if (dsx*dsx+dsy*dsy<=R2) {\n-            sfacarea+=fff(iii,jjj)/ffftot;\n+            sfacarea+=1./(m_binSubpix*m_binSubpix);\n           }\n         }\n       }\n@@ -942,7 +930,7 @@ namespace MER_APhot {\n           double dsy=-(dx+((float)jjj+0.5)*m_dSubpix)*sinPPAA+(dy+((float)iii+0.5)*m_dSubpix)*cosPPAA;\n \n           if ((dsx*dsx)/(aa*aa)+(dsy*dsy)/(bb*bb)<=1.0) {\n-            sfacarea+=fff(iii,jjj)/ffftot;\n+            sfacarea+=1./(m_binSubpix*m_binSubpix);\n           }\n         }\n       }\n",
                            "DataModel update for launch + fixed data model unit tests",
                            "Samuele Galeotta",
                            "2023-06-23T16:08:42.000+02:00",
                            "ffcdf15aae04da9be6bbae90c122fcdec9d49a58"
                        ]
                    ],
                    "MER_APhot/src/program/MER_APhotCircular.cpp": [
                        [
                            "@@ -169,6 +169,8 @@ public:\n     \n     /// Loop on sources\n     int numProcessedSources=0;\n+    std::ofstream fw(workdirData+\"region_negative_ellipses.reg\", std::ofstream::out);\n+\n     for (size_t idx=0; idx<inputCatalog.getSourceId().size(); ++idx){\n \n       logger.debug(\"Working on ID: \"+std::to_string(inputCatalog.getSourceId()[idx]));\n@@ -211,8 +213,13 @@ public:\n     \toutputCatalog.setBackgroundPix(idx, singleCut.getBackground());\n       }\n       outputCatalog.setNirOnly(idx, inputCatalog.getNirOnly()[idx]);\n+\n+      if (singleCut.getCircularFluxes()[0]==0.0){\n+        fw << \"circle(\"+std::to_string(static_cast<int>(std::round(inputCatalog.getXCenter()[idx]+1)))+\",\"+std::to_string(static_cast<int>(std::round(inputCatalog.getYCenter()[idx]+1)))+\",\"+std::to_string(rMax)+\")\" << std::endl;\n+      }\n     }\n     \n+    fw.close();\n     logger.info(\"\");\n     logger.info(\"Processed: \"+std::to_string(numProcessedSources)+\" sources\");\n     \n",
                            "DataModel update for launch + fixed data model unit tests",
                            "Samuele Galeotta",
                            "2023-06-23T16:08:42.000+02:00",
                            "ffcdf15aae04da9be6bbae90c122fcdec9d49a58"
                        ]
                    ],
                    "MER_APhot/src/program/MER_APhotDetection.cpp": [
                        [
                            "@@ -228,6 +228,10 @@ public:\n     \n     /// Loop on NIR sources\n     numProcessedSources=0;\n+\n+    std::ofstream fw(workdirData+\"region_negative_ellipses.reg\", std::ofstream::out);\n+    std::ofstream fw2(workdirData+\"region_positive_ellipses.reg\", std::ofstream::out);\n+\n     for (size_t idx=0; idx<inputCatalog.getSourceId().size(); ++idx){\n       if (!inputCatalog.getNirOnly()[idx]){\n         continue;\n@@ -260,7 +264,17 @@ public:\n       outputCatalog.setFlag(idx, singleCut.getFlag());\n       outputCatalog.setNirOnly(idx, inputCatalog.getNirOnly()[idx]);\n       outputCatalog.setKronRadius(idx, singleCut.getR1());\n-    }    \n+\n+      if (singleCut.getKronFlux()<0){\n+        fw << \"ellipse(\"+std::to_string(static_cast<int>(std::round(inputCatalog.getXCenter()[idx]+1)))+\",\"+std::to_string(static_cast<int>(std::round(inputCatalog.getYCenter()[idx]+1)))+\",\"+std::to_string(singleCut.getR1())+\",\"+std::to_string(singleCut.getR1()*(1.0-singleCut.getE()))+\",\"+std::to_string(singleCut.getTheta()*57.2958)+\")\" << std::endl;\n+      } else{\n+        fw2 << \"ellipse(\"+std::to_string(static_cast<int>(std::round(inputCatalog.getXCenter()[idx]+1)))+\",\"+std::to_string(static_cast<int>(std::round(inputCatalog.getYCenter()[idx]+1)))+\",\"+std::to_string(singleCut.getR1())+\",\"+std::to_string(singleCut.getR1()*(1.0-singleCut.getE()))+\",\"+std::to_string(singleCut.getTheta()*57.2958)+\")\" << std::endl;\n+      }\n+    }\n+\n+    fw.close();\n+    fw2.close();\n+\n     logger.info(\"\");\n     logger.info(\"Processed: \"+std::to_string(numProcessedSources)+\" NIR sources\");\n     \n",
                            "DataModel update for launch + fixed data model unit tests",
                            "Samuele Galeotta",
                            "2023-06-23T16:08:42.000+02:00",
                            "ffcdf15aae04da9be6bbae90c122fcdec9d49a58"
                        ],
                        [
                            "@@ -233,7 +233,7 @@ public:\n         continue;\n       }\n \n-      int nirSourceId = nirInputCatalog.getSourceIdFromCenter(inputCatalog.getXCenter()[idx], inputCatalog.getYCenter()[idx]);\n+      int nirSourceId = inputCatalog.getSourceId()[idx]-inputCatalog.getNirSourceIDOffset();\n \n       logger.debug(\"Working on ID: \"+std::to_string(nirSourceId)+\" which is: \"+std::to_string(inputCatalog.getSourceId()[idx]));\n       logger.debug(\">>> Values: \"+std::to_string(inputCatalog.getA()[idx])+\" \"+std::to_string(inputCatalog.getEll()[idx])+\" \"+std::to_string(inputCatalog.getTheta()[idx]));\n@@ -248,7 +248,7 @@ public:\n       std::vector<double> kronList(1, 1.0);\n       singleCut.computeEllipticalFluxes(inputImage.getPixels(), inputCatalog.getXCenter()[idx], inputCatalog.getYCenter()[idx], kronList);\n       numProcessedSources++;\n-      \n+\n       // Write output for this object\n       outputCatalog.setSourceId(idx, inputCatalog.getSourceId()[idx]);\n       outputCatalog.setXCenter(idx, inputCatalog.getXCenter()[idx]+1);\n",
                            "Bug in source id from NIR to combined",
                            "Samuele Galeotta",
                            "2023-06-12T18:44:41.000+02:00",
                            "52f0557b788dd750fbde15111729ca02ab7e3583"
                        ]
                    ],
                    "MER_TPhot/tests/data/combinedSegmentMap.xml": [
                        [
                            "@@ -1,27 +1,25 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n-<ns1:DpdMerSegmentationMap xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/segmentationmap\">\n+<ns1:DpdMerSegmentationMap xmlns:ns1=\"http://ecdm.euclid-ec.org/schema/dpd/mer/segmentationmap\">\n \t<Header>\n \t\t<ProductId>1550763168.9061744</ProductId>\n \t\t<ProductType>dpdMerSegmentationMap</ProductType>\n \t\t<SoftwareName>MER_Pipeline</SoftwareName>\n-\t\t<SoftwareRelease>1.0</SoftwareRelease>\n+\t\t<SoftwareRelease>0.0</SoftwareRelease>\n+\t\t<EuclidPipelineSoftwareRelease>0.0</EuclidPipelineSoftwareRelease>\n+\t\t<ProdSDC>SDC-IT</ProdSDC>\n+\t\t<DataSetRelease>NA</DataSetRelease>\n+\t\t<Purpose>UNKNOWN</Purpose>\n+\t\t<PlanId>4373a896-d221-4c1f-9df4-65bd5c89459d</PlanId>\n+\t\t<PPOId>f357411a-7e06-4bbe-b400-cbd96a321b2b</PPOId>\n+\t\t<PipelineDefinitionId>PipelineDefinitionId</PipelineDefinitionId>\n+\t\t<PpoStatus>NA</PpoStatus>\n \t\t<ManualValidationStatus>UNKNOWN</ManualValidationStatus>\n-\t\t<PipelineRun>XXXX</PipelineRun>\n-\t\t<ExitStatusCode>0</ExitStatusCode>\n-\t\t<DataModelVersion>1.8.3</DataModelVersion>\n-\t\t<MinDataModelVersion>1.8.3</MinDataModelVersion>\n-\t\t<ScientificCustodian>MER</ScientificCustodian>\n-\t\t<AccessRights>\n-\t\t\t<EuclidConsortiumRead>true</EuclidConsortiumRead>\n-\t\t\t<EuclidConsortiumWrite>true</EuclidConsortiumWrite>\n-\t\t\t<ScientificGroupRead>true</ScientificGroupRead>\n-\t\t\t<ScientificGroupWrite>true</ScientificGroupWrite>\n-\t\t</AccessRights>\n-\t\t<Curator>\n-\t\t\t<Name>Javier Gracia Carpio</Name>\n-\t\t\t<Email>jgracia@mpe.mpg.de</Email>\n-\t\t</Curator>\n-\t\t<Creator>SDC-IT</Creator>\n+\t\t<ProductNotifiedToBeChecked>UNKNOWN</ProductNotifiedToBeChecked>\n+\t\t<AutomatedValidationStatus>UNKNOWN</AutomatedValidationStatus>\n+\t\t<ExpirationDate>2023-04-15T17:55:02.879Z</ExpirationDate>\n+\t\t<ToBePublished>0</ToBePublished>\n+\t\t<Published>0</Published>\n+\t\t<Curator>MER</Curator>\n \t\t<CreationDate>2019-02-21T15:32:48.907Z</CreationDate>\n \t</Header>\n \t<Data>\n@@ -29,7 +27,6 @@\n \t\t\t<Category>SCIENCE</Category>\n \t\t\t<FirstType>STD</FirstType>\n \t\t\t<SecondType>SKY</SecondType>\n-\t\t\t<ThirdType>WIDE</ThirdType>\n \t\t\t<Technique>IMAGE</Technique>\n \t\t</ImgType>\n \t\t<ImgNumber>1</ImgNumber>\n@@ -74,100 +71,68 @@\n \t\t<ImgSpatialFootprint>\n \t\t\t<Polygon>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>53.12444084711672</C1>\n-\t\t\t\t\t\t<C2>-27.79648605519883</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>53.12444084711672</C1>\n+\t\t\t\t\t<C2>-27.79648605519883</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>53.1224704235607</C1>\n-\t\t\t\t\t\t<C2>-27.796486097129815</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>53.1224704235607</C1>\n+\t\t\t\t\t<C2>-27.796486097129815</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>53.1205</C1>\n-\t\t\t\t\t\t<C2>-27.796486111106802</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>53.1205</C1>\n+\t\t\t\t\t<C2>-27.796486111106802</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>53.1185295764393</C1>\n-\t\t\t\t\t\t<C2>-27.796486097129815</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>53.1185295764393</C1>\n+\t\t\t\t\t<C2>-27.796486097129815</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>53.116559152883276</C1>\n-\t\t\t\t\t\t<C2>-27.79648605519883</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>53.116559152883276</C1>\n+\t\t\t\t\t<C2>-27.79648605519883</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>53.11655921607569</C1>\n-\t\t\t\t\t\t<C2>-27.79474299965117</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>53.11655921607569</C1>\n+\t\t\t\t\t<C2>-27.79474299965117</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>53.11655927926611</C1>\n-\t\t\t\t\t\t<C2>-27.79299994410027</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>53.11655927926611</C1>\n+\t\t\t\t\t<C2>-27.79299994410027</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>53.116559342454465</C1>\n-\t\t\t\t\t\t<C2>-27.791256888549377</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>53.116559342454465</C1>\n+\t\t\t\t\t<C2>-27.791256888549377</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>53.11655940564082</C1>\n-\t\t\t\t\t\t<C2>-27.78951383300171</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>53.11655940564082</C1>\n+\t\t\t\t\t<C2>-27.78951383300171</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>53.11852970281808</C1>\n-\t\t\t\t\t\t<C2>-27.789513874920324</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>53.11852970281808</C1>\n+\t\t\t\t\t<C2>-27.789513874920324</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>53.1205</C1>\n-\t\t\t\t\t\t<C2>-27.789513888893225</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>53.1205</C1>\n+\t\t\t\t\t<C2>-27.789513888893225</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>53.12247029718192</C1>\n-\t\t\t\t\t\t<C2>-27.789513874920324</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>53.12247029718192</C1>\n+\t\t\t\t\t<C2>-27.789513874920324</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>53.12444059435918</C1>\n-\t\t\t\t\t\t<C2>-27.78951383300171</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>53.12444059435918</C1>\n+\t\t\t\t\t<C2>-27.78951383300171</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>53.124440657545534</C1>\n-\t\t\t\t\t\t<C2>-27.791256888549377</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>53.124440657545534</C1>\n+\t\t\t\t\t<C2>-27.791256888549377</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>53.12444072073389</C1>\n-\t\t\t\t\t\t<C2>-27.79299994410027</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>53.12444072073389</C1>\n+\t\t\t\t\t<C2>-27.79299994410027</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>53.12444078392431</C1>\n-\t\t\t\t\t\t<C2>-27.79474299965117</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>53.12444078392431</C1>\n+\t\t\t\t\t<C2>-27.79474299965117</C2>\n \t\t\t\t</Vertex>\n \t\t\t</Polygon>\n \t\t</ImgSpatialFootprint>\n@@ -179,12 +144,8 @@\n \t\t<QualityParams>\n \t\t\t<NonZeroFraction flagged=\"false\">0.12662194507432603</NonZeroFraction>\n \t\t</QualityParams>\n-\t\t<ProcessingSteps>\n-\t\t\t<ProcessingStep>\n-\t\t\t\t<Name>Empty</Name>\n-\t\t\t\t<ProgramName></ProgramName>\n-\t\t\t\t<SoftwareVersion>1.0</SoftwareVersion>\n-\t\t\t</ProcessingStep>\n-\t\t</ProcessingSteps>\n \t</Data>\n+\t<QualityFlags>\n+\t\t<NonZeroFractionRangeExceeded xpath=\"/*/Data/QualityParams/NonZeroFraction\" minLimit=\"0.005\" maxLimit=\"0.3\" flagged=\"false\">false</NonZeroFractionRangeExceeded>\n+\t</QualityFlags>\n </ns1:DpdMerSegmentationMap>\n",
                            "DataModel update for launch + fixed data model unit tests",
                            "Samuele Galeotta",
                            "2023-06-23T16:08:42.000+02:00",
                            "ffcdf15aae04da9be6bbae90c122fcdec9d49a58"
                        ]
                    ],
                    "MER_TPhot/tests/data/highResMosaic.xml": [
                        [
                            "@@ -1,5 +1,5 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n-<ns1:DpdMerBksMosaic xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/bksmosaic\">\n+<ns1:DpdMerBksMosaic xmlns:ns1=\"http://ecdm.euclid-ec.org/schema/dpd/mer/bksmosaic\">\n \t<Header>\n \t\t<ProductId>4e288f78-d5d1-43bf-8b5b-262466e9e91e</ProductId>\n \t\t<ProductType>DpdMerBksMosaic</ProductType>\n@@ -14,6 +14,8 @@\n \t\t<PipelineDefinitionId>PipelineDefinitionId</PipelineDefinitionId>\n \t\t<PpoStatus>NA</PpoStatus>\n \t\t<ManualValidationStatus>UNKNOWN</ManualValidationStatus>\n+\t\t<ProductNotifiedToBeChecked>UNKNOWN</ProductNotifiedToBeChecked>\n+\t\t<AutomatedValidationStatus>UNKNOWN</AutomatedValidationStatus>\n \t\t<ExpirationDate>2021-01-14T17:43:16.73Z</ExpirationDate>\n \t\t<ToBePublished>0</ToBePublished>\n \t\t<Published>0</Published>\n@@ -64,33 +66,27 @@\n \t\t<ImgSpatialFootprint>\n \t\t\t<Polygon>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>11.916295352647511</C1>\n-\t\t\t\t\t\t<C2>-19.266433971441476</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>11.916295352647511</C1>\n+\t\t\t\t\t<C2>-19.266433971441476</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>11.351359633452487</C1>\n-\t\t\t\t\t\t<C2>-19.266433971441476</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>11.351359633452487</C1>\n+\t\t\t\t\t<C2>-19.266433971441476</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>11.352263474307009</C1>\n-\t\t\t\t\t\t<C2>-18.733138726263114</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>11.352263474307009</C1>\n+\t\t\t\t\t<C2>-18.733138726263114</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>11.91539151179299</C1>\n-\t\t\t\t\t\t<C2>-18.733138726263114</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>11.91539151179299</C1>\n+\t\t\t\t\t<C2>-18.733138726263114</C2>\n \t\t\t\t</Vertex>\n \t\t\t</Polygon>\n \t\t</ImgSpatialFootprint>\n \t\t<TileIndex>45035</TileIndex>\n+\t\t<PatchIdList></PatchIdList>\n \t\t<ObservationIdList>31279 31285</ObservationIdList>\n+\t\t<CalblockIdList></CalblockIdList>\n \t\t<ProcessingMode>WIDE</ProcessingMode>\n \t\t<DataStorage format=\"mer.mosaic\" version=\"0.4\">\n \t\t\t<DataContainer filestatus=\"PROPOSED\">\n",
                            "DataModel update for launch + fixed data model unit tests",
                            "Samuele Galeotta",
                            "2023-06-23T16:08:42.000+02:00",
                            "ffcdf15aae04da9be6bbae90c122fcdec9d49a58"
                        ]
                    ],
                    "MER_TPhot/tests/data/matchedMosaic.xml": [
                        [
                            "@@ -1,5 +1,5 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n-<ns1:DpdMerPsfTransformationKernel xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/psftransformationkernel\">\n+<ns1:DpdMerPsfTransformationKernel xmlns:ns1=\"http://ecdm.euclid-ec.org/schema/dpd/mer/psftransformationkernel\">\n \t<Header>\n \t\t<ProductId>9ae56885-5c6f-49f6-8653-15dd354d129e</ProductId>\n \t\t<ProductType>DpdMerPsfTransformationKernel</ProductType>\n@@ -14,6 +14,8 @@\n \t\t<PipelineDefinitionId>PipelineDefinitionId</PipelineDefinitionId>\n \t\t<PpoStatus>NA</PpoStatus>\n \t\t<ManualValidationStatus>UNKNOWN</ManualValidationStatus>\n+\t\t<ProductNotifiedToBeChecked>UNKNOWN</ProductNotifiedToBeChecked>\n+\t\t<AutomatedValidationStatus>UNKNOWN</AutomatedValidationStatus>\n \t\t<ExpirationDate>2022-02-09T11:24:40.535Z</ExpirationDate>\n \t\t<ToBePublished>0</ToBePublished>\n \t\t<Published>0</Published>\n@@ -22,7 +24,9 @@\n \t</Header>\n \t<Data>\n \t\t<TileIndex>45035</TileIndex>\n+\t\t<PatchIdList></PatchIdList>\n \t\t<ObservationIdList>31279 31285</ObservationIdList>\n+\t\t<CalblockIdList></CalblockIdList>\n \t\t<ProcessingMode>WIDE</ProcessingMode>\n \t\t<FromFilter>\n \t\t\t<Name>VIS</Name>\n@@ -33,28 +37,20 @@\n \t\t<SpatialFootprint>\n \t\t\t<Polygon>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>11.916295352647511</C1>\n-\t\t\t\t\t\t<C2>-19.266433971441476</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>11.916295352647511</C1>\n+\t\t\t\t\t<C2>-19.266433971441476</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>11.351359633452487</C1>\n-\t\t\t\t\t\t<C2>-19.266433971441476</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>11.351359633452487</C1>\n+\t\t\t\t\t<C2>-19.266433971441476</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>11.352263474307009</C1>\n-\t\t\t\t\t\t<C2>-18.733138726263114</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>11.352263474307009</C1>\n+\t\t\t\t\t<C2>-18.733138726263114</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>11.91539151179299</C1>\n-\t\t\t\t\t\t<C2>-18.733138726263114</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>11.91539151179299</C1>\n+\t\t\t\t\t<C2>-18.733138726263114</C2>\n \t\t\t\t</Vertex>\n \t\t\t</Polygon>\n \t\t</SpatialFootprint>\n",
                            "DataModel update for launch + fixed data model unit tests",
                            "Samuele Galeotta",
                            "2023-06-23T16:08:42.000+02:00",
                            "ffcdf15aae04da9be6bbae90c122fcdec9d49a58"
                        ]
                    ],
                    "MER_TPhot/tests/data/nirDetectionImage.xml": [
                        [
                            "@@ -1,5 +1,5 @@\n <?xml version=\"1.0\" encoding=\"utf-8\"?>\n-<ns1:DpdMerDetectionMosaic xmlns:ns1=\"http://euclid.esa.org/schema/dpd/mer/detectionmosaic\">\n+<ns1:DpdMerDetectionMosaic xmlns:ns1=\"http://ecdm.euclid-ec.org/schema/dpd/mer/detectionmosaic\">\n \t<Header>\n \t\t<ProductId>98e33529-9804-4a85-8f92-e12d7da2d377</ProductId>\n \t\t<ProductType>DpdMerDetectionMosaic</ProductType>\n@@ -14,6 +14,8 @@\n \t\t<PipelineDefinitionId>PipelineDefinitionId</PipelineDefinitionId>\n \t\t<PpoStatus>NA</PpoStatus>\n \t\t<ManualValidationStatus>UNKNOWN</ManualValidationStatus>\n+\t\t<ProductNotifiedToBeChecked>UNKNOWN</ProductNotifiedToBeChecked>\n+\t\t<AutomatedValidationStatus>UNKNOWN</AutomatedValidationStatus>\n \t\t<ExpirationDate>2021-01-14T12:33:58.914Z</ExpirationDate>\n \t\t<ToBePublished>0</ToBePublished>\n \t\t<Published>0</Published>\n@@ -60,33 +62,27 @@\n \t\t\t<Error>0.1</Error>\n \t\t</ZeroPoint>\n \t\t<TileIndex>45035</TileIndex>\n+\t\t<PatchIdList></PatchIdList>\n \t\t<ObservationIdList>31279 31285</ObservationIdList>\n+\t\t<CalblockIdList></CalblockIdList>\n \t\t<ProcessingMode>WIDE</ProcessingMode>\n \t\t<ImgSpatialFootprint>\n \t\t\t<Polygon>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>11.916295352647511</C1>\n-\t\t\t\t\t\t<C2>-19.266433971441476</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>11.916295352647511</C1>\n+\t\t\t\t\t<C2>-19.266433971441476</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>11.351359633452487</C1>\n-\t\t\t\t\t\t<C2>-19.266433971441476</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>11.351359633452487</C1>\n+\t\t\t\t\t<C2>-19.266433971441476</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>11.352263474307009</C1>\n-\t\t\t\t\t\t<C2>-18.733138726263114</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>11.352263474307009</C1>\n+\t\t\t\t\t<C2>-18.733138726263114</C2>\n \t\t\t\t</Vertex>\n \t\t\t\t<Vertex>\n-\t\t\t\t\t<Position coordUnit=\"deg\">\n-\t\t\t\t\t\t<C1>11.91539151179299</C1>\n-\t\t\t\t\t\t<C2>-18.733138726263114</C2>\n-\t\t\t\t\t</Position>\n+\t\t\t\t\t<C1>11.91539151179299</C1>\n+\t\t\t\t\t<C2>-18.733138726263114</C2>\n \t\t\t\t</Vertex>\n \t\t\t</Polygon>\n \t\t</ImgSpatialFootprint>\n",
                            "DataModel update for launch + fixed data model unit tests",
                            "Samuele Galeotta",
                            "2023-06-23T16:08:42.000+02:00",
                            "ffcdf15aae04da9be6bbae90c122fcdec9d49a58"
                        ]
                    ],
                    "Makefile": [
                        [
                            "@@ -44,170 +44,19 @@\n #\n ################################################################################\n \n-# settings\n-CMAKE := cmake\n-CTEST := ctest\n-NINJA := $(shell which ninja-build 2> /dev/null)\n-ifeq ($(NINJA),)\n-  NINJA := $(shell which ninja 2> /dev/null)\n-endif\n-\n-# Looking for the Custom make library\n-\n-CUSTOM_MAKE_LIB := Custom.mk\n-\n-ifneq ($(wildcard $(CURDIR)/make/$(CUSTOM_MAKE_LIB)),)\n-  CUSTOM_MAKE_LIB_FILE := $(CURDIR)/make/$(CUSTOM_MAKE_LIB)\n-else\n-  ifneq ($(CMAKE_PREFIX_PATH),)\n-    PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    CUSTOM_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(CUSTOM_MAKE_LIB) $(dir)/../make/$(CUSTOM_MAKE_LIB)))\n-  endif\n-  CUSTOM_MAKE_LIB_LIST += /usr/share/Elements/make/$(CUSTOM_MAKE_LIB)\n-  CUSTOM_MAKE_LIB_FILE := $(firstword $(CUSTOM_MAKE_LIB_LIST))\n-endif\n-\n-# Looking for the ToolChain\n-\n-TOOLCHAIN_NAME := ElementsToolChain.cmake\n+ELEMENTS_MAKE_LIB := Elements.mk\n \n-ifneq ($(wildcard $(CURDIR)/cmake/$(TOOLCHAIN_NAME)),)\n-  TOOLCHAIN_FILE := $(CURDIR)/cmake/$(TOOLCHAIN_NAME)\n+ifneq ($(wildcard $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)),)\n+  ELEMENTS_MAKE_LIB_FILE := $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)\n else\n   ifneq ($(CMAKE_PREFIX_PATH),)\n     PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    TOOLCHAIN_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/lib*/cmake/ElementsProject/$(TOOLCHAIN_NAME) $(dir)/$(TOOLCHAIN_NAME)))\n-    TOOLCHAIN_FILE := $(firstword $(TOOLCHAIN_LIST))\n-  endif\n-endif\n-\n-override ALL_CMAKEFLAGS := -Wno-dev --no-warn-unused-cli\n-\n-ifneq ($(TOOLCHAIN_FILE),)\n-  # A toolchain has been found. Lets use it.\n-  override ALL_CMAKEFLAGS += -DCMAKE_TOOLCHAIN_FILE=$(TOOLCHAIN_FILE)\n-endif\n-\n-\n-BUILD_PREFIX_NAME := build\n-\n-override ALL_CMAKEFLAGS += -DUSE_LOCAL_INSTALLAREA=ON -DBUILD_PREFIX_NAME:STRING=$(BUILD_PREFIX_NAME)\n-override ALL_CMAKEFLAGS += -DUSE_VERSIONED_LIBRARIES=OFF\n-\n-ifndef BINARY_TAG\n-  ifdef CMAKECONFIG\n-    BINARY_TAG := ${CMAKECONFIG}\n-  else\n-    ifdef CMTCONFIG\n-      BINARY_TAG := ${CMTCONFIG}\n-    endif\n-  endif\n-endif\n-\n-ifdef BINARY_TAG\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME).$(BINARY_TAG)\n-else\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME)\n-endif\n-BUILDDIR := $(CURDIR)/$(BUILD_SUBDIR)\n-\n-# build tool\n-\n-ifneq ($(USE_NINJA),)\n-  # enable Ninja\n-  override ALL_CMAKEFLAGS += -GNinja\n-  BUILD_CONF_FILE := build.ninja\n-  BUILDFLAGS := $(NINJAFLAGS)\n-  ifneq ($(VERBOSE),)\n-    BUILDFLAGS := -v $(BUILDFLAGS)\n+    ELEMENTS_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(ELEMENTS_MAKE_LIB) $(dir)/../make/$(ELEMENTS_MAKE_LIB)))\n   endif\n-else\n-  BUILD_CONF_FILE := Makefile\n-endif\n-BUILD_CMD := $(CMAKE) --build $(BUILD_SUBDIR) --target\n-\n-\n-# Use environment variable for extra flags\n-\n-# Replace the \":\" from eclipse variable list to spaces  \n-ifneq ($(EXPAND_FLAGS),)\n-  CMAKEFLAGS := $(subst :-, -,$(CMAKEFLAGS))\n-endif\n-\n-ifneq ($(CMAKEFLAGS),)\n-  override ALL_CMAKEFLAGS += $(CMAKEFLAGS)\n+  ELEMENTS_MAKE_LIB_LIST += /usr/share/Elements/make/$(ELEMENTS_MAKE_LIB)\n+  ELEMENTS_MAKE_LIB_FILE := $(firstword $(ELEMENTS_MAKE_LIB_LIST))\n endif\n \n-# default target\n-all:\n-\n-# deep clean\n-purge:\n-\t$(RM) -r $(BUILDDIR) $(CURDIR)/InstallArea/$(BINARY_TAG)\n-\tfind $(CURDIR) \"(\" -name \"InstallArea\" -prune -o -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# Remove all the possible directories and the whole InstallArea as well\n-mrproper:\n-\t$(RM) -r $(CURDIR)/build $(CURDIR)/build.* $(CURDIR)/InstallArea\n-\tfind $(CURDIR) \"(\" -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# delegate any target to the build directory (except 'purge')\n-ifneq ($(MAKECMDGOALS),purge)\n-ifneq ($(MAKECMDGOALS),mrproper)\n-%: $(BUILDDIR)/$(BUILD_CONF_FILE) FORCE\n-\t+$(BUILD_CMD) $* -- $(BUILDFLAGS)\n-endif\n-endif\n-\n-# aliases\n-.PHONY: configure tests FORCE\n-ifneq ($(wildcard $(BUILDDIR)/$(BUILD_CONF_FILE)),)\n-configure: rebuild_cache\n-else\n-configure: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-endif\n-\t@ # do not delegate further\n-\n-\n-# This wrapping around the test target is used to ensure the generation of\n-# the XML output from ctest.\n-test: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-\n-# This target ensures that the \"all\" target is called before\n-# running the tests (unlike the \"test\" default target of CMake)\n-tests: all\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-ifeq ($(VERBOSE),)\n-# less verbose install\n-# (emulate the default CMake install target)\n-install: all\n-\tcd $(BUILDDIR) && $(CMAKE) -P cmake_install.cmake | grep -v \"^-- Up-to-date:\"\n-endif\n-\n-# import the library to look for a custom Makefile\n--include $(CUSTOM_MAKE_LIB_FILE)\n-\n-# ensure that the target are always passed to the CMake Makefile\n-FORCE: ;\n-\n-# Makefiles are used as implicit targets in make, but we should not consider\n-# them for delegation.\n-$(MAKEFILE_LIST): ;\n-\n-\n-# trigger CMake configuration\n-$(BUILDDIR)/$(BUILD_CONF_FILE): | $(BUILDDIR)\n-\tcd $(BUILDDIR) && $(CMAKE) $(ALL_CMAKEFLAGS) $(CURDIR)\n-\n-$(BUILDDIR):\n-\tmkdir -p $(BUILDDIR)\n+$(info Using the $(ELEMENTS_MAKE_LIB_FILE) make library)\n+include $(ELEMENTS_MAKE_LIB_FILE)\n \n",
                            "DataModel update for launch + fixed data model unit tests",
                            "Samuele Galeotta",
                            "2023-06-23T16:08:42.000+02:00",
                            "ffcdf15aae04da9be6bbae90c122fcdec9d49a58"
                        ]
                    ],
                    "MER_TPhot/MER_TPhot/FitsObject.h": [
                        [
                            "@@ -220,6 +220,12 @@ template<class T>\n     char errorMessage[32] = {0};\n     fits_get_errstatus(m_lastStatus, errorMessage);\n     logger.debug(\"Read Key: \"+keyName+\" \"+std::string(errorMessage));\n+    if (m_lastStatus != 0){\n+      std::stringstream zeroVal;\n+      zeroVal << std::string(\"0\");\n+      zeroVal >> keyValue;\n+      return keyValue;\n+    }\n \n     // if the key is a string i need to remove the first char (')\n     std::stringstream tmpVal;\n",
                            "Merge branch 'develop' of gitlab.euclid-sgs.uk:PF-MER/MER_Photometry into develop",
                            "Samuele Galeotta",
                            "2023-06-12T18:44:59.000+02:00",
                            "3930fb5101a1d1454c477f423a2e84e8b2dda913"
                        ]
                    ],
                    "MER_APhot/MER_APhot/APhotInputCatalog.h": [
                        [
                            "@@ -111,7 +111,10 @@ namespace MER_APhot {\n      */\n     std::vector<int>& getParentId();\n \n-    int getSourceIdFromCenter(double xCenter, double yCenter);\n+    /**\n+     * Give the source ID offset added to NIR\n+     */\n+    int getNirSourceIDOffset();\n \n     /**\n      * @brief   Read catalog for Aperture Photometry\n@@ -139,6 +142,8 @@ namespace MER_APhot {\n     std::vector<double> m_a;\n     /// Ellipticity\n     std::vector<double> m_ell;\n+\n+    int m_nirSourceIDOffset;\n     \n   }; /* End of APhotInput Catalog class */\n   \n",
                            "Bug in source id from NIR to combined",
                            "Samuele Galeotta",
                            "2023-06-12T18:44:41.000+02:00",
                            "52f0557b788dd750fbde15111729ca02ab7e3583"
                        ]
                    ],
                    "MER_APhot/src/lib/APhotInputCatalog.cpp": [
                        [
                            "@@ -89,16 +89,9 @@ namespace MER_APhot {\n     return m_parentId;\n   }\n   \n-  int APhotInputCatalog::getSourceIdFromCenter(double xCenter, double yCenter){\n-    for (size_t idx=0; idx<m_sourceId.size(); idx++){\n-      if (m_xCenter[idx]==xCenter){\n-        if (m_yCenter[idx]==yCenter){\n-          return m_sourceId[idx];\n-        }\n-      }\n-    }\n-    \n-    return -1;\n+  /// Give the source ID offset added to NIR\n+  int APhotInputCatalog::getNirSourceIDOffset(){\n+    return m_nirSourceIDOffset;\n   }\n   \n   /// Read catalog for Aperture Photometry\n@@ -111,6 +104,9 @@ namespace MER_APhot {\n     }\n     fileHandle.gotoHDU(2);\n \n+    // Read NIR_OFFSET\n+    m_nirSourceIDOffset = fileHandle.getKey<int>(\"NIR_OFF\");\n+\n     m_sourceId = fileHandle.getColumn<int>(\"SOURCE_ID\");\n     if (m_sourceId.size() == 0) {\n       logger.error(std::string(\"Empty Catalog: \")+fileName);\n",
                            "Bug in source id from NIR to combined",
                            "Samuele Galeotta",
                            "2023-06-12T18:44:41.000+02:00",
                            "52f0557b788dd750fbde15111729ca02ab7e3583"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "9.1.0",
                        "created_at": "2023-03-07T11:08:38.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.0",
                        "created_at": "2023-07-03T19:04:54.000+02:00",
                        "author_name": "Samuele Galeotta"
                    },
                    {
                        "name": "10.1.1",
                        "created_at": "2023-08-14T12:39:51.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    }
                ]
            },
            "PF-MER/MER_CatalogAssembly": {
                "start date": "2023-06-09 09:00",
                "end date": "2023-08-23 15:00",
                "start tag": "> 9.2.0",
                "end tag": "> 10.1.2",
                "count_files_modified": "6",
                "modifications_by_file": {
                    "MER_CatalogAssembly/python/MER_CatalogAssembly/add_catalog_features.py": [
                        [
                            "@@ -23,6 +23,7 @@ Integrated by: Erik Romelli\n import ElementsKernel.Logging as log\n \n import os\n+from astropy.time import Time\n \n from MER_DataModelUtils import DmUtils as dm_utils\n from MER_DA.MER_AddBrightStarCol import AddBrightStarCol\n@@ -89,6 +90,7 @@ def add_gaia_match(workdir: str,\n             gaia_cutout_path = os.path.join(workdir, gaia_cutout_list[0])\n             gaia_cutout = dm_utils.read_product_metadata(gaia_cutout_path)\n             gaia_path = os.path.join(workdir, 'data', gaia_cutout.get_data())\n+            epoch = Time(\"2023.915\", format='jyear')\n             MER_position_crossmatch(catname_1 = final_cat_path,\n                                     ext_num_1 = 1,\n                                     ra_name_1 = \"RIGHT_ASCENSION\",\n@@ -106,6 +108,8 @@ def add_gaia_match(workdir: str,\n                                     output_path = final_cat_path,\n                                     matched_id_outputname = \"GAIA_ID\",\n                                     matched_quality_outputname = \"GAIA_MATCH_QUALITY\",\n+                                    pmcorr_2=True,\n+                                    epoch_1=epoch,\n                                     logger=logger)\n         elif len(gaia_cutout_list) == 0:\n             logger.info(\"# No gaia cutout given: skip cross matching the final catalog with Gaia\")\n",
                            "modified cross match calls to incorporate proper motion correction",
                            "yfang",
                            "2023-08-23T13:59:16.000+02:00",
                            "ae48a8a0752b9e2176e361800333edaed1606759"
                        ],
                        [
                            "@@ -47,8 +47,7 @@ def add_bright_star_col(workdir: str,\n         vis_mosaic_path = os.path.join(workdir, vis_mosaic)\n         vis_mosaic = dm_utils.read_product_metadata(vis_mosaic_path)\n         filter_name = vis_mosaic.get_filter()\n-        star_mask = vis_mosaic.get_extra_file(\"STAR-MASKS\")\n-        logger.info(f\"STAR-MASK json file: {star_mask}\")\n+        star_mask = vis_mosaic.get_bright_star_masks()\n         if star_mask:\n             bright_star_maks_path = os.path.join(workdir, \"data\", star_mask)\n             cat_modifier = AddBrightStarCol(final_cat_path,\n@@ -62,7 +61,7 @@ def add_bright_star_col(workdir: str,\n             nir_mosaic_path = os.path.join(workdir, nir_mosaic_file_name)\n             nir_mosaic = dm_utils.read_product_metadata(nir_mosaic_path)\n             filter_name = nir_mosaic.get_filter()\n-            star_mask = nir_mosaic.get_extra_file(\"STAR-MASKS\")\n+            star_mask = nir_mosaic.get_bright_star_masks()\n             if star_mask:\n                 bright_star_maks_path = os.path.join(workdir, \"data\", star_mask)\n                 cat_modifier = AddBrightStarCol(final_cat_path,\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_CatalogAssembly into develop",
                            "yfang",
                            "2023-08-18T14:02:03.000+02:00",
                            "47217754e2494cc8e0afd78a32a9472a8f4ff97c"
                        ],
                        [
                            "@@ -41,12 +41,14 @@ def add_bright_star_col(workdir: str,\n \n     final_cat_path = os.path.join(workdir, \"data\", final_cat)\n     logger.debug(f\"Final catalog path: {final_cat_path}\")\n+    logger.info(f\"Final catalog path: {final_cat_path}\")\n \n     if vis_mosaic:\n         vis_mosaic_path = os.path.join(workdir, vis_mosaic)\n         vis_mosaic = dm_utils.read_product_metadata(vis_mosaic_path)\n         filter_name = vis_mosaic.get_filter()\n         star_mask = vis_mosaic.get_extra_file(\"STAR-MASKS\")\n+        logger.info(f\"STAR-MASK json file: {star_mask}\")\n         if star_mask:\n             bright_star_maks_path = os.path.join(workdir, \"data\", star_mask)\n             cat_modifier = AddBrightStarCol(final_cat_path,\n",
                            "print debug info",
                            "yfang",
                            "2023-08-18T13:59:47.000+02:00",
                            "67a786bbdffc4d35fbc85c3ceb411a995e560a94"
                        ],
                        [
                            "@@ -46,7 +46,7 @@ def add_bright_star_col(workdir: str,\n         vis_mosaic_path = os.path.join(workdir, vis_mosaic)\n         vis_mosaic = dm_utils.read_product_metadata(vis_mosaic_path)\n         filter_name = vis_mosaic.get_filter()\n-        star_mask = vis_mosaic.get_extra_file(\"STAR-MASKS\")\n+        star_mask = vis_mosaic.get_bright_star_masks()\n         if star_mask:\n             bright_star_maks_path = os.path.join(workdir, \"data\", star_mask)\n             cat_modifier = AddBrightStarCol(final_cat_path,\n@@ -60,7 +60,7 @@ def add_bright_star_col(workdir: str,\n             nir_mosaic_path = os.path.join(workdir, nir_mosaic_file_name)\n             nir_mosaic = dm_utils.read_product_metadata(nir_mosaic_path)\n             filter_name = nir_mosaic.get_filter()\n-            star_mask = nir_mosaic.get_extra_file(\"STAR-MASKS\")\n+            star_mask = nir_mosaic.get_bright_star_masks()\n             if star_mask:\n                 bright_star_maks_path = os.path.join(workdir, \"data\", star_mask)\n                 cat_modifier = AddBrightStarCol(final_cat_path,\n",
                            "use new method to get the bright star masks files",
                            "Javier Gracia Carpio",
                            "2023-07-20T12:51:26.000+00:00",
                            "3dac371bc796428d95900e42dda4dce82b7243cc"
                        ]
                    ],
                    "CMakeLists.txt": [
                        [
                            "@@ -16,5 +16,5 @@ elements_project(MER_CatalogAssembly 10.2 USE Elements 6.2.1\n                                              MER_DA 10.2\n                                              MER_Classification 10.2\n                                              MER_DataModelUtils 10.2\n-                                             EL_Utils 1.4.1\n+                                             EL_Utils 1.5.1\n                                              LE3_GALEXT_ED 10.2)\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_CatalogAssembly into develop",
                            "yfang",
                            "2023-08-18T14:02:03.000+02:00",
                            "47217754e2494cc8e0afd78a32a9472a8f4ff97c"
                        ],
                        [
                            "@@ -16,5 +16,5 @@ elements_project(MER_CatalogAssembly 10.2 USE Elements 6.2.1\n                                              MER_DA 10.2\n                                              MER_Classification 10.2\n                                              MER_DataModelUtils 10.2\n-                                             EL_Utils 1.4.2\n+                                             EL_Utils 1.5.1\n                                              LE3_GALEXT_ED 10.2)\n",
                            "Use new EL_Utils version",
                            "Javier Gracia Carpio",
                            "2023-08-14T15:40:37.000+00:00",
                            "6587bae214e741fddb37f8a24f5e1ef29153c652"
                        ],
                        [
                            "@@ -16,5 +16,5 @@ elements_project(MER_CatalogAssembly 10.2 USE Elements 6.2.1\n                                              MER_DA 10.2\n                                              MER_Classification 10.2\n                                              MER_DataModelUtils 10.2\n-                                             EL_Utils 1.4.1\n+                                             EL_Utils 1.4.2\n                                              LE3_GALEXT_ED 10.2)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-08-11T15:51:37.000+00:00",
                            "6dd606b7e877da3e45a94e82f1393b6cb4d71368"
                        ],
                        [
                            "@@ -12,9 +12,9 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_CatalogAssembly 10.1 USE Elements 6.2.1\n-                                             MER_DA 10.1\n-                                             MER_Classification 10.1\n-                                             MER_DataModelUtils 10.1\n+elements_project(MER_CatalogAssembly 10.2 USE Elements 6.2.1\n+                                             MER_DA 10.2\n+                                             MER_Classification 10.2\n+                                             MER_DataModelUtils 10.2\n                                              EL_Utils 1.4.1\n-                                             LE3_GALEXT_ED 10.1)\n+                                             LE3_GALEXT_ED 10.2)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-07-03T14:17:37.000+00:00",
                            "37792dcfc2fe05eeaab95a9bb7e48fddb5bd5373"
                        ],
                        [
                            "@@ -12,9 +12,9 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(MER_CatalogAssembly 10.0 USE Elements 6.1.1\n-                                             MER_DA 10.0\n-                                             MER_Classification 10.0\n-                                             MER_DataModelUtils 10.0\n-                                             EL_Utils 1.3.1\n-                                             LE3_GALEXT_ED 10.0)\n+elements_project(MER_CatalogAssembly 10.1 USE Elements 6.2.1\n+                                             MER_DA 10.1\n+                                             MER_Classification 10.1\n+                                             MER_DataModelUtils 10.1\n+                                             EL_Utils 1.4.1\n+                                             LE3_GALEXT_ED 10.1)\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:59:46.000+00:00",
                            "9537b122fb961fd6b8965283c1c5275253143f9a"
                        ]
                    ],
                    "MER_CatalogAssembly/python/MER_CatalogAssembly/fill_catalog.py": [
                        [
                            "@@ -260,11 +260,12 @@ class FillCatalog(object):\n                                             stat_cat = self.cat_dict[key.replace('TPHOT', 'STATS')])\n                     self.finalcat_table.data[f\"FLUX_{self.convert_filter_name(key.split('.')[1])}_TEMPLFIT\"] = photcat.results[0]\n                     self.finalcat_table.data[f\"FLUXERR_{self.convert_filter_name(key.split('.')[1])}_TEMPLFIT\"] = photcat.results[1]\n+                ## COLOR wants the VIS ZP, i.e. 'PSF'\n                 elif \"COLOR\" in key:\n                     ## IF COLOR is NIR band it is VIS only!\n                     if 'NIR' in key:\n                         photcat.process_catalog(cat = self.cat_dict[key],\n-                                                zp = self.zp_dict[key],\n+                                                zp = self.zp_dict['PSF'],\n                                                 method = \"TPHOT\",\n                                                 idx_vis = idx_vis,\n                                                 stat_cat = self.cat_dict[key.replace('COLOR', 'STATS')])\n@@ -272,7 +273,7 @@ class FillCatalog(object):\n                         self.finalcat_table.data[f\"FLUXERR_VIS_TO_{self.convert_filter_name(key.split('.')[1])}_TEMPLFIT\"] = photcat.results[1]\n                     else:\n                         photcat.process_catalog(cat = self.cat_dict[key],\n-                                                zp = self.zp_dict[key],\n+                                                zp = self.zp_dict['PSF'],\n                                                 method = \"TPHOT\",\n                                                 stat_cat = self.cat_dict[key.replace('COLOR', 'STATS')])\n                         self.finalcat_table.data[f\"FLUX_VIS_TO_{self.convert_filter_name(key.split('.')[1])}_TEMPLFIT\"] = photcat.results[0]\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-MER/MER_CatalogAssembly into develop",
                            "yfang",
                            "2023-08-18T14:02:03.000+02:00",
                            "47217754e2494cc8e0afd78a32a9472a8f4ff97c"
                        ]
                    ],
                    "MER_CatalogAssembly/python/MER_CatalogAssembly/catalog_tailoring.py": [
                        [
                            "@@ -84,7 +84,7 @@ def split_final_cat_visnir(cat_file_name: str,\n     tmp_vis = os.path.join(data_dir, mer_filename(product='CAT', prefix='FINAL', filter1=\"VIS\", tile_index=tile_index, ext='fits'))\n \n     hdu_vis=fits.HDUList([fits.PrimaryHDU(), fits.BinTableHDU(vis)])\n-    hdu_vis.writeto(tmp_vis, clobber = True)\n+    hdu_vis.writeto(tmp_vis, overwrite = True)\n \n     logger.info('# > Creating region files...')\n     reg_file = Regionfile(tmp_vis,\n@@ -105,7 +105,7 @@ def split_final_cat_visnir(cat_file_name: str,\n         tmp_nir = os.path.join(data_dir, mer_filename(product='CAT', prefix='FINAL', filter1=\"NIR\", tile_index=tile_index, ext='fits'))\n \n         hdu_nir=fits.HDUList([fits.PrimaryHDU(), fits.BinTableHDU(nir)])\n-        hdu_nir.writeto(tmp_nir, clobber = True)\n+        hdu_nir.writeto(tmp_nir, overwrite = True)\n \n         logger.info('# > Creating region files...')\n         reg_file = Regionfile(tmp_nir,\n",
                            "Use overwrite instead of clobber",
                            "Javier Gracia Carpio",
                            "2023-06-25T12:15:37.000+00:00",
                            "2536a7ac8ea4da7539102fbe8c89978ac8b17654"
                        ]
                    ],
                    ".jenkinsFile": [
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\n-@Library('integration-library@release-9') _\n-pipelineElements(artifactId:\"MER_CatalogAssembly\", component:'eden.3.0')\n\\ No newline at end of file\n+@Library(value='integration-library@release-10') _\n+pipelineElements(name:\"MER_CatalogAssembly\", component:'eden.3.1')\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:59:46.000+00:00",
                            "9537b122fb961fd6b8965283c1c5275253143f9a"
                        ]
                    ],
                    "Makefile": [
                        [
                            "@@ -44,170 +44,19 @@\n #\n ################################################################################\n \n-# settings\n-CMAKE := cmake\n-CTEST := ctest\n-NINJA := $(shell which ninja-build 2> /dev/null)\n-ifeq ($(NINJA),)\n-  NINJA := $(shell which ninja 2> /dev/null)\n-endif\n-\n-# Looking for the Custom make library\n-\n-CUSTOM_MAKE_LIB := Custom.mk\n-\n-ifneq ($(wildcard $(CURDIR)/make/$(CUSTOM_MAKE_LIB)),)\n-  CUSTOM_MAKE_LIB_FILE := $(CURDIR)/make/$(CUSTOM_MAKE_LIB)\n-else\n-  ifneq ($(CMAKE_PREFIX_PATH),)\n-    PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    CUSTOM_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(CUSTOM_MAKE_LIB) $(dir)/../make/$(CUSTOM_MAKE_LIB)))\n-  endif\n-  CUSTOM_MAKE_LIB_LIST += /usr/share/Elements/make/$(CUSTOM_MAKE_LIB)\n-  CUSTOM_MAKE_LIB_FILE := $(firstword $(CUSTOM_MAKE_LIB_LIST))\n-endif\n-\n-# Looking for the ToolChain\n-\n-TOOLCHAIN_NAME := ElementsToolChain.cmake\n+ELEMENTS_MAKE_LIB := Elements.mk\n \n-ifneq ($(wildcard $(CURDIR)/cmake/$(TOOLCHAIN_NAME)),)\n-  TOOLCHAIN_FILE := $(CURDIR)/cmake/$(TOOLCHAIN_NAME)\n+ifneq ($(wildcard $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)),)\n+  ELEMENTS_MAKE_LIB_FILE := $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)\n else\n   ifneq ($(CMAKE_PREFIX_PATH),)\n     PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    TOOLCHAIN_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/lib*/cmake/ElementsProject/$(TOOLCHAIN_NAME) $(dir)/$(TOOLCHAIN_NAME)))\n-    TOOLCHAIN_FILE := $(firstword $(TOOLCHAIN_LIST))\n-  endif\n-endif\n-\n-override ALL_CMAKEFLAGS := -Wno-dev --no-warn-unused-cli\n-\n-ifneq ($(TOOLCHAIN_FILE),)\n-  # A toolchain has been found. Lets use it.\n-  override ALL_CMAKEFLAGS += -DCMAKE_TOOLCHAIN_FILE=$(TOOLCHAIN_FILE)\n-endif\n-\n-\n-BUILD_PREFIX_NAME := build\n-\n-override ALL_CMAKEFLAGS += -DUSE_LOCAL_INSTALLAREA=ON -DBUILD_PREFIX_NAME:STRING=$(BUILD_PREFIX_NAME)\n-override ALL_CMAKEFLAGS += -DUSE_VERSIONED_LIBRARIES=OFF\n-\n-ifndef BINARY_TAG\n-  ifdef CMAKECONFIG\n-    BINARY_TAG := ${CMAKECONFIG}\n-  else\n-    ifdef CMTCONFIG\n-      BINARY_TAG := ${CMTCONFIG}\n-    endif\n-  endif\n-endif\n-\n-ifdef BINARY_TAG\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME).$(BINARY_TAG)\n-else\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME)\n-endif\n-BUILDDIR := $(CURDIR)/$(BUILD_SUBDIR)\n-\n-# build tool\n-\n-ifneq ($(USE_NINJA),)\n-  # enable Ninja\n-  override ALL_CMAKEFLAGS += -GNinja\n-  BUILD_CONF_FILE := build.ninja\n-  BUILDFLAGS := $(NINJAFLAGS)\n-  ifneq ($(VERBOSE),)\n-    BUILDFLAGS := -v $(BUILDFLAGS)\n+    ELEMENTS_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(ELEMENTS_MAKE_LIB) $(dir)/../make/$(ELEMENTS_MAKE_LIB)))\n   endif\n-else\n-  BUILD_CONF_FILE := Makefile\n-endif\n-BUILD_CMD := $(CMAKE) --build $(BUILD_SUBDIR) --target\n-\n-\n-# Use environment variable for extra flags\n-\n-# Replace the \":\" from eclipse variable list to spaces  \n-ifneq ($(EXPAND_FLAGS),)\n-  CMAKEFLAGS := $(subst :-, -,$(CMAKEFLAGS))\n-endif\n-\n-ifneq ($(CMAKEFLAGS),)\n-  override ALL_CMAKEFLAGS += $(CMAKEFLAGS)\n+  ELEMENTS_MAKE_LIB_LIST += /usr/share/Elements/make/$(ELEMENTS_MAKE_LIB)\n+  ELEMENTS_MAKE_LIB_FILE := $(firstword $(ELEMENTS_MAKE_LIB_LIST))\n endif\n \n-# default target\n-all:\n-\n-# deep clean\n-purge:\n-\t$(RM) -r $(BUILDDIR) $(CURDIR)/InstallArea/$(BINARY_TAG)\n-\tfind $(CURDIR) \"(\" -name \"InstallArea\" -prune -o -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# Remove all the possible directories and the whole InstallArea as well\n-mrproper:\n-\t$(RM) -r $(CURDIR)/build $(CURDIR)/build.* $(CURDIR)/InstallArea\n-\tfind $(CURDIR) \"(\" -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# delegate any target to the build directory (except 'purge')\n-ifneq ($(MAKECMDGOALS),purge)\n-ifneq ($(MAKECMDGOALS),mrproper)\n-%: $(BUILDDIR)/$(BUILD_CONF_FILE) FORCE\n-\t+$(BUILD_CMD) $* -- $(BUILDFLAGS)\n-endif\n-endif\n-\n-# aliases\n-.PHONY: configure tests FORCE\n-ifneq ($(wildcard $(BUILDDIR)/$(BUILD_CONF_FILE)),)\n-configure: rebuild_cache\n-else\n-configure: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-endif\n-\t@ # do not delegate further\n-\n-\n-# This wrapping around the test target is used to ensure the generation of\n-# the XML output from ctest.\n-test: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-\n-# This target ensures that the \"all\" target is called before\n-# running the tests (unlike the \"test\" default target of CMake)\n-tests: all\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-ifeq ($(VERBOSE),)\n-# less verbose install\n-# (emulate the default CMake install target)\n-install: all\n-\tcd $(BUILDDIR) && $(CMAKE) -P cmake_install.cmake | grep -v \"^-- Up-to-date:\"\n-endif\n-\n-# import the library to look for a custom Makefile\n--include $(CUSTOM_MAKE_LIB_FILE)\n-\n-# ensure that the target are always passed to the CMake Makefile\n-FORCE: ;\n-\n-# Makefiles are used as implicit targets in make, but we should not consider\n-# them for delegation.\n-$(MAKEFILE_LIST): ;\n-\n-\n-# trigger CMake configuration\n-$(BUILDDIR)/$(BUILD_CONF_FILE): | $(BUILDDIR)\n-\tcd $(BUILDDIR) && $(CMAKE) $(ALL_CMAKEFLAGS) $(CURDIR)\n-\n-$(BUILDDIR):\n-\tmkdir -p $(BUILDDIR)\n+$(info Using the $(ELEMENTS_MAKE_LIB_FILE) make library)\n+include $(ELEMENTS_MAKE_LIB_FILE)\n \n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T22:59:46.000+00:00",
                            "9537b122fb961fd6b8965283c1c5275253143f9a"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "9.2.0",
                        "created_at": "2023-03-08T17:14:36.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.0",
                        "created_at": "2023-07-03T14:17:07.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.1",
                        "created_at": "2023-07-27T12:32:55.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.2",
                        "created_at": "2023-08-14T13:23:35.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    }
                ]
            },
            "PF-MER/MER_Pipeline": {
                "start date": "2023-06-09 09:00",
                "end date": "2023-08-23 15:00",
                "start tag": "> 9.1.0",
                "end tag": "> 10.1.1",
                "count_files_modified": "16",
                "modifications_by_file": {
                    "MER_MorphoPatch_Step/auxdir/morpho_patch_conf_nd.conf": [
                        [
                            "@@ -49,13 +49,12 @@ use-cleaning=false\n \n #assoc-copy=136,325,327,329,331\n #assoc-copy=136,325,327,329,331\n-assoc-copy=4\n-\n+#assoc-copy=4\n #assoc-radius=5\n-assoc-columns=2,3\n+#assoc-columns=2,3\n #assoc-mode=nearest\n assoc-filter=matched\n assoc-coord-type=WORLD\n assoc-default-pixel-size=25\n-assoc-group-id=9\n-assoc-source-sizes=8\n+#assoc-group-id=9\n+#assoc-source-sizes=8\n",
                            "Improved the structure and the style",
                            "Martin Kuemmel",
                            "2023-08-21T11:47:46.000+02:00",
                            "dff56eb3db0cbaf511f0a3f4efde9fccf7b45ece"
                        ],
                        [
                            "@@ -57,5 +57,5 @@ assoc-columns=2,3\n assoc-filter=matched\n assoc-coord-type=WORLD\n assoc-default-pixel-size=25\n-#assoc-group-id=7\n-assoc-source-sizes=6\n+assoc-group-id=9\n+assoc-source-sizes=8\n",
                            "Added a grouping according to the deblending",
                            "Martin Kuemmel",
                            "2023-08-20T20:30:09.000+02:00",
                            "507ae9a72530e9bbeb1cbe47e327dc317ec5bfde"
                        ],
                        [
                            "@@ -0,0 +1,61 @@\n+auto-kron-factor=2.5\n+auto-kron-min-radius=3.5\n+background-cell-size=1024\n+smoothing-box-size=3\n+#use-cleaning=0\n+cleaning-minimum-area=10\n+#core-threshold-value=1.3\n+#core-minimum-area=10\n+#partition-corethreshold=1\n+background-value=0.0\n+#detection-threshold=0.9\n+#detection-image-gain=0\n+#segmentation-use-filtering=1\n+#segmentation-filter=gauss_3.0_7x7.conv\n+#segmentation-lutz-window-size=500\n+#detection-image-interpolation=0\n+#detection-image-interpolation-gap=5\n+#detection-minimum-area=10\n+use-attractors-partition=0\n+#grouping-algorithm=moffat\n+#grouping-moffat-threshold=0.06\n+#grouping-moffat-max-distance=200\n+magnitude-zero-point=24.486630\n+tile-memory-limit=8192\n+tile-size=2048\n+model-fitting-iterations=120\n+model-fitting-engine=levmar\n+thread-count=1\n+#partition-multithreshold=0\n+#partition-threshold-count=32\n+#partition-minimum-area=10\n+#partition-minimum-contrast=0.005\n+output-catalog-format=FITS\n+output-properties=FlexibleModelFitting,AssocMode\n+output-flush-size=1000\n+output-flush-sorted=0\n+psf-fwhm=2.0\n+psf-pixel-sampling=0.5\n+#weight-absolute=1\n+#weight-type=rms\n+#weight-threshold=9.0E+15\n+weight-use-symmetry=1\n+progress-bar=0\n+\n+segmentation-algorithm=ASSOC\n+partition-multithreshold=false\n+grouping-algorithm=ASSOC\n+use-cleaning=false\n+\n+#assoc-copy=136,325,327,329,331\n+#assoc-copy=136,325,327,329,331\n+assoc-copy=4\n+\n+#assoc-radius=5\n+assoc-columns=2,3\n+#assoc-mode=nearest\n+assoc-filter=matched\n+assoc-coord-type=WORLD\n+assoc-default-pixel-size=25\n+#assoc-group-id=7\n+assoc-source-sizes=6\n",
                            "First draft to run SE++ on *all* objects",
                            "Martin Kuemmel",
                            "2023-08-16T13:57:02.000+02:00",
                            "87ee990613559c87f1e8d618209ac784c2585eb9"
                        ]
                    ],
                    "MER_MorphoPatch_Step/python/MER_MorphoPatch_Step/MER_MorphoPatch.py": [
                        [
                            "@@ -115,8 +115,8 @@ def mainMethod(args):\n                                                       logger = logger)\n \n     # edit the object_id column in the assoc catalog to avoid long to float conversion issues\n-    assoc_catalog, last_idx = MER_MorphoPatchUtils.generate_assoc_catalog(catalog = catalog,\n-                                                                          outdir = os.path.join(args.workdir, outdir))\n+    assoc_catalog, col_specs = MER_MorphoPatchUtils.generate_assoc_catalog(catalog = catalog,\n+                                                                           outdir = os.path.join(args.workdir, outdir))\n \n     # get conf from auxdir\n     configuration = getAuxiliaryPath('morpho_patch_conf_nd.conf')\n@@ -137,9 +137,12 @@ def mainMethod(args):\n     comm.extend(['--check-image-model-fitting', sepp_model_img])\n     comm.extend(['--check-image-residual', sepp_residual_img])\n     comm.extend(['--assoc-catalog', assoc_catalog])\n+    comm.extend(['--assoc-columns', '%i,%i' % (col_specs['assoc-columns'][0],col_specs['assoc-columns'][1])])\n+    comm.extend(['--assoc-source-sizes', '%i' % col_specs['assoc-source-sizes']])\n+    comm.extend(['--assoc-group-id', '%i' % col_specs['assoc-group-id']])\n+    comm.extend(['--assoc-copy', '%i' % col_specs['assoc-copy']])\n     comm.extend(['--tile-memory-limit', '17000'])\n     comm.extend(['--tile-size', '2048'])\n-    #comm.extend(['--assoc-copy', f'{last_idx}'])\n     comm.extend(['--thread-count', '%i'%MER_MorphoPatchUtils.get_threadcount_param(logger)])\n     comm.extend(['--log-level', 'INFO'])\n \n",
                            "Improved the structure and the style",
                            "Martin Kuemmel",
                            "2023-08-21T11:47:46.000+02:00",
                            "dff56eb3db0cbaf511f0a3f4efde9fccf7b45ece"
                        ],
                        [
                            "@@ -150,7 +150,7 @@ def mainMethod(args):\n                                         logger=logger)\n     ret_code = cmd.run()\n     if ret_code:\n-        err_msg = f'Return code for SourceXtractorPP run on {vis_detection_mosaic}'\n+        err_msg = 'Return code for SourceXtractorPP run on %s: %i' % (mf_images, ret_code)\n         raise Exception(err_msg)\n \n     # update and save the morphology catalog\n",
                            "Added a grouping according to the deblending",
                            "Martin Kuemmel",
                            "2023-08-20T20:30:09.000+02:00",
                            "507ae9a72530e9bbeb1cbe47e327dc317ec5bfde"
                        ],
                        [
                            "@@ -36,6 +36,8 @@ import ElementsKernel.Logging as log\n from ElementsKernel.Auxiliary import getAuxiliaryPath\n \n #from MER_DA.ExecuteCommand import ExecuteCommand\n+from MER_DA import MERUtilities\n+from MER_DA.MERUtilities import print_input_arguments\n from MER_DA import ExecuteCommand\n from MER_DataModelUtils import DmUtils as dm_utils\n from MER_DataModelUtils.FileNaming import mer_filename\n@@ -60,9 +62,6 @@ def defineSpecificProgramOptions():\n     parser.add_argument(\"--final_catalog\", dest=\"final_catalog\",\n                         type=str, help=\"Input MER final catalog data product.\")\n \n-    parser.add_argument(\"--vis_detection_mosaic\", dest=\"vis_detection_mosaic\",\n-                        type=str, help=\"Detection VIS mosaic\")\n-\n     parser.add_argument('--measurement_mosaics', type=str, dest='measurement_mosaics',\n                         required=False, help='Input json file with all the measurement '\n                         'mosaic XMLs', default=None)\n@@ -91,18 +90,15 @@ def mainMethod(args):\n     logger.info(\"# Entering MER_MorphoPatch mainMethod()\")\n     logger.info(\"#\")\n \n+    # print all parameters to the screen\n+    print_input_arguments(args, logger)\n+\n     # Store the start time\n     start_time = time.time()\n \n     outdir = os.path.dirname(args.updated_final_catalog)\n \n     # get VIS fits detection mosaic\n-    vis_detection_mosaic_path = os.path.join(args.workdir, args.vis_detection_mosaic)\n-    vis_detection_mosaic_dpd = dm_utils.read_product_metadata(vis_detection_mosaic_path)\n-    vis_detection_mosaic = os.path.join(args.workdir, 'data', vis_detection_mosaic_dpd.get_data())\n-    vis_detection_mosaic = MER_MorphoPatchUtils.unzip_data(vis_detection_mosaic, logger)\n-    detection_rms = os.path.join(args.workdir, 'data', vis_detection_mosaic_dpd.get_rms())      \n-    detection_rms = MER_MorphoPatchUtils.unzip_data(detection_rms, logger)   \n     measure_mosaic_list_path = os.path.join(args.workdir, args.measurement_mosaics)\n \n     # get catalog\n@@ -119,13 +115,13 @@ def mainMethod(args):\n                                                       logger = logger)\n \n     # edit the object_id column in the assoc catalog to avoid long to float conversion issues\n-    assoc_catalog, last_idx = MER_MorphoPatchUtils.updateID(catalog = catalog,\n-                                                            outdir = os.path.join(args.workdir, outdir))\n+    assoc_catalog, last_idx = MER_MorphoPatchUtils.generate_assoc_catalog(catalog = catalog,\n+                                                                          outdir = os.path.join(args.workdir, outdir))\n \n     # get conf from auxdir\n-    configuration = getAuxiliaryPath('morpho_patch_conf.conf')\n+    configuration = getAuxiliaryPath('morpho_patch_conf_nd.conf')\n     py_root = os.path.dirname(os.path.abspath(__file__))\n-    py_configuration = os.path.join(py_root, 'morpho_patch_conf.py')\n+    py_configuration = os.path.join(py_root, 'morpho_patch_conf_nd.py')\n     segmentation_filter = getAuxiliaryPath('gauss2.4.conv')\n \n     time_stamp = datetime.now().strftime(\"%Y%m%dT%H%M%S\")\n@@ -134,9 +130,6 @@ def mainMethod(args):\n     sepp_residual_img = os.path.join(args.workdir, outdir, 'residual.fits')\n \n     comm = [\"sourcextractor++\"]\n-    comm.extend(['--detection-image', vis_detection_mosaic])\n-    comm.extend(['--weight-image', detection_rms])\n-    comm.extend(['--segmentation-filter', segmentation_filter])\n     comm.extend(['--conf', configuration])\n     comm.extend([f'--python-config-file={py_configuration}'])\n     comm.extend(['--python-arg',f'mf_images={mf_images}'])\n@@ -146,10 +139,10 @@ def mainMethod(args):\n     comm.extend(['--assoc-catalog', assoc_catalog])\n     comm.extend(['--tile-memory-limit', '17000'])\n     comm.extend(['--tile-size', '2048'])\n-    comm.extend(['--assoc-copy', f'{last_idx}'])\n+    #comm.extend(['--assoc-copy', f'{last_idx}'])\n     comm.extend(['--thread-count', '%i'%MER_MorphoPatchUtils.get_threadcount_param(logger)])\n-    #comm.extend(['--log-level', args.log-level])\n-    \n+    comm.extend(['--log-level', 'INFO'])\n+\n     # run SE++\n     cmd = ExecuteCommand.ExecuteCommand('Morpho_SourceXtractorPP_run_%s'%time_stamp,\n                                         comm,\n",
                            "First draft to run SE++ on *all* objects",
                            "Martin Kuemmel",
                            "2023-08-16T13:57:02.000+02:00",
                            "87ee990613559c87f1e8d618209ac784c2585eb9"
                        ]
                    ],
                    "MER_MorphoPatch_Step/python/MER_MorphoPatch_Step/MER_MorphoPatchUtils.py": [
                        [
                            "@@ -47,35 +47,37 @@ def generate_assoc_catalog(catalog,\n \n     Returns:\n         assoc_catalog (str): Name of the updated catalog\n-        last_col_idx (int): Index of the last column\n+        col_specs (dict): Indices of columns to be funelled to SE++ \n     \"\"\"\n+    # define the columns to copy to the assoc table and store their index in a dict\n     transfer_columns = ['OBJECT_ID', 'RIGHT_ASCENSION', 'DECLINATION', 'FLUX_DETECTION_TOTAL', 'SEMIMAJOR_AXIS', 'PARENT_ID', 'PARENT_VISNIR']\n-    with fits.open(catalog) as hdul:\n-        orig_table = hdul[1].data\n+    col_specs = {'assoc-columns': [2,3], 'assoc-copy': 4}\n+    \n+    # get the input table\n+    with fits.open(catalog) as hdu_in:\n+        orig_table = hdu_in[1].data\n         orig_cols = orig_table.columns\n-        orig_names = orig_table.columns.names\n \n-    transfer_cols = []\n-    for act_name in transfer_columns:\n-        transfer_cols.append(orig_cols[act_name])\n+    # store the columns that are copied\n+    new_coldefs = fits.ColDefs([])\n+    for index in range(len(transfer_columns)):\n+        col_index = orig_cols.names.index(transfer_columns[index])\n+        new_coldefs.add_col(orig_cols[col_index])\n \n-    #transfer_cols.append(fits.ColDefs([\n-    #    fits.Column(name='SEPP_SIZE', format='D',\n-    #                array=3.0*orig_table['SEMIMAJOR_AXIS'])]))\n+    # create the size and group ID columns and store their indices\n     group_column = MER_AddGrouping(catalog, 'PARENT_ID', 'PARENT_VISNIR')\n-    new_cols = fits.ColDefs([fits.Column(name='SEPP_SIZE', format='D', array=3.0*orig_table['SEMIMAJOR_AXIS']),\n-                             group_column.get_grouping_column('GROUP_ID')])\n-    #hdu = fits.BinTableHDU.from_columns(orig_cols + new_cols)\n-    hdu = fits.BinTableHDU.from_columns(transfer_cols)\n-    old_cols = hdu.data.columns\n-    hdu2 = fits.BinTableHDU.from_columns(old_cols+new_cols)\n-    \n-    \n-    #hdu.data['SEMIMAJOR_AXIS'] = 3.0*hdu.data['SEMIMAJOR_AXIS']\n-    assoc_name = os.path.join(outdir, \"assoc_catalog.fits\")\n+    new_coldefs.add_col(fits.Column(name='SEPP_SIZE', format='D', array=3.0*orig_table['SEMIMAJOR_AXIS']))\n+    new_coldefs.add_col(group_column.get_grouping_column('GROUP_ID'))\n+    col_specs['assoc-source-sizes'] = 8\n+    col_specs['assoc-group-id'] = 9\n \n-    hdu2.writeto(assoc_name, overwrite=True)\n-    return assoc_name, len(orig_cols)+1\n+    # write the assoc table out    \n+    hdu_out = fits.BinTableHDU.from_columns(new_coldefs)\n+    assoc_name = os.path.join(outdir, \"assoc_catalog.fits\")\n+    hdu_out.writeto(assoc_name, overwrite=True)\n+    \n+    # return the table name and column indices    \n+    return assoc_name, col_specs\n \n def updateID(catalog,\n              outdir):\n@@ -262,20 +264,14 @@ class MER_AddGrouping(object):\n             # make the default array with no grouping\n             grouping_array = np.arange(len(parent_id))\n \n-            #print(grouping_array)\n             # find the parent ID numbers and the inverse unique\n             unique_ids, unique_inverse = np.unique(parent_id, return_inverse=True)\n-            #print(unique_ids)\n-            #print(len(unique_ids))\n-            #print(unique_inverse)\n-            #print(len(unique_inverse))\n \n             # start the index marking groups\n             # browse through all parent ID numbers\n             group_index = len(grouping_array)\n             for act_group in range(2, len(unique_ids)):\n \n-                #print(unique_ids[act_group])\n                 # populate the group member objects with the new group ID\n                 grouping_array[np.where(unique_inverse==act_group)] = group_index\n                 group_index+=1\n",
                            "Improved the structure and the style",
                            "Martin Kuemmel",
                            "2023-08-21T11:47:46.000+02:00",
                            "dff56eb3db0cbaf511f0a3f4efde9fccf7b45ece"
                        ],
                        [
                            "@@ -49,7 +49,7 @@ def generate_assoc_catalog(catalog,\n         assoc_catalog (str): Name of the updated catalog\n         last_col_idx (int): Index of the last column\n     \"\"\"\n-    transfer_columns = ['OBJECT_ID', 'RIGHT_ASCENSION', 'DECLINATION', 'FLUX_DETECTION_TOTAL', 'SEMIMAJOR_AXIS']\n+    transfer_columns = ['OBJECT_ID', 'RIGHT_ASCENSION', 'DECLINATION', 'FLUX_DETECTION_TOTAL', 'SEMIMAJOR_AXIS', 'PARENT_ID', 'PARENT_VISNIR']\n     with fits.open(catalog) as hdul:\n         orig_table = hdul[1].data\n         orig_cols = orig_table.columns\n@@ -62,9 +62,9 @@ def generate_assoc_catalog(catalog,\n     #transfer_cols.append(fits.ColDefs([\n     #    fits.Column(name='SEPP_SIZE', format='D',\n     #                array=3.0*orig_table['SEMIMAJOR_AXIS'])]))\n-    new_cols = fits.ColDefs([\n-        fits.Column(name='SEPP_SIZE', format='D',\n-                    array=3.0*orig_table['SEMIMAJOR_AXIS'])])\n+    group_column = MER_AddGrouping(catalog, 'PARENT_ID', 'PARENT_VISNIR')\n+    new_cols = fits.ColDefs([fits.Column(name='SEPP_SIZE', format='D', array=3.0*orig_table['SEMIMAJOR_AXIS']),\n+                             group_column.get_grouping_column('GROUP_ID')])\n     #hdu = fits.BinTableHDU.from_columns(orig_cols + new_cols)\n     hdu = fits.BinTableHDU.from_columns(transfer_cols)\n     old_cols = hdu.data.columns\n@@ -225,3 +225,88 @@ def get_threadcount_param(logger):\n         logger.info('Threadcount set to maxvalue: %i!'%n_threads)\n     return n_threads\n \n+class MER_AddGrouping(object):\n+    \"\"\"\n+    \"\"\"\n+    def __init__(self, table_name, id_col_one, id_col_two=None, logger=None):\n+        \"\"\"\n+        \"\"\"\n+        # save all the input params\n+        self._table_name = table_name\n+        self._id_col_one = id_col_one\n+        self._od_col_two = id_col_two\n+        self._logger = logger\n+\n+        # compute the grouoing array\n+        self._grouping_array = self._make_grouping_array(table_name, id_col_one)\n+        \n+    def _info(self, message):\n+        \"\"\"General feedback method\n+        \"\"\"\n+        # push to the logger if existing\n+        if self._logger is not None:\n+            self._logger.info('# %s' % message)\n+        else:\n+            # push to stdout\n+            print('# %s'%message)\n+\n+    def _make_grouping_array(self, table_name, id_col_one):\n+        \"\"\"\n+        \"\"\"\n+        # open the table\n+        with fits.open(table_name) as table_fits:\n+\n+            # read in the column with parent ids\n+            parent_id = table_fits[1].data[id_col_one]\n+\n+            # make the default array with no grouping\n+            grouping_array = np.arange(len(parent_id))\n+\n+            #print(grouping_array)\n+            # find the parent ID numbers and the inverse unique\n+            unique_ids, unique_inverse = np.unique(parent_id, return_inverse=True)\n+            #print(unique_ids)\n+            #print(len(unique_ids))\n+            #print(unique_inverse)\n+            #print(len(unique_inverse))\n+\n+            # start the index marking groups\n+            # browse through all parent ID numbers\n+            group_index = len(grouping_array)\n+            for act_group in range(2, len(unique_ids)):\n+\n+                #print(unique_ids[act_group])\n+                # populate the group member objects with the new group ID\n+                grouping_array[np.where(unique_inverse==act_group)] = group_index\n+                group_index+=1\n+\n+            # return the grouping array\n+            return grouping_array\n+\n+    def get_grouping_column(self, group_colname='GROUP_ID'):\n+        \"\"\"\n+        \"\"\"\n+        # return the grouping values as fits column\n+        return fits.Column(name=group_colname, array=self._grouping_array, format='K')\n+\n+    def write_group_id(self, group_colname='GROUP_ID', out_table=None):\n+        \"\"\"\n+        \"\"\"\n+        # open the fits table\n+        with fits.open(self._table_name) as table_fits:\n+            # save the original columns and ensure that the \n+            # new group column can be built\n+            old_columns = table_fits[1].data.columns\n+            if group_colname in old_columns.names:\n+                err_msg = \"Columns: %s exists already in table: %s\" % (group_colname, self._table_name)\n+                raise Exception(err_msg)\n+\n+            # compose and save the new table\n+            group_columns = fits.ColDefs([fits.Column(name=group_colname, array=self._grouping_array, format='1J')])\n+            new_hdu = fits.BinTableHDU.from_columns(old_columns + group_columns)\n+            if out_table is None:\n+                out_table = self._table_name\n+            new_hdu.writeto(out_table, overwrite=True)\n+\n+        return out_table\n+    \n\\ No newline at end of file\n",
                            "Added a grouping according to the deblending",
                            "Martin Kuemmel",
                            "2023-08-20T20:30:09.000+02:00",
                            "507ae9a72530e9bbeb1cbe47e327dc317ec5bfde"
                        ],
                        [
                            "@@ -36,6 +36,47 @@ from MER_DataModelUtils import DmUtils as dm_utils\n \n NMAX_THREAD=4\n \n+def generate_assoc_catalog(catalog,\n+                           outdir):\n+    \"\"\"\n+    Append the local assoc_id column of the association catalog\n+    to avoid long int to float conversion issues\n+\n+    Args:\n+            catalog (str): the input assoc catalog\n+\n+    Returns:\n+        assoc_catalog (str): Name of the updated catalog\n+        last_col_idx (int): Index of the last column\n+    \"\"\"\n+    transfer_columns = ['OBJECT_ID', 'RIGHT_ASCENSION', 'DECLINATION', 'FLUX_DETECTION_TOTAL', 'SEMIMAJOR_AXIS']\n+    with fits.open(catalog) as hdul:\n+        orig_table = hdul[1].data\n+        orig_cols = orig_table.columns\n+        orig_names = orig_table.columns.names\n+\n+    transfer_cols = []\n+    for act_name in transfer_columns:\n+        transfer_cols.append(orig_cols[act_name])\n+\n+    #transfer_cols.append(fits.ColDefs([\n+    #    fits.Column(name='SEPP_SIZE', format='D',\n+    #                array=3.0*orig_table['SEMIMAJOR_AXIS'])]))\n+    new_cols = fits.ColDefs([\n+        fits.Column(name='SEPP_SIZE', format='D',\n+                    array=3.0*orig_table['SEMIMAJOR_AXIS'])])\n+    #hdu = fits.BinTableHDU.from_columns(orig_cols + new_cols)\n+    hdu = fits.BinTableHDU.from_columns(transfer_cols)\n+    old_cols = hdu.data.columns\n+    hdu2 = fits.BinTableHDU.from_columns(old_cols+new_cols)\n+    \n+    \n+    #hdu.data['SEMIMAJOR_AXIS'] = 3.0*hdu.data['SEMIMAJOR_AXIS']\n+    assoc_name = os.path.join(outdir, \"assoc_catalog.fits\")\n+\n+    hdu2.writeto(assoc_name, overwrite=True)\n+    return assoc_name, len(orig_cols)+1\n+\n def updateID(catalog,\n              outdir):\n     \"\"\"\n@@ -64,7 +105,6 @@ def updateID(catalog,\n     hdu.writeto(assoc_name, overwrite=True)\n     return assoc_name, len(orig_cols)+1\n \n-\n def adapt_psf_to_sepp(psf_path, logger):\n     \"\"\" Adapts the PSF to work with SE++\n     \"\"\"\n",
                            "First draft to run SE++ on *all* objects",
                            "Martin Kuemmel",
                            "2023-08-16T13:57:02.000+02:00",
                            "87ee990613559c87f1e8d618209ac784c2585eb9"
                        ]
                    ],
                    "CMakeLists.txt": [
                        [
                            "@@ -18,4 +18,4 @@ elements_project(MER_Pipeline 10.2 USE Elements 6.2.1\n \t                                  MER_PsfMosaic 10.2\n                                       MER_PSFHomogenization 10.2\n                                       CP_PositionCrossMatch 2.2\n-                                      SourceXtractorPlusPlus 0.2)\n+                                      SourceXtractorPlusPlus 0.20)\n",
                            "First draft to run SE++ on *all* objects",
                            "Martin Kuemmel",
                            "2023-08-16T13:57:02.000+02:00",
                            "87ee990613559c87f1e8d618209ac784c2585eb9"
                        ],
                        [
                            "@@ -11,11 +11,11 @@ find_package(ElementsProject)\n # Example with dependency:\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n-elements_project(MER_Pipeline 10.1 USE Elements 6.2.1\n-                                      MER_DataModelUtils 10.1\n-                                      MER_DA 10.1\n-                                      MER_Mosaicing 10.1\n-\t                                  MER_PsfMosaic 10.1\n-                                      MER_PSFHomogenization 10.1\n-                                      CP_PositionCrossMatch 2.1\n+elements_project(MER_Pipeline 10.2 USE Elements 6.2.1\n+                                      MER_DataModelUtils 10.2\n+                                      MER_DA 10.2\n+                                      MER_Mosaicing 10.2\n+\t                                  MER_PsfMosaic 10.2\n+                                      MER_PSFHomogenization 10.2\n+                                      CP_PositionCrossMatch 2.2\n                                       SourceXtractorPlusPlus 0.2)\n",
                            "Update CMakeLists.txt",
                            "Javier Gracia Carpio",
                            "2023-07-03T17:02:01.000+00:00",
                            "39a0a16308446529e5ec2a25ebf5dd2eb0629aa6"
                        ],
                        [
                            "@@ -11,11 +11,11 @@ find_package(ElementsProject)\n # Example with dependency:\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n-elements_project(MER_Pipeline 10.0 USE Elements 6.1.1\n-                                      MER_DataModelUtils 10.0\n-                                      MER_DA 10.0\n-                                      MER_Mosaicing 10.0\n-\t                                  MER_PsfMosaic 10.0\n-                                      MER_PSFHomogenization 10.0\n-                                      CP_PositionCrossMatch 2.0\n-                                      SourceXtractorPlusPlus 0.20)\n+elements_project(MER_Pipeline 10.1 USE Elements 6.2.1\n+                                      MER_DataModelUtils 10.1\n+                                      MER_DA 10.1\n+                                      MER_Mosaicing 10.1\n+\t                                  MER_PsfMosaic 10.1\n+                                      MER_PSFHomogenization 10.1\n+                                      CP_PositionCrossMatch 2.1\n+                                      SourceXtractorPlusPlus 0.2)\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T23:34:51.000+00:00",
                            "a24e22ee23f8558127eb3da064d6f83c281a8a7c"
                        ]
                    ],
                    "MER_MorphoPatch_Step/python/MER_MorphoPatch_Step/morpho_patch_conf_nd.py": [
                        [
                            "@@ -0,0 +1,95 @@\n+import numpy as np\n+import json\n+from sourcextractor.config import *\n+\n+REFMAG_AB = 23.9\n+\n+# read out the field name\n+args = Arguments(mf_images=\"mf_images\")\n+\n+measurement_images = list()\n+mag_zeropoints = dict()\n+jy_conversion = dict()\n+\n+with open(args.mf_images, 'r') as f:\n+    mf_images = json.load(f)   \n+\n+for image in mf_images:\n+    measurement_images.append(MeasurementImage(fits_file=image['img'],\n+                                               weight_file=image['rms'],\n+                                               psf_file=image['psf'],\n+                                               weight_type='rms',\n+                                               weight_absolute=1, \n+                                               weight_threshold=1.E+15,\n+                                               constant_background=0.0,\n+                                               gain=0.0))\n+    mag_zeropoints[image['filter']] = image['zp']\n+    jy_conversion[image['filter']] = np.power(10, 0.4*(REFMAG_AB-image['zp']))\n+\n+# sort the measurement images\n+top = ImageGroup(images=measurement_images)\n+top.split(ByKeyword('FILTER'))\n+mesgroup = MeasurementGroup(top)\n+\n+set_max_iterations(100)\n+set_engine('levmar')\n+\n+# define the sersic parameters\n+sersic_radius = FreeParameter(2.0, Range((1.0,20.0), RangeType.EXPONENTIAL))\n+#sersic_radius = FreeParameter(lambda o: o.radius, Range(lambda v, o: (.1 * v, 10*v), RangeType.EXPONENTIAL))\n+sersic = FreeParameter(1.0, Range((0.3, 5.5), RangeType.LINEAR))\n+\n+# this deals with sersic ratio and orientation;\n+# it is not clear whether a direct approach is better\n+e1 = FreeParameter( 0.0, Range((-0.9999, 0.9999), RangeType.LINEAR))\n+e2 = FreeParameter( 0.0, Range((-0.9999, 0.9999), RangeType.LINEAR))\n+emod = DependentParameter( lambda x,y: np.sqrt( x*x + y*y ), e1, e2 )\n+angle = DependentParameter( lambda e1,e2 : 0.5*np.arctan2( e1, e2 ), e1, e2 )\n+angle_deg = DependentParameter(lambda x: np.fmod(x,np.pi/2.0)/np.pi*180.0, angle)\n+sersic_ratio = DependentParameter( lambda e : np.abs(1-e)/(1+e), emod )\n+add_prior( e1, 0.0, 0.3 )\n+add_prior( e2, 0.0, 0.3 )\n+\n+# initialize the positions\n+#x,y = get_pos_parameters()\n+x = FreeParameter(lambda o: o.centroid_x)\n+y = FreeParameter(lambda o: o.centroid_y)\n+ra,dec = get_world_position_parameters(x, y)\n+flux = {}\n+mag = {}\n+flux_mujy = {}\n+\n+i=0\n+for band, group in mesgroup:\n+\n+    # initialize the flux\n+    #flux = get_flux_parameter()\n+    flux[i] = FreeParameter(lambda o: o.assoc_value_0)\n+    #flux[i] = FreeParameter(10.)\n+\n+    # create AB mag as a dependent parameter\n+    mag[i] = DependentParameter( lambda f, zp=mag_zeropoints[band]: -2.5 * np.log10(f) + zp, flux[i])\n+\n+    #flux_mujy = DependentParameter( lambda f, zp=mag_zeropoints[band]: flux * np.power(10, 0.4*(REFMAG_AB-zp)), flux)\n+    flux_mujy[i] = DependentParameter( lambda f, scale=jy_conversion[band]: f * scale, flux[i])\n+\n+    #self.results[1] *= np.power(10, 0.4*(self.refmag - zp))\n+\n+    # add the exponential and the Sersic model\n+    add_model(group, SersicModel(x, y, flux[i], sersic_radius, sersic_ratio, angle, sersic))\n+\n+    # add the photometry columns for the current band\n+    add_output_column('flux_%s'%str(band), flux[i])\n+    add_output_column('mag_%s'%str(band), mag[i])\n+    add_output_column('flux_mujy_%s'%str(band), flux_mujy[i])\n+    i+=1\n+\n+# add the morphology columns\n+add_output_column('x', x)\n+add_output_column('y', y)\n+add_output_column('ra', ra)\n+add_output_column('dec', dec)\n+add_output_column('sersic_radius', sersic_radius)\n+add_output_column('sersic_ratio', sersic_ratio)\n+add_output_column('sersic', sersic)\n+add_output_column('angle_deg', angle_deg)\n",
                            "First draft to run SE++ on *all* objects",
                            "Martin Kuemmel",
                            "2023-08-16T13:57:02.000+02:00",
                            "87ee990613559c87f1e8d618209ac784c2585eb9"
                        ]
                    ],
                    "MER_Mosaicing_Step/python/MER_Mosaicing_Step/MER_Mosaicing.py": [
                        [
                            "@@ -41,7 +41,7 @@ from MER_DataModelUtils import ExtDmUtils as ext_utils\n from MER_DataModelUtils import MerDmUtils as mer_utils\n from MER_DataModelUtils.FileNaming import mer_filename\n from MER_SingCombine.ImageCombiner import ImageCombiner\n-from MER_SingCombine.BrightStars import BrightStars\n+#from MER_SingCombine.BrightStars import BrightStars\n \n def defineSpecificProgramOptions():\n     \"\"\"Defines the command line input and output parameters specific to this\n@@ -169,7 +169,41 @@ def extract_zero_points(product):\n \n     return zero_points\n \n+def bright_star_setup(workdir, gaia_cutouts, mosaicing_parameters, filter_name, logger):\n+    \"\"\"Generates the setup for the bright star masking\n+    \"\"\"\n+    gaia_cutout_file = 'no.file'\n+    bright_star_template = None\n+\n+    # Calculate the bright stars masking\n+    if (\"bright_star_masking\" in mosaicing_parameters) and mosaicing_parameters[\"bright_star_masking\"]:\n+        with open(os.path.join(workdir, gaia_cutouts), 'r') as gaia_cutouts_list_file:\n+            gaia_cutout_list = json.load(gaia_cutouts_list_file)\n+        if len(gaia_cutout_list) == 1:\n+            gaia_cutout_xml = gaia_cutout_list[0]\n+            if filter_name in ['VIS', 'NIR_Y', 'NIR_J', 'NIR_H']:\n+\n+                # get the GAIA catalog and the correct template\n+                gaia_cutout = dm_utils.read_product_metadata(\n+                    os.path.join(workdir, gaia_cutout_xml))\n+                gaia_cutout_file = gaia_cutout.get_data()\n+                if filter_name in ['VIS']:\n+                    bright_star_template = mosaicing_parameters['bright_star_template_vis']\n+                elif filter_name in ['NIR_Y', 'NIR_J', 'NIR_H']:\n+                    bright_star_template = mosaicing_parameters['bright_star_template_nir']\n+\n+                logger.info(\"# Bright Stars Masking for filter %s, GAIA: %s, template: %s\" % (filter_name, gaia_cutout_file, bright_star_template))\n \n+        elif len(gaia_cutout_list) == 0:\n+            logger.info(\"# Skip Bright Stars Masking\")\n+        else:\n+            logger.info(\"# There are multiple Gaia cutout tables: skip bright stars masking!\")\n+    else:\n+        logger.info(\"# Skip Bright Stars Masking\")\n+    \n+    # return bright star files\n+    return gaia_cutout_file, bright_star_template\n+        \n def mainMethod(args):\n     \"\"\" The \"main\" method.\n \n@@ -215,7 +249,9 @@ def mainMethod(args):\n \n     # Create the directory to run Swarp if it doesn't exist\n     if not os.path.exists(swarp_path):\n-        os.mkdir(swarp_path)\n+        #os.mkdir(swarp_path)\n+        os.makedirs(swarp_path)\n+        logger.debug('# Created SWARP dir: %s'%swarp_path)\n \n     # Get the tile index from the tile product\n     tile_file_name = os.path.join(args.workdir, args.tile)\n@@ -325,6 +361,10 @@ def mainMethod(args):\n         \"PSF\", prefix=psf_prefix, filter1=filter_name, tile_index=tile_index)\n     mosaic_bps_file_name = mer_filename(\n         'FILTER-TRANSMISSION', filter1=filter_name, tile_index=tile_index)\n+    mosaic_mask_file_name = mer_filename(\"STAR-MASKS\", filter1=filter_name, tile_index=tile_index, ext='json')\n+\n+    # generate the bright star masking setup\n+    gaia_cutout_file, bright_star_template = bright_star_setup(args.workdir, args.gaia_cutouts, mosaicing_parameters, filter_name, logger)\n \n     # Produce the mosaic fits files combining all the input products\n     image_combiner.produce_mosaic(\n@@ -332,7 +372,10 @@ def mainMethod(args):\n         os.path.join(data_path, mosaic_rms_file_name),\n         os.path.join(data_path, mosaic_flag_file_name),\n         os.path.join(data_path, mosaic_psf_file_name),\n-        os.path.join(data_path, mosaic_bps_file_name))\n+        os.path.join(data_path, mosaic_bps_file_name),\n+        os.path.join(data_path, mosaic_mask_file_name),\n+        os.path.join(data_path, gaia_cutout_file),\n+        bright_star_template)\n \n     # Create the mosaic XML file\n     mosaic = mer_utils.create_mosaic(telescope, instrument, filter_name)\n@@ -362,6 +405,8 @@ def mainMethod(args):\n     mosaic.set_observation_id_list(observation_ids)\n     mosaic.set_calblock_id_list(calblock_ids)\n     mosaic.set_processing_mode(processing_mode)\n+    if bright_star_template is not None:\n+        mosaic.set_bright_star_masks(mosaic_mask_file_name)\n \n     # Calculate the quality parameters\n     mosaic.calculate_quality_parameters(\n@@ -373,40 +418,6 @@ def mainMethod(args):\n         os.path.join(args.workdir, args.flag_limits))\n     mosaic.calculate_quality_flags(flag_limits)\n \n-    # Calculate the bright stars masking\n-    if (\"bright_star_masking\" in mosaicing_parameters) and mosaicing_parameters[\"bright_star_masking\"]:\n-        with open(os.path.join(args.workdir, args.gaia_cutouts), 'r') as gaia_cutouts_list_file:\n-            gaia_cutout_list = json.load(gaia_cutouts_list_file)\n-        if len(gaia_cutout_list) == 1:\n-            gaia_cutout_xml = gaia_cutout_list[0]\n-            if filter_name in ['VIS', 'NIR_Y', 'NIR_J', 'NIR_H']:\n-                logger.info(\"# Bright Stars Masking for %s filter\" % filter_name)\n-                mask_output_filename = mer_filename(\"STAR-MASKS\", filter1=filter_name, tile_index=tile_index, ext='json')\n-                mosaic.set_bright_star_masks(mask_output_filename)\n-                output_file_path = os.path.join(data_path, mask_output_filename)\n-                logger.info(\"# Step path = %s\"%swarp_path)\n-\n-                gaia_cutout = dm_utils.read_product_metadata(\n-                    os.path.join(args.workdir, gaia_cutout_xml))\n-                gaia_cutout_path = os.path.join(data_path, gaia_cutout.get_data())\n-\n-                if filter_name in ['VIS']:\n-                    template_file_name = mosaicing_parameters['bright_star_template_vis']\n-                elif filter_name in ['NIR_Y', 'NIR_J', 'NIR_H']:\n-                    template_file_name = mosaicing_parameters['bright_star_template_nir']\n-\n-                bright_stars = BrightStars(\n-                    filter_name, os.path.join(swarp_path, 'sciData.lis'),\n-                    tile_file_name, gaia_cutout_path, template_file_name,\n-                    swarp_path, output_file_path, log_path, logger)\n-                bright_stars.run()\n-        elif len(gaia_cutout_list) == 0:\n-            logger.info(\"# Skip Bright Stars Masking\")\n-        else:\n-            logger.info(\"# There are multiple Gaia cutout tables: skip bright stars masking!\")\n-    else:\n-        logger.info(\"# Skip Bright Stars Masking\")\n-    \n     # Save the mosaic XML file\n     mosaic.save_xml(os.path.join(args.workdir, args.mosaic))\n \n",
                            "Merge branch 'feature/low_diskspace' into 'develop'",
                            "Javier Gracia Carpio",
                            "2023-08-11T12:41:26.000+00:00",
                            "eec346d251813e54e96b04d72d9ef0d5a94830e4"
                        ],
                        [
                            "@@ -182,17 +182,18 @@ def bright_star_setup(workdir, gaia_cutouts, mosaicing_parameters, filter_name,\n         if len(gaia_cutout_list) == 1:\n             gaia_cutout_xml = gaia_cutout_list[0]\n             if filter_name in ['VIS', 'NIR_Y', 'NIR_J', 'NIR_H']:\n-                logger.info(\"# Bright Stars Masking for %s filter\" % filter_name)\n \n+                # get the GAIA catalog and the correct template\n                 gaia_cutout = dm_utils.read_product_metadata(\n                     os.path.join(workdir, gaia_cutout_xml))\n                 gaia_cutout_file = gaia_cutout.get_data()\n-\n                 if filter_name in ['VIS']:\n                     bright_star_template = mosaicing_parameters['bright_star_template_vis']\n                 elif filter_name in ['NIR_Y', 'NIR_J', 'NIR_H']:\n                     bright_star_template = mosaicing_parameters['bright_star_template_nir']\n \n+                logger.info(\"# Bright Stars Masking for filter %s, GAIA: %s, template: %s\" % (filter_name, gaia_cutout_file, bright_star_template))\n+\n         elif len(gaia_cutout_list) == 0:\n             logger.info(\"# Skip Bright Stars Masking\")\n         else:\n@@ -362,9 +363,8 @@ def mainMethod(args):\n         'FILTER-TRANSMISSION', filter1=filter_name, tile_index=tile_index)\n     mosaic_mask_file_name = mer_filename(\"STAR-MASKS\", filter1=filter_name, tile_index=tile_index, ext='json')\n \n+    # generate the bright star masking setup\n     gaia_cutout_file, bright_star_template = bright_star_setup(args.workdir, args.gaia_cutouts, mosaicing_parameters, filter_name, logger)\n-    logger.info('# --> %s'%gaia_cutout_file)\n-    logger.info('# --> %s'%bright_star_template)\n \n     # Produce the mosaic fits files combining all the input products\n     image_combiner.produce_mosaic(\n@@ -418,42 +418,6 @@ def mainMethod(args):\n         os.path.join(args.workdir, args.flag_limits))\n     mosaic.calculate_quality_flags(flag_limits)\n \n-    \"\"\"\n-    # Calculate the bright stars masking\n-    if (\"bright_star_masking\" in mosaicing_parameters) and mosaicing_parameters[\"bright_star_masking\"]:\n-        with open(os.path.join(args.workdir, args.gaia_cutouts), 'r') as gaia_cutouts_list_file:\n-            gaia_cutout_list = json.load(gaia_cutouts_list_file)\n-        if len(gaia_cutout_list) == 1:\n-            gaia_cutout_xml = gaia_cutout_list[0]\n-            if filter_name in ['VIS', 'NIR_Y', 'NIR_J', 'NIR_H']:\n-                logger.info(\"# Bright Stars Masking for %s filter\" % filter_name)\n-                mask_output_filename = mer_filename(\"STAR-MASKS\", filter1=filter_name, tile_index=tile_index, ext='json')\n-                mosaic.set_bright_star_masks(mask_output_filename)\n-                output_file_path = os.path.join(data_path, mask_output_filename)\n-                logger.info(\"# Step path = %s\"%swarp_path)\n-\n-                gaia_cutout = dm_utils.read_product_metadata(\n-                    os.path.join(args.workdir, gaia_cutout_xml))\n-                gaia_cutout_path = os.path.join(data_path, gaia_cutout.get_data())\n-\n-                if filter_name in ['VIS']:\n-                    template_file_name = mosaicing_parameters['bright_star_template_vis']\n-                elif filter_name in ['NIR_Y', 'NIR_J', 'NIR_H']:\n-                    template_file_name = mosaicing_parameters['bright_star_template_nir']\n-\n-                bright_stars = BrightStars(\n-                    filter_name, os.path.join(swarp_path, 'sciData.lis'),\n-                    tile_file_name, gaia_cutout_path, template_file_name,\n-                    swarp_path, output_file_path, logger)\n-                bright_stars.run()\n-        elif len(gaia_cutout_list) == 0:\n-            logger.info(\"# Skip Bright Stars Masking\")\n-        else:\n-            logger.info(\"# There are multiple Gaia cutout tables: skip bright stars masking!\")\n-    else:\n-        logger.info(\"# Skip Bright Stars Masking\")\n-    \"\"\"\n-\n     # Save the mosaic XML file\n     mosaic.save_xml(os.path.join(args.workdir, args.mosaic))\n \n",
                            "That should work now.",
                            "Martin Kuemmel",
                            "2023-08-10T18:23:28.000+02:00",
                            "61beb1095aee0941f00479b8cbd077cf2c108d1b"
                        ],
                        [
                            "@@ -41,7 +41,7 @@ from MER_DataModelUtils import ExtDmUtils as ext_utils\n from MER_DataModelUtils import MerDmUtils as mer_utils\n from MER_DataModelUtils.FileNaming import mer_filename\n from MER_SingCombine.ImageCombiner import ImageCombiner\n-from MER_SingCombine.BrightStars import BrightStars\n+#from MER_SingCombine.BrightStars import BrightStars\n \n def defineSpecificProgramOptions():\n     \"\"\"Defines the command line input and output parameters specific to this\n@@ -169,7 +169,40 @@ def extract_zero_points(product):\n \n     return zero_points\n \n+def bright_star_setup(workdir, gaia_cutouts, mosaicing_parameters, filter_name, logger):\n+    \"\"\"Generates the setup for the bright star masking\n+    \"\"\"\n+    gaia_cutout_file = 'no.file'\n+    bright_star_template = None\n+\n+    # Calculate the bright stars masking\n+    if (\"bright_star_masking\" in mosaicing_parameters) and mosaicing_parameters[\"bright_star_masking\"]:\n+        with open(os.path.join(workdir, gaia_cutouts), 'r') as gaia_cutouts_list_file:\n+            gaia_cutout_list = json.load(gaia_cutouts_list_file)\n+        if len(gaia_cutout_list) == 1:\n+            gaia_cutout_xml = gaia_cutout_list[0]\n+            if filter_name in ['VIS', 'NIR_Y', 'NIR_J', 'NIR_H']:\n+                logger.info(\"# Bright Stars Masking for %s filter\" % filter_name)\n+\n+                gaia_cutout = dm_utils.read_product_metadata(\n+                    os.path.join(workdir, gaia_cutout_xml))\n+                gaia_cutout_file = gaia_cutout.get_data()\n+\n+                if filter_name in ['VIS']:\n+                    bright_star_template = mosaicing_parameters['bright_star_template_vis']\n+                elif filter_name in ['NIR_Y', 'NIR_J', 'NIR_H']:\n+                    bright_star_template = mosaicing_parameters['bright_star_template_nir']\n \n+        elif len(gaia_cutout_list) == 0:\n+            logger.info(\"# Skip Bright Stars Masking\")\n+        else:\n+            logger.info(\"# There are multiple Gaia cutout tables: skip bright stars masking!\")\n+    else:\n+        logger.info(\"# Skip Bright Stars Masking\")\n+    \n+    # return bright star files\n+    return gaia_cutout_file, bright_star_template\n+        \n def mainMethod(args):\n     \"\"\" The \"main\" method.\n \n@@ -215,7 +248,9 @@ def mainMethod(args):\n \n     # Create the directory to run Swarp if it doesn't exist\n     if not os.path.exists(swarp_path):\n-        os.mkdir(swarp_path)\n+        #os.mkdir(swarp_path)\n+        os.makedirs(swarp_path)\n+        logger.debug('# Created SWARP dir: %s'%swarp_path)\n \n     # Get the tile index from the tile product\n     tile_file_name = os.path.join(args.workdir, args.tile)\n@@ -325,6 +360,11 @@ def mainMethod(args):\n         \"PSF\", prefix=psf_prefix, filter1=filter_name, tile_index=tile_index)\n     mosaic_bps_file_name = mer_filename(\n         'FILTER-TRANSMISSION', filter1=filter_name, tile_index=tile_index)\n+    mosaic_mask_file_name = mer_filename(\"STAR-MASKS\", filter1=filter_name, tile_index=tile_index, ext='json')\n+\n+    gaia_cutout_file, bright_star_template = bright_star_setup(args.workdir, args.gaia_cutouts, mosaicing_parameters, filter_name, logger)\n+    logger.info('# --> %s'%gaia_cutout_file)\n+    logger.info('# --> %s'%bright_star_template)\n \n     # Produce the mosaic fits files combining all the input products\n     image_combiner.produce_mosaic(\n@@ -332,7 +372,10 @@ def mainMethod(args):\n         os.path.join(data_path, mosaic_rms_file_name),\n         os.path.join(data_path, mosaic_flag_file_name),\n         os.path.join(data_path, mosaic_psf_file_name),\n-        os.path.join(data_path, mosaic_bps_file_name))\n+        os.path.join(data_path, mosaic_bps_file_name),\n+        os.path.join(data_path, mosaic_mask_file_name),\n+        os.path.join(data_path, gaia_cutout_file),\n+        bright_star_template)\n \n     # Create the mosaic XML file\n     mosaic = mer_utils.create_mosaic(telescope, instrument, filter_name)\n@@ -362,6 +405,8 @@ def mainMethod(args):\n     mosaic.set_observation_id_list(observation_ids)\n     mosaic.set_calblock_id_list(calblock_ids)\n     mosaic.set_processing_mode(processing_mode)\n+    if bright_star_template is not None:\n+        mosaic.set_bright_star_masks(mosaic_mask_file_name)\n \n     # Calculate the quality parameters\n     mosaic.calculate_quality_parameters(\n@@ -373,6 +418,7 @@ def mainMethod(args):\n         os.path.join(args.workdir, args.flag_limits))\n     mosaic.calculate_quality_flags(flag_limits)\n \n+    \"\"\"\n     # Calculate the bright stars masking\n     if (\"bright_star_masking\" in mosaicing_parameters) and mosaicing_parameters[\"bright_star_masking\"]:\n         with open(os.path.join(args.workdir, args.gaia_cutouts), 'r') as gaia_cutouts_list_file:\n@@ -398,7 +444,7 @@ def mainMethod(args):\n                 bright_stars = BrightStars(\n                     filter_name, os.path.join(swarp_path, 'sciData.lis'),\n                     tile_file_name, gaia_cutout_path, template_file_name,\n-                    swarp_path, output_file_path, log_path, logger)\n+                    swarp_path, output_file_path, logger)\n                 bright_stars.run()\n         elif len(gaia_cutout_list) == 0:\n             logger.info(\"# Skip Bright Stars Masking\")\n@@ -406,7 +452,8 @@ def mainMethod(args):\n             logger.info(\"# There are multiple Gaia cutout tables: skip bright stars masking!\")\n     else:\n         logger.info(\"# Skip Bright Stars Masking\")\n-    \n+    \"\"\"\n+\n     # Save the mosaic XML file\n     mosaic.save_xml(os.path.join(args.workdir, args.mosaic))\n \n",
                            "Different treatment of BrightStar masking",
                            "Martin Kuemmel",
                            "2023-08-10T00:35:27.000+02:00",
                            "912dfecdc5828d0fcda252ce544f7be486c528ce"
                        ],
                        [
                            "@@ -15,8 +15,6 @@\n # along with this library; if not, write to the Free Software Foundation, Inc.,\n # 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n #\n-from mypy.test.testmodulefinder import data_path\n-\n \"\"\"\n File: python/MER_Mosaicing_Step/MER_Mosaicing.py\n \n@@ -384,8 +382,7 @@ def mainMethod(args):\n             if filter_name in ['VIS', 'NIR_Y', 'NIR_J', 'NIR_H']:\n                 logger.info(\"# Bright Stars Masking for %s filter\" % filter_name)\n                 mask_output_filename = mer_filename(\"STAR-MASKS\", filter1=filter_name, tile_index=tile_index, ext='json')\n-                mosaic.add_extra_file(\"STAR-MASKS\", mask_output_filename)\n-                # mask_output_filename = mosaic.get_extra_file(\"STAR-MASKS\")\n+                mosaic.set_bright_star_masks(mask_output_filename)\n                 output_file_path = os.path.join(data_path, mask_output_filename)\n                 logger.info(\"# Step path = %s\"%swarp_path)\n \n",
                            "Use new setter method",
                            "Javier Gracia Carpio",
                            "2023-06-28T12:12:57.000+00:00",
                            "b65556ee9ddb2f13d8574c8de612144b6a2d4d97"
                        ]
                    ],
                    ".jenkinsFile": [
                        [
                            "@@ -1,3 +1,3 @@\n #!groovy\n-@Library('integration-library@release-9') _\n-pipelineElements(artifactId:\"MER_Pipeline\", component:'eden.3.0')\n+@Library(value='integration-library@release-10') _\n+pipelineElements(name:\"MER_Pipeline\", component:'eden.3.1')\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T23:34:51.000+00:00",
                            "a24e22ee23f8558127eb3da064d6f83c281a8a7c"
                        ]
                    ],
                    "MER_Kernel_Step/tests/python/MER_KernelAPhotNIRStack_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 02/07/17\n Author: user\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_Kernel_Step.MER_KernelAPhotNIRStack\n \n class TestMER_KernelAPhotNIRStack(object):\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T23:34:51.000+00:00",
                            "a24e22ee23f8558127eb3da064d6f83c281a8a7c"
                        ]
                    ],
                    "MER_Kernel_Step/tests/python/MER_KernelAPhot_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 02/07/17\n Author: user\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_Kernel_Step.MER_KernelAPhot\n \n class TestMER_KernelAPhot(object):\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T23:34:51.000+00:00",
                            "a24e22ee23f8558127eb3da064d6f83c281a8a7c"
                        ]
                    ],
                    "MER_Kernel_Step/tests/python/MER_KernelTPhot_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 02/07/17\n Author: user\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_Kernel_Step.MER_KernelTPhot\n \n class TestMER_KernelTPhot(object):\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T23:34:51.000+00:00",
                            "a24e22ee23f8558127eb3da064d6f83c281a8a7c"
                        ]
                    ],
                    "MER_MorphoPatch_Step/tests/python/MER_MorphoPatchUtils_test.py": [
                        [
                            "@@ -23,7 +23,7 @@\n :author: user\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_MorphoPatch_Step.MER_MorphoPatchUtils\n \n class TestMER_MorphoPatchUtils(object):\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T23:34:51.000+00:00",
                            "a24e22ee23f8558127eb3da064d6f83c281a8a7c"
                        ]
                    ],
                    "MER_MorphoPatch_Step/tests/python/MER_MorphoPatch_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 02/07/17\n Author: user\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_MorphoPatch_Step.MER_MorphoPatch\n \n class TestMER_MorphoPatch(object):\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T23:34:51.000+00:00",
                            "a24e22ee23f8558127eb3da064d6f83c281a8a7c"
                        ]
                    ],
                    "MER_Mosaicing_Step/tests/python/MER_Mosaicing_test.py": [
                        [
                            "@@ -24,7 +24,7 @@ Author: user\n \"\"\"\n \n \n-import py.test\n+import pytest\n import MER_Mosaicing_Step.MER_Mosaicing\n \n class TestMER_Mosaicing(object):\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T23:34:51.000+00:00",
                            "a24e22ee23f8558127eb3da064d6f83c281a8a7c"
                        ]
                    ],
                    "MER_PsfExtraction_Step/tests/python/MER_LowResPsfExtraction_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 02/07/17\n Author: user\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_PsfExtraction_Step.MER_LowResPsfExtraction\n \n class TestMER_LowResPsfExtraction(object):\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T23:34:51.000+00:00",
                            "a24e22ee23f8558127eb3da064d6f83c281a8a7c"
                        ]
                    ],
                    "MER_PsfExtraction_Step/tests/python/MER_PsfExtraction_test.py": [
                        [
                            "@@ -23,7 +23,7 @@ Created on: 02/07/17\n Author: user\n \"\"\"\n \n-import py.test\n+import pytest\n import MER_PsfExtraction_Step.MER_PsfExtraction\n \n class TestMER_PsfExtraction(object):\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T23:34:51.000+00:00",
                            "a24e22ee23f8558127eb3da064d6f83c281a8a7c"
                        ]
                    ],
                    "Makefile": [
                        [
                            "@@ -44,169 +44,19 @@\n #\n ################################################################################\n \n-# settings\n-CMAKE := cmake\n-CTEST := ctest\n-NINJA := $(shell which ninja-build 2> /dev/null)\n-ifeq ($(NINJA),)\n-  NINJA := $(shell which ninja 2> /dev/null)\n-endif\n-\n-# Looking for the Custom make library\n-\n-CUSTOM_MAKE_LIB := Custom.mk\n-\n-ifneq ($(wildcard $(CURDIR)/make/$(CUSTOM_MAKE_LIB)),)\n-  CUSTOM_MAKE_LIB_FILE := $(CURDIR)/make/$(CUSTOM_MAKE_LIB)\n-else\n-  ifneq ($(CMAKE_PREFIX_PATH),)\n-    PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    CUSTOM_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(CUSTOM_MAKE_LIB) $(dir)/../make/$(CUSTOM_MAKE_LIB)))\n-  endif\n-  CUSTOM_MAKE_LIB_LIST += /usr/share/Elements/make/$(CUSTOM_MAKE_LIB)\n-  CUSTOM_MAKE_LIB_FILE := $(firstword $(CUSTOM_MAKE_LIB_LIST))\n-endif\n-\n-# Looking for the ToolChain\n-\n-TOOLCHAIN_NAME := ElementsToolChain.cmake\n+ELEMENTS_MAKE_LIB := Elements.mk\n \n-ifneq ($(wildcard $(CURDIR)/cmake/$(TOOLCHAIN_NAME)),)\n-  TOOLCHAIN_FILE := $(CURDIR)/cmake/$(TOOLCHAIN_NAME)\n+ifneq ($(wildcard $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)),)\n+  ELEMENTS_MAKE_LIB_FILE := $(CURDIR)/make/$(ELEMENTS_MAKE_LIB)\n else\n   ifneq ($(CMAKE_PREFIX_PATH),)\n     PREFIX_LIST := $(subst :, ,$(CMAKE_PREFIX_PATH))\n-    TOOLCHAIN_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/lib*/cmake/ElementsProject/$(TOOLCHAIN_NAME) $(dir)/$(TOOLCHAIN_NAME)))\n-    TOOLCHAIN_FILE := $(firstword $(TOOLCHAIN_LIST))\n+    ELEMENTS_MAKE_LIB_LIST := $(foreach dir,$(PREFIX_LIST),$(wildcard $(dir)/share/Elements/make/$(ELEMENTS_MAKE_LIB) $(dir)/../make/$(ELEMENTS_MAKE_LIB)))\n   endif\n+  ELEMENTS_MAKE_LIB_LIST += /usr/share/Elements/make/$(ELEMENTS_MAKE_LIB)\n+  ELEMENTS_MAKE_LIB_FILE := $(firstword $(ELEMENTS_MAKE_LIB_LIST))\n endif\n \n-override ALL_CMAKEFLAGS := -Wno-dev --no-warn-unused-cli\n-\n-ifneq ($(TOOLCHAIN_FILE),)\n-  # A toolchain has been found. Lets use it.\n-  override ALL_CMAKEFLAGS += -DCMAKE_TOOLCHAIN_FILE=$(TOOLCHAIN_FILE)\n-endif\n-\n-\n-BUILD_PREFIX_NAME := build\n-\n-override ALL_CMAKEFLAGS += -DUSE_LOCAL_INSTALLAREA=ON -DBUILD_PREFIX_NAME:STRING=$(BUILD_PREFIX_NAME)\n-override ALL_CMAKEFLAGS += -DUSE_VERSIONED_LIBRARIES=OFF\n-\n-ifndef BINARY_TAG\n-  ifdef CMAKECONFIG\n-    BINARY_TAG := ${CMAKECONFIG}\n-  else\n-    ifdef CMTCONFIG\n-      BINARY_TAG := ${CMTCONFIG}\n-    endif\n-  endif\n-endif\n-\n-ifdef BINARY_TAG\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME).$(BINARY_TAG)\n-else\n-  BUILD_SUBDIR := $(BUILD_PREFIX_NAME)\n-endif\n-BUILDDIR := $(CURDIR)/$(BUILD_SUBDIR)\n-\n-# build tool\n-\n-ifneq ($(USE_NINJA),)\n-  # enable Ninja\n-  override ALL_CMAKEFLAGS += -GNinja\n-  BUILD_CONF_FILE := build.ninja\n-  BUILDFLAGS := $(NINJAFLAGS)\n-  ifneq ($(VERBOSE),)\n-    BUILDFLAGS := -v $(BUILDFLAGS)\n-  endif\n-else\n-  BUILD_CONF_FILE := Makefile\n-endif\n-BUILD_CMD := $(CMAKE) --build $(BUILD_SUBDIR) --target\n-\n-\n-# Use environment variable for extra flags\n-\n-# Replace the \":\" from eclipse variable list to spaces  \n-ifneq ($(EXPAND_FLAGS),)\n-  CMAKEFLAGS := $(subst :-, -,$(CMAKEFLAGS))\n-endif\n-\n-ifneq ($(CMAKEFLAGS),)\n-  override ALL_CMAKEFLAGS += $(CMAKEFLAGS)\n-endif\n-\n-# default target\n-all:\n-\n-# deep clean\n-purge:\n-\t$(RM) -r $(BUILDDIR) $(CURDIR)/InstallArea/$(BINARY_TAG)\n-\tfind $(CURDIR) \"(\" -name \"InstallArea\" -prune -o -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# Remove all the possible directories and the whole InstallArea as well\n-mrproper:\n-\t$(RM) -r $(CURDIR)/build $(CURDIR)/build.* $(CURDIR)/InstallArea\n-\tfind $(CURDIR) \"(\" -name \"*.pyc\" -o -name \"*.pyo\" \")\" -a -type f -exec $(RM) -v \\{} \\;\n-\tfind $(CURDIR) -depth -type d -name \"__pycache__\" -exec $(RM) -rv \\{} \\;\n-\n-# delegate any target to the build directory (except 'purge')\n-ifneq ($(MAKECMDGOALS),purge)\n-ifneq ($(MAKECMDGOALS),mrproper)\n-%: $(BUILDDIR)/$(BUILD_CONF_FILE) FORCE\n-\t+$(BUILD_CMD) $* -- $(BUILDFLAGS)\n-endif\n-endif\n-\n-# aliases\n-.PHONY: configure tests FORCE\n-ifneq ($(wildcard $(BUILDDIR)/$(BUILD_CONF_FILE)),)\n-configure: rebuild_cache\n-else\n-configure: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-endif\n-\t@ # do not delegate further\n-\n-\n-# This wrapping around the test target is used to ensure the generation of\n-# the XML output from ctest.\n-test: $(BUILDDIR)/$(BUILD_CONF_FILE)\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-\n-# This target ensures that the \"all\" target is called before\n-# running the tests (unlike the \"test\" default target of CMake)\n-tests: all\n-\t$(RM) -r $(BUILDDIR)/Testing $(BUILDDIR)/html\n-\t-cd $(BUILDDIR) && $(CTEST) -T test $(ARGS)\n-\t+$(BUILD_CMD) JUnitSummary\n-\n-ifeq ($(VERBOSE),)\n-# less verbose install\n-# (emulate the default CMake install target)\n-install: all\n-\tcd $(BUILDDIR) && $(CMAKE) -P cmake_install.cmake | grep -v \"^-- Up-to-date:\"\n-endif\n-\n-# import the library to look for a custom Makefile\n--include $(CUSTOM_MAKE_LIB_FILE)\n-\n-# ensure that the target are always passed to the CMake Makefile\n-FORCE: ;\n-\n-# Makefiles are used as implicit targets in make, but we should not consider\n-# them for delegation.\n-$(MAKEFILE_LIST): ;\n-\n-\n-# trigger CMake configuration\n-$(BUILDDIR)/$(BUILD_CONF_FILE): | $(BUILDDIR)\n-\tcd $(BUILDDIR) && $(CMAKE) $(ALL_CMAKEFLAGS) $(CURDIR)\n+$(info Using the $(ELEMENTS_MAKE_LIB_FILE) make library)\n+include $(ELEMENTS_MAKE_LIB_FILE)\n \n-$(BUILDDIR):\n-\tmkdir -p $(BUILDDIR)\n",
                            "Updates to latest DM and Eden3.1",
                            "Javier Gracia Carpio",
                            "2023-06-24T23:34:51.000+00:00",
                            "a24e22ee23f8558127eb3da064d6f83c281a8a7c"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "9.1.0",
                        "created_at": "2023-03-07T14:51:26.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.0",
                        "created_at": "2023-07-04T09:55:27.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    },
                    {
                        "name": "10.1.1",
                        "created_at": "2023-08-14T13:14:30.000+00:00",
                        "author_name": "Javier Gracia Carpio"
                    }
                ]
            }
        },
        "PF-VIS": {
            "PF-VIS/VIS_DiffractionSpikesFocus": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/vis_instrument_tools": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_DQReport": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "OU-VIS/VIS_PTC": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_ImageLib": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/vis_autoarray": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_Common": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_CTI_Pipeline": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_AutoFit": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_LargeFlatCalibration": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/vis_illumcalibration": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/vis_darkcorrection": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/vis_darkcalibration": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_IAL_Pipelines": {
                "start date": "2023-08-14T16:13:23",
                "end date": "2023-08-22T16:21:35",
                "start tag": "13.0.12",
                "end tag": "13.0.14",
                "count_files_modified": "18",
                "modifications_by_file": {
                    "doc/release_note/VIS_Software_Release_Note.md": [
                        [
                            "@@ -1,9 +1,9 @@\n |         |**Document Identification**                                                                          |\n |---------|-----------------------------------------------------------------------------------------------------|\n |Title|Euclid SGS VIS PF Software Release Note |\n-|PF Release| 13.0.13 |\n-|Date:|16/08/2023|\n-|Doc. Issue| 13.0.13 |\n+|PF Release| 13.0.14 |\n+|Date:|22/08/2023|\n+|Doc. Issue| 13.0.14 |\n |Reference:|EUCL-IAP-TN-8-019|\n |Custodian:|C. Grenet|\n \n@@ -22,6 +22,7 @@\n 5. [Patch releases](#patches)\n    * [5.1 Patch 13.0.12](#patch13.0.12)\n    * [5.2 Patch 13.0.13](#patch13.0.13)\n+   * [5.3 Patch 13.0.14](#patch13.0.14)\n 6. [Known issues](#known_issues)\n \n # 1. Purpose and Scope <a name=\"purpose_and_scope\"></a>\n@@ -58,7 +59,7 @@ The PF User Manual [RD5] describes the principal software parts of the system, i\n |------|------|\n | EDEN | `3.1` |\n | Data Model | `9.2.0` |\n-| PF IAL Pipelines conf. | [13.0.13](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines/-/tree/13.0.13) |\n+| PF IAL Pipelines conf. | [13.0.14](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines/-/tree/13.0.14) |\n \n \n ## 3.2 PF software products configuration <a name=\"products\"></a>\n@@ -66,7 +67,7 @@ The PF User Manual [RD5] describes the principal software parts of the system, i\n \n | Gitlab project    | Gitlab tag | SonarQube analysis\n | ----------- | ----------- | ----------- |\n-| [VIS_Tasks](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks) | [13.0.13](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks/-/tags/13.0.13)|[release-13.0](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-13.0&id=VIS_Tasks)|\n+| [VIS_Tasks](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks) | [13.0.14](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks/-/tags/13.0.13)|[release-13.0](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-13.0&id=VIS_Tasks)|\n | [VIS_PyLibrary](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_PyLibrary) | [3.20.2](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_PyLibrary/-/tags/3.20.2) |[release-3.20](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-2.20&id=VIS_PyLibrary)|\n | [VIS_ImageTools](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_ImageTools) | [3.16.0](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_ImageTools/-/tags/3.16.0) | [release-3.16](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-3.16&id=VIS_ImageTools)|\n  | [VIS_CTI](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_CTI) | [5.9.0](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_CTI/-/tags/5.9.0) |[release-5.9](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-5.9&id=VIS_CTI)|\n@@ -141,7 +142,7 @@ New features:\n | [#23227](https://euclid.roe.ac.uk/issues/23227) | BloomingCalibration: PTC values added to output product\n | None                                            | VIS_CTI: new version 5.9.0\n \n-# 5.1 Patch 13.0.13 <a name=\"patch13.0.13\"></a>\n+# 5.2 Patch 13.0.13 <a name=\"patch13.0.13\"></a>\n \n Solved issues:\n \n@@ -151,7 +152,22 @@ Solved issues:\n | [#23486](https://euclid.roe.ac.uk/issues/23486) | MasterBias pipeline creates incorrect DpdVisAnalysisResult that fails to be ingested\n | [#23494](https://euclid.roe.ac.uk/issues/23494) | VIS MasterDark crash even on long exposures\n \n+# 5.3 Patch 13.0.14 <a name=\"patch13.0.14\"></a>\n \n+Solved issues:\n+\n+| Issue                                           | Title       |\n+| ----------------------------------------------- | ----------- |\n+| [#23453](https://euclid.roe.ac.uk/issues/23453) | In the stacked images produced of the commissioning data, the astrometric solution is not correct |\n+| [#23511](https://euclid.roe.ac.uk/issues/23511) | [CALBLOCK-PV-027] TrapPumping processing crash\n+| [#23513](https://euclid.roe.ac.uk/issues/23513) | VIS_MasterDark_Pipeline: Data.ExposureTime missing in DpdVisMasterDarkFrame\n+| [#23522](https://euclid.roe.ac.uk/issues/23522) | VIS_BloomingCalibration_Pipeline: blooming model has inconsistent unit\n+\n+New features:\n+\n+| Issue                                           | Title       |\n+| ----------------------------------------------- | ----------- |\n+| [#23518](https://euclid.roe.ac.uk/issues/23518) | VIS_BloomingCalibration pipeline: use object masks\n \n # 6. Known issues <a name=\"known_issues\"></a>\n \n",
                            "[UPD]SRN for release 13.0.14",
                            "Catherine Grenet",
                            "2023-08-22T16:21:35.000+02:00",
                            "1a535557d1a6db40c47d4248cb17106f5ee7aa57"
                        ],
                        [
                            "@@ -1,9 +1,9 @@\n |         |**Document Identification**                                                                          |\n |---------|-----------------------------------------------------------------------------------------------------|\n |Title|Euclid SGS VIS PF Software Release Note |\n-|PF Release| 13.0.6 |\n-|Date:|02/08/2023|\n-|Doc. Issue| 13.0.6 |\n+|PF Release| 13.0.13 |\n+|Date:|16/08/2023|\n+|Doc. Issue| 13.0.13 |\n |Reference:|EUCL-IAP-TN-8-019|\n |Custodian:|C. Grenet|\n \n@@ -20,6 +20,8 @@\n     * [4.1 Functional changes in this release](#changes)\n     * [4.2 Issues fixed](#fixed_issues)\n 5. [Patch releases](#patches)\n+   * [5.1 Patch 13.0.12](#patch13.0.12)\n+   * [5.2 Patch 13.0.13](#patch13.0.13)\n 6. [Known issues](#known_issues)\n \n # 1. Purpose and Scope <a name=\"purpose_and_scope\"></a>\n@@ -55,8 +57,8 @@ The PF User Manual [RD5] describes the principal software parts of the system, i\n | Envt  | Version  |\n |------|------|\n | EDEN | `3.1` |\n-| Data Model | `9.0.2` |\n-| PF IAL Pipelines conf. | [13.0.6](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines/-/tree/13.0.6) |\n+| Data Model | `9.2.0` |\n+| PF IAL Pipelines conf. | [13.0.13](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines/-/tree/13.0.13) |\n \n \n ## 3.2 PF software products configuration <a name=\"products\"></a>\n@@ -64,10 +66,10 @@ The PF User Manual [RD5] describes the principal software parts of the system, i\n \n | Gitlab project    | Gitlab tag | SonarQube analysis\n | ----------- | ----------- | ----------- |\n-| [VIS_Tasks](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks) | [13.0.6](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks/-/tags/13.0.6)|[release-13.0](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-13.0&id=VIS_Tasks)|\n-| [VIS_PyLibrary](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_PyLibrary) | [3.20.2](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_PyLibrary/-/tags/3.20.2) |[release-3.20](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-3.20&id=VIS_PyLibrary)|\n+| [VIS_Tasks](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks) | [13.0.13](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks/-/tags/13.0.13)|[release-13.0](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-13.0&id=VIS_Tasks)|\n+| [VIS_PyLibrary](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_PyLibrary) | [3.20.2](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_PyLibrary/-/tags/3.20.2) |[release-3.20](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-2.20&id=VIS_PyLibrary)|\n | [VIS_ImageTools](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_ImageTools) | [3.16.0](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_ImageTools/-/tags/3.16.0) | [release-3.16](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-3.16&id=VIS_ImageTools)|\n- | [VIS_CTI](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_CTI) | [5.8.1](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_CTI/-/tags/5.8.1) |[release-5.8](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-5.8&id=VIS_CTI)|\n+ | [VIS_CTI](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_CTI) | [5.9.0](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_CTI/-/tags/5.9.0) |[release-5.9](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-5.9&id=VIS_CTI)|\n  | [VIS_Instrument_Tools](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Instrument_Tools) | [0.7.0](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Instrument_Tools/-/tags/0.7.0) | [release-0.7](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-0.7&id=VIS_Instrument_Tools) |\n  | [VIS_DiffractionSpikesFocus](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_DiffractionSpikesFocus) | [1.1.0](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_DiffractionSpikesFocus/-/tags/1.1.0) | [release-1.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-1.1&id=VIS_DiffractionSpikesFocus) |\n \n@@ -112,6 +114,45 @@ Processing of science exposures has been splitted in two pipelines: VIS_ProcessF\n | [#20089](https://euclid.roe.ac.uk/issues/20089)| VIS_LargeFlatCalibration_Pipeline: psf_model and starmask_model inputs are mandatory|\n \n \n+# 5. Patch releases <a name=\"patches\"></a>\n+\n+# 5.1 Patch 13.0.12 <a name=\"patch13.0.12\"></a>\n+\n+Solved issues:\n+\n+| Issue | Title |\n+| -----------   | ----------- |\n+| [#20505](https://euclid.roe.ac.uk/issues/20505) | CalblockId not copied in VIS output products\n+| [#23096](https://euclid.roe.ac.uk/issues/23096) | FITS files are trucated when ZipOutputs = True\n+| [#23101](https://euclid.roe.ac.uk/issues/23101) | Large-scale Flat model CCDs may be showing an indexing error\n+| [#23168](https://euclid.roe.ac.uk/issues/23168) | VIS_BrighterFatterCalibrationCalibration_Pipeline: output product is DpdVisFileContainer instead of DpdVisBFEModel\n+| [#23190](https://euclid.roe.ac.uk/issues/23190) | wcsfit crashes on SIM-PV2-008_R2 EXTRA-FOCAL and INTRA-FOCAL exposures\n+| [#23233](https://euclid.roe.ac.uk/issues/23233) | Scattered light in VIS calblock-001 data \n+| [#23265](https://euclid.roe.ac.uk/issues/23265) | VIS_ProcessField_Pipeline: VIS_Calibrate_Photometry crashes on out-of-focus exposures\n+| [#23455](https://euclid.roe.ac.uk/issues/23455) | bias_modelling.py uses a lot of memory\n+\n+New features:\n+\n+| Issue | Title |\n+| -----------   | ----------- |\n+| [#22219](https://euclid.roe.ac.uk/issues/22219) | VIS_SmallScaleFlat: add DQC ouptut, should now accept any combination of single-LED/single-fluence master flats (see #22219)\n+| [#22650](https://euclid.roe.ac.uk/issues/22650) | PTCNLCalibration pipeline enhancements\n+| [#23191](https://euclid.roe.ac.uk/issues/23191) | Astrometric calibration: adapt magnitude range selection to exposure duration\n+| [#23227](https://euclid.roe.ac.uk/issues/23227) | BloomingCalibration: PTC values added to output product\n+| None                                            | VIS_CTI: new version 5.9.0\n+\n+# 5.1 Patch 13.0.13 <a name=\"patch13.0.13\"></a>\n+\n+Solved issues:\n+\n+| Issue | Title |\n+| -----------   | ----------- |\n+| [#23449](https://euclid.roe.ac.uk/issues/23449) | VIS_CTICalibration_Pipeline: Pipeline outputs and returned values should have the same cardinality\n+| [#23486](https://euclid.roe.ac.uk/issues/23486) | MasterBias pipeline creates incorrect DpdVisAnalysisResult that fails to be ingested\n+| [#23494](https://euclid.roe.ac.uk/issues/23494) | VIS MasterDark crash even on long exposures\n+\n+\n+\n # 6. Known issues <a name=\"known_issues\"></a>\n \n Bug reports and software change/addition requests should be submitted through the Euclid Redmine tool at https://euclid.roe.ac.uk/projects/vis_pf/issues.\n@@ -129,13 +170,7 @@ Bug reports and software change/addition requests should be submitted through th\n | [#22976](https://euclid.roe.ac.uk/issues/22976) | VIS_MasterDark_Pipeline (95 s exposures): Exception: model_dark(): All pixels are masked (perhaps the hot pixel threshold is too low?)\n | [#23033](https://euclid.roe.ac.uk/issues/23033) | Astrometric calibration (use-fpa-model) fails on SIM-PV2-006_R2\n | [#23072](https://euclid.roe.ac.uk/issues/23072) | Insufficient CR rejection in the newest VIS PVPR#2 data\n-| [#23096](https://euclid.roe.ac.uk/issues/23096) | FITS files are trucated when ZipOutputs = True\n-| [#23101](https://euclid.roe.ac.uk/issues/23101) | Large-scale Flat model CCDs may be showing an indexing error\n-| [#23168](https://euclid.roe.ac.uk/issues/23168) | VIS_BrighterFatterCalibrationCalibration_Pipeline: output product is DpdVisFileContainer instead of DpdVisBFEModel\n-| [#23190](https://euclid.roe.ac.uk/issues/23190) | wcsfit crashes on SIM-PV2-008_R2 EXTRA-FOCAL and INTRA-FOCAL exposures\n-| [#23233](https://euclid.roe.ac.uk/issues/23233) | Scattered light in VIS calblock-001 data\n | [#23243](https://euclid.roe.ac.uk/issues/23243) | VIS_NonLinCalibration_Pipeline (APERTURE mode) produces incorrect results\n-| [#23265](https://euclid.roe.ac.uk/issues/23265) | VIS_ProcessField_Pipeline: VIS_Calibrate_Photometry crashes on out-of-focus exposures\n | [#23266](https://euclid.roe.ac.uk/issues/23266) | stacking output product XML is empty\n \n \n",
                            "Merge branch 'release-13.0' into develop: #23449 CTICalib decorators, #23455 MasterBias ram, #23518 Blooming object masks",
                            "Catherine Grenet",
                            "2023-08-21T17:30:06.000+02:00",
                            "3266962f8cb5374c52678180c4d4e0592338bdb8"
                        ],
                        [
                            "@@ -1,9 +1,9 @@\n |         |**Document Identification**                                                                          |\n |---------|-----------------------------------------------------------------------------------------------------|\n |Title|Euclid SGS VIS PF Software Release Note |\n-|PF Release| 13.0.12 |\n-|Date:|14/08/2023|\n-|Doc. Issue| 13.0.12 |\n+|PF Release| 13.0.13 |\n+|Date:|16/08/2023|\n+|Doc. Issue| 13.0.13 |\n |Reference:|EUCL-IAP-TN-8-019|\n |Custodian:|C. Grenet|\n \n@@ -21,6 +21,7 @@\n     * [4.2 Issues fixed](#fixed_issues)\n 5. [Patch releases](#patches)\n    * [5.1 Patch 13.0.12](#patch13.0.12)\n+   * [5.2 Patch 13.0.13](#patch13.0.13)\n 6. [Known issues](#known_issues)\n \n # 1. Purpose and Scope <a name=\"purpose_and_scope\"></a>\n@@ -57,7 +58,7 @@ The PF User Manual [RD5] describes the principal software parts of the system, i\n |------|------|\n | EDEN | `3.1` |\n | Data Model | `9.2.0` |\n-| PF IAL Pipelines conf. | [13.0.12](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines/-/tree/13.0.12) |\n+| PF IAL Pipelines conf. | [13.0.13](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines/-/tree/13.0.13) |\n \n \n ## 3.2 PF software products configuration <a name=\"products\"></a>\n@@ -65,7 +66,7 @@ The PF User Manual [RD5] describes the principal software parts of the system, i\n \n | Gitlab project    | Gitlab tag | SonarQube analysis\n | ----------- | ----------- | ----------- |\n-| [VIS_Tasks](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks) | [13.0.12](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks/-/tags/13.0.12)|[release-13.0](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-13.0&id=VIS_Tasks)|\n+| [VIS_Tasks](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks) | [13.0.13](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks/-/tags/13.0.13)|[release-13.0](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-13.0&id=VIS_Tasks)|\n | [VIS_PyLibrary](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_PyLibrary) | [3.20.2](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_PyLibrary/-/tags/3.20.2) |[release-3.20](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-2.20&id=VIS_PyLibrary)|\n | [VIS_ImageTools](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_ImageTools) | [3.16.0](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_ImageTools/-/tags/3.16.0) | [release-3.16](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-3.16&id=VIS_ImageTools)|\n  | [VIS_CTI](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_CTI) | [5.9.0](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_CTI/-/tags/5.9.0) |[release-5.9](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-5.9&id=VIS_CTI)|\n@@ -140,6 +141,16 @@ New features:\n | [#23227](https://euclid.roe.ac.uk/issues/23227) | BloomingCalibration: PTC values added to output product\n | None                                            | VIS_CTI: new version 5.9.0\n \n+# 5.1 Patch 13.0.13 <a name=\"patch13.0.13\"></a>\n+\n+Solved issues:\n+\n+| Issue | Title |\n+| -----------   | ----------- |\n+| [#23449](https://euclid.roe.ac.uk/issues/23449) | VIS_CTICalibration_Pipeline: Pipeline outputs and returned values should have the same cardinality\n+| [#23486](https://euclid.roe.ac.uk/issues/23486) | MasterBias pipeline creates incorrect DpdVisAnalysisResult that fails to be ingested\n+| [#23494](https://euclid.roe.ac.uk/issues/23494) | VIS MasterDark crash even on long exposures\n+\n \n \n # 6. Known issues <a name=\"known_issues\"></a>\n",
                            "Merge branch 'release-13.0' into master_ci_memory",
                            "James Nightingale",
                            "2023-08-18T17:55:53.000+02:00",
                            "961b01b509e96c9e2b52d75b5383fbd55e0be960"
                        ],
                        [
                            "@@ -1,9 +1,9 @@\n |         |**Document Identification**                                                                          |\n |---------|-----------------------------------------------------------------------------------------------------|\n |Title|Euclid SGS VIS PF Software Release Note |\n-|PF Release| 13.0.12 |\n-|Date:|14/08/2023|\n-|Doc. Issue| 13.0.12 |\n+|PF Release| 13.0.13 |\n+|Date:|16/08/2023|\n+|Doc. Issue| 13.0.13 |\n |Reference:|EUCL-IAP-TN-8-019|\n |Custodian:|C. Grenet|\n \n@@ -21,6 +21,7 @@\n     * [4.2 Issues fixed](#fixed_issues)\n 5. [Patch releases](#patches)\n    * [5.1 Patch 13.0.12](#patch13.0.12)\n+   * [5.2 Patch 13.0.13](#patch13.0.13)\n 6. [Known issues](#known_issues)\n \n # 1. Purpose and Scope <a name=\"purpose_and_scope\"></a>\n@@ -57,7 +58,7 @@ The PF User Manual [RD5] describes the principal software parts of the system, i\n |------|------|\n | EDEN | `3.1` |\n | Data Model | `9.2.0` |\n-| PF IAL Pipelines conf. | [13.0.12](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines/-/tree/13.0.12) |\n+| PF IAL Pipelines conf. | [13.0.13](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines/-/tree/13.0.13) |\n \n \n ## 3.2 PF software products configuration <a name=\"products\"></a>\n@@ -65,7 +66,7 @@ The PF User Manual [RD5] describes the principal software parts of the system, i\n \n | Gitlab project    | Gitlab tag | SonarQube analysis\n | ----------- | ----------- | ----------- |\n-| [VIS_Tasks](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks) | [13.0.12](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks/-/tags/13.0.12)|[release-13.0](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-13.0&id=VIS_Tasks)|\n+| [VIS_Tasks](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks) | [13.0.13](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks/-/tags/13.0.13)|[release-13.0](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-13.0&id=VIS_Tasks)|\n | [VIS_PyLibrary](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_PyLibrary) | [3.20.2](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_PyLibrary/-/tags/3.20.2) |[release-3.20](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-2.20&id=VIS_PyLibrary)|\n | [VIS_ImageTools](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_ImageTools) | [3.16.0](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_ImageTools/-/tags/3.16.0) | [release-3.16](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-3.16&id=VIS_ImageTools)|\n  | [VIS_CTI](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_CTI) | [5.9.0](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_CTI/-/tags/5.9.0) |[release-5.9](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-5.9&id=VIS_CTI)|\n@@ -140,6 +141,16 @@ New features:\n | [#23227](https://euclid.roe.ac.uk/issues/23227) | BloomingCalibration: PTC values added to output product\n | None                                            | VIS_CTI: new version 5.9.0\n \n+# 5.1 Patch 13.0.13 <a name=\"patch13.0.13\"></a>\n+\n+Solved issues:\n+\n+| Issue | Title |\n+| -----------   | ----------- |\n+| [#23449](https://euclid.roe.ac.uk/issues/23449) | VIS_CTICalibration_Pipeline: Pipeline outputs and returned values should have the same cardinality\n+| [#23486](https://euclid.roe.ac.uk/issues/23486) | MasterBias pipeline creates incorrect DpdVisAnalysisResult that fails to be ingested\n+| [#23494](https://euclid.roe.ac.uk/issues/23494) | VIS MasterDark crash even on long exposures\n+\n \n \n # 6. Known issues <a name=\"known_issues\"></a>\n",
                            "Merge branch 'release-13.0' of https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines into release-13.0",
                            "James Nightingale",
                            "2023-08-18T17:50:03.000+02:00",
                            "22bec8642685bff3087cfb2386d20e518a3f4a96"
                        ],
                        [
                            "@@ -1,9 +1,9 @@\n |         |**Document Identification**                                                                          |\n |---------|-----------------------------------------------------------------------------------------------------|\n |Title|Euclid SGS VIS PF Software Release Note |\n-|PF Release| 13.0.12 |\n-|Date:|14/08/2023|\n-|Doc. Issue| 13.0.12 |\n+|PF Release| 13.0.13 |\n+|Date:|16/08/2023|\n+|Doc. Issue| 13.0.13 |\n |Reference:|EUCL-IAP-TN-8-019|\n |Custodian:|C. Grenet|\n \n@@ -21,6 +21,7 @@\n     * [4.2 Issues fixed](#fixed_issues)\n 5. [Patch releases](#patches)\n    * [5.1 Patch 13.0.12](#patch13.0.12)\n+   * [5.2 Patch 13.0.13](#patch13.0.13)\n 6. [Known issues](#known_issues)\n \n # 1. Purpose and Scope <a name=\"purpose_and_scope\"></a>\n@@ -57,7 +58,7 @@ The PF User Manual [RD5] describes the principal software parts of the system, i\n |------|------|\n | EDEN | `3.1` |\n | Data Model | `9.2.0` |\n-| PF IAL Pipelines conf. | [13.0.12](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines/-/tree/13.0.12) |\n+| PF IAL Pipelines conf. | [13.0.13](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines/-/tree/13.0.13) |\n \n \n ## 3.2 PF software products configuration <a name=\"products\"></a>\n@@ -65,7 +66,7 @@ The PF User Manual [RD5] describes the principal software parts of the system, i\n \n | Gitlab project    | Gitlab tag | SonarQube analysis\n | ----------- | ----------- | ----------- |\n-| [VIS_Tasks](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks) | [13.0.12](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks/-/tags/13.0.12)|[release-13.0](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-13.0&id=VIS_Tasks)|\n+| [VIS_Tasks](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks) | [13.0.13](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks/-/tags/13.0.13)|[release-13.0](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-13.0&id=VIS_Tasks)|\n | [VIS_PyLibrary](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_PyLibrary) | [3.20.2](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_PyLibrary/-/tags/3.20.2) |[release-3.20](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-2.20&id=VIS_PyLibrary)|\n | [VIS_ImageTools](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_ImageTools) | [3.16.0](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_ImageTools/-/tags/3.16.0) | [release-3.16](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-3.16&id=VIS_ImageTools)|\n  | [VIS_CTI](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_CTI) | [5.9.0](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_CTI/-/tags/5.9.0) |[release-5.9](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-5.9&id=VIS_CTI)|\n@@ -140,6 +141,16 @@ New features:\n | [#23227](https://euclid.roe.ac.uk/issues/23227) | BloomingCalibration: PTC values added to output product\n | None                                            | VIS_CTI: new version 5.9.0\n \n+# 5.1 Patch 13.0.13 <a name=\"patch13.0.13\"></a>\n+\n+Solved issues:\n+\n+| Issue | Title |\n+| -----------   | ----------- |\n+| [#23449](https://euclid.roe.ac.uk/issues/23449) | VIS_CTICalibration_Pipeline: Pipeline outputs and returned values should have the same cardinality\n+| [#23486](https://euclid.roe.ac.uk/issues/23486) | MasterBias pipeline creates incorrect DpdVisAnalysisResult that fails to be ingested\n+| [#23494](https://euclid.roe.ac.uk/issues/23494) | VIS MasterDark crash even on long exposures\n+\n \n \n # 6. Known issues <a name=\"known_issues\"></a>\n",
                            "Merge branch 'feature-SUM' into release-13.0: [DOC][FIX]Bug #23494,[UPD] SRN 13.0.13",
                            "Catherine Grenet",
                            "2023-08-16T15:26:57.000+02:00",
                            "63fd4293bf64c2e9895af3adad163bf543d3d23f"
                        ],
                        [
                            "@@ -1,9 +1,9 @@\n |         |**Document Identification**                                                                          |\n |---------|-----------------------------------------------------------------------------------------------------|\n |Title|Euclid SGS VIS PF Software Release Note |\n-|PF Release| 13.0.12 |\n-|Date:|14/08/2023|\n-|Doc. Issue| 13.0.12 |\n+|PF Release| 13.0.13 |\n+|Date:|16/08/2023|\n+|Doc. Issue| 13.0.13 |\n |Reference:|EUCL-IAP-TN-8-019|\n |Custodian:|C. Grenet|\n \n@@ -21,6 +21,7 @@\n     * [4.2 Issues fixed](#fixed_issues)\n 5. [Patch releases](#patches)\n    * [5.1 Patch 13.0.12](#patch13.0.12)\n+   * [5.2 Patch 13.0.13](#patch13.0.13)\n 6. [Known issues](#known_issues)\n \n # 1. Purpose and Scope <a name=\"purpose_and_scope\"></a>\n@@ -57,7 +58,7 @@ The PF User Manual [RD5] describes the principal software parts of the system, i\n |------|------|\n | EDEN | `3.1` |\n | Data Model | `9.2.0` |\n-| PF IAL Pipelines conf. | [13.0.12](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines/-/tree/13.0.12) |\n+| PF IAL Pipelines conf. | [13.0.13](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines/-/tree/13.0.13) |\n \n \n ## 3.2 PF software products configuration <a name=\"products\"></a>\n@@ -65,7 +66,7 @@ The PF User Manual [RD5] describes the principal software parts of the system, i\n \n | Gitlab project    | Gitlab tag | SonarQube analysis\n | ----------- | ----------- | ----------- |\n-| [VIS_Tasks](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks) | [13.0.12](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks/-/tags/13.0.12)|[release-13.0](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-13.0&id=VIS_Tasks)|\n+| [VIS_Tasks](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks) | [13.0.13](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks/-/tags/13.0.13)|[release-13.0](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-13.0&id=VIS_Tasks)|\n | [VIS_PyLibrary](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_PyLibrary) | [3.20.2](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_PyLibrary/-/tags/3.20.2) |[release-3.20](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-2.20&id=VIS_PyLibrary)|\n | [VIS_ImageTools](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_ImageTools) | [3.16.0](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_ImageTools/-/tags/3.16.0) | [release-3.16](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-3.16&id=VIS_ImageTools)|\n  | [VIS_CTI](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_CTI) | [5.9.0](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_CTI/-/tags/5.9.0) |[release-5.9](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-5.9&id=VIS_CTI)|\n@@ -140,6 +141,16 @@ New features:\n | [#23227](https://euclid.roe.ac.uk/issues/23227) | BloomingCalibration: PTC values added to output product\n | None                                            | VIS_CTI: new version 5.9.0\n \n+# 5.1 Patch 13.0.13 <a name=\"patch13.0.13\"></a>\n+\n+Solved issues:\n+\n+| Issue | Title |\n+| -----------   | ----------- |\n+| [#23449](https://euclid.roe.ac.uk/issues/23449) | VIS_CTICalibration_Pipeline: Pipeline outputs and returned values should have the same cardinality\n+| [#23486](https://euclid.roe.ac.uk/issues/23486) | MasterBias pipeline creates incorrect DpdVisAnalysisResult that fails to be ingested\n+| [#23494](https://euclid.roe.ac.uk/issues/23494) | VIS MasterDark crash even on long exposures\n+\n \n \n # 6. Known issues <a name=\"known_issues\"></a>\n",
                            "[DOC]Software Release Note updated for VIS PF 13.0.13",
                            "Catherine Grenet",
                            "2023-08-16T15:23:58.000+02:00",
                            "8b3dcd6b5830e9db44a41bc594ddec60c5ff530b"
                        ],
                        [
                            "@@ -1,9 +1,9 @@\n |         |**Document Identification**                                                                          |\n |---------|-----------------------------------------------------------------------------------------------------|\n |Title|Euclid SGS VIS PF Software Release Note |\n-|PF Release| 13.0.6 |\n-|Date:|02/08/2023|\n-|Doc. Issue| 13.0.6 |\n+|PF Release| 13.0.12 |\n+|Date:|14/08/2023|\n+|Doc. Issue| 13.0.12 |\n |Reference:|EUCL-IAP-TN-8-019|\n |Custodian:|C. Grenet|\n \n@@ -20,6 +20,7 @@\n     * [4.1 Functional changes in this release](#changes)\n     * [4.2 Issues fixed](#fixed_issues)\n 5. [Patch releases](#patches)\n+   * [5.1 Patch 13.0.12](#patch13.0.12)\n 6. [Known issues](#known_issues)\n \n # 1. Purpose and Scope <a name=\"purpose_and_scope\"></a>\n@@ -55,8 +56,8 @@ The PF User Manual [RD5] describes the principal software parts of the system, i\n | Envt  | Version  |\n |------|------|\n | EDEN | `3.1` |\n-| Data Model | `9.0.2` |\n-| PF IAL Pipelines conf. | [13.0.6](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines/-/tree/13.0.6) |\n+| Data Model | `9.2.0` |\n+| PF IAL Pipelines conf. | [13.0.12](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines/-/tree/13.0.12) |\n \n \n ## 3.2 PF software products configuration <a name=\"products\"></a>\n@@ -64,10 +65,10 @@ The PF User Manual [RD5] describes the principal software parts of the system, i\n \n | Gitlab project    | Gitlab tag | SonarQube analysis\n | ----------- | ----------- | ----------- |\n-| [VIS_Tasks](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks) | [13.0.6](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks/-/tags/13.0.6)|[release-13.0](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-13.0&id=VIS_Tasks)|\n-| [VIS_PyLibrary](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_PyLibrary) | [3.20.2](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_PyLibrary/-/tags/3.20.2) |[release-3.20](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-3.20&id=VIS_PyLibrary)|\n+| [VIS_Tasks](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks) | [13.0.12](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks/-/tags/13.0.12)|[release-13.0](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-13.0&id=VIS_Tasks)|\n+| [VIS_PyLibrary](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_PyLibrary) | [3.20.2](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_PyLibrary/-/tags/3.20.2) |[release-3.20](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-2.20&id=VIS_PyLibrary)|\n | [VIS_ImageTools](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_ImageTools) | [3.16.0](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_ImageTools/-/tags/3.16.0) | [release-3.16](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-3.16&id=VIS_ImageTools)|\n- | [VIS_CTI](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_CTI) | [5.8.1](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_CTI/-/tags/5.8.1) |[release-5.8](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-5.8&id=VIS_CTI)|\n+ | [VIS_CTI](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_CTI) | [5.9.0](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_CTI/-/tags/5.9.0) |[release-5.9](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-5.9&id=VIS_CTI)|\n  | [VIS_Instrument_Tools](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Instrument_Tools) | [0.7.0](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Instrument_Tools/-/tags/0.7.0) | [release-0.7](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-0.7&id=VIS_Instrument_Tools) |\n  | [VIS_DiffractionSpikesFocus](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_DiffractionSpikesFocus) | [1.1.0](https://gitlab.euclid-sgs.uk/PF-VIS/VIS_DiffractionSpikesFocus/-/tags/1.1.0) | [release-1.1](https://codeen-app.euclid-ec.org/sonar/dashboard?branch=release-1.1&id=VIS_DiffractionSpikesFocus) |\n \n@@ -112,6 +113,35 @@ Processing of science exposures has been splitted in two pipelines: VIS_ProcessF\n | [#20089](https://euclid.roe.ac.uk/issues/20089)| VIS_LargeFlatCalibration_Pipeline: psf_model and starmask_model inputs are mandatory|\n \n \n+# 5. Patch releases <a name=\"patches\"></a>\n+\n+# 5.1 Patch 13.0.12 <a name=\"patch13.0.12\"></a>\n+\n+Solved issues:\n+\n+| Issue | Title |\n+| -----------   | ----------- |\n+| [#20505](https://euclid.roe.ac.uk/issues/20505) | CalblockId not copied in VIS output products\n+| [#23096](https://euclid.roe.ac.uk/issues/23096) | FITS files are trucated when ZipOutputs = True\n+| [#23101](https://euclid.roe.ac.uk/issues/23101) | Large-scale Flat model CCDs may be showing an indexing error\n+| [#23168](https://euclid.roe.ac.uk/issues/23168) | VIS_BrighterFatterCalibrationCalibration_Pipeline: output product is DpdVisFileContainer instead of DpdVisBFEModel\n+| [#23190](https://euclid.roe.ac.uk/issues/23190) | wcsfit crashes on SIM-PV2-008_R2 EXTRA-FOCAL and INTRA-FOCAL exposures\n+| [#23233](https://euclid.roe.ac.uk/issues/23233) | Scattered light in VIS calblock-001 data \n+| [#23265](https://euclid.roe.ac.uk/issues/23265) | VIS_ProcessField_Pipeline: VIS_Calibrate_Photometry crashes on out-of-focus exposures\n+| [#23455](https://euclid.roe.ac.uk/issues/23455) | bias_modelling.py uses a lot of memory\n+\n+New features:\n+\n+| Issue | Title |\n+| -----------   | ----------- |\n+| [#22219](https://euclid.roe.ac.uk/issues/22219) | VIS_SmallScaleFlat: add DQC ouptut, should now accept any combination of single-LED/single-fluence master flats (see #22219)\n+| [#22650](https://euclid.roe.ac.uk/issues/22650) | PTCNLCalibration pipeline enhancements\n+| [#23191](https://euclid.roe.ac.uk/issues/23191) | Astrometric calibration: adapt magnitude range selection to exposure duration\n+| [#23227](https://euclid.roe.ac.uk/issues/23227) | BloomingCalibration: PTC values added to output product\n+| None                                            | VIS_CTI: new version 5.9.0\n+\n+\n+\n # 6. Known issues <a name=\"known_issues\"></a>\n \n Bug reports and software change/addition requests should be submitted through the Euclid Redmine tool at https://euclid.roe.ac.uk/projects/vis_pf/issues.\n@@ -129,13 +159,7 @@ Bug reports and software change/addition requests should be submitted through th\n | [#22976](https://euclid.roe.ac.uk/issues/22976) | VIS_MasterDark_Pipeline (95 s exposures): Exception: model_dark(): All pixels are masked (perhaps the hot pixel threshold is too low?)\n | [#23033](https://euclid.roe.ac.uk/issues/23033) | Astrometric calibration (use-fpa-model) fails on SIM-PV2-006_R2\n | [#23072](https://euclid.roe.ac.uk/issues/23072) | Insufficient CR rejection in the newest VIS PVPR#2 data\n-| [#23096](https://euclid.roe.ac.uk/issues/23096) | FITS files are trucated when ZipOutputs = True\n-| [#23101](https://euclid.roe.ac.uk/issues/23101) | Large-scale Flat model CCDs may be showing an indexing error\n-| [#23168](https://euclid.roe.ac.uk/issues/23168) | VIS_BrighterFatterCalibrationCalibration_Pipeline: output product is DpdVisFileContainer instead of DpdVisBFEModel\n-| [#23190](https://euclid.roe.ac.uk/issues/23190) | wcsfit crashes on SIM-PV2-008_R2 EXTRA-FOCAL and INTRA-FOCAL exposures\n-| [#23233](https://euclid.roe.ac.uk/issues/23233) | Scattered light in VIS calblock-001 data\n | [#23243](https://euclid.roe.ac.uk/issues/23243) | VIS_NonLinCalibration_Pipeline (APERTURE mode) produces incorrect results\n-| [#23265](https://euclid.roe.ac.uk/issues/23265) | VIS_ProcessField_Pipeline: VIS_Calibrate_Photometry crashes on out-of-focus exposures\n | [#23266](https://euclid.roe.ac.uk/issues/23266) | stacking output product XML is empty\n \n \n",
                            "Merge branch 'feature-SUM' into release-13.0: SRN VIS PF 13.0.12",
                            "Catherine Grenet",
                            "2023-08-14T16:13:23.000+02:00",
                            "bec4d2f7797ae8a84255ffd581f45f5a4f533835"
                        ]
                    ],
                    "VIS_IAL_Pipelines/auxdir/VIS_IAL_Pipelines/VIS_BloomingCalibration_Pipeline/PipScript_VIS_BloomingCalibration.py": [
                        [
                            "@@ -28,7 +28,7 @@ def process_quad(config, MDB, exposure_in):\n \n @pipeline(outputs=('blooming_model_xml_out'))\n def VIS_BloomingCalibration( raw_frames_in, vis_config_in, MDB, flagmaps, gains_model, masterbias,\n-                             xtalk_model, nlcorr_model, saturation_model, ron_model, cti_model, bfe_model):\n+                             xtalk_model, nlcorr_model, saturation_model, ron_model, cti_model, bfe_model, object_masks):\n \n    rawexp_list, config = \\\n         PkgDef.VIS_blooming_xml_in( vis_config_in=   vis_config_in,\n@@ -42,7 +42,8 @@ def VIS_BloomingCalibration( raw_frames_in, vis_config_in, MDB, flagmaps, gains_\n                                     saturation_model=saturation_model,\n                                     ron_model=       ron_model,\n                                     cti_model=       cti_model,\n-                                    bfe_model=       bfe_model)\n+                                    bfe_model=       bfe_model,\n+                                    object_masks=    object_masks)\n \n    processed_quad_list, processed_quad_flg_list = process_quad( config=config,\n                                                                 MDB=MDB,\n",
                            "Merge branch 'release-13.0' into develop: #23449 CTICalib decorators, #23455 MasterBias ram, #23518 Blooming object masks",
                            "Catherine Grenet",
                            "2023-08-21T17:30:06.000+02:00",
                            "3266962f8cb5374c52678180c4d4e0592338bdb8"
                        ]
                    ],
                    "VIS_IAL_Pipelines/auxdir/VIS_IAL_Pipelines/VIS_BloomingCalibration_Pipeline/PkgDef_VIS_BloomingCalibration.py": [
                        [
                            "@@ -26,7 +26,8 @@ VIS_blooming_xml_in = Executable(command   = f\"E-Run VIS_Tasks {TASKS_VER} VIS_x\n                                           Input(\"nlcorr_model\",     content_type=\"listfile\"),\n                                           Input(\"ron_model\",        content_type=\"listfile\"),\n                                           Input(\"cti_model\",        content_type=\"listfile\"),\n-                                          Input(\"bfe_model\",        content_type=\"listfile\"),],\n+                                          Input(\"bfe_model\",        content_type=\"listfile\"),\n+                                          Input(\"object_masks\",   content_type=\"listfile\")],\n                              outputs   = [Output(\"rawexp_list\", mime_type=\"json\", content_type=\"listfile\"),\n                                           Output(\"piperun_config\", mime_type=\"cfg\")],\n                              resources = ComputingResources(cores = 1,\n",
                            "Merge branch 'release-13.0' into develop: #23449 CTICalib decorators, #23455 MasterBias ram, #23518 Blooming object masks",
                            "Catherine Grenet",
                            "2023-08-21T17:30:06.000+02:00",
                            "3266962f8cb5374c52678180c4d4e0592338bdb8"
                        ]
                    ],
                    "VIS_IAL_Pipelines/auxdir/VIS_IAL_Pipelines/VIS_CTICalibration_Pipeline/PipScript_VIS_CTICalibration.py": [
                        [
                            "@@ -46,7 +46,8 @@ def process_cti_to_quad(config, MDB, rawexp_list):\n \n @parallel(\n     iterable=\"ccd_in\",\n-    outputs=(\"cti_parallel_output\", \"cti_serial_output\")\n+    outputs=(\"cti_parallel_output\", \"cti_serial_output\"),\n+    one_list_per_output=True\n )\n def process_calibrate_cti(\n         config,\n@@ -63,9 +64,9 @@ def process_calibrate_cti(\n \n def process_calibrate_cti_to_ccd(config, ccd_list):\n \n-    calibrate_cti = process_calibrate_cti(config=config, ccd_in=ccd_list)\n+    cti_parallel_output, cti_serial_output = process_calibrate_cti(config=config, ccd_in=ccd_list)\n \n-    return calibrate_cti\n+    return cti_parallel_output, cti_serial_output\n \n \n @pipeline(outputs=(\"parallel_cti_xml_out\", \"serial_cti_xml_out\"))\n@@ -117,14 +118,15 @@ def processCTI(\n \n     # Using each ccd_list, perform CTI calibration. This occurs in total 36 times, with a unique calibration for each\n     # CCD.\n-    calibrate_cti_results_list = process_calibrate_cti_to_ccd(\n+    cti_parallel_output, cti_serial_output = process_calibrate_cti_to_ccd(\n         config=config,\n         ccd_list=ccd_list\n     )\n \n     parallel_cti_xml_out, serial_cti_xml_out = PkgDef.VIS_cti_xml_out(\n         config=config,\n-        calibrate_cti_results_list=calibrate_cti_results_list\n+        parallel_calibrate_cti_results_list=cti_parallel_output,\n+        serial_calibrate_cti_results_list=cti_serial_output\n     )\n \n     return parallel_cti_xml_out, serial_cti_xml_out\n",
                            "Merge branch 'release-13.0' into develop: #23449 CTICalib decorators, #23455 MasterBias ram, #23518 Blooming object masks",
                            "Catherine Grenet",
                            "2023-08-21T17:30:06.000+02:00",
                            "3266962f8cb5374c52678180c4d4e0592338bdb8"
                        ],
                        [
                            "@@ -46,7 +46,8 @@ def process_cti_to_quad(config, MDB, rawexp_list):\n \n @parallel(\n     iterable=\"ccd_in\",\n-    outputs=(\"cti_parallel_output, cti_serial_output\")\n+    outputs=(\"cti_parallel_output\", \"cti_serial_output\"),\n+    one_list_per_output=True\n )\n def process_calibrate_cti(\n         config,\n@@ -63,9 +64,9 @@ def process_calibrate_cti(\n \n def process_calibrate_cti_to_ccd(config, ccd_list):\n \n-    calibrate_cti = process_calibrate_cti(config=config, ccd_in=ccd_list)\n+    cti_parallel_output, cti_serial_output = process_calibrate_cti(config=config, ccd_in=ccd_list)\n \n-    return calibrate_cti\n+    return cti_parallel_output, cti_serial_output\n \n \n @pipeline(outputs=(\"parallel_cti_xml_out\", \"serial_cti_xml_out\"))\n@@ -117,14 +118,15 @@ def processCTI(\n \n     # Using each ccd_list, perform CTI calibration. This occurs in total 36 times, with a unique calibration for each\n     # CCD.\n-    calibrate_cti_results_list = process_calibrate_cti_to_ccd(\n+    cti_parallel_output, cti_serial_output = process_calibrate_cti_to_ccd(\n         config=config,\n         ccd_list=ccd_list\n     )\n \n     parallel_cti_xml_out, serial_cti_xml_out = PkgDef.VIS_cti_xml_out(\n         config=config,\n-        calibrate_cti_results_list=calibrate_cti_results_list\n+        parallel_calibrate_cti_results_list=cti_parallel_output,\n+        serial_calibrate_cti_results_list=cti_serial_output\n     )\n \n     return parallel_cti_xml_out, serial_cti_xml_out\n",
                            "Merge branch 'hotfix/cti_xml_decorators' into 'release-13.0' [FIX]Bug #23449",
                            "Catherine Grenet",
                            "2023-08-16T12:43:00.000+00:00",
                            "e9be5c494febc0a5a9aa0f70f01f2838e721eca1"
                        ],
                        [
                            "@@ -46,7 +46,8 @@ def process_cti_to_quad(config, MDB, rawexp_list):\n \n @parallel(\n     iterable=\"ccd_in\",\n-    outputs=(\"cti_parallel_output, cti_serial_output\")\n+    outputs=(\"cti_parallel_output\", \"cti_serial_output\"),\n+    one_list_per_output=True\n )\n def process_calibrate_cti(\n         config,\n@@ -63,9 +64,9 @@ def process_calibrate_cti(\n \n def process_calibrate_cti_to_ccd(config, ccd_list):\n \n-    calibrate_cti = process_calibrate_cti(config=config, ccd_in=ccd_list)\n+    cti_parallel_output, cti_serial_output = process_calibrate_cti(config=config, ccd_in=ccd_list)\n \n-    return calibrate_cti\n+    return cti_parallel_output, cti_serial_output\n \n \n @pipeline(outputs=(\"parallel_cti_xml_out\", \"serial_cti_xml_out\"))\n@@ -117,14 +118,15 @@ def processCTI(\n \n     # Using each ccd_list, perform CTI calibration. This occurs in total 36 times, with a unique calibration for each\n     # CCD.\n-    calibrate_cti_results_list = process_calibrate_cti_to_ccd(\n+    cti_parallel_output, cti_serial_output = process_calibrate_cti_to_ccd(\n         config=config,\n         ccd_list=ccd_list\n     )\n \n     parallel_cti_xml_out, serial_cti_xml_out = PkgDef.VIS_cti_xml_out(\n         config=config,\n-        calibrate_cti_results_list=calibrate_cti_results_list\n+        parallel_calibrate_cti_results_list=cti_parallel_output,\n+        serial_calibrate_cti_results_list=cti_serial_output\n     )\n \n     return parallel_cti_xml_out, serial_cti_xml_out\n",
                            "Merge branch 'hotfix/cti_xml_decorators' into release-13.0",
                            "James Nightingale",
                            "2023-08-16T13:57:21.000+02:00",
                            "85e6369b56cd5bf4ddfdda7166ade026edd79dc7"
                        ]
                    ],
                    "VIS_IAL_Pipelines/auxdir/VIS_IAL_Pipelines/VIS_CTICalibration_Pipeline/PkgDef_VIS_CTICalibration.py": [
                        [
                            "@@ -63,10 +63,14 @@ calibrate_cti = Executable(\n \n VIS_cti_xml_out = Executable(\n     command=f\"E-Run VIS_Tasks {TASKS_VER} VIS_cti_xml_out\",\n-    inputs=[\"config\", \"calibrate_cti_results_list\"],\n+    inputs=[\n+        \"config\",\n+        Input(\"parallel_calibrate_cti_results_list\"),\n+        Input(\"serial_calibrate_cti_results_list\")\n+    ],\n     outputs=[\n         Output(\"parallel_cti_xml_out\"),\n         Output(\"serial_cti_xml_out\"),\n     ],\n     resources=ComputingResources(cores=1, ram=7.0, walltime=3.0),\n-)\n\\ No newline at end of file\n+)\n",
                            "Merge branch 'release-13.0' into develop: #23449 CTICalib decorators, #23455 MasterBias ram, #23518 Blooming object masks",
                            "Catherine Grenet",
                            "2023-08-21T17:30:06.000+02:00",
                            "3266962f8cb5374c52678180c4d4e0592338bdb8"
                        ],
                        [
                            "@@ -60,7 +60,7 @@ calibrate_cti = Executable(\n         Output(\"cti_parallel_output\", mime_type=\"json\"),\n         Output(\"cti_serial_output\", mime_type=\"json\")\n     ],\n-    resources=ComputingResources(cores=1, ram=256.0, walltime=16.0),\n+    resources=ComputingResources(cores=8, ram=128.0, walltime=8.0),\n )\n \n VIS_cti_xml_out = Executable(\n",
                            "cti calibration pieline cores",
                            "James Nightingale",
                            "2023-08-18T17:49:52.000+02:00",
                            "5de471ce755cad4421d81ed0e45cc7dd3c0a4734"
                        ],
                        [
                            "@@ -18,6 +18,8 @@ import os\n \n PIPE_NAME = \"VIS_\" + os.path.splitext( os.path.basename( __file__))[0].split( \"VIS_\")[1]\n \n+TASKS_VER = \"13.0.14\"\n+\n VIS_cti_xml_in = Executable(\n     command=f\"E-Run VIS_Tasks {TASKS_VER} VIS_xml_in --pipeline_name={PIPE_NAME} \",\n     inputs=[\n",
                            "manual edits to IAL to allow for local runs",
                            "James Nightingale",
                            "2023-08-16T16:01:33.000+02:00",
                            "fc4c14a564cdba2d11ab4e1426e2a02183cb9fcb"
                        ],
                        [
                            "@@ -18,8 +18,6 @@ import os\n \n PIPE_NAME = \"VIS_\" + os.path.splitext( os.path.basename( __file__))[0].split( \"VIS_\")[1]\n \n-TASKS_VERSION = \"13.0.13\"\n-\n VIS_cti_xml_in = Executable(\n     command=f\"E-Run VIS_Tasks {TASKS_VER} VIS_xml_in --pipeline_name={PIPE_NAME} \",\n     inputs=[\n",
                            "hot fix tested in end-to-end run",
                            "James Nightingale",
                            "2023-08-16T13:47:26.000+02:00",
                            "f66fa0d8f8f7577454c36e82268dc2f8ba83c0da"
                        ]
                    ],
                    "VIS_IAL_Pipelines/auxdir/VIS_IAL_Pipelines/VIS_MasterBias_Pipeline/PkgDef_VIS_MasterBias.py": [
                        [
                            "@@ -71,7 +71,7 @@ processBiasQuad = Executable(command = f\"E-Run VIS_Tasks {TASKS_VER} VIS_process\n                                         Output(\"output_quadrant_stdev\", mime_type=\"json\", content_type=\"listfile\"),\n                                         Output(\"output_quadrant_count\", mime_type=\"json\", content_type=\"listfile\"),],\n                              resources = ComputingResources(cores = 1,\n-                                                            ram = 6.0,\n+                                                            ram = 9.0,\n                                                             walltime = 3.0))\n \n quad2FPA = Executable(command = f\"E-Run VIS_Tasks {TASKS_VER} VIS_quad_to_fpa\",\n",
                            "Merge branch 'release-13.0' into develop: #23449 CTICalib decorators, #23455 MasterBias ram, #23518 Blooming object masks",
                            "Catherine Grenet",
                            "2023-08-21T17:30:06.000+02:00",
                            "3266962f8cb5374c52678180c4d4e0592338bdb8"
                        ]
                    ],
                    "doc/user_manual/chap04.md": [
                        [
                            "@@ -86,57 +86,18 @@ Processing of science exposures uses two pipelines:\n \n All other pipelines are intended to produce calibration models from calibration data.\n \n-The current version of this document describes VIS pipelines operation during PV phase. We describe below the processing of some complex calblocks which require to run several pipelines.\n+Operation of the pipelines during PV phase is described in chapter PV operations.\n \n-### PV-001 Self Calibration\n-\n-1. Execution of VIS_PSFCalibration pipeline to produce a PSF model\n-\n-   This PSF model will be used in all subsequent steps where a PSF model is needed.\n-\n-2. Execution of 2 instances of VIS_ProcessField pipeline without stacking, using the PSF model above, possibly in parallel:  \n-   * one on the raw short exposures: it will produce short calibrated exposures and catalogs\n-   * one on the raw nominal exposures: it will produce nominal calibrated exposures and catalogs\n-\n-3. Possibly in parallel\n-   * Execution of the VIS_LargeFlatCalibration pipeline on the short calibrated catalogs produced in the previous step: it will produce the short large flat\n-   * Execution of the VIS_LargeFlatCalibration pipeline on the nominal calibrated catalogs produced in the previous step: it will produce the nominal large flat\n-   * Execution of the VIS_Stacking pipeline on the nominal calibrated exposures produced in the previous step: it will produce the astrometric catalog for NIR\n-\n-   These large flats will be used in all subsequent steps where a large flat is needed.\n-\n-4. Possibly in parallel\n-   * Execution of 2 instances of VIS_ProcessField pipeline without stacking\n-     * one on the raw short exposures, using the short large flat produced in step 3\n-     * one on the raw nominal exposures, using the nominal large flat produced in step 3\n-\n-5. Possibly in parallel\n-   * Execution of VIS_PhotometryCalibration pipeline on the short calibrated catalogs produced in step 4: it will produce a first estimation of the zero point\n-   * Execution of VIS_GhostsCalibration pipeline on the ghosts catalogs produced in step 4, both nominal and short\n-   * Execution of VIS_XTalkCalibration pipeline on the raw nominal exposures\n-\n-6. Execution of 2 instances of VIS_ProcessField pipeline with stacking, possibly in parallel:\n-   * one on the raw short exposures\n-   * one on the raw nominal exposures\n-\n-   using PSF model, large flats, zero point and crosstalk model produced in the previous steps.\n-\n-   This final step wil produce the standard VIS products calibrated in photometry.\n-\n-### PV-002 NISP-P and VIS Absolute Photometric Standards\n-\n-TBW\n-   \n \n ## PF configuration file\n \n Each pipeline has in input a configuration file, named hereafter VIS PF configuration file, which controls its behavior. The configuration file is of type `DpdVisConfigurationFile`.\n \n-Three configuration files are provided, listed below with their ProductId:\n+Four configuration files are provided, listed below with their ProductId:\n \n * `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_ini`: generic configuration file, to be used when no specific instructions are provided.\n * `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_nostack_ini`: to be used to execute a `ProcessField` pipeline without stacking\n * `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_normtmp_ini`: to be used to execute a pipeline without removing temporary files from the workdir\n-\n+* `DpdVisConfigurationFile_EUC_VIS_ConfigFile_15AUG2023_ini`: same as `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_ini` with different hot and warm pixel thresholds for VIS_MasterDark pipeline (0.1 vs 0.01)\n \n \n",
                            "Merge branch 'release-13.0' into develop: #23449 CTICalib decorators, #23455 MasterBias ram, #23518 Blooming object masks",
                            "Catherine Grenet",
                            "2023-08-21T17:30:06.000+02:00",
                            "3266962f8cb5374c52678180c4d4e0592338bdb8"
                        ],
                        [
                            "@@ -93,11 +93,11 @@ Operation of the pipelines during PV phase is described in chapter PV operations\n \n Each pipeline has in input a configuration file, named hereafter VIS PF configuration file, which controls its behavior. The configuration file is of type `DpdVisConfigurationFile`.\n \n-Three configuration files are provided, listed below with their ProductId:\n+Four configuration files are provided, listed below with their ProductId:\n \n * `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_ini`: generic configuration file, to be used when no specific instructions are provided.\n * `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_nostack_ini`: to be used to execute a `ProcessField` pipeline without stacking\n * `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_normtmp_ini`: to be used to execute a pipeline without removing temporary files from the workdir\n-\n+* `DpdVisConfigurationFile_EUC_VIS_ConfigFile_15AUG2023_ini`: same as `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_ini` with different hot and warm pixel thresholds for VIS_MasterDark pipeline (0.1 vs 0.01)\n \n \n",
                            "Merge branch 'release-13.0' into master_ci_memory",
                            "James Nightingale",
                            "2023-08-18T17:55:53.000+02:00",
                            "961b01b509e96c9e2b52d75b5383fbd55e0be960"
                        ],
                        [
                            "@@ -93,11 +93,11 @@ Operation of the pipelines during PV phase is described in chapter PV operations\n \n Each pipeline has in input a configuration file, named hereafter VIS PF configuration file, which controls its behavior. The configuration file is of type `DpdVisConfigurationFile`.\n \n-Three configuration files are provided, listed below with their ProductId:\n+Four configuration files are provided, listed below with their ProductId:\n \n * `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_ini`: generic configuration file, to be used when no specific instructions are provided.\n * `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_nostack_ini`: to be used to execute a `ProcessField` pipeline without stacking\n * `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_normtmp_ini`: to be used to execute a pipeline without removing temporary files from the workdir\n-\n+* `DpdVisConfigurationFile_EUC_VIS_ConfigFile_15AUG2023_ini`: same as `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_ini` with different hot and warm pixel thresholds for VIS_MasterDark pipeline (0.1 vs 0.01)\n \n \n",
                            "Merge branch 'release-13.0' of https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines into release-13.0",
                            "James Nightingale",
                            "2023-08-18T17:50:03.000+02:00",
                            "22bec8642685bff3087cfb2386d20e518a3f4a96"
                        ],
                        [
                            "@@ -93,11 +93,11 @@ Operation of the pipelines during PV phase is described in chapter PV operations\n \n Each pipeline has in input a configuration file, named hereafter VIS PF configuration file, which controls its behavior. The configuration file is of type `DpdVisConfigurationFile`.\n \n-Three configuration files are provided, listed below with their ProductId:\n+Four configuration files are provided, listed below with their ProductId:\n \n * `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_ini`: generic configuration file, to be used when no specific instructions are provided.\n * `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_nostack_ini`: to be used to execute a `ProcessField` pipeline without stacking\n * `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_normtmp_ini`: to be used to execute a pipeline without removing temporary files from the workdir\n-\n+* `DpdVisConfigurationFile_EUC_VIS_ConfigFile_15AUG2023_ini`: same as `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_ini` with different hot and warm pixel thresholds for VIS_MasterDark pipeline (0.1 vs 0.01)\n \n \n",
                            "Merge branch 'feature-SUM' into release-13.0: [DOC][FIX]Bug #23494,[UPD] SRN 13.0.13",
                            "Catherine Grenet",
                            "2023-08-16T15:26:57.000+02:00",
                            "63fd4293bf64c2e9895af3adad163bf543d3d23f"
                        ],
                        [
                            "@@ -93,11 +93,11 @@ Operation of the pipelines during PV phase is described in chapter PV operations\n \n Each pipeline has in input a configuration file, named hereafter VIS PF configuration file, which controls its behavior. The configuration file is of type `DpdVisConfigurationFile`.\n \n-Three configuration files are provided, listed below with their ProductId:\n+Four configuration files are provided, listed below with their ProductId:\n \n * `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_ini`: generic configuration file, to be used when no specific instructions are provided.\n * `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_nostack_ini`: to be used to execute a `ProcessField` pipeline without stacking\n * `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_normtmp_ini`: to be used to execute a pipeline without removing temporary files from the workdir\n-\n+* `DpdVisConfigurationFile_EUC_VIS_ConfigFile_15AUG2023_ini`: same as `DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_ini` with different hot and warm pixel thresholds for VIS_MasterDark pipeline (0.1 vs 0.01)\n \n \n",
                            "[FIX]SUM Bug #23494 New configuration file for MasterDark pipeline.",
                            "Catherine Grenet",
                            "2023-08-16T15:10:41.000+02:00",
                            "c1be58ac83f804692e2dafe1ddeeecb9328ff79b"
                        ],
                        [
                            "@@ -86,47 +86,8 @@ Processing of science exposures uses two pipelines:\n \n All other pipelines are intended to produce calibration models from calibration data.\n \n-The current version of this document describes VIS pipelines operation during PV phase. We describe below the processing of some complex calblocks which require to run several pipelines.\n+Operation of the pipelines during PV phase is described in chapter PV operations.\n \n-### PV-001 Self Calibration\n-\n-1. Execution of VIS_PSFCalibration pipeline to produce a PSF model\n-\n-   This PSF model will be used in all subsequent steps where a PSF model is needed.\n-\n-2. Execution of 2 instances of VIS_ProcessField pipeline without stacking, using the PSF model above, possibly in parallel:  \n-   * one on the raw short exposures: it will produce short calibrated exposures and catalogs\n-   * one on the raw nominal exposures: it will produce nominal calibrated exposures and catalogs\n-\n-3. Possibly in parallel\n-   * Execution of the VIS_LargeFlatCalibration pipeline on the short calibrated catalogs produced in the previous step: it will produce the short large flat\n-   * Execution of the VIS_LargeFlatCalibration pipeline on the nominal calibrated catalogs produced in the previous step: it will produce the nominal large flat\n-   * Execution of the VIS_Stacking pipeline on the nominal calibrated exposures produced in the previous step: it will produce the astrometric catalog for NIR\n-\n-   These large flats will be used in all subsequent steps where a large flat is needed.\n-\n-4. Possibly in parallel\n-   * Execution of 2 instances of VIS_ProcessField pipeline without stacking\n-     * one on the raw short exposures, using the short large flat produced in step 3\n-     * one on the raw nominal exposures, using the nominal large flat produced in step 3\n-\n-5. Possibly in parallel\n-   * Execution of VIS_PhotometryCalibration pipeline on the short calibrated catalogs produced in step 4: it will produce a first estimation of the zero point\n-   * Execution of VIS_GhostsCalibration pipeline on the ghosts catalogs produced in step 4, both nominal and short\n-   * Execution of VIS_XTalkCalibration pipeline on the raw nominal exposures\n-\n-6. Execution of 2 instances of VIS_ProcessField pipeline with stacking, possibly in parallel:\n-   * one on the raw short exposures\n-   * one on the raw nominal exposures\n-\n-   using PSF model, large flats, zero point and crosstalk model produced in the previous steps.\n-\n-   This final step wil produce the standard VIS products calibrated in photometry.\n-\n-### PV-002 NISP-P and VIS Absolute Photometric Standards\n-\n-TBW\n-   \n \n ## PF configuration file\n \n",
                            "Merge branch 'feature-SUM' into release-13.0: SRN VIS PF 13.0.12",
                            "Catherine Grenet",
                            "2023-08-14T16:13:23.000+02:00",
                            "bec4d2f7797ae8a84255ffd581f45f5a4f533835"
                        ]
                    ],
                    "doc/user_manual/chap05_AstrometryCalibration.md": [
                        [
                            "@@ -37,8 +37,6 @@ graph LR\n     DpdVisMasterFlatFrame -.->|masterflat<br>0..1| pipeline\n     DpdVisDistortionModel -.->|dist_model<br>0..1| pipeline\n     DpdVisLargeFlatFrame -.->|lsf_model<br>0..1| pipeline\n-    DpdVisGhostModel -.->|ghost_model<br>1..1| pipeline\n-    DpdVisStarMask -.->|starmask_model<br>1..1| pipeline\n     DpdVisBFEModel -.->|bfe_model<br>0..1| pipeline\n     DpdTrueUniverseOutput -->|ref_catalogues<br>1..*| pipeline\n     pipeline -->|dist_model_xml_out<br>>1..1| DpdVisDistortionModel\n@@ -62,8 +60,6 @@ graph LR\n * `masterflat`: master flat frame\n * `dist_model`: distortion model, not to be used\n * `lsf_model`: large scale flat model from `VIS_LargeFlatCalibration` pipeline\n-* `ghost_model`: ghost model\n-* `starmask_model`: star mask model\n * `bfe_model`: brighter-fatter model\n * `ref_catalogues`: list of reference catalogues covering raw science frames sky area\n \n@@ -73,7 +69,7 @@ The pipeline will be executed on calblock PV-023. Only nominal exposures shall b\n \n xtalk_model, nlcorr_model, cti_model, lsf_model, bfe_model should not used because the corresponding models will not be available at the time PV-023 is received.\n \n-gains_model, ron_model, saturation_model, zero_point, ghost_model, starmask_model: on-ground models should be used.\n+gains_model, ron_model, saturation_model, zero_point: on-ground models should be used.\n \n ## Operational constraints\n \n@@ -85,7 +81,7 @@ A run on a simulated realisation of PV-023 (20 nominal exposures) requires:\n \n | Cores | RSS (GB) | Walltime (h) | Disk space (GB) |\n | ----- | -------- | ------------ | --------------- |\n-| 20    | TBW      | 5            | TBW             |\n+| 20    | TBW      | 5            | 350             |\n \n ## Normal termination\n \n",
                            "Merge branch 'release-13.0' into develop: #23449 CTICalib decorators, #23455 MasterBias ram, #23518 Blooming object masks",
                            "Catherine Grenet",
                            "2023-08-21T17:30:06.000+02:00",
                            "3266962f8cb5374c52678180c4d4e0592338bdb8"
                        ]
                    ],
                    "doc/user_manual/chap06_BloomingCalibration.md": [
                        [
                            "@@ -34,15 +34,16 @@ graph LR\n     DpdVisNonLinearityModel -.->|nlcorr_model<br>0..1| pipeline\n     DpdVisCTIModel -.->|cti_model<br>0..1| pipeline\n     DpdVisBFEModel -.->|bfe_model<br>0..1| pipeline\n+    DpdVisFlagMap -.->|object_masks<br>0..*| pipeline\n     pipeline -->|dpdcalib_blooming<br>1..*| DpdVisBloomingModel&nbsp\n ```\n \n **Ports description:**\n \n-* `DpdVisRawFrame`: raw flat field frames\n+* `raw_frames_in`: raw flat field frames\n * `vis_config_in`: VIS PF configuration file\n * `MDB`: Mission DataBase\n-* `DpdVisGainModel`: gain model from `VIS_GainCalibration` pipeline\n+* `gains_model`: gain model from `VIS_GainCalibration` pipeline\n * `ron_model`: readout noise model\n * `saturation_model`: saturation model, not used\n * `masterbias`: master bias frame from `VIS_MasterBias` pipeline\n@@ -51,6 +52,7 @@ graph LR\n * `nlcorr_model`: non-linearity correction model\n * `cti_model`: CTI model\n * `bfe_model`: bfe model\n+* `object_masks`: objet masks from VIS_FlagObjects pipeline\n \n \n \n@@ -72,7 +74,7 @@ A typical run on 10 raw flat frames requires:\n \n | Cores | RSS (GB) | Walltime (h) | Disk space (GB) |\n | ----- | -------- | ------------ | --------------- |\n-| TBW   | TBW      | TBW          | TBW             |\n+| TBW   | TBW      | 5            | 550             |\n \n ## Normal termination\n \n",
                            "Merge branch 'release-13.0' into develop: #23449 CTICalib decorators, #23455 MasterBias ram, #23518 Blooming object masks",
                            "Catherine Grenet",
                            "2023-08-21T17:30:06.000+02:00",
                            "3266962f8cb5374c52678180c4d4e0592338bdb8"
                        ],
                        [
                            "@@ -34,15 +34,16 @@ graph LR\n     DpdVisNonLinearityModel -.->|nlcorr_model<br>0..1| pipeline\n     DpdVisCTIModel -.->|cti_model<br>0..1| pipeline\n     DpdVisBFEModel -.->|bfe_model<br>0..1| pipeline\n+    DpdVisFlagMap -.->|object_masks<br>0..*| pipeline\n     pipeline -->|dpdcalib_blooming<br>1..*| DpdVisBloomingModel&nbsp\n ```\n \n **Ports description:**\n \n-* `DpdVisRawFrame`: raw flat field frames\n+* `raw_frames_in`: raw flat field frames\n * `vis_config_in`: VIS PF configuration file\n * `MDB`: Mission DataBase\n-* `DpdVisGainModel`: gain model from `VIS_GainCalibration` pipeline\n+* `gains_model`: gain model from `VIS_GainCalibration` pipeline\n * `ron_model`: readout noise model\n * `saturation_model`: saturation model, not used\n * `masterbias`: master bias frame from `VIS_MasterBias` pipeline\n@@ -51,6 +52,7 @@ graph LR\n * `nlcorr_model`: non-linearity correction model\n * `cti_model`: CTI model\n * `bfe_model`: bfe model\n+* `object_masks`: objet masks from VIS_FlagObjects pipeline\n \n \n \n",
                            "Merge branch 'feature-SUM' into release-13.0: PV-022, PV-029, PV-031 additions",
                            "Catherine Grenet",
                            "2023-08-21T17:00:25.000+02:00",
                            "8c05d2935966f233f6059e719e252def83a096b0"
                        ],
                        [
                            "@@ -34,15 +34,16 @@ graph LR\n     DpdVisNonLinearityModel -.->|nlcorr_model<br>0..1| pipeline\n     DpdVisCTIModel -.->|cti_model<br>0..1| pipeline\n     DpdVisBFEModel -.->|bfe_model<br>0..1| pipeline\n+    DpdVisFlagMap -.->|object_masks<br>0..*| pipeline\n     pipeline -->|dpdcalib_blooming<br>1..*| DpdVisBloomingModel&nbsp\n ```\n \n **Ports description:**\n \n-* `DpdVisRawFrame`: raw flat field frames\n+* `raw_frames_in`: raw flat field frames\n * `vis_config_in`: VIS PF configuration file\n * `MDB`: Mission DataBase\n-* `DpdVisGainModel`: gain model from `VIS_GainCalibration` pipeline\n+* `gains_model`: gain model from `VIS_GainCalibration` pipeline\n * `ron_model`: readout noise model\n * `saturation_model`: saturation model, not used\n * `masterbias`: master bias frame from `VIS_MasterBias` pipeline\n@@ -51,6 +52,7 @@ graph LR\n * `nlcorr_model`: non-linearity correction model\n * `cti_model`: CTI model\n * `bfe_model`: bfe model\n+* `object_masks`: objet masks from VIS_FlagObjects pipeline\n \n \n \n",
                            "[UPD]SUM Blooming calibration now uses objets masks #23518",
                            "Catherine Grenet",
                            "2023-08-21T15:21:24.000+02:00",
                            "9057df5abab53351e0430279c1db3794a3c164a7"
                        ],
                        [
                            "@@ -72,7 +72,7 @@ A typical run on 10 raw flat frames requires:\n \n | Cores | RSS (GB) | Walltime (h) | Disk space (GB) |\n | ----- | -------- | ------------ | --------------- |\n-| TBW   | TBW      | TBW          | TBW             |\n+| TBW   | TBW      | 5            | 550             |\n \n ## Normal termination\n \n",
                            "Merge branch 'feature-SUM' into release-13.0: SRN VIS PF 13.0.12",
                            "Catherine Grenet",
                            "2023-08-14T16:13:23.000+02:00",
                            "bec4d2f7797ae8a84255ffd581f45f5a4f533835"
                        ]
                    ],
                    "doc/user_manual/chap08_CTICalibration.md": [
                        [
                            "@@ -16,7 +16,9 @@ The related GitLab projects are following [RD6]:\n \n ## Pipeline ports with inputs/outputs\n \n-The following diagram represents the ports of `Pipeline VIS_CTICalibration`. For each port, the product type, port name and cardinality are provided. The thick arrow is for the key input port. Optional ports are represented by dotted arrows.\n+The following diagram represents the ports of `Pipeline VIS_CTICalibration`. For each port, the product type,\n+port name and cardinality are provided. The thick arrow is for the key input port. Optional ports are represented\n+by dotted arrows.\n \n ```mermaid\n graph LR\n@@ -32,8 +34,8 @@ graph LR\n     DpdVisNonLinearityModel -.->|nlcorr_model<br>0..1| pipeline\n     DpdVisRONModel -->|ron_model<br>1..1| pipeline\n     DpdVisBloomingModel -.->|saturation_model<br>0..1| pipeline\n-    pipeline -->|dpdcticalibration<br>1..1| DpdVisCTICalibrationResults\n-    pipeline -->|dpdanalysis_out<br>1..1| DpdVisAnalysisResults\n+    pipeline -->|parallel_cti_xml_out<br>1..1| DpdVisCTICalibrationResults\n+    pipeline -->|serial_cti_xml_out<br>1..1| DpdVisCTICalibrationResults\n ```\n \n **Ports description:**\n@@ -49,8 +51,8 @@ graph LR\n * `nlcorr_model`: non-linearity correction model\n * `ron_model`: readout noise model\n * `saturation_model`: saturation model\n-* `dpdcticalibration`: CTI calibration results, including best-fit model with errors.\n-* `dpdanalysis`: quality assessment parameters\n+* `parallel_cti_xml_out`: Parallel CTI calibration results, including best-fit model with errors and DQ images.\n+* `serial_cti_xml_out`: Serial CTI calibration results, including best-fit model with errors and DQ images.\n \n Input ports not described above are currently unused.\n \n@@ -70,7 +72,7 @@ A typical run on 8 raw charge injection frames requires:\n \n | Cores | RSS (GB)        | Walltime (h) | Disk space (GB) |\n |-------|-----------------|-------------|-----------------|\n-| 36    | 9216 (36 * 256) | 12          | TBW             | # Estimate from workdir\n+| 36    | 9216 (36 * 256) | 12          | 4               |\n \n ## Normal termination\n \n@@ -79,4 +81,4 @@ order should have its `ProcessingState` element set to `Completed`.\n \n ## Error condition\n \n-In case of runtime error contact PF support.\n+In case of runtime error contact PF support.\n\\ No newline at end of file\n",
                            "Merge branch 'release-13.0' into develop: #23449 CTICalib decorators, #23455 MasterBias ram, #23518 Blooming object masks",
                            "Catherine Grenet",
                            "2023-08-21T17:30:06.000+02:00",
                            "3266962f8cb5374c52678180c4d4e0592338bdb8"
                        ]
                    ],
                    "doc/user_manual/chap09_CTIMasterCI.md": [
                        [
                            "@@ -16,7 +16,9 @@ The related GitLab projects are following [RD6]:\n \n ## Pipeline ports with inputs/outputs\n \n-The following diagram represents the ports of `Pipeline VIS_CTIMasterCI`. For each port, the product type, port name and cardinality are provided. The thick arrow is for the key input port. Optional ports are represented by dotted arrows.\n+The following diagram represents the ports of `Pipeline VIS_CTIMasterCI`. For each port, the product type,\n+port name and cardinality are provided. The thick arrow is for the key input port. Optional ports are represented\n+by dotted arrows.\n \n ```mermaid\n graph LR\n@@ -32,8 +34,7 @@ graph LR\n     DpdVisNonLinearityModel -.->|nlcorr_model<br>0..1| pipeline\n     DpdVisRONModel -->|ron_model<br>1..1| pipeline\n     DpdVisBloomingModel -.->|saturation_model<br>0..1| pipeline\n-    pipeline -->|dpdmasterci<br>1..1| DpdVisMasterCIFrame\n-    pipeline -->|dpdanalysis_out<br>1..1| DpdVisAnalysisResults\n+    pipeline -->|master_ci_xml_out<br>1..1| DpdVisMasterCIFrame\n ```\n \n **Ports description:**\n@@ -49,16 +50,15 @@ graph LR\n * `nlcorr_model`: non-linearity correction model\n * `ron_model`: readout noise model\n * `saturation_model`: saturation model\n-* `dpdcticalibration`: CTI calibration results, including best-fit model with errors.\n-* `dpdanalysis`: quality assessment parameters\n+* `master_ci_xml_out`: FPA of master charge injection images.\n \n Input ports not described above are currently unused.\n \n ## Processing triggering assumptions\n \n-The pipeline only runs during PV, on reception of calblock PV-028.\n+The pipeline only runs during PV, on reception of CALBLOCK PV-028.\n \n-The process should be triggered independently according to the two variants in the calblock:\n+The process should be triggered independently according to the two variants in the CALBLOCK:\n \n - ROS variant: 32 times for each set of ROS sequence charge injection settings.\n \n@@ -74,7 +74,7 @@ A typical run on 6 raw charge injection frames requires:\n \n | Cores | RSS (GB)        | Walltime (h) | Disk space (GB) |\n |-------|-----------------|--------------|-----------------|\n-| 36    | 9216 (36 * 256) | 4            | TBW             | # Estimate from workdir\n+| 36    | 9216 (36 * 256) | 4            | 4               |\n \n ## Normal termination\n \n@@ -83,4 +83,4 @@ order should have its `ProcessingState` element set to `Completed`.\n \n ## Error condition\n \n-In case of runtime error contact PF support.\n+In case of runtime error contact PF support.\n\\ No newline at end of file\n",
                            "Merge branch 'release-13.0' into develop: #23449 CTICalib decorators, #23455 MasterBias ram, #23518 Blooming object masks",
                            "Catherine Grenet",
                            "2023-08-21T17:30:06.000+02:00",
                            "3266962f8cb5374c52678180c4d4e0592338bdb8"
                        ]
                    ],
                    "doc/user_manual/chap20_PSFCalibration.md": [
                        [
                            "@@ -32,16 +32,8 @@ graph LR\n     DpdVisXTalkModel -.->|xtalk_model<br>0..1| pipeline\n     DpdVisNonLinearityModel -.->|nlcorr_model<br>0..1| pipeline\n     DpdVisCTIModel -.->|cti_model<br>0..1| pipeline\n-    DpdVisZeroPoint -.->|zero_point<br>0..1| pipeline\n     DpdVisMasterDarkFrame -.->|masterdark<br>0..1| pipeline\n     DpdVisMasterFlatFrame -.->|masterflat<br>0..1| pipeline\n-    DpdVisPSFModel -.->|psf_model<br>0..1| pipeline\n-    DpdVisDistortionModel -.->|dist_model<br>0..1| pipeline\n-    DpdVisLargeFlatFrame -.->|lsf_model<br>0..1| pipeline\n-    DpdVisGhostModel -.->|ghost_model<br>0..1| pipeline\n-    DpdVisStarMask -.->|starmask_model<br>0..1| pipeline\n-    DpdVisBFEModel -.->|bfe_model<br>0..1| pipeline\n-    DpdTrueUniverseOutput -.->|ref_catalogues<br>0..*| pipeline\n     pipeline -->|psf_model_xml_out<br>1..1| DpdVisPSFModel\n ```\n \n@@ -58,16 +50,8 @@ graph LR\n * `xtalk_model`: crosstalk model\n * `nlcorr_model`: non-linearity correction model\n * `cti_model`: CTI model\n-* `zero_point`: zero point, not used\n * `masterdark`: master dark, not to be used as long as dark is not measurable\n * `masterflat`: master flat frame\n-* `psf_model`: PSF model, not used\n-* `dist_model`: distortion model, not used\n-* `lsf_model`: large scale flat model from `VIS_LargeFlatCalibration` pipeline, none if not available\n-* `ghost_model`: ghost model, not used\n-* `starmask_model`: star mask model, not used\n-* `bfe_model`: brighter-fatter model\n-* `ref_catalogues`: list of reference catalogues covering raw science frames sky area, not used\n \n ## Processing triggering assumptions\n \n",
                            "Merge branch 'release-13.0' into develop: #23449 CTICalib decorators, #23455 MasterBias ram, #23518 Blooming object masks",
                            "Catherine Grenet",
                            "2023-08-21T17:30:06.000+02:00",
                            "3266962f8cb5374c52678180c4d4e0592338bdb8"
                        ]
                    ],
                    "doc/user_manual/chap24_ProcessField.md": [
                        [
                            "@@ -6,6 +6,8 @@\n \n **VIS_ProcessField**: Production of calibrated frames and associated catalogs from a list of raw science exposures. Optionally, production of the stacked image and its associated catalog.\n \n+Stack production is controlled by the PF configuration file (see PF Operations Environment).\n+\n The related GitLab projects are following [RD6]:\n \n * `VIS_Tasks`\n@@ -88,10 +90,6 @@ During nominal operations the pipeline will be triggered on each observation (RO\n \n Either during PV or nominal operations, short and nominal science exposures should always be processed in different instances of the pipeline, because the large flat model is different depending on exposure duration.\n \n-Below we describe the operation of the pipeline during PV, in chronological order of calblocks.\n-\n-TBW\n-\n ## Operational constraints\n \n None.\n",
                            "Merge branch 'release-13.0' into develop: #23449 CTICalib decorators, #23455 MasterBias ram, #23518 Blooming object masks",
                            "Catherine Grenet",
                            "2023-08-21T17:30:06.000+02:00",
                            "3266962f8cb5374c52678180c4d4e0592338bdb8"
                        ]
                    ],
                    "doc/user_manual/chap27_TrapPumpingCalibration.md": [
                        [
                            "@@ -58,23 +58,23 @@ For MSTP (`TrapPumping.Status=MultipleSerial`), each pipeline instance requires\n \n ### PV configurations\n \n-During PV the pipeline will be triggered on reception of calblock PV-027, with an instance to be run for each TP parameter configuration. For VTP, there are 2 IG1 voltages and 4 shuffling modes, giving a total of 8 pipeline instances. For MSTP, there are 2 IG1 voltages and 2 shuffling modes, so 4 instances. The frame selection queries are given below.\n+During PV the pipeline will be triggered on reception of calblock PV-027, with an instance to be run for each TP parameter configuration. For VTP, there are 2 IG1 voltages and 4 shuffling modes, giving a total of 8 pipeline instances. For MSTP, there are 2 IG1 voltages and 2 shuffling modes, so 4 instances. The frame selection criteria are given below.\n \n **VTP:**\n \n-The queries follow the pattern\n+The frame selections follow the pattern\n ```\n-ObservationSequence.CalblockId=PV-027&ObservationSequence.CalblockVariant=PARALLEL-CI-<variant>&(TrapPumping.ParallelTrapPumpingParameters.ShufflingCyclesCount=1|TrapPumping.ParallelTrapPumpingParameters.ShufflingMode=<mode>)\n+ObservationSequence.CalblockId=PV-027 & ObservationSequence.CalblockVariant=PARALLEL-CI-<variant> & (TrapPumping.ParallelTrapPumpingParameters.ShufflingCyclesCount=1 | TrapPumping.ParallelTrapPumpingParameters.ShufflingMode=<mode>)\n ```\n with `<variant>` taking the values `HIGH` and `LOW` and, for each of these, `<mode>` taking the values `234`, `123`, `341` and `412`.\n \n **STP:**\n \n-The queries follow the pattern\n+The frame selections follow the pattern\n ```\n-ObservationSequence.CalBlockId=PV-027&ObservationSequence.CalBlockVariant=SERIAL&ChargeInjection.Parameters.InjectionGate1Voltage.Value=<ig1>&TrapPumping.SerialTrapPumpingParameters.SerialTrapPumpingParameterList.SerialTrapPumpingParameterSet1.ShufflingMode=<mode>\n+ObservationSequence.CalBlockId=PV-027 & ObservationSequence.CalBlockVariant=SERIAL & ChargeInjection.Parameters.InjectionGate1Voltage.Value=<ig1> & TrapPumping.SerialTrapPumpingParameters.SerialTrapPumpingParameterList.SerialTrapPumpingParameterSet1.ShufflingMode=<mode>\n ```\n-with `<ig1>` taking the values `4.0` and `4.75` and, for each of these, `<mode>` taking the values `23` and `31`.\n+with `<ig1>` taking the values of approximately `4.0` and `4.75` and, for each of these, `<mode>` taking the values `23` and `31`. Since IG1 voltages will vary around the nominal values and there are only two options, a single threshold can be used to separate them, giving a pair of criteria such as `InjectionGate1Voltage.Value < 4.4` and `InjectionGate1Voltage.Value > 4.4`.\n \n ## Operational constraints\n \n",
                            "Merge branch 'release-13.0' into develop: #23449 CTICalib decorators, #23455 MasterBias ram, #23518 Blooming object masks",
                            "Catherine Grenet",
                            "2023-08-21T17:30:06.000+02:00",
                            "3266962f8cb5374c52678180c4d4e0592338bdb8"
                        ]
                    ],
                    "doc/user_manual/chap29_PVOperations.md": [
                        [
                            "@@ -0,0 +1,836 @@\n+\\newpage\n+\n+# PV operations\n+\n+## Commonalities\n+\n+There is no VIS pipeline to trigger for Calblocks not mentioned in this chapter.\n+\n+Unless otherwise stated, the following inputs will be used for all pipelines:\n+\n+- vis_config_in: DpdVisConfigurationFile ProductId=DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_ini\n+- MDB: DpdMdbDataBase ProductId=EUC_MDB_MISSIONCONFIGURATION-DEV_2023-07-17T12:00:00.00Z_00\n+\n+These inputs will not be repeated hereafter.\n+\n+Some pipelines will use on-ground models. These on-ground models are:\n+\n+- gains_model: DpdVisGainModel ProductId=DpdVisGainModel_EUC_VIS_MDL-PTC01_GAIN_elperadu_MAP_json\n+- psf_model: DpdVisPSFModel ProductId=DpdVisPSFModel_EUC_VIS_MDL-PSF_OH_issue-20981-44_2022-12-20\n+- ron_model: DpdVisRONModel ProductId=DpdVisRONModel_EUC_VIS_MDL-BIAS02_RON_ELE_MAP_json\n+- saturation_model: DpdVisBloomingModel ProductId=DpdVisBloomingModel_EUC_VIS_MDL-SC8_BLOOM_ELE_json\n+- zero_point: DpdVisZeroPoint ProductId=DpdVisZeroPoint_2436_040223_json\n+- ghost_model: DpdVisGhostModel ProductId=DpdVisGhostModel_ghost_model_JAN2022_json\n+- starmask_model: DpdVisStarMask ProductId=DpdVisStarMask_starmask_JAN2022_fits\n+- crosstalk model: DpdVisXTalkModel ProductId=DpdVisXTalkModel_EUC_VIS_MDL-XTK-VGCC-coeffs_20210915_json\n+\n+Hereafter these products are referenced as _on-ground_.\n+\n+Note that when ExposureTime is used for selection, the exact value in real data may not be the one mentioned in the current version of this document.\n+\n+VIS_FlagObjects pipeline is intended to run on Calbloks PV-022, PV-029, and PV-031. It processes the short science exposures in the Calblock to create masks of celestial objects for each pointing. These masks are then used by the pipelines in charge of processing the flat-field exposures of each calblock. These pipelines need in input the masks corresponding to the flats to process, but more can be given: each pipeline will search for the masks corresponding to the flat fields they are processing.\n+\n+The detailed description of VIS_FlagObjects is given only once for PV-022 variant PRNU2-10000ADU. For the other calblocks and variants we just mention the differences with this first run.\n+\n+VIS_MasterFlat pipeline is intended to run on all variants of Calbloks PV-022. It produces a master flat for each pair of LED and fluence.\n+LED selection is done with CalibUnit.LedMask:\n+\n+- LED1: CalibUnit.LedMask=0x1\n+- LED2: CalibUnit.LedMask=0x2\n+- LED3: CalibUnit.LedMask=0x4\n+- LED4: CalibUnit.LedMask=0x8\n+\n+Fluence selection is done with the calblock variant, except for LED 5 and 6 (PV-022 variant LED56-PRNU1-PRNU2-BF).\n+\n+The detailed description of VIS_MasterFlat pipeline is given only once for PV-022 variant PRNU2-10000ADU. For other variants we just mention the differences with this first run.\n+\n+## PV-021\n+\n+### Pipeline: VIS_MasterBias\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-021 & ImgType.FirstType=BIAS\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: empty\n+- flagmaps: empty\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+\n+**Outputs:**\n+\n+- dpdcalib_data: CALPRODUCT VS-003 VIS Bias\n+- dpdanalysis: quality assessment parameters\n+\n+### Pipeline: VIS_MasterDark\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-021 & ImgType.FirstType=DARK & ExposureTime=565\n+- vis_config_in: DpdVisConfigurationFile_EUC_VIS_ConfigFile_15AUG2023_ini\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: empty\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- flagmaps: empty\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+\n+**Outputs:**\n+\n+- dpdcalib_data: CALPRODUCT VS-009 VIS Darks\n+- dpdcalib_flag: map of defects in darkness, first part of CALPRODUCT VS-007 VIS Cosmetic Map\n+- dpdanalysis: quality assessment parameters\n+\n+## F-014\n+\n+## PV-022 - PRNU2-10000ADU\n+\n+### Pipeline: VIS_FlagObjects\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 &  ObservationSequence.CalBlockVariant=PRNU2-10000ADU & ImgType.FirstType=SURVEY\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- flagmaps: map of defects in darkness, output of PV-021\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- zero_point: on-ground\n+- masterdark: empty\n+- masterflat: empty\n+- psf_model: on-ground\n+- dist_model: empty\n+- lsf_model: empty\n+- ghost_model: empty\n+- starmask_model: empty\n+- bfe_model: empty\n+- ref_catalogues: empty\n+\n+**Outputs:**\n+\n+- objects_flagmap_xml_out: list of object masks, one for each input exposure\n+\n+### Pipeline: VIS_MasterFlat\n+\n+4 instances of the pipelines will be run, one for each of LEDs 1, 2, 3, 4. The 4 instances can be run in parallel.\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=PRNU2-10000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=_mask for LEDi_\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: empty\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- flagmaps: map of defects in darkness, output of VIS_MasterDark pipeline\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- masterdark: empty\n+- bfe_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n+\n+**Outputs:**\n+\n+- dpdcalib_data: master flat _LEDi_ 10kADU\n+- dpdcalib_flag: map of defects in photoresponse at 10 kADU\n+- dpdanalysis: quality assessment parameters\n+- dpd_ledprofile: calibration unit profile\n+\n+## PV-029 - PTC-SERIES-1\n+\n+### Pipeline: VIS_FlagObjects\n+\n+Same as in PV-022 PRNU2-10000ADU except:\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-1 & ImgType.FirstType=SURVEY\n+\n+### Pipeline: VIS_BloomingCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-1 & ImgType.FirstType=FLAT\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias: CALPRODUCT VS-003\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- bfe_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n+\n+**Outputs:**\n+\n+- dpdcalib_blooming: preliminary version of VIS Photon Transfer Curve, part of CALPRODUCT VS-011\n+\n+### Pipeline:  VIS_PTCNLCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-1 & ImgType.FirstType=FLAT\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias:  CALPRODUCT VS-003\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- masterdark: empty\n+- bfe_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n+\n+**Outputs:**\n+\n+- dpdcalib_ptc: ???\n+- dpdcalib_nl: non-linearity model, preliminary version of candidate CALPRODUCT VS-016 VIS Nonlinearity\n+\n+\n+## PV-027 - PARALLEL-CI-HIGH\n+## PV-027 - PARALLEL-CI-LOW\n+## PV-027 - SERIAL\n+\n+## PV-028 - CI-ROS - VIS_CTIMasterCI\n+\n+### Pipeline: VIS_CTIMasterCI\n+\n+Set of 6 x 32 CIL images taken with different charge injection parameters corresponding to\n+[table 11 of this webpage](http://calibration.pages.euclid-sgs.uk/CalTQ-Framework/calobs/calobs-vis-cti-cil.html#calobs-vis-cti-cil).\n+\n+Each batch of 6 CIL images taken with identical charge injection parameters (e.g. each row of table 11) are passed\n+to the VIS_CTIMasterCI pipeline, outputting a single master CIL image for each input image. In total, 32 independent\n+runs of this pipeline are performed for the CI-ROS calblock.\n+\n+**Inputs:**\n+\n+- raw_frames_in: x6 DpdVisRawFrame raw charge injection frames corresponding to each row of table 11 (see example query below).\n+- MDB:\n+- flagmaps: map of defects in darkness, output of PV-021\n+- gains_model: on-ground\n+- xtalk_model: empty\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- masterdark: empty\n+- nlcorr_model: empty\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+\n+**Outputs:**\n+\n+- master_ci_xml_out: MasterCIFrame corresponding to an FPA of charge injection data for a single set of charge injection parameter settings for CALPRODUCT-VS-005.\n+\n+**Example Query for Row 1:**\n+\n+```\n+ImgType.FirstType=CHARGE_INJECTION\n+ObservationSequence.CalblockId=PV-028\n+ChargeInjection.Parameters.InjectedLinesCount=420\n+ChargeInjection.Parameters.NonInjectedLinesCount=100\n+ChargeInjection.Parameters.InjectionDrainLowPulseDelay.Value>2.4 && ChargeInjection.Parameters.InjectionDrainLowPulseDelay.Value<2.6\n+ChargeInjection.Parameters.InjectionGate1Voltage.Value>4.24 && ChargeInjection.Parameters.InjectionGate1Voltage.Value<4.26\n+ChargeInjection.Parameters.InjectionGate2Voltage.Value>5.98 && ChargeInjection.Parameters.InjectionGate2Voltage.Value<6.02\n+```\n+\n+## PV-028 - IG1-SCAN\n+\n+### Pipeline: VIS_CTIMasterCI\n+\n+Identical to PV-028 - CI-ROS, except that the charge injection parameters are varied in a grid scan of IG1 values,\n+given by [table 45 of this webpage](http://calibration.pages.euclid-sgs.uk/CalTQ-Framework/calobs/calobs-block-pv-vis-cti-charge-injection.html).\n+\n+**Inputs:**\n+\n+- raw_frames_in: x6 DpdVisRawFrame raw charge injection frames corresponding to each row of table 45 (see example query below).\n+- MDB:\n+- flagmaps: map of defects in darkness, output of PV-021\n+- gains_model: on-ground\n+- xtalk_model: empty\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- masterdark: empty\n+- nlcorr_model: empty\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+\n+**Outputs:**\n+\n+- master_ci_xml_out: MasterCIFrame corresponding to an FPA of charge injection data for a single set of charge injection parameter settings for CALPRODUCT-VS-005.\n+\n+**Example Query for Row 1:**\n+\n+```\n+ImgType.FirstType=CHARGE_INJECTION\n+ObservationSequence.CalblockId=PV-028\n+ChargeInjection.Parameters.InjectedLinesCount=420\n+ChargeInjection.Parameters.NonInjectedLinesCount=100\n+ChargeInjection.Parameters.InjectionDrainLowPulseDelay.Value>2.4 && ChargeInjection.Parameters.InjectionDrainLowPulseDelay.Value<2.6\n+ChargeInjection.Parameters.InjectionGate1Voltage.Value>3.24 && ChargeInjection.Parameters.InjectionGate1Voltage.Value<3.26\n+ChargeInjection.Parameters.InjectionGate2Voltage.Value>5.98 && ChargeInjection.Parameters.InjectionGate2Voltage.Value<6.02\n+```\n+\n+## PV-028 - CI-ROS - VIS_CTICalibration\n+\n+### Pipeline: VIS_CTICalibration\n+\n+4 independent runs of the CTI calibration pipeline, using a subset of the ROS data (and none of the IG1-Scan data).\n+\n+For each set of 6 CIL taken with identical charge injection settings, only one of each set of the 6 images are used.\n+\n+Therefore, in total  32 images with settings corresponding to the 32 rows\n+[table 11 of this webpage](http://calibration.pages.euclid-sgs.uk/CalTQ-Framework/calobs/calobs-vis-cti-cil.html#calobs-vis-cti-cil)\n+are used.\n+\n+Four independent runs of the pipeline, each with 8 CIL images are performed, corresponding to\n+rows 1-8, 9-16, 17-24 and 25-32 of table 11.\n+\n+**Inputs:**\n+\n+- raw_frames_in: x8 DpdVisRawFrame raw charge injection frames corresponding to a block of 8 rows of table 11 (see example query below).\n+- MDB:\n+- flagmaps: map of defects in darkness, output of PV-021\n+- gains_model: on-ground\n+- xtalk_model: empty\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- masterdark: empty\n+- nlcorr_model: empty\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+\n+**Outputs:**\n+\n+- parallel_cti_xml_out: Parallel CTICalibrationResults for CALPRODUCT-VS-005.\n+- serial_cti_xml_out: Serial CTICalibrationResults for CALPRODUCT-VS-005.\n+\n+**Example Query for Row 1:**\n+\n+```\n+ImgType.FirstType=CHARGE_INJECTION\n+ObservationSequence.CalblockId=PV-028\n+ChargeInjection.Parameters.InjectedLinesCount=420\n+ChargeInjection.Parameters.NonInjectedLinesCount=100\n+ChargeInjection.Parameters.InjectionDrainLowPulseDelay.Value>2.4 && ChargeInjection.Parameters.InjectionDrainLowPulseDelay.Value<2.6\n+ChargeInjection.Parameters.InjectionGate1Voltage.Value>4.24 && ChargeInjection.Parameters.InjectionGate1Voltage.Value<4.26\n+ChargeInjection.Parameters.InjectionGate2Voltage.Value>5.98 && ChargeInjection.Parameters.InjectionGate2Voltage.Value<6.02\n+```\n+\n+## PV-034 VIS Charge Injection Timing\n+\n+No processing during PV.\n+\n+## PV-023\n+\n+### Pipeline: VIS_AstrometryCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-023 & ImgType.Category=SCIENCE & ExposureTime=565\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse at 10 kADU, output of PV-022 - PRNU2-10000ADU\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- zero_point: on-ground\n+- masterdark: empty\n+- masterflat: master flat LED3 10kADU, output of PV-022 - PRNU2-10000ADU\n+- dist_model: empty\n+- lsf_model: empty\n+- bfe_model: empty\n+- ref_catalogues: DpdExtGaiaCutout covering raw science frames sky area\n+\n+\n+**Outputs:**\n+\n+- dist_model_xml_out: CALPRODUCT VS-010 VIS Focal Plane Astrometric Solution\n+\n+Quality control plots are in the workdir in logs/VIS_astrom_calib.\n+\n+## F-014\n+\n+## PV-022 - LOW1-1000ADU\n+\n+### Pipeline: VIS_FlagObjects\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW1-1000ADU & ImgType.FirstType=SURVEY\n+\n+**Outputs:**\n+\n+- objects_flagmap_xml_out: list of object masks, one for each input exposure\n+\n+\n+### Pipeline: VIS_GainCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW1-1000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=0x4\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse at 10 kADU, output of PV-022 - PRNU2-10000ADU\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- masterdark: empty\n+- bfe_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n+\n+**Outputs:**\n+\n+- gain_model_xml_out: gain model, part of CALPRODUCT VS-011\n+\n+### Pipeline: VIS_MasterFlat\n+\n+4 instances of the pipelines will be run, one for each of LEDs 1, 2, 3, 4. The 4 instances can be run in parallel.\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW1-1000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=_mask for LEDi_\n+\n+**Outputs:**\n+\n+- dpdcalib_data: master flat _LEDi_ 1kADU\n+- dpdcalib_flag: map of defects in photoresponse at 1 kADU\n+- dpdanalysis: quality assessment parameters\n+- dpd_ledprofile: calibration unit profile\n+\n+\n+## PV-022 - LOW2-5000ADU\n+\n+### Pipeline: VIS_FlagObjects\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW2-5000ADU & ImgType.FirstType=SURVEY\n+\n+### Pipeline: VIS_MasterFlat\n+\n+4 instances of the pipelines will be run, one for each of LEDs 1, 2, 3, 4. The 4 instances can be run in parallel.\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW2-5000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=_mask for LEDi_\n+\n+**Outputs:**\n+\n+- dpdcalib_data: master flat _LEDi_ 5kADU\n+- dpdcalib_flag: map of defects in photoresponse at 5 kADU\n+- dpdanalysis: quality assessment parameters\n+- dpd_ledprofile: calibration unit profile\n+\n+## PV-022 - BF-40000ADU\n+\n+### Pipeline: VIS_FlagObjects\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=BF-40000ADU & ImgType.FirstType=SURVEY\n+\n+**Outputs:**\n+\n+- objects_flagmap_xml_out: list of object masks, one for each input exposure\n+\n+\n+### Pipeline: VIS_BrighterFatterCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=BF-40000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=Ox4\n+- vis_config_in:\n+- MDB:\n+- gains_model: gain model CALPRODUCT VS-011\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse at 10 kADU, output of PV-022 - PRNU2-10000ADU\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n+\n+**Outputs:**\n+\n+- bfecalib_xml_out: brighter-fatter model CALPRODUCT VS-004 VIS Brighter-fatter Effect\n+\n+### Pipeline: VIS_MasterFlat\n+\n+4 instances of the pipelines will be run, one for each of LEDs 1, 2, 3, 4. The 4 instances can be run in parallel.\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=BF-40000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=_mask for LEDi_\n+\n+**Outputs:**\n+\n+- dpdcalib_data: master flat _LEDi_ 40kADU\n+- dpdcalib_flag: map of defects in photoresponse at 40 kADU\n+- dpdanalysis: quality assessment parameters\n+- dpd_ledprofile: calibration unit profile\n+\n+\n+## PV-007 - PROPOSAL-08-M33\n+## PV-007 - PROPOSAL-11-A370\n+## PV-007 - PROPOSAL-11-N01\n+\n+## PV-001 - VISIT-1\n+\n+### Step 1 - Pipeline: VIS_PSFCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-001 & ObservationSequence.CalBlockVariant=likeVISIT-1* & ImgType.FirstType=SELF_CALIBRATION & ExposureTime =106\n+- vis_config_in:\n+- MDB:\n+- gains_model: gain model CALPRODUCT VS-011\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse at 10 kADU, output of PV-022 - PRNU2-10000ADU\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- masterdark: empty\n+- masterflat: master flat LED3 10kADU, output of PV-022 - PRNU2-10000ADU\n+\n+\n+**Outputs:**\n+\n+- psf_model_xml_out: PSF model\n+\n+### Step 2 - Pipelines: VIS_ProcessField\n+\n+2 instances of VIS_ProcessField without stacking will be run, possibly in parallel, one on the short exposures and one on the nominal exposures.\n+\n+**Inputs:**\n+\n+- raw_frames_in:\n+  - short exposures: DpdVisRawFrame ObservationSequence.CalblockId=PV-001 & ObservationSequence.CalBlockVariant=likeVISIT-1* & ImgType.FirstType=SELF_CALIBRATION & ExposureTime = 106\n+  - nominal exposures: DpdVisRawFrame ObservationSequence.CalblockId=PV-001 & ObservationSequence.CalBlockVariant=likeVISIT-1* & ImgType.FirstType=SELF_CALIBRATION & ExposureTime = 565\n+- vis_config_in: DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_nostack_ini\n+- MDB:\n+- gains_model: gain model CALPRODUCT VS-011\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias:  CALPRODUCT VS-003 VIS Bias\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse at 10 kADU, output of PV-022 - PRNU2-10000ADU\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- zero_point: on-ground\n+- masterdark: empty\n+- masterflat: master flat LED3 10kADU, output of PV-022 - PRNU2-10000ADU\n+- psf_model: output of previous VIS_PSFCalibration\n+- dist_model: distortion model CALPRODUCT VS-010 VIS\n+- lsf_model: empty\n+- ghost_model: on-ground\n+- starmask_model: on-ground\n+- bfe_model: empty\n+- ref_catalogues: DpdExtGaiaCutout covering raw science frames sky area\n+\n+**Outputs:**\n+\n+- dpdcalibrated_frames: VIS calibrated frames\n+- dpdcalibrated_catalogues: VIS calibrated catalogues\n+- dpdghost_catalogues: unused in the rest of the processing\n+\n+### Step 3 - Pipelines: VIS_LargeFlatCalibration\n+\n+2 instances of VIS_LargeFlatCalibration will be run, possibly in parallel, one on the short exposure catalogs and one on the nominal exposure catalogs.\n+\n+**Inputs:**\n+\n+- vis_config_in:\n+- MDB:\n+- catalogues_in: DpdVisCalibratedFrameCatalog\n+  - short exposures: DpdVisCalibratedFrameCatalog, output the previous VIS_ProcessField on short exposures\n+  - nominal exposures: DpdVisCalibratedFrameCatalog, output the previous VIS_ProcessField on nominal exposures\n+\n+**Outputs:**\n+\n+- largeflatcal_output: large flat for short and nominal exposures, respectively, CALPRODUCT VS-013\n+\n+### Step 4 - Pipelines: VIS_ProcessField\n+\n+2 instances of VIS_ProcessField without stacking will be run, possibly in parallel, one on the short exposures and one on the nominal exposures. It is exactly the same processing as in step 4, except that large flat correction will be applied. Below we describe only the differences with Step 2.\n+\n+**Inputs:**\n+\n+- lsf_model:\n+  - short exposures: CALPRODUCT VS-013, output of VIS_LargeFlatCalibration for short exposures\n+  - nominal exposures: CALPRODUCT VS-013, output of VIS_LargeFlatCalibration for nominal exposures\n+\n+**Outputs:**\n+\n+- dpdcalibrated_frames: VIS calibrated frames\n+- dpdcalibrated_catalogues: VIS calibrated catalogues\n+- dpdghost_catalogues: ghost catalogues\n+\n+### Step 5 - Pipeline: VIS_PhotometryCalibration\n+\n+**Inputs:**\n+\n+- vis_config_in:\n+- MDB:\n+- catalogues_in: list of DpdVisCalibratedFrameCatalog from VIS_ProcessField on short exposures in step 4\n+\n+**Outputs:**\n+\n+- zero_point_xml_out: updated VIS zero point CALPRODUCT VS-001\n+\n+### Step 6 - Pipeline: VIS_GhostsCalibration\n+\n+This pipeline can be run in parallel with VIS_PhotometryCalibration in step 5.\n+\n+**Inputs:**\n+\n+- MDB:\n+- ghost_cat_list: ghost catalogues, output of both VIS_ProcessField in step 4 (long and short exposures)\n+- ref_ghost_model_in: on-ground\n+\n+**Outputs:**\n+\n+ghost_model_xml_out: updated ghost model CALPRODUCT VS-012\n+\n+### Step 7 - Pipeline: VIS_XTalkCalibration_Pipeline\n+\n+This pipeline can be run in parallel with VIS_PhotometryCalibration in step 5 and VIS_GhostsCalibration in step 6.\n+It will be run on the raw nominal exposures only.\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-001 & ObservationSequence.CalBlockVariant=likeVISIT-1* & ImgType.FirstType=SELF_CALIBRATION & ExposureTime = 565\n+- vis_config_in: DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_normtmp_ini\n+- MDB:\n+- gains_model: gain model CALPRODUCT VS-011\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias:  CALPRODUCT VS-003 VIS Bias\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse at 10 kADU, output of PV-022 - PRNU2-10000ADU\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- zero_point: on-ground\n+- masterdark: empty\n+- masterflat: master flat LED3 10kADU, output of PV-022 - PRNU2-10000ADU\n+- psf_model: output of previous VIS_PSFCalibration\n+- dist_model: distortion model CALPRODUCT VS-010 VIS\n+- lsf_model: CALPRODUCT VS-013, output of VIS_LargeFlatCalibration for nominal exposures\n+- ghost_model: on-ground\n+- starmask_model: on-ground\n+- bfe_model: empty\n+- ref_catalogues: DpdExtGaiaCutout covering raw science frames sky area\n+\n+**Outputs:**\n+\n+- xtalk_model_xml_out: crosstalk model, CALPRODUCT VS-008\n+\n+### Step 8  - Pipelines: VIS_ProcessField\n+\n+2 instances of VIS_ProcessField without stacking will be run, possibly in parallel, one on the short exposures and one on the nominal exposures. It is the same processing as in step 4, except that we will use the zero point and the crosstalk model produced in the previous steps. Below we describe only the differences with step 4.\n+\n+**Inputs:**\n+\n+- xtalk_model: crosstalk model CALPRODUCT VS-008\n+- zero_point: VIS zero point CALPRODUCT VS-001\n+\n+**Outputs:**\n+\n+- dpdcalibrated_frames: VIS calibrated frames for MER\n+\n+### Step X - Pipeline: VIS stacking\n+\n+This pipeline aims at producing the astrometric catalogue for NIR. This step can be executed either after step 2, 4 or 8, depending on NIR needs.\n+\n+**Inputs:**\n+\n+- vis_config_in:\n+- ref_catalogues: DpdExtGaiaCutout covering raw science frames sky area\n+- exposure_list: list of DpdVisCalibratedFrame, output of VIS_ProcessField in step 2, 4 or 8\n+\n+**Outputs:**\n+\n+- dpdstacked_catalogue: single VIS catalog for NIR\n+\n+\n+\n+## PV-006\tELAT-90-20\n+## PV-006\tELAT-100-20\n+## PV-006\tGLAT-20\n+\n+## PV-024\n+\n+## F-014\n+\n+## PV-029 PTC-SERIES-2\n+\n+### Pipeline: VIS_FlagObjects\n+\n+Same as in PV-022 PRNU2-10000ADU except:\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-2 & ImgType.FirstType=SURVEY\n+\n+\n+## PV-031\n+\n+### Pipeline: VIS_FlagObjects\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-031 & ImgType.FirstType=SURVEY\n+\n+### Pipeline: VIS_BloomingCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame (ObservationSequence.CalblockId=PV-029 | ObservationSequence.CalblockId=PV-031) & ImgType.FirstType=FLAT\n+- vis_config_in:\n+- MDB:\n+- gains_model: gains model CALPRODUCT VS-011\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias: CALPRODUCT VS-003\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+- xtalk_model: CALPRODUCT VS-008\n+- nlcorr_model: empty\n+- cti_model: empty\n+- bfe_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n+\n+**Outputs:**\n+\n+- dpdcalib_blooming:\n+  - VIS Photon Transfer Curve, part of CALPRODUCT VS-011\n+  - VIS Blooming threshold CALPRODUCT VS-020\n+\n+### Pipeline:  VIS_PTCNLCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 & ImgType.FirstType=FLAT\n+- vis_config_in:\n+- MDB:\n+- gains_model: gains model CALPRODUCT VS-011\n+- ron_model: on-ground\n+- saturation_model: CALPRODUCT VS-020\n+- masterbias:  CALPRODUCT VS-003\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+- xtalk_model: CALPRODUCT VS-008\n+- nlcorr_model: empty\n+- cti_model: empty\n+- masterdark: empty\n+- bfe_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n+\n+**Outputs:**\n+\n+- dpdcalib_ptc: ???\n+- dpdcalib_nl: non-linearity model, candidate CALPRODUCT VS-016 VIS Nonlinearity\n+\n+\n+## PV-004 GLINT-CHECK\n+\n+## PV-007 PROPOSAL-09\n+\n+## PV-005 CDFS-24\n+## PV-005 EDFS-24-47ROS\n+\n+## PV-001 VISIT-2\n+\n+## PV-005 EDFN-FULL-25\n+## PV-005 EDFN-3x3-25\n+\n+## PV-001 VISIT-3\n+\n+## PV-022 PRNU1-25000ADU\n+\n+### Pipeline: VIS_FlagObjects\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=PRNU1-25000ADU & ImgType.FirstType=SURVEY\n+\n+### Pipeline: VIS_MasterFlat\n+\n+4 instances of the pipelines will be run, one for each of LEDs 1, 2, 3, 4. The 4 instances can be run in parallel.\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=PRNU1-25000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=_mask for LEDi_\n+\n+**Outputs:**\n+\n+- dpdcalib_data: master flat _LEDi_ 25kADU\n+- dpdcalib_flag: map of defects in photoresponse at 25 kADU\n+- dpdanalysis: quality assessment parameters\n+- dpd_ledprofile: calibration unit profile\n+\n+### Pipeline: VIS_SmallScaleFlat\n+\n+This pipeline combines all the individual single-LED (1, 2, 3, 4) single-fluence (10k, 25k, 40k) MasterFlat frames available so far to produce one unique \"small-scale\" MasterFlat to use in all subsequent masterflat input ports.\n+\n+**Inputs:**\n+\n+- vis_config_in:\n+- MDB:\n+- prnulist_in: DpdVisMasterFlatFrame outputs of previous PV-022 VIS_MasterFlat pipelines (12 objects: 4 LEDs x 3 fluences)\n+- flagmaps_in: map of defects in photoresponse, dpdcalib_flag outputs of previous 12 PV-022 VIS_MasterFlat pipelines\n+\n+**Outputs:**\n+\n+- smallscaleflat_out: DpdVisMasterFlatFrame containing the combined small-scale MasterFlat CALPRODUCT VS-022\n+- prnuflagmap_out: DpdVisFlagMap associated to smallscaleflat_out\n+- dqc_out: DpdVisAnalysisResults, data quality control product, containing the 'slope' and 'standard error' products of each extrapolated to 0-signal flat per LED\n+\n+\n+\n+\n+\n",
                            "Merge branch 'release-13.0' into develop: #23449 CTICalib decorators, #23455 MasterBias ram, #23518 Blooming object masks",
                            "Catherine Grenet",
                            "2023-08-21T17:30:06.000+02:00",
                            "3266962f8cb5374c52678180c4d4e0592338bdb8"
                        ],
                        [
                            "@@ -21,7 +21,8 @@ Some pipelines will use on-ground models. These on-ground models are:\n - saturation_model: DpdVisBloomingModel ProductId=DpdVisBloomingModel_EUC_VIS_MDL-SC8_BLOOM_ELE_json\n - zero_point: DpdVisZeroPoint ProductId=DpdVisZeroPoint_2436_040223_json\n - ghost_model: DpdVisGhostModel ProductId=DpdVisGhostModel_ghost_model_JAN2022_json\n-- starmask_model: DpdVisStarMask ProductId= DpdVisStarMask_starmask_JAN2022_fits\n+- starmask_model: DpdVisStarMask ProductId=DpdVisStarMask_starmask_JAN2022_fits\n+- crosstalk model: DpdVisXTalkModel ProductId=DpdVisXTalkModel_EUC_VIS_MDL-XTK-VGCC-coeffs_20210915_json\n \n Hereafter these products are referenced as _on-ground_.\n \n@@ -31,6 +32,18 @@ VIS_FlagObjects pipeline is intended to run on Calbloks PV-022, PV-029, and PV-0\n \n The detailed description of VIS_FlagObjects is given only once for PV-022 variant PRNU2-10000ADU. For the other calblocks and variants we just mention the differences with this first run.\n \n+VIS_MasterFlat pipeline is intended to run on all variants of Calbloks PV-022. It produces a master flat for each pair of LED and fluence.\n+LED selection is done with CalibUnit.LedMask:\n+\n+- LED1: CalibUnit.LedMask=0x1\n+- LED2: CalibUnit.LedMask=0x2\n+- LED3: CalibUnit.LedMask=0x4\n+- LED4: CalibUnit.LedMask=0x8\n+\n+Fluence selection is done with the calblock variant, except for LED 5 and 6 (PV-022 variant LED56-PRNU1-PRNU2-BF).\n+\n+The detailed description of VIS_MasterFlat pipeline is given only once for PV-022 variant PRNU2-10000ADU. For other variants we just mention the differences with this first run.\n+\n ## PV-021\n \n ### Pipeline: VIS_MasterBias\n@@ -113,13 +126,6 @@ The detailed description of VIS_FlagObjects is given only once for PV-022 varian\n \n 4 instances of the pipelines will be run, one for each of LEDs 1, 2, 3, 4. The 4 instances can be run in parallel.\n \n- LED selection is done with CalibUnit.LedMask:\n-\n-- LED1: CalibUnit.LedMask=0x1\n-- LED2: CalibUnit.LedMask=0x2\n-- LED3: CalibUnit.LedMask=0x4\n-- LED4: CalibUnit.LedMask=0x8\n-\n **Inputs:**\n \n - raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=PRNU2-10000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=_mask for LEDi_\n@@ -140,7 +146,7 @@ The detailed description of VIS_FlagObjects is given only once for PV-022 varian\n **Outputs:**\n \n - dpdcalib_data: master flat _LEDi_ 10kADU\n-- dpdcalib_flag: map of defects in photoresponse at 10 kADU, second part of CALPRODUCT VS-007 VIS Cosmetic Map\n+- dpdcalib_flag: map of defects in photoresponse at 10 kADU\n - dpdanalysis: quality assessment parameters\n - dpd_ledprofile: calibration unit profile\n \n@@ -153,9 +159,6 @@ Same as in PV-022 PRNU2-10000ADU except:\n **Inputs:**\n \n - raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-1 & ImgType.FirstType=SURVEY\n-- flagmaps:\n-  - map of defects in darkness, output of PV-021\n-  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n \n ### Pipeline: VIS_BloomingCalibration\n \n@@ -175,6 +178,7 @@ Same as in PV-022 PRNU2-10000ADU except:\n - nlcorr_model: empty\n - cti_model: empty\n - bfe_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n \n **Outputs:**\n \n@@ -379,9 +383,6 @@ Quality control plots are in the workdir in logs/VIS_astrom_calib.\n **Inputs:**\n \n - raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW1-1000ADU & ImgType.FirstType=SURVEY\n-- flagmaps:\n-  - map of defects in darkness, output of PV-021\n-  - map of defects in photoresponse at 10 kADU, output of PV-022 - PRNU2-10000ADU\n \n **Outputs:**\n \n@@ -392,7 +393,7 @@ Quality control plots are in the workdir in logs/VIS_astrom_calib.\n \n **Inputs:**\n \n-- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW1-1000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=Ox4\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW1-1000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=0x4\n - vis_config_in:\n - MDB:\n - gains_model: on-ground\n@@ -413,8 +414,45 @@ Quality control plots are in the workdir in logs/VIS_astrom_calib.\n \n - gain_model_xml_out: gain model, part of CALPRODUCT VS-011\n \n+### Pipeline: VIS_MasterFlat\n+\n+4 instances of the pipelines will be run, one for each of LEDs 1, 2, 3, 4. The 4 instances can be run in parallel.\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW1-1000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=_mask for LEDi_\n+\n+**Outputs:**\n+\n+- dpdcalib_data: master flat _LEDi_ 1kADU\n+- dpdcalib_flag: map of defects in photoresponse at 1 kADU\n+- dpdanalysis: quality assessment parameters\n+- dpd_ledprofile: calibration unit profile\n+\n+\n ## PV-022 - LOW2-5000ADU\n \n+### Pipeline: VIS_FlagObjects\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW2-5000ADU & ImgType.FirstType=SURVEY\n+\n+### Pipeline: VIS_MasterFlat\n+\n+4 instances of the pipelines will be run, one for each of LEDs 1, 2, 3, 4. The 4 instances can be run in parallel.\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW2-5000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=_mask for LEDi_\n+\n+**Outputs:**\n+\n+- dpdcalib_data: master flat _LEDi_ 5kADU\n+- dpdcalib_flag: map of defects in photoresponse at 5 kADU\n+- dpdanalysis: quality assessment parameters\n+- dpd_ledprofile: calibration unit profile\n+\n ## PV-022 - BF-40000ADU\n \n ### Pipeline: VIS_FlagObjects\n@@ -422,9 +460,6 @@ Quality control plots are in the workdir in logs/VIS_astrom_calib.\n **Inputs:**\n \n - raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=BF-40000ADU & ImgType.FirstType=SURVEY\n-- flagmaps:\n-  - map of defects in darkness, output of PV-021\n-  - map of defects in photoresponse at 10 kADU, output of PV-022 - PRNU2-10000ADU\n \n **Outputs:**\n \n@@ -454,6 +489,22 @@ Quality control plots are in the workdir in logs/VIS_astrom_calib.\n \n - bfecalib_xml_out: brighter-fatter model CALPRODUCT VS-004 VIS Brighter-fatter Effect\n \n+### Pipeline: VIS_MasterFlat\n+\n+4 instances of the pipelines will be run, one for each of LEDs 1, 2, 3, 4. The 4 instances can be run in parallel.\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=BF-40000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=_mask for LEDi_\n+\n+**Outputs:**\n+\n+- dpdcalib_data: master flat _LEDi_ 40kADU\n+- dpdcalib_flag: map of defects in photoresponse at 40 kADU\n+- dpdanalysis: quality assessment parameters\n+- dpd_ledprofile: calibration unit profile\n+\n+\n ## PV-007 - PROPOSAL-08-M33\n ## PV-007 - PROPOSAL-11-A370\n ## PV-007 - PROPOSAL-11-N01\n@@ -655,11 +706,129 @@ This pipeline aims at producing the astrometric catalogue for NIR. This step can\n \n ## PV-029 PTC-SERIES-2\n \n+### Pipeline: VIS_FlagObjects\n+\n+Same as in PV-022 PRNU2-10000ADU except:\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-2 & ImgType.FirstType=SURVEY\n+\n+\n ## PV-031\n \n+### Pipeline: VIS_FlagObjects\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-031 & ImgType.FirstType=SURVEY\n+\n+### Pipeline: VIS_BloomingCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame (ObservationSequence.CalblockId=PV-029 | ObservationSequence.CalblockId=PV-031) & ImgType.FirstType=FLAT\n+- vis_config_in:\n+- MDB:\n+- gains_model: gains model CALPRODUCT VS-011\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias: CALPRODUCT VS-003\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+- xtalk_model: CALPRODUCT VS-008\n+- nlcorr_model: empty\n+- cti_model: empty\n+- bfe_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n+\n+**Outputs:**\n+\n+- dpdcalib_blooming:\n+  - VIS Photon Transfer Curve, part of CALPRODUCT VS-011\n+  - VIS Blooming threshold CALPRODUCT VS-020\n+\n+### Pipeline:  VIS_PTCNLCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 & ImgType.FirstType=FLAT\n+- vis_config_in:\n+- MDB:\n+- gains_model: gains model CALPRODUCT VS-011\n+- ron_model: on-ground\n+- saturation_model: CALPRODUCT VS-020\n+- masterbias:  CALPRODUCT VS-003\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+- xtalk_model: CALPRODUCT VS-008\n+- nlcorr_model: empty\n+- cti_model: empty\n+- masterdark: empty\n+- bfe_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n+\n+**Outputs:**\n+\n+- dpdcalib_ptc: ???\n+- dpdcalib_nl: non-linearity model, candidate CALPRODUCT VS-016 VIS Nonlinearity\n+\n+\n+## PV-004 GLINT-CHECK\n+\n+## PV-007 PROPOSAL-09\n+\n+## PV-005 CDFS-24\n+## PV-005 EDFS-24-47ROS\n+\n+## PV-001 VISIT-2\n+\n+## PV-005 EDFN-FULL-25\n+## PV-005 EDFN-3x3-25\n+\n+## PV-001 VISIT-3\n+\n+## PV-022 PRNU1-25000ADU\n+\n+### Pipeline: VIS_FlagObjects\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=PRNU1-25000ADU & ImgType.FirstType=SURVEY\n \n+### Pipeline: VIS_MasterFlat\n+\n+4 instances of the pipelines will be run, one for each of LEDs 1, 2, 3, 4. The 4 instances can be run in parallel.\n+\n+**Inputs:**\n \n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=PRNU1-25000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=_mask for LEDi_\n+\n+**Outputs:**\n+\n+- dpdcalib_data: master flat _LEDi_ 25kADU\n+- dpdcalib_flag: map of defects in photoresponse at 25 kADU\n+- dpdanalysis: quality assessment parameters\n+- dpd_ledprofile: calibration unit profile\n+\n+### Pipeline: VIS_SmallScaleFlat\n+\n+This pipeline combines all the individual single-LED (1, 2, 3, 4) single-fluence (10k, 25k, 40k) MasterFlat frames available so far to produce one unique \"small-scale\" MasterFlat to use in all subsequent masterflat input ports.\n+\n+**Inputs:**\n+\n+- vis_config_in:\n+- MDB:\n+- prnulist_in: DpdVisMasterFlatFrame outputs of previous PV-022 VIS_MasterFlat pipelines (12 objects: 4 LEDs x 3 fluences)\n+- flagmaps_in: map of defects in photoresponse, dpdcalib_flag outputs of previous 12 PV-022 VIS_MasterFlat pipelines\n+\n+**Outputs:**\n \n+- smallscaleflat_out: DpdVisMasterFlatFrame containing the combined small-scale MasterFlat CALPRODUCT VS-022\n+- prnuflagmap_out: DpdVisFlagMap associated to smallscaleflat_out\n+- dqc_out: DpdVisAnalysisResults, data quality control product, containing the 'slope' and 'standard error' products of each extrapolated to 0-signal flat per LED\n \n \n \n",
                            "Merge branch 'feature-SUM' into release-13.0: PV-022, PV-029, PV-031 additions",
                            "Catherine Grenet",
                            "2023-08-21T17:00:25.000+02:00",
                            "8c05d2935966f233f6059e719e252def83a096b0"
                        ],
                        [
                            "@@ -741,6 +741,7 @@ Same as in PV-022 PRNU2-10000ADU except:\n - nlcorr_model: empty\n - cti_model: empty\n - bfe_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n \n **Outputs:**\n \n",
                            "[FIX]SUM SUM Blooming calibration now uses objets masks #23518 for PV-029 PTC-SERIES-2 also",
                            "Catherine Grenet",
                            "2023-08-21T16:46:03.000+02:00",
                            "e1f7d165b9eb21e5ec8257ac410e83d71c63bd99"
                        ],
                        [
                            "@@ -178,6 +178,7 @@ Same as in PV-022 PRNU2-10000ADU except:\n - nlcorr_model: empty\n - cti_model: empty\n - bfe_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n \n **Outputs:**\n \n",
                            "[UPD]SUM Blooming calibration now uses objets masks #23518",
                            "Catherine Grenet",
                            "2023-08-21T15:21:24.000+02:00",
                            "9057df5abab53351e0430279c1db3794a3c164a7"
                        ],
                        [
                            "@@ -29,7 +29,7 @@ Note that when ExposureTime is used for selection, the exact value in real data\n \n VIS_FlagObjects pipeline is intended to run on Calbloks PV-022, PV-029, and PV-031. It processes the short science exposures in the Calblock to create masks of celestial objects for each pointing. These masks are then used by the pipelines in charge of processing the flat-field exposures of each calblock. These pipelines need in input the masks corresponding to the flats to process, but more can be given: each pipeline will search for the masks corresponding to the flat fields they are processing.\n \n-The detailed description of VIS_FlagObjects is given only once for PV-022. For the other calblocks we just mention the differences with this first run.\n+The detailed description of VIS_FlagObjects is given only once for PV-022 variant PRNU2-10000ADU. For the other calblocks and variants we just mention the differences with this first run.\n \n ## PV-021\n \n@@ -58,7 +58,7 @@ The detailed description of VIS_FlagObjects is given only once for PV-022. For t\n **Inputs:**\n \n - raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-021 & ImgType.FirstType=DARK & ExposureTime=565\n-- vis_config_in:\n+- vis_config_in: DpdVisConfigurationFile_EUC_VIS_ConfigFile_15AUG2023_ini\n - MDB:\n - gains_model: on-ground\n - ron_model: on-ground\n@@ -146,6 +146,67 @@ The detailed description of VIS_FlagObjects is given only once for PV-022. For t\n \n ## PV-029 - PTC-SERIES-1\n \n+### Pipeline: VIS_FlagObjects\n+\n+Same as in PV-022 PRNU2-10000ADU except:\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-1 & ImgType.FirstType=SURVEY\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+\n+### Pipeline: VIS_BloomingCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-1 & ImgType.FirstType=FLAT\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias: CALPRODUCT VS-003\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- bfe_model: empty\n+\n+**Outputs:**\n+\n+- dpdcalib_blooming: preliminary version of VIS Photon Transfer Curve, part of CALPRODUCT VS-011\n+\n+### Pipeline:  VIS_PTCNLCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-1 & ImgType.FirstType=FLAT\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias:  CALPRODUCT VS-003\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- masterdark: empty\n+- bfe_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n+\n+**Outputs:**\n+\n+- dpdcalib_ptc: ???\n+- dpdcalib_nl: non-linearity model, preliminary version of candidate CALPRODUCT VS-016 VIS Nonlinearity\n+\n+\n ## PV-027 - PARALLEL-CI-HIGH\n ## PV-027 - PARALLEL-CI-LOW\n ## PV-027 - SERIAL\n",
                            "Merge branch 'release-13.0' into master_ci_memory",
                            "James Nightingale",
                            "2023-08-18T17:55:53.000+02:00",
                            "961b01b509e96c9e2b52d75b5383fbd55e0be960"
                        ],
                        [
                            "@@ -29,7 +29,7 @@ Note that when ExposureTime is used for selection, the exact value in real data\n \n VIS_FlagObjects pipeline is intended to run on Calbloks PV-022, PV-029, and PV-031. It processes the short science exposures in the Calblock to create masks of celestial objects for each pointing. These masks are then used by the pipelines in charge of processing the flat-field exposures of each calblock. These pipelines need in input the masks corresponding to the flats to process, but more can be given: each pipeline will search for the masks corresponding to the flat fields they are processing.\n \n-The detailed description of VIS_FlagObjects is given only once for PV-022. For the other calblocks we just mention the differences with this first run.\n+The detailed description of VIS_FlagObjects is given only once for PV-022 variant PRNU2-10000ADU. For the other calblocks and variants we just mention the differences with this first run.\n \n ## PV-021\n \n@@ -58,7 +58,7 @@ The detailed description of VIS_FlagObjects is given only once for PV-022. For t\n **Inputs:**\n \n - raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-021 & ImgType.FirstType=DARK & ExposureTime=565\n-- vis_config_in:\n+- vis_config_in: DpdVisConfigurationFile_EUC_VIS_ConfigFile_15AUG2023_ini\n - MDB:\n - gains_model: on-ground\n - ron_model: on-ground\n@@ -146,6 +146,67 @@ The detailed description of VIS_FlagObjects is given only once for PV-022. For t\n \n ## PV-029 - PTC-SERIES-1\n \n+### Pipeline: VIS_FlagObjects\n+\n+Same as in PV-022 PRNU2-10000ADU except:\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-1 & ImgType.FirstType=SURVEY\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+\n+### Pipeline: VIS_BloomingCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-1 & ImgType.FirstType=FLAT\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias: CALPRODUCT VS-003\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- bfe_model: empty\n+\n+**Outputs:**\n+\n+- dpdcalib_blooming: preliminary version of VIS Photon Transfer Curve, part of CALPRODUCT VS-011\n+\n+### Pipeline:  VIS_PTCNLCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-1 & ImgType.FirstType=FLAT\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias:  CALPRODUCT VS-003\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- masterdark: empty\n+- bfe_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n+\n+**Outputs:**\n+\n+- dpdcalib_ptc: ???\n+- dpdcalib_nl: non-linearity model, preliminary version of candidate CALPRODUCT VS-016 VIS Nonlinearity\n+\n+\n ## PV-027 - PARALLEL-CI-HIGH\n ## PV-027 - PARALLEL-CI-LOW\n ## PV-027 - SERIAL\n",
                            "Merge branch 'release-13.0' of https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines into release-13.0",
                            "James Nightingale",
                            "2023-08-18T17:50:03.000+02:00",
                            "22bec8642685bff3087cfb2386d20e518a3f4a96"
                        ],
                        [
                            "@@ -21,7 +21,8 @@ Some pipelines will use on-ground models. These on-ground models are:\n - saturation_model: DpdVisBloomingModel ProductId=DpdVisBloomingModel_EUC_VIS_MDL-SC8_BLOOM_ELE_json\n - zero_point: DpdVisZeroPoint ProductId=DpdVisZeroPoint_2436_040223_json\n - ghost_model: DpdVisGhostModel ProductId=DpdVisGhostModel_ghost_model_JAN2022_json\n-- starmask_model: DpdVisStarMask ProductId= DpdVisStarMask_starmask_JAN2022_fits\n+- starmask_model: DpdVisStarMask ProductId=DpdVisStarMask_starmask_JAN2022_fits\n+- crosstalk model: DpdVisXTalkModel ProductId=DpdVisXTalkModel_EUC_VIS_MDL-XTK-VGCC-coeffs_20210915_json\n \n Hereafter these products are referenced as _on-ground_.\n \n",
                            "[UPD]SUM: on-ground crosstalk model reference added.",
                            "Catherine Grenet",
                            "2023-08-18T10:27:37.000+02:00",
                            "339f8bd156fabe47ccf73bf08f7daec836776466"
                        ],
                        [
                            "@@ -704,6 +704,15 @@ This pipeline aims at producing the astrometric catalogue for NIR. This step can\n \n ## PV-029 PTC-SERIES-2\n \n+### Pipeline: VIS_FlagObjects\n+\n+Same as in PV-022 PRNU2-10000ADU except:\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-2 & ImgType.FirstType=SURVEY\n+\n+\n ## PV-031\n \n ### Pipeline: VIS_FlagObjects\n@@ -712,6 +721,57 @@ This pipeline aims at producing the astrometric catalogue for NIR. This step can\n \n - raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-031 & ImgType.FirstType=SURVEY\n \n+### Pipeline: VIS_BloomingCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame (ObservationSequence.CalblockId=PV-029 | ObservationSequence.CalblockId=PV-031) & ImgType.FirstType=FLAT\n+- vis_config_in:\n+- MDB:\n+- gains_model: gains model CALPRODUCT VS-011\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias: CALPRODUCT VS-003\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+- xtalk_model: CALPRODUCT VS-008\n+- nlcorr_model: empty\n+- cti_model: empty\n+- bfe_model: empty\n+\n+**Outputs:**\n+\n+- dpdcalib_blooming:\n+  - VIS Photon Transfer Curve, part of CALPRODUCT VS-011\n+  - VIS Blooming threshold CALPRODUCT VS-020\n+\n+### Pipeline:  VIS_PTCNLCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 & ImgType.FirstType=FLAT\n+- vis_config_in:\n+- MDB:\n+- gains_model: gains model CALPRODUCT VS-011\n+- ron_model: on-ground\n+- saturation_model: CALPRODUCT VS-020\n+- masterbias:  CALPRODUCT VS-003\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+- xtalk_model: CALPRODUCT VS-008\n+- nlcorr_model: empty\n+- cti_model: empty\n+- masterdark: empty\n+- bfe_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n+\n+**Outputs:**\n+\n+- dpdcalib_ptc: ???\n+- dpdcalib_nl: non-linearity model, candidate CALPRODUCT VS-016 VIS Nonlinearity\n+\n \n ## PV-004 GLINT-CHECK\n \n",
                            "[UPD]SUM: processing of PV-029 PTC-SERIES-2 and PV-031 added.",
                            "Catherine Grenet",
                            "2023-08-17T11:01:27.000+02:00",
                            "df7f88c92021a28377979fde11d73f072dca8669"
                        ],
                        [
                            "@@ -31,6 +31,18 @@ VIS_FlagObjects pipeline is intended to run on Calbloks PV-022, PV-029, and PV-0\n \n The detailed description of VIS_FlagObjects is given only once for PV-022 variant PRNU2-10000ADU. For the other calblocks and variants we just mention the differences with this first run.\n \n+VIS_MasterFlat pipeline is intended to run on all variants of Calbloks PV-022. It produces a master flat for each pair of LED and fluence.\n+LED selection is done with CalibUnit.LedMask:\n+\n+- LED1: CalibUnit.LedMask=0x1\n+- LED2: CalibUnit.LedMask=0x2\n+- LED3: CalibUnit.LedMask=0x4\n+- LED4: CalibUnit.LedMask=0x8\n+\n+Fluence selection is done with the calblock variant, except for LED 5 and 6 (PV-022 variant LED56-PRNU1-PRNU2-BF).\n+\n+The detailed description of VIS_MasterFlat pipeline is given only once for PV-022 variant PRNU2-10000ADU. For other variants we just mention the differences with this first run.\n+\n ## PV-021\n \n ### Pipeline: VIS_MasterBias\n@@ -113,13 +125,6 @@ The detailed description of VIS_FlagObjects is given only once for PV-022 varian\n \n 4 instances of the pipelines will be run, one for each of LEDs 1, 2, 3, 4. The 4 instances can be run in parallel.\n \n- LED selection is done with CalibUnit.LedMask:\n-\n-- LED1: CalibUnit.LedMask=0x1\n-- LED2: CalibUnit.LedMask=0x2\n-- LED3: CalibUnit.LedMask=0x4\n-- LED4: CalibUnit.LedMask=0x8\n-\n **Inputs:**\n \n - raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=PRNU2-10000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=_mask for LEDi_\n@@ -140,7 +145,7 @@ The detailed description of VIS_FlagObjects is given only once for PV-022 varian\n **Outputs:**\n \n - dpdcalib_data: master flat _LEDi_ 10kADU\n-- dpdcalib_flag: map of defects in photoresponse at 10 kADU, second part of CALPRODUCT VS-007 VIS Cosmetic Map\n+- dpdcalib_flag: map of defects in photoresponse at 10 kADU\n - dpdanalysis: quality assessment parameters\n - dpd_ledprofile: calibration unit profile\n \n@@ -153,9 +158,6 @@ Same as in PV-022 PRNU2-10000ADU except:\n **Inputs:**\n \n - raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-1 & ImgType.FirstType=SURVEY\n-- flagmaps:\n-  - map of defects in darkness, output of PV-021\n-  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n \n ### Pipeline: VIS_BloomingCalibration\n \n@@ -379,9 +381,6 @@ Quality control plots are in the workdir in logs/VIS_astrom_calib.\n **Inputs:**\n \n - raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW1-1000ADU & ImgType.FirstType=SURVEY\n-- flagmaps:\n-  - map of defects in darkness, output of PV-021\n-  - map of defects in photoresponse at 10 kADU, output of PV-022 - PRNU2-10000ADU\n \n **Outputs:**\n \n@@ -392,7 +391,7 @@ Quality control plots are in the workdir in logs/VIS_astrom_calib.\n \n **Inputs:**\n \n-- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW1-1000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=Ox4\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW1-1000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=0x4\n - vis_config_in:\n - MDB:\n - gains_model: on-ground\n@@ -413,8 +412,45 @@ Quality control plots are in the workdir in logs/VIS_astrom_calib.\n \n - gain_model_xml_out: gain model, part of CALPRODUCT VS-011\n \n+### Pipeline: VIS_MasterFlat\n+\n+4 instances of the pipelines will be run, one for each of LEDs 1, 2, 3, 4. The 4 instances can be run in parallel.\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW1-1000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=_mask for LEDi_\n+\n+**Outputs:**\n+\n+- dpdcalib_data: master flat _LEDi_ 1kADU\n+- dpdcalib_flag: map of defects in photoresponse at 1 kADU\n+- dpdanalysis: quality assessment parameters\n+- dpd_ledprofile: calibration unit profile\n+\n+\n ## PV-022 - LOW2-5000ADU\n \n+### Pipeline: VIS_FlagObjects\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW2-5000ADU & ImgType.FirstType=SURVEY\n+\n+### Pipeline: VIS_MasterFlat\n+\n+4 instances of the pipelines will be run, one for each of LEDs 1, 2, 3, 4. The 4 instances can be run in parallel.\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW2-5000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=_mask for LEDi_\n+\n+**Outputs:**\n+\n+- dpdcalib_data: master flat _LEDi_ 5kADU\n+- dpdcalib_flag: map of defects in photoresponse at 5 kADU\n+- dpdanalysis: quality assessment parameters\n+- dpd_ledprofile: calibration unit profile\n+\n ## PV-022 - BF-40000ADU\n \n ### Pipeline: VIS_FlagObjects\n@@ -422,9 +458,6 @@ Quality control plots are in the workdir in logs/VIS_astrom_calib.\n **Inputs:**\n \n - raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=BF-40000ADU & ImgType.FirstType=SURVEY\n-- flagmaps:\n-  - map of defects in darkness, output of PV-021\n-  - map of defects in photoresponse at 10 kADU, output of PV-022 - PRNU2-10000ADU\n \n **Outputs:**\n \n@@ -454,6 +487,22 @@ Quality control plots are in the workdir in logs/VIS_astrom_calib.\n \n - bfecalib_xml_out: brighter-fatter model CALPRODUCT VS-004 VIS Brighter-fatter Effect\n \n+### Pipeline: VIS_MasterFlat\n+\n+4 instances of the pipelines will be run, one for each of LEDs 1, 2, 3, 4. The 4 instances can be run in parallel.\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=BF-40000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=_mask for LEDi_\n+\n+**Outputs:**\n+\n+- dpdcalib_data: master flat _LEDi_ 40kADU\n+- dpdcalib_flag: map of defects in photoresponse at 40 kADU\n+- dpdanalysis: quality assessment parameters\n+- dpd_ledprofile: calibration unit profile\n+\n+\n ## PV-007 - PROPOSAL-08-M33\n ## PV-007 - PROPOSAL-11-A370\n ## PV-007 - PROPOSAL-11-N01\n@@ -657,9 +706,66 @@ This pipeline aims at producing the astrometric catalogue for NIR. This step can\n \n ## PV-031\n \n+### Pipeline: VIS_FlagObjects\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-031 & ImgType.FirstType=SURVEY\n+\n+\n+## PV-004 GLINT-CHECK\n+\n+## PV-007 PROPOSAL-09\n+\n+## PV-005 CDFS-24\n+## PV-005 EDFS-24-47ROS\n+\n+## PV-001 VISIT-2\n+\n+## PV-005 EDFN-FULL-25\n+## PV-005 EDFN-3x3-25\n+\n+## PV-001 VISIT-3\n \n+## PV-022 PRNU1-25000ADU\n \n+### Pipeline: VIS_FlagObjects\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=PRNU1-25000ADU & ImgType.FirstType=SURVEY\n+\n+### Pipeline: VIS_MasterFlat\n+\n+4 instances of the pipelines will be run, one for each of LEDs 1, 2, 3, 4. The 4 instances can be run in parallel.\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=PRNU1-25000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=_mask for LEDi_\n+\n+**Outputs:**\n+\n+- dpdcalib_data: master flat _LEDi_ 25kADU\n+- dpdcalib_flag: map of defects in photoresponse at 25 kADU\n+- dpdanalysis: quality assessment parameters\n+- dpd_ledprofile: calibration unit profile\n+\n+### Pipeline: VIS_SmallScaleFlat\n+\n+This pipeline combines all the individual single-LED (1, 2, 3, 4) single-fluence (10k, 25k, 40k) MasterFlat frames available so far to produce one unique \"small-scale\" MasterFlat to use in all subsequent masterflat input ports.\n+\n+**Inputs:**\n+\n+- vis_config_in:\n+- MDB:\n+- prnulist_in: DpdVisMasterFlatFrame outputs of previous PV-022 VIS_MasterFlat pipelines (12 objects: 4 LEDs x 3 fluences)\n+- flagmaps_in: map of defects in photoresponse, dpdcalib_flag outputs of previous 12 PV-022 VIS_MasterFlat pipelines\n+\n+**Outputs:**\n \n+- smallscaleflat_out: DpdVisMasterFlatFrame containing the combined small-scale MasterFlat CALPRODUCT VS-022\n+- prnuflagmap_out: DpdVisFlagMap associated to smallscaleflat_out\n+- dqc_out: DpdVisAnalysisResults, data quality control product, containing the 'slope' and 'standard error' products of each extrapolated to 0-signal flat per LED\n \n \n \n",
                            "[UPD]SUM Processing of all PV-022 variants except LED56 added.",
                            "Catherine Grenet",
                            "2023-08-16T17:46:10.000+02:00",
                            "0d14940c9f7f0b974c84f73fb6af9b072c6ef019"
                        ],
                        [
                            "@@ -29,7 +29,7 @@ Note that when ExposureTime is used for selection, the exact value in real data\n \n VIS_FlagObjects pipeline is intended to run on Calbloks PV-022, PV-029, and PV-031. It processes the short science exposures in the Calblock to create masks of celestial objects for each pointing. These masks are then used by the pipelines in charge of processing the flat-field exposures of each calblock. These pipelines need in input the masks corresponding to the flats to process, but more can be given: each pipeline will search for the masks corresponding to the flat fields they are processing.\n \n-The detailed description of VIS_FlagObjects is given only once for PV-022. For the other calblocks we just mention the differences with this first run.\n+The detailed description of VIS_FlagObjects is given only once for PV-022 variant PRNU2-10000ADU. For the other calblocks and variants we just mention the differences with this first run.\n \n ## PV-021\n \n@@ -58,7 +58,7 @@ The detailed description of VIS_FlagObjects is given only once for PV-022. For t\n **Inputs:**\n \n - raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-021 & ImgType.FirstType=DARK & ExposureTime=565\n-- vis_config_in:\n+- vis_config_in: DpdVisConfigurationFile_EUC_VIS_ConfigFile_15AUG2023_ini\n - MDB:\n - gains_model: on-ground\n - ron_model: on-ground\n@@ -146,6 +146,67 @@ The detailed description of VIS_FlagObjects is given only once for PV-022. For t\n \n ## PV-029 - PTC-SERIES-1\n \n+### Pipeline: VIS_FlagObjects\n+\n+Same as in PV-022 PRNU2-10000ADU except:\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-1 & ImgType.FirstType=SURVEY\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+\n+### Pipeline: VIS_BloomingCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-1 & ImgType.FirstType=FLAT\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias: CALPRODUCT VS-003\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- bfe_model: empty\n+\n+**Outputs:**\n+\n+- dpdcalib_blooming: preliminary version of VIS Photon Transfer Curve, part of CALPRODUCT VS-011\n+\n+### Pipeline:  VIS_PTCNLCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-1 & ImgType.FirstType=FLAT\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias:  CALPRODUCT VS-003\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- masterdark: empty\n+- bfe_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n+\n+**Outputs:**\n+\n+- dpdcalib_ptc: ???\n+- dpdcalib_nl: non-linearity model, preliminary version of candidate CALPRODUCT VS-016 VIS Nonlinearity\n+\n+\n ## PV-027 - PARALLEL-CI-HIGH\n ## PV-027 - PARALLEL-CI-LOW\n ## PV-027 - SERIAL\n",
                            "Merge branch 'feature-SUM' into release-13.0: [DOC][FIX]Bug #23494,[UPD] SRN 13.0.13",
                            "Catherine Grenet",
                            "2023-08-16T15:26:57.000+02:00",
                            "63fd4293bf64c2e9895af3adad163bf543d3d23f"
                        ],
                        [
                            "@@ -58,7 +58,7 @@ The detailed description of VIS_FlagObjects is given only once for PV-022 varian\n **Inputs:**\n \n - raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-021 & ImgType.FirstType=DARK & ExposureTime=565\n-- vis_config_in:\n+- vis_config_in: DpdVisConfigurationFile_EUC_VIS_ConfigFile_15AUG2023_ini\n - MDB:\n - gains_model: on-ground\n - ron_model: on-ground\n",
                            "[FIX]SUM Bug #23494 New configuration file for MasterDark pipeline.",
                            "Catherine Grenet",
                            "2023-08-16T15:10:41.000+02:00",
                            "c1be58ac83f804692e2dafe1ddeeecb9328ff79b"
                        ],
                        [
                            "@@ -29,7 +29,7 @@ Note that when ExposureTime is used for selection, the exact value in real data\n \n VIS_FlagObjects pipeline is intended to run on Calbloks PV-022, PV-029, and PV-031. It processes the short science exposures in the Calblock to create masks of celestial objects for each pointing. These masks are then used by the pipelines in charge of processing the flat-field exposures of each calblock. These pipelines need in input the masks corresponding to the flats to process, but more can be given: each pipeline will search for the masks corresponding to the flat fields they are processing.\n \n-The detailed description of VIS_FlagObjects is given only once for PV-022. For the other calblocks we just mention the differences with this first run.\n+The detailed description of VIS_FlagObjects is given only once for PV-022 variant PRNU2-10000ADU. For the other calblocks and variants we just mention the differences with this first run.\n \n ## PV-021\n \n@@ -146,6 +146,67 @@ The detailed description of VIS_FlagObjects is given only once for PV-022. For t\n \n ## PV-029 - PTC-SERIES-1\n \n+### Pipeline: VIS_FlagObjects\n+\n+Same as in PV-022 PRNU2-10000ADU except:\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-1 & ImgType.FirstType=SURVEY\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+\n+### Pipeline: VIS_BloomingCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-1 & ImgType.FirstType=FLAT\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias: CALPRODUCT VS-003\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- bfe_model: empty\n+\n+**Outputs:**\n+\n+- dpdcalib_blooming: preliminary version of VIS Photon Transfer Curve, part of CALPRODUCT VS-011\n+\n+### Pipeline:  VIS_PTCNLCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-029 &  ObservationSequence.CalBlockVariant=PTC-SERIES-1 & ImgType.FirstType=FLAT\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias:  CALPRODUCT VS-003\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse for LED3, output of PV-022 PRNU2-10000ADU MasterFlat LED3\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- masterdark: empty\n+- bfe_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n+\n+**Outputs:**\n+\n+- dpdcalib_ptc: ???\n+- dpdcalib_nl: non-linearity model, preliminary version of candidate CALPRODUCT VS-016 VIS Nonlinearity\n+\n+\n ## PV-027 - PARALLEL-CI-HIGH\n ## PV-027 - PARALLEL-CI-LOW\n ## PV-027 - SERIAL\n",
                            "[NEW]SUM: chap29_PVOperations.md Description of PV-029 PTC-SERIES-1 added.",
                            "Catherine Grenet",
                            "2023-08-15T19:50:59.000+02:00",
                            "9946689e5acb65da9a4794b571c51fe33e63dddb"
                        ],
                        [
                            "@@ -0,0 +1,606 @@\n+\\newpage\n+\n+# PV operations\n+\n+## Commonalities\n+\n+There is no VIS pipeline to trigger for Calblocks not mentioned in this chapter.\n+\n+Unless otherwise stated, the following inputs will be used for all pipelines:\n+\n+- vis_config_in: DpdVisConfigurationFile ProductId=DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_ini\n+- MDB: DpdMdbDataBase ProductId=EUC_MDB_MISSIONCONFIGURATION-DEV_2023-07-17T12:00:00.00Z_00\n+\n+These inputs will not be repeated hereafter.\n+\n+Some pipelines will use on-ground models. These on-ground models are:\n+\n+- gains_model: DpdVisGainModel ProductId=DpdVisGainModel_EUC_VIS_MDL-PTC01_GAIN_elperadu_MAP_json\n+- psf_model: DpdVisPSFModel ProductId=DpdVisPSFModel_EUC_VIS_MDL-PSF_OH_issue-20981-44_2022-12-20\n+- ron_model: DpdVisRONModel ProductId=DpdVisRONModel_EUC_VIS_MDL-BIAS02_RON_ELE_MAP_json\n+- saturation_model: DpdVisBloomingModel ProductId=DpdVisBloomingModel_EUC_VIS_MDL-SC8_BLOOM_ELE_json\n+- zero_point: DpdVisZeroPoint ProductId=DpdVisZeroPoint_2436_040223_json\n+- ghost_model: DpdVisGhostModel ProductId=DpdVisGhostModel_ghost_model_JAN2022_json\n+- starmask_model: DpdVisStarMask ProductId= DpdVisStarMask_starmask_JAN2022_fits\n+\n+Hereafter these products are referenced as _on-ground_.\n+\n+Note that when ExposureTime is used for selection, the exact value in real data may not be the one mentioned in the current version of this document.\n+\n+VIS_FlagObjects pipeline is intended to run on Calbloks PV-022, PV-029, and PV-031. It processes the short science exposures in the Calblock to create masks of celestial objects for each pointing. These masks are then used by the pipelines in charge of processing the flat-field exposures of each calblock. These pipelines need in input the masks corresponding to the flats to process, but more can be given: each pipeline will search for the masks corresponding to the flat fields they are processing.\n+\n+The detailed description of VIS_FlagObjects is given only once for PV-022. For the other calblocks we just mention the differences with this first run.\n+\n+## PV-021\n+\n+### Pipeline: VIS_MasterBias\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-021 & ImgType.FirstType=BIAS\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: empty\n+- flagmaps: empty\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+\n+**Outputs:**\n+\n+- dpdcalib_data: CALPRODUCT VS-003 VIS Bias\n+- dpdanalysis: quality assessment parameters\n+\n+### Pipeline: VIS_MasterDark\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-021 & ImgType.FirstType=DARK & ExposureTime=565\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: empty\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- flagmaps: empty\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+\n+**Outputs:**\n+\n+- dpdcalib_data: CALPRODUCT VS-009 VIS Darks\n+- dpdcalib_flag: map of defects in darkness, first part of CALPRODUCT VS-007 VIS Cosmetic Map\n+- dpdanalysis: quality assessment parameters\n+\n+## F-014\n+\n+## PV-022 - PRNU2-10000ADU\n+\n+### Pipeline: VIS_FlagObjects\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 &  ObservationSequence.CalBlockVariant=PRNU2-10000ADU & ImgType.FirstType=SURVEY\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- flagmaps: map of defects in darkness, output of PV-021\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- zero_point: on-ground\n+- masterdark: empty\n+- masterflat: empty\n+- psf_model: on-ground\n+- dist_model: empty\n+- lsf_model: empty\n+- ghost_model: empty\n+- starmask_model: empty\n+- bfe_model: empty\n+- ref_catalogues: empty\n+\n+**Outputs:**\n+\n+- objects_flagmap_xml_out: list of object masks, one for each input exposure\n+\n+### Pipeline: VIS_MasterFlat\n+\n+4 instances of the pipelines will be run, one for each of LEDs 1, 2, 3, 4. The 4 instances can be run in parallel.\n+\n+ LED selection is done with CalibUnit.LedMask:\n+\n+- LED1: CalibUnit.LedMask=0x1\n+- LED2: CalibUnit.LedMask=0x2\n+- LED3: CalibUnit.LedMask=0x4\n+- LED4: CalibUnit.LedMask=0x8\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=PRNU2-10000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=_mask for LEDi_\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: empty\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- flagmaps: map of defects in darkness, output of VIS_MasterDark pipeline\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- masterdark: empty\n+- bfe_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n+\n+**Outputs:**\n+\n+- dpdcalib_data: master flat _LEDi_ 10kADU\n+- dpdcalib_flag: map of defects in photoresponse at 10 kADU, second part of CALPRODUCT VS-007 VIS Cosmetic Map\n+- dpdanalysis: quality assessment parameters\n+- dpd_ledprofile: calibration unit profile\n+\n+## PV-029 - PTC-SERIES-1\n+\n+## PV-027 - PARALLEL-CI-HIGH\n+## PV-027 - PARALLEL-CI-LOW\n+## PV-027 - SERIAL\n+\n+## PV-028 - CI-ROS - VIS_CTIMasterCI\n+\n+### Pipeline: VIS_CTIMasterCI\n+\n+Set of 6 x 32 CIL images taken with different charge injection parameters corresponding to\n+[table 11 of this webpage](http://calibration.pages.euclid-sgs.uk/CalTQ-Framework/calobs/calobs-vis-cti-cil.html#calobs-vis-cti-cil).\n+\n+Each batch of 6 CIL images taken with identical charge injection parameters (e.g. each row of table 11) are passed\n+to the VIS_CTIMasterCI pipeline, outputting a single master CIL image for each input image. In total, 32 independent\n+runs of this pipeline are performed for the CI-ROS calblock.\n+\n+**Inputs:**\n+\n+- raw_frames_in: x6 DpdVisRawFrame raw charge injection frames corresponding to each row of table 11 (see example query below).\n+- MDB:\n+- flagmaps: map of defects in darkness, output of PV-021\n+- gains_model: on-ground\n+- xtalk_model: empty\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- masterdark: empty\n+- nlcorr_model: empty\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+\n+**Outputs:**\n+\n+- master_ci_xml_out: MasterCIFrame corresponding to an FPA of charge injection data for a single set of charge injection parameter settings for CALPRODUCT-VS-005.\n+\n+**Example Query for Row 1:**\n+\n+```\n+ImgType.FirstType=CHARGE_INJECTION\n+ObservationSequence.CalblockId=PV-028\n+ChargeInjection.Parameters.InjectedLinesCount=420\n+ChargeInjection.Parameters.NonInjectedLinesCount=100\n+ChargeInjection.Parameters.InjectionDrainLowPulseDelay.Value>2.4 && ChargeInjection.Parameters.InjectionDrainLowPulseDelay.Value<2.6\n+ChargeInjection.Parameters.InjectionGate1Voltage.Value>4.24 && ChargeInjection.Parameters.InjectionGate1Voltage.Value<4.26\n+ChargeInjection.Parameters.InjectionGate2Voltage.Value>5.98 && ChargeInjection.Parameters.InjectionGate2Voltage.Value<6.02\n+```\n+\n+## PV-028 - IG1-SCAN\n+\n+### Pipeline: VIS_CTIMasterCI\n+\n+Identical to PV-028 - CI-ROS, except that the charge injection parameters are varied in a grid scan of IG1 values,\n+given by [table 45 of this webpage](http://calibration.pages.euclid-sgs.uk/CalTQ-Framework/calobs/calobs-block-pv-vis-cti-charge-injection.html).\n+\n+**Inputs:**\n+\n+- raw_frames_in: x6 DpdVisRawFrame raw charge injection frames corresponding to each row of table 45 (see example query below).\n+- MDB:\n+- flagmaps: map of defects in darkness, output of PV-021\n+- gains_model: on-ground\n+- xtalk_model: empty\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- masterdark: empty\n+- nlcorr_model: empty\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+\n+**Outputs:**\n+\n+- master_ci_xml_out: MasterCIFrame corresponding to an FPA of charge injection data for a single set of charge injection parameter settings for CALPRODUCT-VS-005.\n+\n+**Example Query for Row 1:**\n+\n+```\n+ImgType.FirstType=CHARGE_INJECTION\n+ObservationSequence.CalblockId=PV-028\n+ChargeInjection.Parameters.InjectedLinesCount=420\n+ChargeInjection.Parameters.NonInjectedLinesCount=100\n+ChargeInjection.Parameters.InjectionDrainLowPulseDelay.Value>2.4 && ChargeInjection.Parameters.InjectionDrainLowPulseDelay.Value<2.6\n+ChargeInjection.Parameters.InjectionGate1Voltage.Value>3.24 && ChargeInjection.Parameters.InjectionGate1Voltage.Value<3.26\n+ChargeInjection.Parameters.InjectionGate2Voltage.Value>5.98 && ChargeInjection.Parameters.InjectionGate2Voltage.Value<6.02\n+```\n+\n+## PV-028 - CI-ROS - VIS_CTICalibration\n+\n+### Pipeline: VIS_CTICalibration\n+\n+4 independent runs of the CTI calibration pipeline, using a subset of the ROS data (and none of the IG1-Scan data).\n+\n+For each set of 6 CIL taken with identical charge injection settings, only one of each set of the 6 images are used.\n+\n+Therefore, in total  32 images with settings corresponding to the 32 rows\n+[table 11 of this webpage](http://calibration.pages.euclid-sgs.uk/CalTQ-Framework/calobs/calobs-vis-cti-cil.html#calobs-vis-cti-cil)\n+are used.\n+\n+Four independent runs of the pipeline, each with 8 CIL images are performed, corresponding to\n+rows 1-8, 9-16, 17-24 and 25-32 of table 11.\n+\n+**Inputs:**\n+\n+- raw_frames_in: x8 DpdVisRawFrame raw charge injection frames corresponding to a block of 8 rows of table 11 (see example query below).\n+- MDB:\n+- flagmaps: map of defects in darkness, output of PV-021\n+- gains_model: on-ground\n+- xtalk_model: empty\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- masterdark: empty\n+- nlcorr_model: empty\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+\n+**Outputs:**\n+\n+- parallel_cti_xml_out: Parallel CTICalibrationResults for CALPRODUCT-VS-005.\n+- serial_cti_xml_out: Serial CTICalibrationResults for CALPRODUCT-VS-005.\n+\n+**Example Query for Row 1:**\n+\n+```\n+ImgType.FirstType=CHARGE_INJECTION\n+ObservationSequence.CalblockId=PV-028\n+ChargeInjection.Parameters.InjectedLinesCount=420\n+ChargeInjection.Parameters.NonInjectedLinesCount=100\n+ChargeInjection.Parameters.InjectionDrainLowPulseDelay.Value>2.4 && ChargeInjection.Parameters.InjectionDrainLowPulseDelay.Value<2.6\n+ChargeInjection.Parameters.InjectionGate1Voltage.Value>4.24 && ChargeInjection.Parameters.InjectionGate1Voltage.Value<4.26\n+ChargeInjection.Parameters.InjectionGate2Voltage.Value>5.98 && ChargeInjection.Parameters.InjectionGate2Voltage.Value<6.02\n+```\n+\n+## PV-034 VIS Charge Injection Timing\n+\n+No processing during PV.\n+\n+## PV-023\n+\n+### Pipeline: VIS_AstrometryCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-023 & ImgType.Category=SCIENCE & ExposureTime=565\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse at 10 kADU, output of PV-022 - PRNU2-10000ADU\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- zero_point: on-ground\n+- masterdark: empty\n+- masterflat: master flat LED3 10kADU, output of PV-022 - PRNU2-10000ADU\n+- dist_model: empty\n+- lsf_model: empty\n+- bfe_model: empty\n+- ref_catalogues: DpdExtGaiaCutout covering raw science frames sky area\n+\n+\n+**Outputs:**\n+\n+- dist_model_xml_out: CALPRODUCT VS-010 VIS Focal Plane Astrometric Solution\n+\n+Quality control plots are in the workdir in logs/VIS_astrom_calib.\n+\n+## F-014\n+\n+## PV-022 - LOW1-1000ADU\n+\n+### Pipeline: VIS_FlagObjects\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW1-1000ADU & ImgType.FirstType=SURVEY\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse at 10 kADU, output of PV-022 - PRNU2-10000ADU\n+\n+**Outputs:**\n+\n+- objects_flagmap_xml_out: list of object masks, one for each input exposure\n+\n+\n+### Pipeline: VIS_GainCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=LOW1-1000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=Ox4\n+- vis_config_in:\n+- MDB:\n+- gains_model: on-ground\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse at 10 kADU, output of PV-022 - PRNU2-10000ADU\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- masterdark: empty\n+- bfe_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n+\n+**Outputs:**\n+\n+- gain_model_xml_out: gain model, part of CALPRODUCT VS-011\n+\n+## PV-022 - LOW2-5000ADU\n+\n+## PV-022 - BF-40000ADU\n+\n+### Pipeline: VIS_FlagObjects\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=BF-40000ADU & ImgType.FirstType=SURVEY\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse at 10 kADU, output of PV-022 - PRNU2-10000ADU\n+\n+**Outputs:**\n+\n+- objects_flagmap_xml_out: list of object masks, one for each input exposure\n+\n+\n+### Pipeline: VIS_BrighterFatterCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-022 & ObservationSequence.CalBlockVariant=BF-40000ADU & ImgType.FirstType=FLAT & CalibUnit.LedMask=Ox4\n+- vis_config_in:\n+- MDB:\n+- gains_model: gain model CALPRODUCT VS-011\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse at 10 kADU, output of PV-022 - PRNU2-10000ADU\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- object_masks: outputs of VIS_FlagObjects pipeline\n+\n+**Outputs:**\n+\n+- bfecalib_xml_out: brighter-fatter model CALPRODUCT VS-004 VIS Brighter-fatter Effect\n+\n+## PV-007 - PROPOSAL-08-M33\n+## PV-007 - PROPOSAL-11-A370\n+## PV-007 - PROPOSAL-11-N01\n+\n+## PV-001 - VISIT-1\n+\n+### Step 1 - Pipeline: VIS_PSFCalibration\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-001 & ObservationSequence.CalBlockVariant=likeVISIT-1* & ImgType.FirstType=SELF_CALIBRATION & ExposureTime =106\n+- vis_config_in:\n+- MDB:\n+- gains_model: gain model CALPRODUCT VS-011\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias: CALPRODUCT VS-003 VIS Bias\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse at 10 kADU, output of PV-022 - PRNU2-10000ADU\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- masterdark: empty\n+- masterflat: master flat LED3 10kADU, output of PV-022 - PRNU2-10000ADU\n+\n+\n+**Outputs:**\n+\n+- psf_model_xml_out: PSF model\n+\n+### Step 2 - Pipelines: VIS_ProcessField\n+\n+2 instances of VIS_ProcessField without stacking will be run, possibly in parallel, one on the short exposures and one on the nominal exposures.\n+\n+**Inputs:**\n+\n+- raw_frames_in:\n+  - short exposures: DpdVisRawFrame ObservationSequence.CalblockId=PV-001 & ObservationSequence.CalBlockVariant=likeVISIT-1* & ImgType.FirstType=SELF_CALIBRATION & ExposureTime = 106\n+  - nominal exposures: DpdVisRawFrame ObservationSequence.CalblockId=PV-001 & ObservationSequence.CalBlockVariant=likeVISIT-1* & ImgType.FirstType=SELF_CALIBRATION & ExposureTime = 565\n+- vis_config_in: DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_nostack_ini\n+- MDB:\n+- gains_model: gain model CALPRODUCT VS-011\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias:  CALPRODUCT VS-003 VIS Bias\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse at 10 kADU, output of PV-022 - PRNU2-10000ADU\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- zero_point: on-ground\n+- masterdark: empty\n+- masterflat: master flat LED3 10kADU, output of PV-022 - PRNU2-10000ADU\n+- psf_model: output of previous VIS_PSFCalibration\n+- dist_model: distortion model CALPRODUCT VS-010 VIS\n+- lsf_model: empty\n+- ghost_model: on-ground\n+- starmask_model: on-ground\n+- bfe_model: empty\n+- ref_catalogues: DpdExtGaiaCutout covering raw science frames sky area\n+\n+**Outputs:**\n+\n+- dpdcalibrated_frames: VIS calibrated frames\n+- dpdcalibrated_catalogues: VIS calibrated catalogues\n+- dpdghost_catalogues: unused in the rest of the processing\n+\n+### Step 3 - Pipelines: VIS_LargeFlatCalibration\n+\n+2 instances of VIS_LargeFlatCalibration will be run, possibly in parallel, one on the short exposure catalogs and one on the nominal exposure catalogs.\n+\n+**Inputs:**\n+\n+- vis_config_in:\n+- MDB:\n+- catalogues_in: DpdVisCalibratedFrameCatalog\n+  - short exposures: DpdVisCalibratedFrameCatalog, output the previous VIS_ProcessField on short exposures\n+  - nominal exposures: DpdVisCalibratedFrameCatalog, output the previous VIS_ProcessField on nominal exposures\n+\n+**Outputs:**\n+\n+- largeflatcal_output: large flat for short and nominal exposures, respectively, CALPRODUCT VS-013\n+\n+### Step 4 - Pipelines: VIS_ProcessField\n+\n+2 instances of VIS_ProcessField without stacking will be run, possibly in parallel, one on the short exposures and one on the nominal exposures. It is exactly the same processing as in step 4, except that large flat correction will be applied. Below we describe only the differences with Step 2.\n+\n+**Inputs:**\n+\n+- lsf_model:\n+  - short exposures: CALPRODUCT VS-013, output of VIS_LargeFlatCalibration for short exposures\n+  - nominal exposures: CALPRODUCT VS-013, output of VIS_LargeFlatCalibration for nominal exposures\n+\n+**Outputs:**\n+\n+- dpdcalibrated_frames: VIS calibrated frames\n+- dpdcalibrated_catalogues: VIS calibrated catalogues\n+- dpdghost_catalogues: ghost catalogues\n+\n+### Step 5 - Pipeline: VIS_PhotometryCalibration\n+\n+**Inputs:**\n+\n+- vis_config_in:\n+- MDB:\n+- catalogues_in: list of DpdVisCalibratedFrameCatalog from VIS_ProcessField on short exposures in step 4\n+\n+**Outputs:**\n+\n+- zero_point_xml_out: updated VIS zero point CALPRODUCT VS-001\n+\n+### Step 6 - Pipeline: VIS_GhostsCalibration\n+\n+This pipeline can be run in parallel with VIS_PhotometryCalibration in step 5.\n+\n+**Inputs:**\n+\n+- MDB:\n+- ghost_cat_list: ghost catalogues, output of both VIS_ProcessField in step 4 (long and short exposures)\n+- ref_ghost_model_in: on-ground\n+\n+**Outputs:**\n+\n+ghost_model_xml_out: updated ghost model CALPRODUCT VS-012\n+\n+### Step 7 - Pipeline: VIS_XTalkCalibration_Pipeline\n+\n+This pipeline can be run in parallel with VIS_PhotometryCalibration in step 5 and VIS_GhostsCalibration in step 6.\n+It will be run on the raw nominal exposures only.\n+\n+**Inputs:**\n+\n+- raw_frames_in: DpdVisRawFrame ObservationSequence.CalblockId=PV-001 & ObservationSequence.CalBlockVariant=likeVISIT-1* & ImgType.FirstType=SELF_CALIBRATION & ExposureTime = 565\n+- vis_config_in: DpdVisConfigurationFile_EUC_VIS_ConfigFile_PF12_01JUL2023_normtmp_ini\n+- MDB:\n+- gains_model: gain model CALPRODUCT VS-011\n+- ron_model: on-ground\n+- saturation_model: on-ground\n+- masterbias:  CALPRODUCT VS-003 VIS Bias\n+- flagmaps:\n+  - map of defects in darkness, output of PV-021\n+  - map of defects in photoresponse at 10 kADU, output of PV-022 - PRNU2-10000ADU\n+- xtalk_model: empty\n+- nlcorr_model: empty\n+- cti_model: empty\n+- zero_point: on-ground\n+- masterdark: empty\n+- masterflat: master flat LED3 10kADU, output of PV-022 - PRNU2-10000ADU\n+- psf_model: output of previous VIS_PSFCalibration\n+- dist_model: distortion model CALPRODUCT VS-010 VIS\n+- lsf_model: CALPRODUCT VS-013, output of VIS_LargeFlatCalibration for nominal exposures\n+- ghost_model: on-ground\n+- starmask_model: on-ground\n+- bfe_model: empty\n+- ref_catalogues: DpdExtGaiaCutout covering raw science frames sky area\n+\n+**Outputs:**\n+\n+- xtalk_model_xml_out: crosstalk model, CALPRODUCT VS-008\n+\n+### Step 8  - Pipelines: VIS_ProcessField\n+\n+2 instances of VIS_ProcessField without stacking will be run, possibly in parallel, one on the short exposures and one on the nominal exposures. It is the same processing as in step 4, except that we will use the zero point and the crosstalk model produced in the previous steps. Below we describe only the differences with step 4.\n+\n+**Inputs:**\n+\n+- xtalk_model: crosstalk model CALPRODUCT VS-008\n+- zero_point: VIS zero point CALPRODUCT VS-001\n+\n+**Outputs:**\n+\n+- dpdcalibrated_frames: VIS calibrated frames for MER\n+\n+### Step X - Pipeline: VIS stacking\n+\n+This pipeline aims at producing the astrometric catalogue for NIR. This step can be executed either after step 2, 4 or 8, depending on NIR needs.\n+\n+**Inputs:**\n+\n+- vis_config_in:\n+- ref_catalogues: DpdExtGaiaCutout covering raw science frames sky area\n+- exposure_list: list of DpdVisCalibratedFrame, output of VIS_ProcessField in step 2, 4 or 8\n+\n+**Outputs:**\n+\n+- dpdstacked_catalogue: single VIS catalog for NIR\n+\n+\n+\n+## PV-006\tELAT-90-20\n+## PV-006\tELAT-100-20\n+## PV-006\tGLAT-20\n+\n+## PV-024\n+\n+## F-014\n+\n+## PV-029 PTC-SERIES-2\n+\n+## PV-031\n+\n+\n+\n+\n+\n+\n+\n+\n+\n",
                            "Merge branch 'feature-SUM' into release-13.0: SRN VIS PF 13.0.12",
                            "Catherine Grenet",
                            "2023-08-14T16:13:23.000+02:00",
                            "bec4d2f7797ae8a84255ffd581f45f5a4f533835"
                        ]
                    ],
                    "VIS_IAL_Pipelines/auxdir/VIS_IAL_Pipelines/VIS_ProcessField_Pipeline/PkgDef_VIS_ProcessField.py": [
                        [
                            "@@ -29,18 +29,23 @@\n # /cvmfs/euclid-dev.in2p3.fr/CentOS7/INFRA/1.1/opt/euclid/ST_PipelineRunner/latest/lib/python3.6/site-packages/euclidwf\n from euclidwf.framework.taskdefs import Executable, Input, Output, ComputingResources\n \n-# 1- doesn't work because the Pipeline Runner is running outside of EDEN environment\n-# and PYTHONPTH is not set to include /cvmfs/euclid-dev.in2p3.fr/CentOS7/EDEN-x.y/opt/euclid\n-#import VIS_TASKS_VERSION\n-#TASKS_VER = VIS_TASKS_VERSION.VIS_TASKS_ORIGINAL_VERSION\n-\n-# 2- doesn't work because 'make test' is done on the source tree, not the InstallArea tree...\n-#import importlib.machinery\n-#ialversion_path = os.path.join( os.path.realpath( __file__).split( \"/auxdir/\")[0],\n-#                                \"python/VIS_IAL_PIPELINES_VERSION.py\")\n-#mod = importlib.machinery.SourceFileLoader( \"VIS_IAL_PIPELINES_VERSION\", ialversion_path).load_module()\n+################################################################################\n+\n+# hack to automatically get VIS_IAL_Pipelines version without EDEN environment python path\n+# (pipeline runner doesn't run in EDEN)\n+# commented because it has not been decided yet to synchronise VIS_IAL_Pipelines and VIS_Tasks versions.\n+\n+#import sys\n+#from glob import glob\n+#vip_root = os.path.realpath( __file__).split( \"/VIS_IAL_Pipelines/\")[0]\n+#vip_version_glob = os.path.join( vip_root, \"VIS_IAL_Pipelines/build.*/python/\")\n+#vip_version_path = glob( vip_version_glob)[0]\n+#sys.path.append( vip_version_path)\n+#import VIS_IAL_PIPELINES_VERSION\n #TASKS_VER = VIS_IAL_PIPELINES_VERSION.VIS_IAL_PIPELINES_ORIGINAL_VERSION\n \n+################################################################################\n+\n TASKS_VER = \"13.1\"\n \n import os\n",
                            "PkgDef_VIS_ProcessField.py: add comment with right way to put VIS_IAL_Pipelines version in TASKS_VER, if we one day decide to go this way.",
                            "Sylvain Mottet",
                            "2023-08-21T10:33:18.000+02:00",
                            "6c29e9cbac26d41236f0cc5b5b1bafb285ec1f6d"
                        ],
                        [
                            "@@ -41,7 +41,7 @@ from euclidwf.framework.taskdefs import Executable, Input, Output, ComputingReso\n #mod = importlib.machinery.SourceFileLoader( \"VIS_IAL_PIPELINES_VERSION\", ialversion_path).load_module()\n #TASKS_VER = VIS_IAL_PIPELINES_VERSION.VIS_IAL_PIPELINES_ORIGINAL_VERSION\n \n-TASKS_VER = \"13.0.13\"\n+TASKS_VER = \"13.0.14\"\n \n import os\n PIPE_NAME = \"VIS_\" + os.path.splitext( os.path.basename( __file__))[0].split( \"VIS_\")[1]\n",
                            "Merge branch 'release-13.0' into master_ci_memory",
                            "James Nightingale",
                            "2023-08-18T17:55:53.000+02:00",
                            "961b01b509e96c9e2b52d75b5383fbd55e0be960"
                        ],
                        [
                            "@@ -41,7 +41,7 @@ from euclidwf.framework.taskdefs import Executable, Input, Output, ComputingReso\n #mod = importlib.machinery.SourceFileLoader( \"VIS_IAL_PIPELINES_VERSION\", ialversion_path).load_module()\n #TASKS_VER = VIS_IAL_PIPELINES_VERSION.VIS_IAL_PIPELINES_ORIGINAL_VERSION\n \n-TASKS_VER = \"13.0.13\"\n+TASKS_VER = \"13.0.14\"\n \n import os\n PIPE_NAME = \"VIS_\" + os.path.splitext( os.path.basename( __file__))[0].split( \"VIS_\")[1]\n",
                            "Merge branch 'release-13.0' of https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines into release-13.0",
                            "James Nightingale",
                            "2023-08-18T17:50:03.000+02:00",
                            "22bec8642685bff3087cfb2386d20e518a3f4a96"
                        ],
                        [
                            "@@ -41,7 +41,7 @@ from euclidwf.framework.taskdefs import Executable, Input, Output, ComputingReso\n #mod = importlib.machinery.SourceFileLoader( \"VIS_IAL_PIPELINES_VERSION\", ialversion_path).load_module()\n #TASKS_VER = VIS_IAL_PIPELINES_VERSION.VIS_IAL_PIPELINES_ORIGINAL_VERSION\n \n-TASKS_VER = \"13.0.13\"\n+TASKS_VER = \"13.0.14\"\n \n import os\n PIPE_NAME = \"VIS_\" + os.path.splitext( os.path.basename( __file__))[0].split( \"VIS_\")[1]\n",
                            "[UPD]Set TASKS_VER to 13.0.14",
                            "Catherine Grenet",
                            "2023-08-17T11:26:45.000+02:00",
                            "47051a90d013305fb0914b45d93f55f7cb0e9784"
                        ],
                        [
                            "@@ -41,7 +41,7 @@ from euclidwf.framework.taskdefs import Executable, Input, Output, ComputingReso\n #mod = importlib.machinery.SourceFileLoader( \"VIS_IAL_PIPELINES_VERSION\", ialversion_path).load_module()\n #TASKS_VER = VIS_IAL_PIPELINES_VERSION.VIS_IAL_PIPELINES_ORIGINAL_VERSION\n \n-TASKS_VER = \"13.0.12\"\n+TASKS_VER = \"13.0.13\"\n \n import os\n PIPE_NAME = \"VIS_\" + os.path.splitext( os.path.basename( __file__))[0].split( \"VIS_\")[1]\n",
                            "[UPD]Set TASKS_VER to 13.0.13",
                            "Catherine Grenet",
                            "2023-08-15T16:35:45.000+02:00",
                            "c54232fbcef65d7e6b67dc963ac2afed56344c1f"
                        ]
                    ],
                    "CMakeLists.txt": [
                        [
                            "@@ -12,6 +12,6 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project( VIS_IAL_Pipelines 13.0.13\n+elements_project( VIS_IAL_Pipelines 13.0.14\n                   USE ST_PipelineChecker 1.5.0\n                   DESCRIPTION \"VIS Processing Function pipelines interface description\")\n",
                            "Merge branch 'release-13.0' into master_ci_memory",
                            "James Nightingale",
                            "2023-08-18T17:55:53.000+02:00",
                            "961b01b509e96c9e2b52d75b5383fbd55e0be960"
                        ],
                        [
                            "@@ -12,6 +12,6 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project( VIS_IAL_Pipelines 13.0.12\n+elements_project( VIS_IAL_Pipelines 13.0.13\n                   USE ST_PipelineChecker 1.5.0\n                   DESCRIPTION \"VIS Processing Function pipelines interface description\")\n",
                            "Bump version to 13.0.13",
                            "Catherine Grenet",
                            "2023-08-14T16:29:12.000+02:00",
                            "5729fbc9bf4beeea7010053f3b1f24940207da3a"
                        ]
                    ],
                    "VIS_IAL_Pipelines/auxdir/VIS_IAL_Pipelines/VIS_CTIMasterCI_Pipeline/PkgDef_VIS_CTIMasterCI.py": [
                        [
                            "@@ -51,7 +51,7 @@ master_ci_estimate = Executable(\n         Input(\"quad_list_of_lists\")\n     ],\n     outputs=[Output(\"cti_master_ci\", mime_type=\"json\")],\n-    resources=ComputingResources(cores=1, ram=256.0, walltime=4.0),\n+    resources=ComputingResources(cores=1, ram=24.0, walltime=4.0),\n )\n \n quad2FPA = Executable(\n",
                            "cti calibration pieline cores",
                            "James Nightingale",
                            "2023-08-18T17:49:52.000+02:00",
                            "5de471ce755cad4421d81ed0e45cc7dd3c0a4734"
                        ],
                        [
                            "@@ -19,6 +19,8 @@ import os\n \n PIPE_NAME = \"VIS_\" + os.path.splitext( os.path.basename( __file__))[0].split( \"VIS_\")[1]\n \n+TASKS_VER = \"13.0.14\"\n+\n VIS_cti_xml_in = Executable(\n     command=f\"E-Run VIS_Tasks {TASKS_VER} VIS_xml_in --pipeline_name={PIPE_NAME} \",\n     inputs=[\n",
                            "manual edits to IAL to allow for local runs",
                            "James Nightingale",
                            "2023-08-16T16:01:33.000+02:00",
                            "fc4c14a564cdba2d11ab4e1426e2a02183cb9fcb"
                        ]
                    ]
                },
                "selected_modifications": {
                    "VIS_IAL_Pipelines/auxdir/VIS_IAL_Pipelines/VIS_BloomingCalibration_Pipeline/PkgDef_VIS_BloomingCalibration.py": [
                        [
                            "@@ -26,7 +26,8 @@ VIS_blooming_xml_in = Executable(command   = f\"E-Run VIS_Tasks {TASKS_VER} VIS_x\n                                           Input(\"nlcorr_model\",     content_type=\"listfile\"),\n                                           Input(\"ron_model\",        content_type=\"listfile\"),\n                                           Input(\"cti_model\",        content_type=\"listfile\"),\n-                                          Input(\"bfe_model\",        content_type=\"listfile\"),],\n+                                          Input(\"bfe_model\",        content_type=\"listfile\"),\n+                                          Input(\"object_masks\",   content_type=\"listfile\")],\n                              outputs   = [Output(\"rawexp_list\", mime_type=\"json\", content_type=\"listfile\"),\n                                           Output(\"piperun_config\", mime_type=\"cfg\")],\n                              resources = ComputingResources(cores = 1,\n",
                            "Merge branch 'release-13.0' into develop: #23449 CTICalib decorators, #23455 MasterBias ram, #23518 Blooming object masks",
                            "Catherine Grenet",
                            "2023-08-21T17:30:06.000+02:00",
                            "3266962f8cb5374c52678180c4d4e0592338bdb8"
                        ]
                    ],
                    "VIS_IAL_Pipelines/auxdir/VIS_IAL_Pipelines/VIS_CTICalibration_Pipeline/PkgDef_VIS_CTICalibration.py": [
                        [
                            "@@ -63,10 +63,14 @@ calibrate_cti = Executable(\n \n VIS_cti_xml_out = Executable(\n     command=f\"E-Run VIS_Tasks {TASKS_VER} VIS_cti_xml_out\",\n-    inputs=[\"config\", \"calibrate_cti_results_list\"],\n+    inputs=[\n+        \"config\",\n+        Input(\"parallel_calibrate_cti_results_list\"),\n+        Input(\"serial_calibrate_cti_results_list\")\n+    ],\n     outputs=[\n         Output(\"parallel_cti_xml_out\"),\n         Output(\"serial_cti_xml_out\"),\n     ],\n     resources=ComputingResources(cores=1, ram=7.0, walltime=3.0),\n-)\n\\ No newline at end of file\n+)\n",
                            "Merge branch 'release-13.0' into develop: #23449 CTICalib decorators, #23455 MasterBias ram, #23518 Blooming object masks",
                            "Catherine Grenet",
                            "2023-08-21T17:30:06.000+02:00",
                            "3266962f8cb5374c52678180c4d4e0592338bdb8"
                        ],
                        [
                            "@@ -60,7 +60,7 @@ calibrate_cti = Executable(\n         Output(\"cti_parallel_output\", mime_type=\"json\"),\n         Output(\"cti_serial_output\", mime_type=\"json\")\n     ],\n-    resources=ComputingResources(cores=1, ram=256.0, walltime=16.0),\n+    resources=ComputingResources(cores=8, ram=128.0, walltime=8.0),\n )\n \n VIS_cti_xml_out = Executable(\n",
                            "cti calibration pieline cores",
                            "James Nightingale",
                            "2023-08-18T17:49:52.000+02:00",
                            "5de471ce755cad4421d81ed0e45cc7dd3c0a4734"
                        ],
                        [
                            "@@ -18,6 +18,8 @@ import os\n \n PIPE_NAME = \"VIS_\" + os.path.splitext( os.path.basename( __file__))[0].split( \"VIS_\")[1]\n \n+TASKS_VER = \"13.0.14\"\n+\n VIS_cti_xml_in = Executable(\n     command=f\"E-Run VIS_Tasks {TASKS_VER} VIS_xml_in --pipeline_name={PIPE_NAME} \",\n     inputs=[\n",
                            "manual edits to IAL to allow for local runs",
                            "James Nightingale",
                            "2023-08-16T16:01:33.000+02:00",
                            "fc4c14a564cdba2d11ab4e1426e2a02183cb9fcb"
                        ],
                        [
                            "@@ -18,8 +18,6 @@ import os\n \n PIPE_NAME = \"VIS_\" + os.path.splitext( os.path.basename( __file__))[0].split( \"VIS_\")[1]\n \n-TASKS_VERSION = \"13.0.13\"\n-\n VIS_cti_xml_in = Executable(\n     command=f\"E-Run VIS_Tasks {TASKS_VER} VIS_xml_in --pipeline_name={PIPE_NAME} \",\n     inputs=[\n",
                            "hot fix tested in end-to-end run",
                            "James Nightingale",
                            "2023-08-16T13:47:26.000+02:00",
                            "f66fa0d8f8f7577454c36e82268dc2f8ba83c0da"
                        ]
                    ],
                    "VIS_IAL_Pipelines/auxdir/VIS_IAL_Pipelines/VIS_MasterBias_Pipeline/PkgDef_VIS_MasterBias.py": [
                        [
                            "@@ -71,7 +71,7 @@ processBiasQuad = Executable(command = f\"E-Run VIS_Tasks {TASKS_VER} VIS_process\n                                         Output(\"output_quadrant_stdev\", mime_type=\"json\", content_type=\"listfile\"),\n                                         Output(\"output_quadrant_count\", mime_type=\"json\", content_type=\"listfile\"),],\n                              resources = ComputingResources(cores = 1,\n-                                                            ram = 6.0,\n+                                                            ram = 9.0,\n                                                             walltime = 3.0))\n \n quad2FPA = Executable(command = f\"E-Run VIS_Tasks {TASKS_VER} VIS_quad_to_fpa\",\n",
                            "Merge branch 'release-13.0' into develop: #23449 CTICalib decorators, #23455 MasterBias ram, #23518 Blooming object masks",
                            "Catherine Grenet",
                            "2023-08-21T17:30:06.000+02:00",
                            "3266962f8cb5374c52678180c4d4e0592338bdb8"
                        ]
                    ],
                    "VIS_IAL_Pipelines/auxdir/VIS_IAL_Pipelines/VIS_ProcessField_Pipeline/PkgDef_VIS_ProcessField.py": [
                        [
                            "@@ -29,18 +29,23 @@\n # /cvmfs/euclid-dev.in2p3.fr/CentOS7/INFRA/1.1/opt/euclid/ST_PipelineRunner/latest/lib/python3.6/site-packages/euclidwf\n from euclidwf.framework.taskdefs import Executable, Input, Output, ComputingResources\n \n-# 1- doesn't work because the Pipeline Runner is running outside of EDEN environment\n-# and PYTHONPTH is not set to include /cvmfs/euclid-dev.in2p3.fr/CentOS7/EDEN-x.y/opt/euclid\n-#import VIS_TASKS_VERSION\n-#TASKS_VER = VIS_TASKS_VERSION.VIS_TASKS_ORIGINAL_VERSION\n-\n-# 2- doesn't work because 'make test' is done on the source tree, not the InstallArea tree...\n-#import importlib.machinery\n-#ialversion_path = os.path.join( os.path.realpath( __file__).split( \"/auxdir/\")[0],\n-#                                \"python/VIS_IAL_PIPELINES_VERSION.py\")\n-#mod = importlib.machinery.SourceFileLoader( \"VIS_IAL_PIPELINES_VERSION\", ialversion_path).load_module()\n+################################################################################\n+\n+# hack to automatically get VIS_IAL_Pipelines version without EDEN environment python path\n+# (pipeline runner doesn't run in EDEN)\n+# commented because it has not been decided yet to synchronise VIS_IAL_Pipelines and VIS_Tasks versions.\n+\n+#import sys\n+#from glob import glob\n+#vip_root = os.path.realpath( __file__).split( \"/VIS_IAL_Pipelines/\")[0]\n+#vip_version_glob = os.path.join( vip_root, \"VIS_IAL_Pipelines/build.*/python/\")\n+#vip_version_path = glob( vip_version_glob)[0]\n+#sys.path.append( vip_version_path)\n+#import VIS_IAL_PIPELINES_VERSION\n #TASKS_VER = VIS_IAL_PIPELINES_VERSION.VIS_IAL_PIPELINES_ORIGINAL_VERSION\n \n+################################################################################\n+\n TASKS_VER = \"13.1\"\n \n import os\n",
                            "PkgDef_VIS_ProcessField.py: add comment with right way to put VIS_IAL_Pipelines version in TASKS_VER, if we one day decide to go this way.",
                            "Sylvain Mottet",
                            "2023-08-21T10:33:18.000+02:00",
                            "6c29e9cbac26d41236f0cc5b5b1bafb285ec1f6d"
                        ],
                        [
                            "@@ -41,7 +41,7 @@ from euclidwf.framework.taskdefs import Executable, Input, Output, ComputingReso\n #mod = importlib.machinery.SourceFileLoader( \"VIS_IAL_PIPELINES_VERSION\", ialversion_path).load_module()\n #TASKS_VER = VIS_IAL_PIPELINES_VERSION.VIS_IAL_PIPELINES_ORIGINAL_VERSION\n \n-TASKS_VER = \"13.0.13\"\n+TASKS_VER = \"13.0.14\"\n \n import os\n PIPE_NAME = \"VIS_\" + os.path.splitext( os.path.basename( __file__))[0].split( \"VIS_\")[1]\n",
                            "Merge branch 'release-13.0' into master_ci_memory",
                            "James Nightingale",
                            "2023-08-18T17:55:53.000+02:00",
                            "961b01b509e96c9e2b52d75b5383fbd55e0be960"
                        ],
                        [
                            "@@ -41,7 +41,7 @@ from euclidwf.framework.taskdefs import Executable, Input, Output, ComputingReso\n #mod = importlib.machinery.SourceFileLoader( \"VIS_IAL_PIPELINES_VERSION\", ialversion_path).load_module()\n #TASKS_VER = VIS_IAL_PIPELINES_VERSION.VIS_IAL_PIPELINES_ORIGINAL_VERSION\n \n-TASKS_VER = \"13.0.13\"\n+TASKS_VER = \"13.0.14\"\n \n import os\n PIPE_NAME = \"VIS_\" + os.path.splitext( os.path.basename( __file__))[0].split( \"VIS_\")[1]\n",
                            "Merge branch 'release-13.0' of https://gitlab.euclid-sgs.uk/PF-VIS/VIS_IAL_Pipelines into release-13.0",
                            "James Nightingale",
                            "2023-08-18T17:50:03.000+02:00",
                            "22bec8642685bff3087cfb2386d20e518a3f4a96"
                        ],
                        [
                            "@@ -41,7 +41,7 @@ from euclidwf.framework.taskdefs import Executable, Input, Output, ComputingReso\n #mod = importlib.machinery.SourceFileLoader( \"VIS_IAL_PIPELINES_VERSION\", ialversion_path).load_module()\n #TASKS_VER = VIS_IAL_PIPELINES_VERSION.VIS_IAL_PIPELINES_ORIGINAL_VERSION\n \n-TASKS_VER = \"13.0.13\"\n+TASKS_VER = \"13.0.14\"\n \n import os\n PIPE_NAME = \"VIS_\" + os.path.splitext( os.path.basename( __file__))[0].split( \"VIS_\")[1]\n",
                            "[UPD]Set TASKS_VER to 13.0.14",
                            "Catherine Grenet",
                            "2023-08-17T11:26:45.000+02:00",
                            "47051a90d013305fb0914b45d93f55f7cb0e9784"
                        ],
                        [
                            "@@ -41,7 +41,7 @@ from euclidwf.framework.taskdefs import Executable, Input, Output, ComputingReso\n #mod = importlib.machinery.SourceFileLoader( \"VIS_IAL_PIPELINES_VERSION\", ialversion_path).load_module()\n #TASKS_VER = VIS_IAL_PIPELINES_VERSION.VIS_IAL_PIPELINES_ORIGINAL_VERSION\n \n-TASKS_VER = \"13.0.12\"\n+TASKS_VER = \"13.0.13\"\n \n import os\n PIPE_NAME = \"VIS_\" + os.path.splitext( os.path.basename( __file__))[0].split( \"VIS_\")[1]\n",
                            "[UPD]Set TASKS_VER to 13.0.13",
                            "Catherine Grenet",
                            "2023-08-15T16:35:45.000+02:00",
                            "c54232fbcef65d7e6b67dc963ac2afed56344c1f"
                        ]
                    ],
                    "VIS_IAL_Pipelines/auxdir/VIS_IAL_Pipelines/VIS_CTIMasterCI_Pipeline/PkgDef_VIS_CTIMasterCI.py": [
                        [
                            "@@ -51,7 +51,7 @@ master_ci_estimate = Executable(\n         Input(\"quad_list_of_lists\")\n     ],\n     outputs=[Output(\"cti_master_ci\", mime_type=\"json\")],\n-    resources=ComputingResources(cores=1, ram=256.0, walltime=4.0),\n+    resources=ComputingResources(cores=1, ram=24.0, walltime=4.0),\n )\n \n quad2FPA = Executable(\n",
                            "cti calibration pieline cores",
                            "James Nightingale",
                            "2023-08-18T17:49:52.000+02:00",
                            "5de471ce755cad4421d81ed0e45cc7dd3c0a4734"
                        ],
                        [
                            "@@ -19,6 +19,8 @@ import os\n \n PIPE_NAME = \"VIS_\" + os.path.splitext( os.path.basename( __file__))[0].split( \"VIS_\")[1]\n \n+TASKS_VER = \"13.0.14\"\n+\n VIS_cti_xml_in = Executable(\n     command=f\"E-Run VIS_Tasks {TASKS_VER} VIS_xml_in --pipeline_name={PIPE_NAME} \",\n     inputs=[\n",
                            "manual edits to IAL to allow for local runs",
                            "James Nightingale",
                            "2023-08-16T16:01:33.000+02:00",
                            "fc4c14a564cdba2d11ab4e1426e2a02183cb9fcb"
                        ]
                    ]
                },
                "count_selected_modifications": "5",
                "tags_in_period": [
                    {
                        "name": "13.0.12",
                        "created_at": "2023-08-14T16:13:23.000+02:00",
                        "author_name": "Catherine Grenet"
                    },
                    {
                        "name": "13.0.13",
                        "created_at": "2023-08-16T15:26:57.000+02:00",
                        "author_name": "Catherine Grenet"
                    },
                    {
                        "name": "13.0.14",
                        "created_at": "2023-08-22T16:21:35.000+02:00",
                        "author_name": "Catherine Grenet"
                    }
                ]
            },
            "PF-VIS/VIS_Transients": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_XTalk": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_BiasCorrection": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_BiasCalibration": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_PRNUCalibration": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_PRNUCorrection": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_Helper_scripts": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_PSF": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_Validation": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_Cosmics": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_CTI": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_NonLinCorrection": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_Pipelines": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_Tasks": {
                "start date": "2023-08-13T15:44:17",
                "end date": "2023-08-22T13:27:01",
                "start tag": "13.0.12",
                "end tag": "13.0.14",
                "count_files_modified": "28",
                "modifications_by_file": {
                    "VIS_Astrometry/python/VIS_Astrometry/wcsfit.py": [
                        [
                            "@@ -42,7 +42,7 @@ import sys\n import numpy as np\n from astropy import wcs\n from astropy.io import fits\n-from astropy.coordinates import SkyCoord, GCRS, CartesianRepresentation\n+from astropy.coordinates import SkyCoord, GCRS, ICRS, CartesianRepresentation\n import astropy.units as u\n from astropy.time import Time\n from configobj import ConfigObj\n@@ -50,6 +50,7 @@ import itertools\n import matplotlib.pyplot as plt\n import matplotlib.colors\n from scipy.spatial.distance import cdist\n+from scipy.optimize import least_squares\n \n from . import wcsfit_core\n from .sip_tpv import sip_to_pv\n@@ -218,6 +219,18 @@ def get_parser():\n         '--refmagmax', type=float, default=None, metavar='MAX_MAG',\n         help='maximum reference star magnitude (default: no limit)'\n     )\n+    ref_opt_args_group.add_argument(\n+        '--flux-rad-min', type=float, default=None, metavar='FLUX_RADIUS',\n+        help='Lower limit on reference star FLUX_RADIUS'\n+    )\n+    ref_opt_args_group.add_argument(\n+        '--flux-rad-max', type=float, default=None, metavar='FLUX_RADIUS',\n+        help='Upper limit on reference star FLUX_RADIUS'\n+    )\n+    ref_opt_args_group.add_argument(\n+        '--flux-rad-peak', type=float, default=None, metavar='FLUX_RADIUS',\n+        help='Approximate reference star FLUX_RADIUS distribution peak'\n+    )\n \n     # minimiser termination optional arguments\n     term_opt_args_group = parser.add_argument_group(\n@@ -325,6 +338,16 @@ def check_cmdargs(_args):\n         plural = '' if len(mag_lims) > 1 else 's'\n         parser.error(' and '.join(mag_lims) + f' require{plural} --refmagcol')\n \n+    # check that the FLUX_RADIUS related arguments are sensible\n+    if _args.flux_rad_min is not None and _args.flux_rad_max is not None:\n+        if _args.flux_rad_min >= _args.flux_rad_max:\n+            parser.error(\"FLUX_RADIUS minimum must be smaller than FLUX_RADIUS maximum\")\n+        if _args.flux_rad_peak is not None:\n+            if _args.flux_rad_peak <= _args.flux_rad_min:\n+                parser.error(\"FLUX_RADIUS peak must be larger than FLUX_RADIUS minimum\")\n+            if _args.flux_rad_peak >= _args.flux_rad_max:\n+                parser.error(\"FLUX_RADIUS peak must be smaller than FLUX_RADIUS maximum\")\n+\n     # check that the number of minimiser iterations is greater than zero\n     if not _args.niter > 0:\n         parser.error('--niter must be >0')\n@@ -444,6 +467,9 @@ def runwcsfit(args, logger=None):\n         refmagkey=args.refmagcol,\n         refmagmin=args.refmagmin,\n         refmagmax=args.refmagmax,\n+        flux_rad_min=args.flux_rad_min,\n+        flux_rad_max=args.flux_rad_max,\n+        flux_rad_peak=args.flux_rad_peak,\n         logger=logger\n     )\n \n@@ -481,12 +507,15 @@ def runwcsfit(args, logger=None):\n \n         # plot the plate scale if requested\n         if args.make_plots is not None:\n-            id_string = os.path.basename(args.output_fpa_model)\n-            plot_plate_scale(\n-                fpa_model, args.make_plots,\n-                alt_fpa_model=args.init_fpa_model,\n-                file_identifier_string=id_string\n-            )\n+            try:\n+                id_string = os.path.basename(args.output_fpa_model)\n+                plot_plate_scale(\n+                    fpa_model, args.make_plots,\n+                    alt_fpa_model=args.init_fpa_model,\n+                    file_identifier_string=id_string\n+                )\n+            except Exception as e:\n+                logger.error(f\"!!! caught exception '{e}' in wcsfit make_plots, ignoring....\")\n \n     elif args.mode == 'use-fpa-model':\n \n@@ -564,10 +593,13 @@ def runwcsfit(args, logger=None):\n \n     # Produce plots if requested\n     if args.make_plots is not None:\n-        plot_sausages(obsdataset, args.make_plots)\n-        plot_vpds(obsdataset, args.make_plots)\n-        plot_residuals(obsdataset, args.make_plots)\n-        plot_local_mean_residual(obsdataset, fpa_model, args.make_plots)\n+        try:\n+            plot_sausages(obsdataset, args.make_plots)\n+            plot_vpds(obsdataset, args.make_plots)\n+            plot_residuals(obsdataset, args.make_plots)\n+            plot_local_mean_residual(obsdataset, fpa_model, args.make_plots)\n+        except Exception as e:\n+            logger.error(f\"!!! caught exception '{e}' in wcsfit make_plots, ignoring....\")\n \n     # store the tables of reference source matches if requested\n     if args.matchcat is not None:\n@@ -1203,6 +1235,21 @@ def copy_wcs_to_file(source_observation, target_file, fpamodel=None):\n               sip_to_pv(src_hdr)\n             replace_header_wcs(src_hdr, dest_hdr)\n \n+            # record the original pointing and position angle\n+            dest_hdr['RA_COMM'] = (\n+                source_observation.commanded_pointing[0],\n+                'commanding pointing RA'\n+            )\n+            dest_hdr['DEC_COMM'] = (\n+                source_observation.commanded_pointing[1],\n+                'commanding pointing DEC'\n+            )\n+            dest_hdr['PA_COMM'] = (\n+                source_observation.commanded_pa,\n+                'commanding position angle'\n+            )\n+\n+            # todo consider the reference frame\n             # add the reconstructed pointing\n             dest_hdr['RA'] = (\n                 source_observation.pointing[0],\n@@ -1288,6 +1335,144 @@ def use_fpa_model(\n         logger=logger\n     )\n \n+    # ecrf to icrs\n+    ecrf_to_icrs(observation, logger=logger)\n+\n+\n+def ecrf_to_icrs(observation, num_cps_per_axis=100, logger=None):\n+    \"\"\"\n+    Take the WCS information from the observation, which maps array\n+    coordinates to the ECRF, and map it from array coords to the ICRS\n+\n+    Parameters\n+    ----------\n+    observation : wcsfit_core.Observation\n+        The observation containing the base WCS\n+    num_cps_per_axis : int, optional\n+        The number of control points to use per axis, default 100.\n+    logger : Logger, optional\n+        A Logger for logging messages (None for no logging, default).\n+    \"\"\"\n+    for ext, ccd in observation.ccds.items():\n+        if logger is not None:\n+            logger.debug(f\"Transforming {ext} WCS from ECRF to ICRS\")\n+\n+        # read the header\n+        orig_hdr = ccd.header.copy()\n+\n+        # generate the control point grid\n+        xy = np.meshgrid(np.linspace(1, orig_hdr[\"NAXIS1\"], num_cps_per_axis),\n+                         np.linspace(1, orig_hdr[\"NAXIS2\"], num_cps_per_axis))\n+        x, y = map(lambda arr: arr.flatten(), xy)\n+\n+        # define the Euclid-centric reference frame\n+        _pos_offset = CartesianRepresentation(\n+            x=observation.pos_offset[0],\n+            y=observation.pos_offset[1],\n+            z=observation.pos_offset[2],\n+            unit=u.km\n+        )\n+        _vel_offset = CartesianRepresentation(\n+            x=observation.vel_offset[0],\n+            y=observation.vel_offset[1],\n+            z=observation.vel_offset[2],\n+            unit=u.km / u.s\n+        )\n+        _obs_time = Time(observation.ref_epoch, format='jyear')\n+        ECRF = GCRS(obstime=_obs_time, obsgeoloc=_pos_offset, obsgeovel=_vel_offset)\n+\n+        # project array coords to ecrf\n+        ecrf_a, ecrf_d = wcs.WCS(orig_hdr).all_pix2world(x, y, 1)\n+        ecrf_sc = SkyCoord(ecrf_a, ecrf_d, frame=ECRF, unit='deg')\n+\n+        # transform to ICRS\n+        icrs_sc = ecrf_sc.transform_to(ICRS)\n+        # must do this otherwise astropy thinks they aren't the same frame\n+        icrs_sc = SkyCoord(icrs_sc.ra.deg, icrs_sc.dec.deg, frame='icrs', unit='deg')\n+\n+        # transform reference star coords back to ICRS\n+        ref_sc_ecrf = SkyCoord(\n+            ccd.ra[ccd.has_sky_coord], ccd.dec[ccd.has_sky_coord], frame=ECRF, unit='deg'\n+        )\n+        ref_sc_icrs = ref_sc_ecrf.transform_to(ICRS)\n+        ccd.ra[ccd.has_sky_coord] = ref_sc_icrs.ra.deg\n+        ccd.dec[ccd.has_sky_coord] = ref_sc_icrs.dec.deg\n+        ccd.update_skycoord_obj()\n+\n+        # compute the new WCS\n+        orig_crvals = np.array([orig_hdr['CRVAL1'], orig_hdr['CRVAL2']])\n+        orig_cdmtx = wcsfit_core.get_cd(orig_hdr).flatten()\n+        orig_sip = wcsfit_core.get_sip_coeffs(orig_hdr)\n+        # starting parameters\n+        p0 = np.concatenate((orig_crvals, orig_cdmtx, orig_sip))\n+\n+        # temporary header\n+        tmp_hdr = orig_hdr.copy()\n+\n+        def min_func(parameters):\n+            # extract the linear terms\n+            _crvals = parameters[:2]\n+            _cd_mtx = parameters[2:6].reshape(2, 2)\n+            _sip_coeffs = parameters[6:]\n+\n+            # send the linear terms to the header\n+            for i in range(1, 3):\n+                tmp_hdr[f'CRVAL{i}'] = _crvals[i - 1]\n+                for j in range(1, 3):\n+                    tmp_hdr[f'CD{i}_{j}'] = _cd_mtx[i - 1, j - 1]\n+\n+            # send the distortion model to the header\n+            k = 0\n+            for dim in 'AB':\n+                order = tmp_hdr[f'{dim}_ORDER']\n+                for p in range(order + 1):\n+                    for q in range(order + 1):\n+                        if 2 <= p + q <= order:\n+                            tmp_hdr[f'{dim}_{p}_{q}'] = _sip_coeffs[k]\n+                            k += 1\n+\n+            # generate the WCS object\n+            tmp_wcs = wcs.WCS(tmp_hdr)\n+\n+            # evaluate the positions of the control points\n+            _ra, _dec = tmp_wcs.all_pix2world(x, y, 1)\n+            _sc = SkyCoord(_ra, _dec, frame='icrs', unit='deg')\n+\n+            # calculate separations between true and predicted positions\n+            dra, ddec = icrs_sc.spherical_offsets_to(_sc)\n+            # convert to milliarcsec\n+            dra, ddec = dra.arcsec * 1000, ddec.arcsec * 1000\n+\n+            # return the flattened residuals\n+            return np.concatenate((dra, ddec)).flatten()\n+\n+        # set bounds\n+        ubounds = np.full_like(p0, np.inf)\n+        lbounds = np.full_like(p0, -np.inf)\n+        lbounds[0] = np.clip(orig_crvals[0] - 5, 0.0, 360.)  # don't allow ra to go crazy\n+        ubounds[0] = np.clip(orig_crvals[0] + 5, 0.0, 360.)\n+        lbounds[1] = np.clip(orig_crvals[1] - 5, -90.0, 90.0)  # don't allow dec to go crazy\n+        ubounds[1] = np.clip(orig_crvals[1] + 5, -90.0, 90.0)\n+\n+        # run the minimizer\n+        solution = least_squares(\n+            min_func, p0, bounds=(lbounds, ubounds), x_scale='jac', jac='3-point'\n+        )\n+\n+        # set the resultant values and get the header\n+        abs_residuals = np.abs(min_func(solution.x))\n+        if logger is not None:\n+            logger.debug(f\"mean, max residual = \"\n+                         f\"{abs_residuals.mean():.2e}, \"\n+                         f\"{abs_residuals.max():.2e} (mas)\")\n+\n+        # send the header to the CCD object\n+        ccd.header = tmp_hdr.copy()\n+        ccd.wcs = wcs.WCS(ccd.header)\n+\n+\n+\n+\n \n def fit_fpa_model(\n         obsdataset,\n@@ -1596,6 +1781,7 @@ def fpa_model_from_observation(observation, sip_order, logger=None):\n def read_observations_references(\n         source_catalogues, reference_catalogues,\n         refmagkey=None, refmagmin=None, refmagmax=None,\n+        flux_rad_min=None, flux_rad_max=None, flux_rad_peak=None,\n         logger=None\n ):\n     \"\"\"\n@@ -1616,6 +1802,15 @@ def read_observations_references(\n     refmagmax : float, optional\n         Maximum magnitude of the reference stars used from refcat (None for\n         no maximum limit).\n+    flux_rad_min : float, optional\n+        Lower limit of acceptable FLUX_RADIUS range for real stars.\n+        Default None, i.e. no minimum FLUX_RADIUS.\n+    flux_rad_max : float, optional\n+        Upper limit of acceptable FLUX_RADIUS range for real stars.\n+        Default None, i.e. no maximum FLUX_RADIUS.\n+    flux_rad_peak : float, optional\n+        The peak of the FLUX_RADIUS distribution for real stars.\n+        Default None, i.e. no FLUX_RADIUS distribution fitting.\n     logger : Logger, optional\n         A Logger for logging messages (None for no logging, default).\n \n@@ -1638,9 +1833,23 @@ def read_observations_references(\n             source_catalogues, reference_catalogues,\n             fillvalue=reference_catalogues[0]\n     ):\n+\n+        # grab data from the observation primary header\n+        pri_hdr = fits.getheader(src_cat_path, 0)\n+        # date of the vis observation\n+        mjdobs = pri_hdr['MJD-OBS']\n+        obs_epoch = Time(mjdobs, format='mjd').jyear\n+        # position of the instrument\n+        pos = tuple([pri_hdr[f\"POS_{elem}\"] for elem in \"XYZ\"])\n+        # velocity of the instrument\n+        vel = tuple([pri_hdr[f\"VEL_{elem}\"] for elem in \"XYZ\"])\n+\n         # read the reference catalogue\n         refdata = get_references(\n             ref_cat_path,\n+            obs_epoch,\n+            pos,\n+            vel,\n             refmagkey=refmagkey,\n             refmagmin=refmagmin,\n             refmagmax=refmagmax,\n@@ -1650,7 +1859,8 @@ def read_observations_references(\n         observations.append(get_observation(\n             src_cat_path, refdata,\n             refmagmin=refmagmin, refmagmax=refmagmax,\n-            logger=logger\n+            flux_rad_min=flux_rad_min, flux_rad_max=flux_rad_max,\n+            flux_rad_peak=flux_rad_peak, logger=logger\n         ))\n \n     # return an ObservationSet instance\n@@ -2116,6 +2326,7 @@ def is_an_astrometric_kwd(kwd, include_naxis=False):\n \n \n def get_observation(src_cat_path, refdata, refmagmin=None, refmagmax=None,\n+                    flux_rad_min=None, flux_rad_max=None, flux_rad_peak=None,\n                     logger=None):\n     \"\"\"\n     Grab data and headers from the catalogue of the relevant observation.\n@@ -2134,6 +2345,18 @@ def get_observation(src_cat_path, refdata, refmagmin=None, refmagmax=None,\n     refmagmax : float, optional\n         Maximum magnitude of the reference stars used from refcat (None for\n         no maximum limit).\n+    flux_rad_min : float, optional\n+        Lower limit of acceptable FLUX_RADIUS range for real stars.\n+        Default None, i.e. no minimum FLUX_RADIUS.\n+    flux_rad_max : float, optional\n+        Upper limit of acceptable FLUX_RADIUS range for real stars.\n+        Default None, i.e. no maximum FLUX_RADIUS.\n+    flux_rad_peak : float, optional\n+        The peak of the FLUX_RADIUS distribution for real stars.\n+        Default None, i.e. no FLUX_RADIUS distribution fitting.\n+    logger : Logger, optional\n+        A logger which will be used for printing the logging messages (None for\n+        no printing).\n \n     Returns\n     -------\n@@ -2157,6 +2380,14 @@ def get_observation(src_cat_path, refdata, refmagmin=None, refmagmax=None,\n         # grab the primary header\n         pri_hdr = srccat_hdul[0].header\n \n+        # date of the vis observation\n+        mjdobs = pri_hdr['MJD-OBS']\n+        obs_epoch = Time(mjdobs, format='mjd').jyear\n+        # position of the instrument\n+        pos_vec = tuple([pri_hdr[f\"POS_{elem}\"] for elem in \"XYZ\"])\n+        # velocity of the instrument\n+        vel_vec = tuple([pri_hdr[f\"VEL_{elem}\"] for elem in \"XYZ\"])\n+\n         # record the primary header exptime if present\n         if 'EXPTIME' in pri_hdr.keys():\n             exptimes.append(float(pri_hdr['EXPTIME']))\n@@ -2218,8 +2449,8 @@ def get_observation(src_cat_path, refdata, refmagmin=None, refmagmax=None,\n             _mask = filter_catalogue(\n                 mags, fluxrad,\n                 mag_min=refmagmin, mag_max=refmagmax, mag_margin=0.5,\n-                flux_rad_min=2.0, flux_rad_max=4.0,\n-                logger=logger\n+                flux_rad_min=flux_rad_min, flux_rad_max=flux_rad_max,\n+                flux_rad_peak=flux_rad_peak, logger=logger\n             )\n \n             # require no large sextractor error flags\n@@ -2278,13 +2509,18 @@ def get_observation(src_cat_path, refdata, refmagmin=None, refmagmax=None,\n     # build an Observation object instance from the list of ccds\n     observation = wcsfit_core.Observation(\n         ccd_list, refdata, pointings[0], pas[0], exptimes[0],\n+        ref_epoch=obs_epoch, pos_offset=pos_vec, vel_offset=vel_vec,\n         filename=src_cat_path, header=pri_hdr\n     )\n \n+    # record the commanded pointing and position angle\n+    observation.commanded_pointing = pointings[0]\n+    observation.commanded_pa = pas[0]\n+\n     return observation\n \n \n-def get_references(refcat,\n+def get_references(refcat, obs_epoch, pos, vel,\n                    refmagkey=None, refmagmin=None, refmagmax=None,\n                    logger=None):\n     \"\"\"\n@@ -2294,6 +2530,12 @@ def get_references(refcat,\n     ----------\n     refcat : str\n         A FITS file with catalogue of position reference stars.\n+    obs_epoch : float\n+        Julian year of observation.\n+    pos : tuple\n+        Geocentric position vector of the instrument.\n+    vel : tuple\n+        Geocentric velocity vector of the instrument.\n     refmagkey : str, optional\n         Name of the column which contains the catalogue magnitudes.\n     refmagmin : float, optional\n@@ -2320,6 +2562,12 @@ def get_references(refcat,\n         ref_ra_error = ref_hdulist[1].data.field('GAIA_RA_ERROR')\n         ref_dec_error = ref_hdulist[1].data.field('GAIA_DEC_ERROR')\n \n+        # Read astrometry from the reference catalogue\n+        ref_epoch = ref_hdulist[1].data.field('REF_EPOCH')\n+        ref_pmra = ref_hdulist[1].data.field('PMRA')\n+        ref_pmdec = ref_hdulist[1].data.field('PMDEC')\n+        ref_parallax = ref_hdulist[1].data.field('PARALLAX')\n+\n         # read the reference star mags\n         if refmagkey is not None:\n             ref_mag = ref_hdulist[1].data.field(refmagkey)\n@@ -2370,6 +2618,15 @@ def get_references(refcat,\n                 f'magnitude selection'\n             )\n \n+    # propagate positions to the correct reference frame and epoch\n+    if logger is not None:\n+        logger.info(f\"rejecting {np.count_nonzero(np.isnan(ref_parallax[mask]))} ref stars with null parallaxes\")\n+    mask[np.isnan(ref_parallax)] = False\n+    ra, dec = icrs_to_ecrf(\n+        ref_ra[mask], ref_dec[mask], ref_parallax[mask], ref_pmra[mask], ref_pmdec[mask],\n+        ref_epoch[mask], obs_epoch, pos, vel\n+    )\n+\n     # filter ref mags if not None\n     if ref_mag is not None:\n         ref_mag = ref_mag[mask]\n@@ -2385,7 +2642,7 @@ def get_references(refcat,\n \n     # create the RefData object\n     refdata = wcsfit_core.RefData(\n-        ref_ra[mask], ref_dec[mask],\n+        ra, dec,\n         ref_ra_error[mask], ref_dec_error[mask],\n         mags=ref_mag, filename=refcat\n     )\n@@ -2428,11 +2685,14 @@ def icrs_to_ecrf(ra, dec, parallax, pmra, pmdec, ref_epoch,\n     new_dec : array-like\n         Declination in the Euclid-centric reference frame at the target_epoch\n     \"\"\"\n+    # deal with negative parallaxes\n+    _parallax = np.clip(parallax, 1E-10, np.inf)\n+\n     # icrs sky coordinates at reference epoch\n     icrs0 = SkyCoord(\n         ra * u.deg, dec * u.deg,\n         pm_ra_cosdec=pmra * u.mas / u.yr, pm_dec=pmdec * u.mas / u.yr,\n-        distance=1000.0 / parallax * u.pc,\n+        distance=1000.0 / _parallax * u.pc,\n         obstime=Time(ref_epoch, format='jyear'),\n         frame='icrs'\n     )\n@@ -2449,11 +2709,11 @@ def icrs_to_ecrf(ra, dec, parallax, pmra, pmdec, ref_epoch,\n         x=vel_offset[0], y=vel_offset[1], z=vel_offset[2],\n         unit=u.km / u.s\n     )\n-    ECRF = GCRS(obstime=Time(target_time), obsgeoloc=_pos_offset, obsgeovel=_vel_offset)\n+    ECRF = GCRS(obstime=target_time, obsgeoloc=_pos_offset, obsgeovel=_vel_offset)\n     # transform coordinates to ECRF system\n     ecrf1 = icrs1.transform_to(ECRF)\n \n-    return ecrf1.ra.dec, ecrf1.dec.deg\n+    return ecrf1.ra.deg, ecrf1.dec.deg\n \n \n def run_checks(srccats=None, refcats=None,\n@@ -2803,7 +3063,7 @@ def _check_srccat(filename, logger=None):\n             try:\n                 extname = hdr['EXTNAME']\n \n-                if not re.match('CCDID [1-6]-[1-6]', extname):\n+                if not re.match('(CCDID )?[1-6]-[1-6](\\\\.[EFGH])?', extname):\n                     if logger is not None:\n                         logger.error(\n                             f'{filename}[{i}] contains a header with an '\n@@ -2913,7 +3173,7 @@ def _check_fpa_model(filename, logger=None):\n     # Check that the sections have the expected format\n     if result:\n         for section_key in config.keys():\n-            if not re.match('CCDID [1-6]-[1-6]', section_key):\n+            if not re.match('(CCDID )?[1-6]-[1-6](\\\\.[EFGH])?', section_key):\n                 if not section_key == 'GLOBAL':\n                     if logger is not None:\n                         logger.error(\n@@ -3100,7 +3360,7 @@ def _check_imgfile(filename, logger=None):\n         for i in range(1, len(hdulist)):\n             try:\n                 extname = hdulist[i].name\n-                if not re.match('CCDID [1-6]-[1-6]', extname):\n+                if not re.match('(CCDID )?[1-6]-[1-6](\\\\.[EFGH])?', extname):\n                     if logger is not None:\n                         logger.error(\n                             f'{filename}[{i}] contains a header with a '\n@@ -3311,13 +3571,12 @@ def gauss_func(x, a, x0, sigma):\n     )\n \n \n-def gauss_fit(xdat, ydat, flux_rad_min, flux_rad_max):\n+def gauss_fit(xdat, ydat, flux_rad_min, flux_rad_max, flux_rad_peak):\n     \"\"\"\n     Perform a Gaussian fit (courtesy of Sylvain Mottet)\n     \"\"\"\n     # initial parameters\n-    flux_rad_med = 0.5 * (flux_rad_min + flux_rad_max)\n-    p0 = np.array([0.5, flux_rad_med, 0.15])\n+    p0 = np.array([0.5, flux_rad_peak, 0.15])\n \n     def func(x, p00, p01, p02):\n         # composite of two Gaussian functions\n@@ -3332,8 +3591,9 @@ def gauss_fit(xdat, ydat, flux_rad_min, flux_rad_max):\n     )\n     return popt  # a, x0, sigma\n \n+\n def filter_catalogue(mag, fluxrad, mag_min=None, mag_max=None, mag_margin=0.0,\n-                     flux_rad_min=0.5, flux_rad_max=2.5,\n+                     flux_rad_min=None, flux_rad_max=None, flux_rad_peak=None,\n                      logger=None):\n     \"\"\"\n     Filter a set of sources by magnitude and flux radius\n@@ -3351,9 +3611,14 @@ def filter_catalogue(mag, fluxrad, mag_min=None, mag_max=None, mag_margin=0.0,\n     mag_margin : float, optional\n         Allowable margin for error on the magnitudes\n     flux_rad_min : float, optional\n-        Lower limit of acceptable flux_radius range, default 0.5.\n+        Lower limit of acceptable FLUX_RADIUS range for real stars.\n+        Default None, i.e. no minimum FLUX_RADIUS.\n     flux_rad_max : float, optional\n-        Upper limit of acceptable flux_radius range, default 2.5.\n+        Upper limit of acceptable FLUX_RADIUS range for real stars.\n+        Default None, i.e. no maximum FLUX_RADIUS.\n+    flux_rad_peak : float, optional\n+        The peak of the FLUX_RADIUS distribution for real stars.\n+        Default None, i.e. no FLUX_RADIUS distribution fitting.\n     logger : Logger, optional\n         A logger which will be used for printing the logging messages (None for\n         no printing).\n@@ -3376,8 +3641,10 @@ def filter_catalogue(mag, fluxrad, mag_min=None, mag_max=None, mag_margin=0.0,\n     if mag_max is not None:\n         mask[mag > (mag_max + mag_margin)] = False\n \n-    \"\"\"\n-    # Commented out: see https://euclid.roe.ac.uk/issues/23190#note-57\n+    if flux_rad_min is None:\n+        flux_rad_min = 0.0\n+    if flux_rad_max is None:\n+        flux_rad_max = np.inf\n \n     # basic fluxrad filtering\n     mask[(fluxrad < flux_rad_min) | (fluxrad > flux_rad_max)] = False\n@@ -3385,41 +3652,32 @@ def filter_catalogue(mag, fluxrad, mag_min=None, mag_max=None, mag_margin=0.0,\n     # check on current source count, can we do something fancy?\n     num_in_range = np.count_nonzero(mask)\n \n-    # some testing suggests 30 sources is enough to do something with\n-    if num_in_range >= 30:\n-        bin_count = 50\n-        # get flux radius histogram\n-        radius_count, bin_edges = np.histogram(\n-            fluxrad[mask], bins=bin_count, range=[flux_rad_min, flux_rad_max], density=True\n-        )\n-        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n+    if flux_rad_peak is not None:\n+        # some testing suggests 30 sources is enough to do something with\n+        if num_in_range >= 30:\n+            bin_count = 50\n+            # get flux radius histogram\n+            radius_count, bin_edges = np.histogram(\n+                fluxrad[mask], bins=bin_count, range=[flux_rad_min, flux_rad_max], density=True\n+            )\n+            bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n \n-        # try to fit a gaussian to the flux_radius distribution\n-        try:\n-            a, x0, sig = gauss_fit(bin_centers, radius_count, flux_rad_min, flux_rad_max)\n-            mask[np.abs(fluxrad - x0) > (5 * sig)] = False\n-\n-            # plt.hist(\n-            #     fluxrad[mask], bins=bin_edges, density=True, histtype='step'\n-            # )\n-            # xx = np.linspace(0.5, 2.5, 1000)\n-            # yy = gauss_func(xx, a, x0, sig)\n-            # plt.plot(xx, yy)\n-            # plt.gca().axvline(x0+5*sig)\n-            # plt.gca().axvline(x0-5*sig)\n-            # print(a, x0, sig)  #, a_2, x0_2, sig_2)\n-            # plt.show()\n-        except RuntimeError:\n+            # try to fit a gaussian to the flux_radius distribution\n+            try:\n+                a, x0, sig = gauss_fit(bin_centers, radius_count, flux_rad_min, flux_rad_max, flux_rad_peak)\n+                mask[np.abs(fluxrad - x0) > (5 * sig)] = False\n+            except RuntimeError:\n+                if logger is not None:\n+                    logger.info(\n+                        f\"flux_radius distribution fitting was unsuccessful\"\n+                    )\n+        else:\n             if logger is not None:\n                 logger.info(\n-                    f\"flux_radius distribution fitting was unsuccessful\"\n+                    f\"too few sources to attempt flux_radius distribution fitting\"\n                 )\n-    else:\n-        if logger is not None:\n-            logger.info(\n-                f\"too few sources to attempt flux_radius distribution fitting\"\n-            )\n-    \"\"\"\n+    elif logger is not None:\n+        logger.debug(\"flux_radius fitting not performed\")\n \n     return mask\n \n",
                            "Merge branch 'hotfix/wcsfit-latest' into 'release-13.0': [FIX]#23453 Velocity aberration",
                            "Catherine Grenet",
                            "2023-08-22T13:27:01.000+00:00",
                            "01ffa5761a241a058ab54fad1f6d060636dd3e30"
                        ],
                        [
                            "@@ -507,12 +507,15 @@ def runwcsfit(args, logger=None):\n \n         # plot the plate scale if requested\n         if args.make_plots is not None:\n-            id_string = os.path.basename(args.output_fpa_model)\n-            plot_plate_scale(\n-                fpa_model, args.make_plots,\n-                alt_fpa_model=args.init_fpa_model,\n-                file_identifier_string=id_string\n-            )\n+            try:\n+                id_string = os.path.basename(args.output_fpa_model)\n+                plot_plate_scale(\n+                    fpa_model, args.make_plots,\n+                    alt_fpa_model=args.init_fpa_model,\n+                    file_identifier_string=id_string\n+                )\n+            except Exception as e:\n+                logger.error(f\"!!! caught exception '{e}' in wcsfit make_plots, ignoring....\")\n \n     elif args.mode == 'use-fpa-model':\n \n@@ -590,10 +593,13 @@ def runwcsfit(args, logger=None):\n \n     # Produce plots if requested\n     if args.make_plots is not None:\n-        plot_sausages(obsdataset, args.make_plots)\n-        plot_vpds(obsdataset, args.make_plots)\n-        plot_residuals(obsdataset, args.make_plots)\n-        plot_local_mean_residual(obsdataset, fpa_model, args.make_plots)\n+        try:\n+            plot_sausages(obsdataset, args.make_plots)\n+            plot_vpds(obsdataset, args.make_plots)\n+            plot_residuals(obsdataset, args.make_plots)\n+            plot_local_mean_residual(obsdataset, fpa_model, args.make_plots)\n+        except Exception as e:\n+            logger.error(f\"!!! caught exception '{e}' in wcsfit make_plots, ignoring....\")\n \n     # store the tables of reference source matches if requested\n     if args.matchcat is not None:\n",
                            "mirror try/except around make plots",
                            "Leigh Smith",
                            "2023-08-21T16:01:04.000+01:00",
                            "8271d73b0acc9355e6ca7ad1802bf166fa572fe6"
                        ],
                        [
                            "@@ -507,12 +507,15 @@ def runwcsfit(args, logger=None):\n \n         # plot the plate scale if requested\n         if args.make_plots is not None:\n-            id_string = os.path.basename(args.output_fpa_model)\n-            plot_plate_scale(\n-                fpa_model, args.make_plots,\n-                alt_fpa_model=args.init_fpa_model,\n-                file_identifier_string=id_string\n-            )\n+            try:\n+                id_string = os.path.basename(args.output_fpa_model)\n+                plot_plate_scale(\n+                    fpa_model, args.make_plots,\n+                    alt_fpa_model=args.init_fpa_model,\n+                    file_identifier_string=id_string\n+                )\n+            except Exception as e:\n+                logger.error(f\"!!! caught exception '{e}' in wcsfit make_plots, ignoring....\")\n \n     elif args.mode == 'use-fpa-model':\n \n@@ -590,10 +593,13 @@ def runwcsfit(args, logger=None):\n \n     # Produce plots if requested\n     if args.make_plots is not None:\n-        plot_sausages(obsdataset, args.make_plots)\n-        plot_vpds(obsdataset, args.make_plots)\n-        plot_residuals(obsdataset, args.make_plots)\n-        plot_local_mean_residual(obsdataset, fpa_model, args.make_plots)\n+        try:\n+            plot_sausages(obsdataset, args.make_plots)\n+            plot_vpds(obsdataset, args.make_plots)\n+            plot_residuals(obsdataset, args.make_plots)\n+            plot_local_mean_residual(obsdataset, fpa_model, args.make_plots)\n+        except Exception as e:\n+            logger.error(f\"!!! caught exception '{e}' in wcsfit make_plots, ignoring....\")\n \n     # store the tables of reference source matches if requested\n     if args.matchcat is not None:\n",
                            "try around making plots",
                            "Leigh Smith",
                            "2023-08-21T15:41:01.000+01:00",
                            "b1120fa82ac8c5307e76b00bb15da905c72ec95d"
                        ],
                        [
                            "@@ -42,7 +42,7 @@ import sys\n import numpy as np\n from astropy import wcs\n from astropy.io import fits\n-from astropy.coordinates import SkyCoord, GCRS, CartesianRepresentation\n+from astropy.coordinates import SkyCoord, GCRS, ICRS, CartesianRepresentation\n import astropy.units as u\n from astropy.time import Time\n from configobj import ConfigObj\n@@ -50,6 +50,7 @@ import itertools\n import matplotlib.pyplot as plt\n import matplotlib.colors\n from scipy.spatial.distance import cdist\n+from scipy.optimize import least_squares\n \n from . import wcsfit_core\n from .sip_tpv import sip_to_pv\n@@ -218,6 +219,18 @@ def get_parser():\n         '--refmagmax', type=float, default=None, metavar='MAX_MAG',\n         help='maximum reference star magnitude (default: no limit)'\n     )\n+    ref_opt_args_group.add_argument(\n+        '--flux-rad-min', type=float, default=None, metavar='FLUX_RADIUS',\n+        help='Lower limit on reference star FLUX_RADIUS'\n+    )\n+    ref_opt_args_group.add_argument(\n+        '--flux-rad-max', type=float, default=None, metavar='FLUX_RADIUS',\n+        help='Upper limit on reference star FLUX_RADIUS'\n+    )\n+    ref_opt_args_group.add_argument(\n+        '--flux-rad-peak', type=float, default=None, metavar='FLUX_RADIUS',\n+        help='Approximate reference star FLUX_RADIUS distribution peak'\n+    )\n \n     # minimiser termination optional arguments\n     term_opt_args_group = parser.add_argument_group(\n@@ -325,6 +338,16 @@ def check_cmdargs(_args):\n         plural = '' if len(mag_lims) > 1 else 's'\n         parser.error(' and '.join(mag_lims) + f' require{plural} --refmagcol')\n \n+    # check that the FLUX_RADIUS related arguments are sensible\n+    if _args.flux_rad_min is not None and _args.flux_rad_max is not None:\n+        if _args.flux_rad_min >= _args.flux_rad_max:\n+            parser.error(\"FLUX_RADIUS minimum must be smaller than FLUX_RADIUS maximum\")\n+        if _args.flux_rad_peak is not None:\n+            if _args.flux_rad_peak <= _args.flux_rad_min:\n+                parser.error(\"FLUX_RADIUS peak must be larger than FLUX_RADIUS minimum\")\n+            if _args.flux_rad_peak >= _args.flux_rad_max:\n+                parser.error(\"FLUX_RADIUS peak must be smaller than FLUX_RADIUS maximum\")\n+\n     # check that the number of minimiser iterations is greater than zero\n     if not _args.niter > 0:\n         parser.error('--niter must be >0')\n@@ -444,6 +467,9 @@ def runwcsfit(args, logger=None):\n         refmagkey=args.refmagcol,\n         refmagmin=args.refmagmin,\n         refmagmax=args.refmagmax,\n+        flux_rad_min=args.flux_rad_min,\n+        flux_rad_max=args.flux_rad_max,\n+        flux_rad_peak=args.flux_rad_peak,\n         logger=logger\n     )\n \n@@ -1203,6 +1229,21 @@ def copy_wcs_to_file(source_observation, target_file, fpamodel=None):\n               sip_to_pv(src_hdr)\n             replace_header_wcs(src_hdr, dest_hdr)\n \n+            # record the original pointing and position angle\n+            dest_hdr['RA_COMM'] = (\n+                source_observation.commanded_pointing[0],\n+                'commanding pointing RA'\n+            )\n+            dest_hdr['DEC_COMM'] = (\n+                source_observation.commanded_pointing[1],\n+                'commanding pointing DEC'\n+            )\n+            dest_hdr['PA_COMM'] = (\n+                source_observation.commanded_pa,\n+                'commanding position angle'\n+            )\n+\n+            # todo consider the reference frame\n             # add the reconstructed pointing\n             dest_hdr['RA'] = (\n                 source_observation.pointing[0],\n@@ -1288,6 +1329,144 @@ def use_fpa_model(\n         logger=logger\n     )\n \n+    # ecrf to icrs\n+    ecrf_to_icrs(observation, logger=logger)\n+\n+\n+def ecrf_to_icrs(observation, num_cps_per_axis=100, logger=None):\n+    \"\"\"\n+    Take the WCS information from the observation, which maps array\n+    coordinates to the ECRF, and map it from array coords to the ICRS\n+\n+    Parameters\n+    ----------\n+    observation : wcsfit_core.Observation\n+        The observation containing the base WCS\n+    num_cps_per_axis : int, optional\n+        The number of control points to use per axis, default 100.\n+    logger : Logger, optional\n+        A Logger for logging messages (None for no logging, default).\n+    \"\"\"\n+    for ext, ccd in observation.ccds.items():\n+        if logger is not None:\n+            logger.debug(f\"Transforming {ext} WCS from ECRF to ICRS\")\n+\n+        # read the header\n+        orig_hdr = ccd.header.copy()\n+\n+        # generate the control point grid\n+        xy = np.meshgrid(np.linspace(1, orig_hdr[\"NAXIS1\"], num_cps_per_axis),\n+                         np.linspace(1, orig_hdr[\"NAXIS2\"], num_cps_per_axis))\n+        x, y = map(lambda arr: arr.flatten(), xy)\n+\n+        # define the Euclid-centric reference frame\n+        _pos_offset = CartesianRepresentation(\n+            x=observation.pos_offset[0],\n+            y=observation.pos_offset[1],\n+            z=observation.pos_offset[2],\n+            unit=u.km\n+        )\n+        _vel_offset = CartesianRepresentation(\n+            x=observation.vel_offset[0],\n+            y=observation.vel_offset[1],\n+            z=observation.vel_offset[2],\n+            unit=u.km / u.s\n+        )\n+        _obs_time = Time(observation.ref_epoch, format='jyear')\n+        ECRF = GCRS(obstime=_obs_time, obsgeoloc=_pos_offset, obsgeovel=_vel_offset)\n+\n+        # project array coords to ecrf\n+        ecrf_a, ecrf_d = wcs.WCS(orig_hdr).all_pix2world(x, y, 1)\n+        ecrf_sc = SkyCoord(ecrf_a, ecrf_d, frame=ECRF, unit='deg')\n+\n+        # transform to ICRS\n+        icrs_sc = ecrf_sc.transform_to(ICRS)\n+        # must do this otherwise astropy thinks they aren't the same frame\n+        icrs_sc = SkyCoord(icrs_sc.ra.deg, icrs_sc.dec.deg, frame='icrs', unit='deg')\n+\n+        # transform reference star coords back to ICRS\n+        ref_sc_ecrf = SkyCoord(\n+            ccd.ra[ccd.has_sky_coord], ccd.dec[ccd.has_sky_coord], frame=ECRF, unit='deg'\n+        )\n+        ref_sc_icrs = ref_sc_ecrf.transform_to(ICRS)\n+        ccd.ra[ccd.has_sky_coord] = ref_sc_icrs.ra.deg\n+        ccd.dec[ccd.has_sky_coord] = ref_sc_icrs.dec.deg\n+        ccd.update_skycoord_obj()\n+\n+        # compute the new WCS\n+        orig_crvals = np.array([orig_hdr['CRVAL1'], orig_hdr['CRVAL2']])\n+        orig_cdmtx = wcsfit_core.get_cd(orig_hdr).flatten()\n+        orig_sip = wcsfit_core.get_sip_coeffs(orig_hdr)\n+        # starting parameters\n+        p0 = np.concatenate((orig_crvals, orig_cdmtx, orig_sip))\n+\n+        # temporary header\n+        tmp_hdr = orig_hdr.copy()\n+\n+        def min_func(parameters):\n+            # extract the linear terms\n+            _crvals = parameters[:2]\n+            _cd_mtx = parameters[2:6].reshape(2, 2)\n+            _sip_coeffs = parameters[6:]\n+\n+            # send the linear terms to the header\n+            for i in range(1, 3):\n+                tmp_hdr[f'CRVAL{i}'] = _crvals[i - 1]\n+                for j in range(1, 3):\n+                    tmp_hdr[f'CD{i}_{j}'] = _cd_mtx[i - 1, j - 1]\n+\n+            # send the distortion model to the header\n+            k = 0\n+            for dim in 'AB':\n+                order = tmp_hdr[f'{dim}_ORDER']\n+                for p in range(order + 1):\n+                    for q in range(order + 1):\n+                        if 2 <= p + q <= order:\n+                            tmp_hdr[f'{dim}_{p}_{q}'] = _sip_coeffs[k]\n+                            k += 1\n+\n+            # generate the WCS object\n+            tmp_wcs = wcs.WCS(tmp_hdr)\n+\n+            # evaluate the positions of the control points\n+            _ra, _dec = tmp_wcs.all_pix2world(x, y, 1)\n+            _sc = SkyCoord(_ra, _dec, frame='icrs', unit='deg')\n+\n+            # calculate separations between true and predicted positions\n+            dra, ddec = icrs_sc.spherical_offsets_to(_sc)\n+            # convert to milliarcsec\n+            dra, ddec = dra.arcsec * 1000, ddec.arcsec * 1000\n+\n+            # return the flattened residuals\n+            return np.concatenate((dra, ddec)).flatten()\n+\n+        # set bounds\n+        ubounds = np.full_like(p0, np.inf)\n+        lbounds = np.full_like(p0, -np.inf)\n+        lbounds[0] = np.clip(orig_crvals[0] - 5, 0.0, 360.)  # don't allow ra to go crazy\n+        ubounds[0] = np.clip(orig_crvals[0] + 5, 0.0, 360.)\n+        lbounds[1] = np.clip(orig_crvals[1] - 5, -90.0, 90.0)  # don't allow dec to go crazy\n+        ubounds[1] = np.clip(orig_crvals[1] + 5, -90.0, 90.0)\n+\n+        # run the minimizer\n+        solution = least_squares(\n+            min_func, p0, bounds=(lbounds, ubounds), x_scale='jac', jac='3-point'\n+        )\n+\n+        # set the resultant values and get the header\n+        abs_residuals = np.abs(min_func(solution.x))\n+        if logger is not None:\n+            logger.debug(f\"mean, max residual = \"\n+                         f\"{abs_residuals.mean():.2e}, \"\n+                         f\"{abs_residuals.max():.2e} (mas)\")\n+\n+        # send the header to the CCD object\n+        ccd.header = tmp_hdr.copy()\n+        ccd.wcs = wcs.WCS(ccd.header)\n+\n+\n+\n+\n \n def fit_fpa_model(\n         obsdataset,\n@@ -1596,6 +1775,7 @@ def fpa_model_from_observation(observation, sip_order, logger=None):\n def read_observations_references(\n         source_catalogues, reference_catalogues,\n         refmagkey=None, refmagmin=None, refmagmax=None,\n+        flux_rad_min=None, flux_rad_max=None, flux_rad_peak=None,\n         logger=None\n ):\n     \"\"\"\n@@ -1616,6 +1796,15 @@ def read_observations_references(\n     refmagmax : float, optional\n         Maximum magnitude of the reference stars used from refcat (None for\n         no maximum limit).\n+    flux_rad_min : float, optional\n+        Lower limit of acceptable FLUX_RADIUS range for real stars.\n+        Default None, i.e. no minimum FLUX_RADIUS.\n+    flux_rad_max : float, optional\n+        Upper limit of acceptable FLUX_RADIUS range for real stars.\n+        Default None, i.e. no maximum FLUX_RADIUS.\n+    flux_rad_peak : float, optional\n+        The peak of the FLUX_RADIUS distribution for real stars.\n+        Default None, i.e. no FLUX_RADIUS distribution fitting.\n     logger : Logger, optional\n         A Logger for logging messages (None for no logging, default).\n \n@@ -1638,9 +1827,23 @@ def read_observations_references(\n             source_catalogues, reference_catalogues,\n             fillvalue=reference_catalogues[0]\n     ):\n+\n+        # grab data from the observation primary header\n+        pri_hdr = fits.getheader(src_cat_path, 0)\n+        # date of the vis observation\n+        mjdobs = pri_hdr['MJD-OBS']\n+        obs_epoch = Time(mjdobs, format='mjd').jyear\n+        # position of the instrument\n+        pos = tuple([pri_hdr[f\"POS_{elem}\"] for elem in \"XYZ\"])\n+        # velocity of the instrument\n+        vel = tuple([pri_hdr[f\"VEL_{elem}\"] for elem in \"XYZ\"])\n+\n         # read the reference catalogue\n         refdata = get_references(\n             ref_cat_path,\n+            obs_epoch,\n+            pos,\n+            vel,\n             refmagkey=refmagkey,\n             refmagmin=refmagmin,\n             refmagmax=refmagmax,\n@@ -1650,7 +1853,8 @@ def read_observations_references(\n         observations.append(get_observation(\n             src_cat_path, refdata,\n             refmagmin=refmagmin, refmagmax=refmagmax,\n-            logger=logger\n+            flux_rad_min=flux_rad_min, flux_rad_max=flux_rad_max,\n+            flux_rad_peak=flux_rad_peak, logger=logger\n         ))\n \n     # return an ObservationSet instance\n@@ -2116,6 +2320,7 @@ def is_an_astrometric_kwd(kwd, include_naxis=False):\n \n \n def get_observation(src_cat_path, refdata, refmagmin=None, refmagmax=None,\n+                    flux_rad_min=None, flux_rad_max=None, flux_rad_peak=None,\n                     logger=None):\n     \"\"\"\n     Grab data and headers from the catalogue of the relevant observation.\n@@ -2134,6 +2339,18 @@ def get_observation(src_cat_path, refdata, refmagmin=None, refmagmax=None,\n     refmagmax : float, optional\n         Maximum magnitude of the reference stars used from refcat (None for\n         no maximum limit).\n+    flux_rad_min : float, optional\n+        Lower limit of acceptable FLUX_RADIUS range for real stars.\n+        Default None, i.e. no minimum FLUX_RADIUS.\n+    flux_rad_max : float, optional\n+        Upper limit of acceptable FLUX_RADIUS range for real stars.\n+        Default None, i.e. no maximum FLUX_RADIUS.\n+    flux_rad_peak : float, optional\n+        The peak of the FLUX_RADIUS distribution for real stars.\n+        Default None, i.e. no FLUX_RADIUS distribution fitting.\n+    logger : Logger, optional\n+        A logger which will be used for printing the logging messages (None for\n+        no printing).\n \n     Returns\n     -------\n@@ -2157,6 +2374,14 @@ def get_observation(src_cat_path, refdata, refmagmin=None, refmagmax=None,\n         # grab the primary header\n         pri_hdr = srccat_hdul[0].header\n \n+        # date of the vis observation\n+        mjdobs = pri_hdr['MJD-OBS']\n+        obs_epoch = Time(mjdobs, format='mjd').jyear\n+        # position of the instrument\n+        pos_vec = tuple([pri_hdr[f\"POS_{elem}\"] for elem in \"XYZ\"])\n+        # velocity of the instrument\n+        vel_vec = tuple([pri_hdr[f\"VEL_{elem}\"] for elem in \"XYZ\"])\n+\n         # record the primary header exptime if present\n         if 'EXPTIME' in pri_hdr.keys():\n             exptimes.append(float(pri_hdr['EXPTIME']))\n@@ -2218,8 +2443,8 @@ def get_observation(src_cat_path, refdata, refmagmin=None, refmagmax=None,\n             _mask = filter_catalogue(\n                 mags, fluxrad,\n                 mag_min=refmagmin, mag_max=refmagmax, mag_margin=0.5,\n-                flux_rad_min=2.0, flux_rad_max=4.0,\n-                logger=logger\n+                flux_rad_min=flux_rad_min, flux_rad_max=flux_rad_max,\n+                flux_rad_peak=flux_rad_peak, logger=logger\n             )\n \n             # require no large sextractor error flags\n@@ -2278,13 +2503,18 @@ def get_observation(src_cat_path, refdata, refmagmin=None, refmagmax=None,\n     # build an Observation object instance from the list of ccds\n     observation = wcsfit_core.Observation(\n         ccd_list, refdata, pointings[0], pas[0], exptimes[0],\n+        ref_epoch=obs_epoch, pos_offset=pos_vec, vel_offset=vel_vec,\n         filename=src_cat_path, header=pri_hdr\n     )\n \n+    # record the commanded pointing and position angle\n+    observation.commanded_pointing = pointings[0]\n+    observation.commanded_pa = pas[0]\n+\n     return observation\n \n \n-def get_references(refcat,\n+def get_references(refcat, obs_epoch, pos, vel,\n                    refmagkey=None, refmagmin=None, refmagmax=None,\n                    logger=None):\n     \"\"\"\n@@ -2294,6 +2524,12 @@ def get_references(refcat,\n     ----------\n     refcat : str\n         A FITS file with catalogue of position reference stars.\n+    obs_epoch : float\n+        Julian year of observation.\n+    pos : tuple\n+        Geocentric position vector of the instrument.\n+    vel : tuple\n+        Geocentric velocity vector of the instrument.\n     refmagkey : str, optional\n         Name of the column which contains the catalogue magnitudes.\n     refmagmin : float, optional\n@@ -2320,6 +2556,12 @@ def get_references(refcat,\n         ref_ra_error = ref_hdulist[1].data.field('GAIA_RA_ERROR')\n         ref_dec_error = ref_hdulist[1].data.field('GAIA_DEC_ERROR')\n \n+        # Read astrometry from the reference catalogue\n+        ref_epoch = ref_hdulist[1].data.field('REF_EPOCH')\n+        ref_pmra = ref_hdulist[1].data.field('PMRA')\n+        ref_pmdec = ref_hdulist[1].data.field('PMDEC')\n+        ref_parallax = ref_hdulist[1].data.field('PARALLAX')\n+\n         # read the reference star mags\n         if refmagkey is not None:\n             ref_mag = ref_hdulist[1].data.field(refmagkey)\n@@ -2370,6 +2612,15 @@ def get_references(refcat,\n                 f'magnitude selection'\n             )\n \n+    # propagate positions to the correct reference frame and epoch\n+    if logger is not None:\n+        logger.info(f\"rejecting {np.count_nonzero(np.isnan(ref_parallax[mask]))} ref stars with null parallaxes\")\n+    mask[np.isnan(ref_parallax)] = False\n+    ra, dec = icrs_to_ecrf(\n+        ref_ra[mask], ref_dec[mask], ref_parallax[mask], ref_pmra[mask], ref_pmdec[mask],\n+        ref_epoch[mask], obs_epoch, pos, vel\n+    )\n+\n     # filter ref mags if not None\n     if ref_mag is not None:\n         ref_mag = ref_mag[mask]\n@@ -2385,7 +2636,7 @@ def get_references(refcat,\n \n     # create the RefData object\n     refdata = wcsfit_core.RefData(\n-        ref_ra[mask], ref_dec[mask],\n+        ra, dec,\n         ref_ra_error[mask], ref_dec_error[mask],\n         mags=ref_mag, filename=refcat\n     )\n@@ -2428,11 +2679,14 @@ def icrs_to_ecrf(ra, dec, parallax, pmra, pmdec, ref_epoch,\n     new_dec : array-like\n         Declination in the Euclid-centric reference frame at the target_epoch\n     \"\"\"\n+    # deal with negative parallaxes\n+    _parallax = np.clip(parallax, 1E-10, np.inf)\n+\n     # icrs sky coordinates at reference epoch\n     icrs0 = SkyCoord(\n         ra * u.deg, dec * u.deg,\n         pm_ra_cosdec=pmra * u.mas / u.yr, pm_dec=pmdec * u.mas / u.yr,\n-        distance=1000.0 / parallax * u.pc,\n+        distance=1000.0 / _parallax * u.pc,\n         obstime=Time(ref_epoch, format='jyear'),\n         frame='icrs'\n     )\n@@ -2449,11 +2703,11 @@ def icrs_to_ecrf(ra, dec, parallax, pmra, pmdec, ref_epoch,\n         x=vel_offset[0], y=vel_offset[1], z=vel_offset[2],\n         unit=u.km / u.s\n     )\n-    ECRF = GCRS(obstime=Time(target_time), obsgeoloc=_pos_offset, obsgeovel=_vel_offset)\n+    ECRF = GCRS(obstime=target_time, obsgeoloc=_pos_offset, obsgeovel=_vel_offset)\n     # transform coordinates to ECRF system\n     ecrf1 = icrs1.transform_to(ECRF)\n \n-    return ecrf1.ra.dec, ecrf1.dec.deg\n+    return ecrf1.ra.deg, ecrf1.dec.deg\n \n \n def run_checks(srccats=None, refcats=None,\n@@ -2803,7 +3057,7 @@ def _check_srccat(filename, logger=None):\n             try:\n                 extname = hdr['EXTNAME']\n \n-                if not re.match('CCDID [1-6]-[1-6]', extname):\n+                if not re.match('(CCDID )?[1-6]-[1-6](\\\\.[EFGH])?', extname):\n                     if logger is not None:\n                         logger.error(\n                             f'{filename}[{i}] contains a header with an '\n@@ -2913,7 +3167,7 @@ def _check_fpa_model(filename, logger=None):\n     # Check that the sections have the expected format\n     if result:\n         for section_key in config.keys():\n-            if not re.match('CCDID [1-6]-[1-6]', section_key):\n+            if not re.match('(CCDID )?[1-6]-[1-6](\\\\.[EFGH])?', section_key):\n                 if not section_key == 'GLOBAL':\n                     if logger is not None:\n                         logger.error(\n@@ -3100,7 +3354,7 @@ def _check_imgfile(filename, logger=None):\n         for i in range(1, len(hdulist)):\n             try:\n                 extname = hdulist[i].name\n-                if not re.match('CCDID [1-6]-[1-6]', extname):\n+                if not re.match('(CCDID )?[1-6]-[1-6](\\\\.[EFGH])?', extname):\n                     if logger is not None:\n                         logger.error(\n                             f'{filename}[{i}] contains a header with a '\n@@ -3311,13 +3565,12 @@ def gauss_func(x, a, x0, sigma):\n     )\n \n \n-def gauss_fit(xdat, ydat, flux_rad_min, flux_rad_max):\n+def gauss_fit(xdat, ydat, flux_rad_min, flux_rad_max, flux_rad_peak):\n     \"\"\"\n     Perform a Gaussian fit (courtesy of Sylvain Mottet)\n     \"\"\"\n     # initial parameters\n-    flux_rad_med = 0.5 * (flux_rad_min + flux_rad_max)\n-    p0 = np.array([0.5, flux_rad_med, 0.15])\n+    p0 = np.array([0.5, flux_rad_peak, 0.15])\n \n     def func(x, p00, p01, p02):\n         # composite of two Gaussian functions\n@@ -3332,8 +3585,9 @@ def gauss_fit(xdat, ydat, flux_rad_min, flux_rad_max):\n     )\n     return popt  # a, x0, sigma\n \n+\n def filter_catalogue(mag, fluxrad, mag_min=None, mag_max=None, mag_margin=0.0,\n-                     flux_rad_min=0.5, flux_rad_max=2.5,\n+                     flux_rad_min=None, flux_rad_max=None, flux_rad_peak=None,\n                      logger=None):\n     \"\"\"\n     Filter a set of sources by magnitude and flux radius\n@@ -3351,9 +3605,14 @@ def filter_catalogue(mag, fluxrad, mag_min=None, mag_max=None, mag_margin=0.0,\n     mag_margin : float, optional\n         Allowable margin for error on the magnitudes\n     flux_rad_min : float, optional\n-        Lower limit of acceptable flux_radius range, default 0.5.\n+        Lower limit of acceptable FLUX_RADIUS range for real stars.\n+        Default None, i.e. no minimum FLUX_RADIUS.\n     flux_rad_max : float, optional\n-        Upper limit of acceptable flux_radius range, default 2.5.\n+        Upper limit of acceptable FLUX_RADIUS range for real stars.\n+        Default None, i.e. no maximum FLUX_RADIUS.\n+    flux_rad_peak : float, optional\n+        The peak of the FLUX_RADIUS distribution for real stars.\n+        Default None, i.e. no FLUX_RADIUS distribution fitting.\n     logger : Logger, optional\n         A logger which will be used for printing the logging messages (None for\n         no printing).\n@@ -3376,8 +3635,10 @@ def filter_catalogue(mag, fluxrad, mag_min=None, mag_max=None, mag_margin=0.0,\n     if mag_max is not None:\n         mask[mag > (mag_max + mag_margin)] = False\n \n-    \"\"\"\n-    # Commented out: see https://euclid.roe.ac.uk/issues/23190#note-57\n+    if flux_rad_min is None:\n+        flux_rad_min = 0.0\n+    if flux_rad_max is None:\n+        flux_rad_max = np.inf\n \n     # basic fluxrad filtering\n     mask[(fluxrad < flux_rad_min) | (fluxrad > flux_rad_max)] = False\n@@ -3385,41 +3646,32 @@ def filter_catalogue(mag, fluxrad, mag_min=None, mag_max=None, mag_margin=0.0,\n     # check on current source count, can we do something fancy?\n     num_in_range = np.count_nonzero(mask)\n \n-    # some testing suggests 30 sources is enough to do something with\n-    if num_in_range >= 30:\n-        bin_count = 50\n-        # get flux radius histogram\n-        radius_count, bin_edges = np.histogram(\n-            fluxrad[mask], bins=bin_count, range=[flux_rad_min, flux_rad_max], density=True\n-        )\n-        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n+    if flux_rad_peak is not None:\n+        # some testing suggests 30 sources is enough to do something with\n+        if num_in_range >= 30:\n+            bin_count = 50\n+            # get flux radius histogram\n+            radius_count, bin_edges = np.histogram(\n+                fluxrad[mask], bins=bin_count, range=[flux_rad_min, flux_rad_max], density=True\n+            )\n+            bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n \n-        # try to fit a gaussian to the flux_radius distribution\n-        try:\n-            a, x0, sig = gauss_fit(bin_centers, radius_count, flux_rad_min, flux_rad_max)\n-            mask[np.abs(fluxrad - x0) > (5 * sig)] = False\n-\n-            # plt.hist(\n-            #     fluxrad[mask], bins=bin_edges, density=True, histtype='step'\n-            # )\n-            # xx = np.linspace(0.5, 2.5, 1000)\n-            # yy = gauss_func(xx, a, x0, sig)\n-            # plt.plot(xx, yy)\n-            # plt.gca().axvline(x0+5*sig)\n-            # plt.gca().axvline(x0-5*sig)\n-            # print(a, x0, sig)  #, a_2, x0_2, sig_2)\n-            # plt.show()\n-        except RuntimeError:\n+            # try to fit a gaussian to the flux_radius distribution\n+            try:\n+                a, x0, sig = gauss_fit(bin_centers, radius_count, flux_rad_min, flux_rad_max, flux_rad_peak)\n+                mask[np.abs(fluxrad - x0) > (5 * sig)] = False\n+            except RuntimeError:\n+                if logger is not None:\n+                    logger.info(\n+                        f\"flux_radius distribution fitting was unsuccessful\"\n+                    )\n+        else:\n             if logger is not None:\n                 logger.info(\n-                    f\"flux_radius distribution fitting was unsuccessful\"\n+                    f\"too few sources to attempt flux_radius distribution fitting\"\n                 )\n-    else:\n-        if logger is not None:\n-            logger.info(\n-                f\"too few sources to attempt flux_radius distribution fitting\"\n-            )\n-    \"\"\"\n+    elif logger is not None:\n+        logger.debug(\"flux_radius fitting not performed\")\n \n     return mask\n \n",
                            "update wcsfit with latest dev work",
                            "Leigh Smith",
                            "2023-08-21T14:55:14.000+01:00",
                            "842e2347473753f0ed3ffdde1bda24e4d736b04f"
                        ],
                        [
                            "@@ -3167,7 +3167,7 @@ def _check_fpa_model(filename, logger=None):\n     # Check that the sections have the expected format\n     if result:\n         for section_key in config.keys():\n-            if not re.match('CCDID [1-6]-[1-6]', section_key):\n+            if not re.match('(CCDID )?[1-6]-[1-6](\\\\.[EFGH])?', section_key):\n                 if not section_key == 'GLOBAL':\n                     if logger is not None:\n                         logger.error(\n@@ -3354,7 +3354,7 @@ def _check_imgfile(filename, logger=None):\n         for i in range(1, len(hdulist)):\n             try:\n                 extname = hdulist[i].name\n-                if not re.match('CCDID [1-6]-[1-6]', extname):\n+                if not re.match('(CCDID )?[1-6]-[1-6](\\\\.[EFGH])?', extname):\n                     if logger is not None:\n                         logger.error(\n                             f'{filename}[{i}] contains a header with a '\n",
                            "more extname is quadrant-agnostic #23456",
                            "Leigh Smith",
                            "2023-08-21T11:47:46.000+01:00",
                            "c10402d2fe47d04cb6393cf0d8423219a92147cd"
                        ],
                        [
                            "@@ -3057,7 +3057,7 @@ def _check_srccat(filename, logger=None):\n             try:\n                 extname = hdr['EXTNAME']\n \n-                if not re.match('CCDID [1-6]-[1-6]', extname):\n+                if not re.match('(CCDID )?[1-6]-[1-6](\\\\.[EFGH])?', extname):\n                     if logger is not None:\n                         logger.error(\n                             f'{filename}[{i}] contains a header with an '\n",
                            "extname is quadrant-agnostic #23456",
                            "Leigh Smith",
                            "2023-08-21T11:45:45.000+01:00",
                            "958eee16b65230c3e189d2128a51f6f361810cd5"
                        ],
                        [
                            "@@ -1229,6 +1229,21 @@ def copy_wcs_to_file(source_observation, target_file, fpamodel=None):\n               sip_to_pv(src_hdr)\n             replace_header_wcs(src_hdr, dest_hdr)\n \n+            # record the original pointing and position angle\n+            dest_hdr['RA_COMM'] = (\n+                source_observation.commanded_pointing[0],\n+                'commanding pointing RA'\n+            )\n+            dest_hdr['DEC_COMM'] = (\n+                source_observation.commanded_pointing[1],\n+                'commanding pointing DEC'\n+            )\n+            dest_hdr['PA_COMM'] = (\n+                source_observation.commanded_pa,\n+                'commanding position angle'\n+            )\n+\n+            # todo consider the reference frame\n             # add the reconstructed pointing\n             dest_hdr['RA'] = (\n                 source_observation.pointing[0],\n@@ -2492,6 +2507,10 @@ def get_observation(src_cat_path, refdata, refmagmin=None, refmagmax=None,\n         filename=src_cat_path, header=pri_hdr\n     )\n \n+    # record the commanded pointing and position angle\n+    observation.commanded_pointing = pointings[0]\n+    observation.commanded_pa = pas[0]\n+\n     return observation\n \n \n",
                            "record commanded pointing",
                            "Leigh Smith",
                            "2023-08-17T14:29:11.000+01:00",
                            "48eb31e3e7d63f32a33b7de4e4753c9bdf70d64c"
                        ],
                        [
                            "@@ -1439,9 +1439,11 @@ def ecrf_to_icrs(observation, num_cps_per_axis=100, logger=None):\n         )\n \n         # set the resultant values and get the header\n-        residuals = min_func(solution.x)\n+        abs_residuals = np.abs(min_func(solution.x))\n         if logger is not None:\n-            logger.debug(f\"mean, max residual = {residuals.mean():.2e}, {residuals.max():.2e} (mas)\")\n+            logger.debug(f\"mean, max residual = \"\n+                         f\"{abs_residuals.mean():.2e}, \"\n+                         f\"{abs_residuals.max():.2e} (mas)\")\n \n         # send the header to the CCD object\n         ccd.header = tmp_hdr.copy()\n",
                            "should use abs(residuals) really",
                            "Leigh Smith",
                            "2023-08-15T15:48:40.000+01:00",
                            "c5dcbde6471cbba59dd0ab322e0a43504a4706c1"
                        ],
                        [
                            "@@ -42,7 +42,7 @@ import sys\n import numpy as np\n from astropy import wcs\n from astropy.io import fits\n-from astropy.coordinates import SkyCoord, GCRS, CartesianRepresentation\n+from astropy.coordinates import SkyCoord, GCRS, ICRS, CartesianRepresentation\n import astropy.units as u\n from astropy.time import Time\n from configobj import ConfigObj\n@@ -50,6 +50,7 @@ import itertools\n import matplotlib.pyplot as plt\n import matplotlib.colors\n from scipy.spatial.distance import cdist\n+from scipy.optimize import least_squares\n \n from . import wcsfit_core\n from .sip_tpv import sip_to_pv\n@@ -1313,6 +1314,142 @@ def use_fpa_model(\n         logger=logger\n     )\n \n+    # ecrf to icrs\n+    ecrf_to_icrs(observation, logger=logger)\n+\n+\n+def ecrf_to_icrs(observation, num_cps_per_axis=100, logger=None):\n+    \"\"\"\n+    Take the WCS information from the observation, which maps array\n+    coordinates to the ECRF, and map it from array coords to the ICRS\n+\n+    Parameters\n+    ----------\n+    observation : wcsfit_core.Observation\n+        The observation containing the base WCS\n+    num_cps_per_axis : int, optional\n+        The number of control points to use per axis, default 100.\n+    logger : Logger, optional\n+        A Logger for logging messages (None for no logging, default).\n+    \"\"\"\n+    for ext, ccd in observation.ccds.items():\n+        if logger is not None:\n+            logger.debug(f\"Transforming {ext} WCS from ECRF to ICRS\")\n+\n+        # read the header\n+        orig_hdr = ccd.header.copy()\n+\n+        # generate the control point grid\n+        xy = np.meshgrid(np.linspace(1, orig_hdr[\"NAXIS1\"], num_cps_per_axis),\n+                         np.linspace(1, orig_hdr[\"NAXIS2\"], num_cps_per_axis))\n+        x, y = map(lambda arr: arr.flatten(), xy)\n+\n+        # define the Euclid-centric reference frame\n+        _pos_offset = CartesianRepresentation(\n+            x=observation.pos_offset[0],\n+            y=observation.pos_offset[1],\n+            z=observation.pos_offset[2],\n+            unit=u.km\n+        )\n+        _vel_offset = CartesianRepresentation(\n+            x=observation.vel_offset[0],\n+            y=observation.vel_offset[1],\n+            z=observation.vel_offset[2],\n+            unit=u.km / u.s\n+        )\n+        _obs_time = Time(observation.ref_epoch, format='jyear')\n+        ECRF = GCRS(obstime=_obs_time, obsgeoloc=_pos_offset, obsgeovel=_vel_offset)\n+\n+        # project array coords to ecrf\n+        ecrf_a, ecrf_d = wcs.WCS(orig_hdr).all_pix2world(x, y, 1)\n+        ecrf_sc = SkyCoord(ecrf_a, ecrf_d, frame=ECRF, unit='deg')\n+\n+        # transform to ICRS\n+        icrs_sc = ecrf_sc.transform_to(ICRS)\n+        # must do this otherwise astropy thinks they aren't the same frame\n+        icrs_sc = SkyCoord(icrs_sc.ra.deg, icrs_sc.dec.deg, frame='icrs', unit='deg')\n+\n+        # transform reference star coords back to ICRS\n+        ref_sc_ecrf = SkyCoord(\n+            ccd.ra[ccd.has_sky_coord], ccd.dec[ccd.has_sky_coord], frame=ECRF, unit='deg'\n+        )\n+        ref_sc_icrs = ref_sc_ecrf.transform_to(ICRS)\n+        ccd.ra[ccd.has_sky_coord] = ref_sc_icrs.ra.deg\n+        ccd.dec[ccd.has_sky_coord] = ref_sc_icrs.dec.deg\n+        ccd.update_skycoord_obj()\n+\n+        # compute the new WCS\n+        orig_crvals = np.array([orig_hdr['CRVAL1'], orig_hdr['CRVAL2']])\n+        orig_cdmtx = wcsfit_core.get_cd(orig_hdr).flatten()\n+        orig_sip = wcsfit_core.get_sip_coeffs(orig_hdr)\n+        # starting parameters\n+        p0 = np.concatenate((orig_crvals, orig_cdmtx, orig_sip))\n+\n+        # temporary header\n+        tmp_hdr = orig_hdr.copy()\n+\n+        def min_func(parameters):\n+            # extract the linear terms\n+            _crvals = parameters[:2]\n+            _cd_mtx = parameters[2:6].reshape(2, 2)\n+            _sip_coeffs = parameters[6:]\n+\n+            # send the linear terms to the header\n+            for i in range(1, 3):\n+                tmp_hdr[f'CRVAL{i}'] = _crvals[i - 1]\n+                for j in range(1, 3):\n+                    tmp_hdr[f'CD{i}_{j}'] = _cd_mtx[i - 1, j - 1]\n+\n+            # send the distortion model to the header\n+            k = 0\n+            for dim in 'AB':\n+                order = tmp_hdr[f'{dim}_ORDER']\n+                for p in range(order + 1):\n+                    for q in range(order + 1):\n+                        if 2 <= p + q <= order:\n+                            tmp_hdr[f'{dim}_{p}_{q}'] = _sip_coeffs[k]\n+                            k += 1\n+\n+            # generate the WCS object\n+            tmp_wcs = wcs.WCS(tmp_hdr)\n+\n+            # evaluate the positions of the control points\n+            _ra, _dec = tmp_wcs.all_pix2world(x, y, 1)\n+            _sc = SkyCoord(_ra, _dec, frame='icrs', unit='deg')\n+\n+            # calculate separations between true and predicted positions\n+            dra, ddec = icrs_sc.spherical_offsets_to(_sc)\n+            # convert to milliarcsec\n+            dra, ddec = dra.arcsec * 1000, ddec.arcsec * 1000\n+\n+            # return the flattened residuals\n+            return np.concatenate((dra, ddec)).flatten()\n+\n+        # set bounds\n+        ubounds = np.full_like(p0, np.inf)\n+        lbounds = np.full_like(p0, -np.inf)\n+        lbounds[0] = np.clip(orig_crvals[0] - 5, 0.0, 360.)  # don't allow ra to go crazy\n+        ubounds[0] = np.clip(orig_crvals[0] + 5, 0.0, 360.)\n+        lbounds[1] = np.clip(orig_crvals[1] - 5, -90.0, 90.0)  # don't allow dec to go crazy\n+        ubounds[1] = np.clip(orig_crvals[1] + 5, -90.0, 90.0)\n+\n+        # run the minimizer\n+        solution = least_squares(\n+            min_func, p0, bounds=(lbounds, ubounds), x_scale='jac', jac='3-point'\n+        )\n+\n+        # set the resultant values and get the header\n+        residuals = min_func(solution.x)\n+        if logger is not None:\n+            logger.debug(f\"mean, max residual = {residuals.mean():.2e}, {residuals.max():.2e} (mas)\")\n+\n+        # send the header to the CCD object\n+        ccd.header = tmp_hdr.copy()\n+        ccd.wcs = wcs.WCS(ccd.header)\n+\n+\n+\n+\n \n def fit_fpa_model(\n         obsdataset,\n@@ -2220,6 +2357,14 @@ def get_observation(src_cat_path, refdata, refmagmin=None, refmagmax=None,\n         # grab the primary header\n         pri_hdr = srccat_hdul[0].header\n \n+        # date of the vis observation\n+        mjdobs = pri_hdr['MJD-OBS']\n+        obs_epoch = Time(mjdobs, format='mjd').jyear\n+        # position of the instrument\n+        pos_vec = tuple([pri_hdr[f\"POS_{elem}\"] for elem in \"XYZ\"])\n+        # velocity of the instrument\n+        vel_vec = tuple([pri_hdr[f\"VEL_{elem}\"] for elem in \"XYZ\"])\n+\n         # record the primary header exptime if present\n         if 'EXPTIME' in pri_hdr.keys():\n             exptimes.append(float(pri_hdr['EXPTIME']))\n@@ -2341,6 +2486,7 @@ def get_observation(src_cat_path, refdata, refmagmin=None, refmagmax=None,\n     # build an Observation object instance from the list of ccds\n     observation = wcsfit_core.Observation(\n         ccd_list, refdata, pointings[0], pas[0], exptimes[0],\n+        ref_epoch=obs_epoch, pos_offset=pos_vec, vel_offset=vel_vec,\n         filename=src_cat_path, header=pri_hdr\n     )\n \n@@ -2536,7 +2682,7 @@ def icrs_to_ecrf(ra, dec, parallax, pmra, pmdec, ref_epoch,\n         x=vel_offset[0], y=vel_offset[1], z=vel_offset[2],\n         unit=u.km / u.s\n     )\n-    ECRF = GCRS(obstime=Time(target_time), obsgeoloc=_pos_offset, obsgeovel=_vel_offset)\n+    ECRF = GCRS(obstime=target_time, obsgeoloc=_pos_offset, obsgeovel=_vel_offset)\n     # transform coordinates to ECRF system\n     ecrf1 = icrs1.transform_to(ECRF)\n \n",
                            "convert wcs ecrf -> icrs #23453",
                            "Leigh Smith",
                            "2023-08-15T15:36:25.000+01:00",
                            "7fe3dc47bd7a5cd280eae6cf384de8c4d63069a0"
                        ]
                    ],
                    "VIS_Astrometry/python/VIS_Astrometry/wcsfit_core.py": [
                        [
                            "@@ -707,11 +707,15 @@ class FPAModel(object):\n             jac_sparsity=jsparse,\n             max_nfev=50  # if not enough then something is probably wrong\n         )\n-        # todo\n-        #   check on active_mask? (i.e. is solution at bounds)\n+\n+        # check on active_mask (i.e. is solution at bounds)\n+        if np.count_nonzero(solution.active_mask) != 0 and logger is not None:\n+            logger.warning(\n+                'At least one of the fpa model parameters is at the bounds'\n+            )\n \n         # warn if max_nfev was the reason for termination\n-        if solution.status == 0:\n+        if solution.status == 0 and logger is not None:\n             logger.warning(\n                 'The fitter terminated because the maximum number of '\n                 'function evaluations was reached'\n@@ -1123,6 +1127,7 @@ class Observation(object):\n \n     def __init__(\n             self, ccd_data, ref_data, pointing, position_angle, exptime,\n+            ref_epoch=None, pos_offset=None, vel_offset=None,\n             filename=None, header=None\n     ):\n         \"\"\"\n@@ -1141,6 +1146,14 @@ class Observation(object):\n             Floating point position angle of observation in decimal degrees.\n         exptime : float\n             Exposure time in seconds.\n+        ref_epoch : float, optional\n+            Reference epoch (i.e. observation epoch) in Julian years\n+        pos_offset : tuple, optional\n+            The 3-component positional offset of the observatory from the\n+            origin of the geocentric reference frame at the target_epoch in km\n+        vel_offset : tuple, optional\n+            The 3-component velocity offset of the observatory from the\n+            origin of the geocentric reference frame at the target epoch in km/s\n         filename : string, optional\n             The filename of the observation.\n         header : header, optional\n@@ -1161,6 +1174,11 @@ class Observation(object):\n         self.position_angle = position_angle\n         self.exptime = exptime\n \n+        # store additional info\n+        self.ref_epoch = ref_epoch\n+        self.pos_offset = pos_offset\n+        self.vel_offset = vel_offset\n+\n         # create an ordered dictionary of CCDData objects\n         self.ccds = OrderedDict()\n         for n, ccd in enumerate(ccd_data):\n@@ -2249,8 +2267,18 @@ class CCDData(object):\n             # return the flattened residuals\n             return self.calc_ref_residuals(mode='standardised').flatten()\n \n+        # set bounds\n+        ubounds = np.full_like(p0, np.inf)\n+        lbounds = np.full_like(p0, -np.inf)\n+        lbounds[0] = np.clip(crvals[0] - 5, 0.0, 360.)  # don't allow ra to go crazy\n+        ubounds[0] = np.clip(crvals[0] + 5, 0.0, 360.)\n+        lbounds[1] = np.clip(crvals[1] - 5, -90.0, 90.0)  # don't allow dec to go crazy\n+        ubounds[1] = np.clip(crvals[1] + 5, -90.0, 90.0)\n+\n         # run the minimizer\n-        solution = least_squares(min_func, p0, x_scale='jac', jac='3-point')\n+        solution = least_squares(\n+            min_func, p0, bounds=(lbounds, ubounds), x_scale='jac', jac='3-point'\n+        )\n \n         # set the resultant values\n         _ = min_func(solution.x)\n",
                            "Merge branch 'hotfix/wcsfit-latest' into 'release-13.0': [FIX]#23453 Velocity aberration",
                            "Catherine Grenet",
                            "2023-08-22T13:27:01.000+00:00",
                            "01ffa5761a241a058ab54fad1f6d060636dd3e30"
                        ],
                        [
                            "@@ -1127,6 +1127,7 @@ class Observation(object):\n \n     def __init__(\n             self, ccd_data, ref_data, pointing, position_angle, exptime,\n+            ref_epoch=None, pos_offset=None, vel_offset=None,\n             filename=None, header=None\n     ):\n         \"\"\"\n@@ -1145,6 +1146,14 @@ class Observation(object):\n             Floating point position angle of observation in decimal degrees.\n         exptime : float\n             Exposure time in seconds.\n+        ref_epoch : float, optional\n+            Reference epoch (i.e. observation epoch) in Julian years\n+        pos_offset : tuple, optional\n+            The 3-component positional offset of the observatory from the\n+            origin of the geocentric reference frame at the target_epoch in km\n+        vel_offset : tuple, optional\n+            The 3-component velocity offset of the observatory from the\n+            origin of the geocentric reference frame at the target epoch in km/s\n         filename : string, optional\n             The filename of the observation.\n         header : header, optional\n@@ -1165,6 +1174,11 @@ class Observation(object):\n         self.position_angle = position_angle\n         self.exptime = exptime\n \n+        # store additional info\n+        self.ref_epoch = ref_epoch\n+        self.pos_offset = pos_offset\n+        self.vel_offset = vel_offset\n+\n         # create an ordered dictionary of CCDData objects\n         self.ccds = OrderedDict()\n         for n, ccd in enumerate(ccd_data):\n@@ -2253,8 +2267,18 @@ class CCDData(object):\n             # return the flattened residuals\n             return self.calc_ref_residuals(mode='standardised').flatten()\n \n+        # set bounds\n+        ubounds = np.full_like(p0, np.inf)\n+        lbounds = np.full_like(p0, -np.inf)\n+        lbounds[0] = np.clip(crvals[0] - 5, 0.0, 360.)  # don't allow ra to go crazy\n+        ubounds[0] = np.clip(crvals[0] + 5, 0.0, 360.)\n+        lbounds[1] = np.clip(crvals[1] - 5, -90.0, 90.0)  # don't allow dec to go crazy\n+        ubounds[1] = np.clip(crvals[1] + 5, -90.0, 90.0)\n+\n         # run the minimizer\n-        solution = least_squares(min_func, p0, x_scale='jac', jac='3-point')\n+        solution = least_squares(\n+            min_func, p0, bounds=(lbounds, ubounds), x_scale='jac', jac='3-point'\n+        )\n \n         # set the resultant values\n         _ = min_func(solution.x)\n",
                            "convert wcs ecrf -> icrs #23453",
                            "Leigh Smith",
                            "2023-08-15T15:36:25.000+01:00",
                            "7fe3dc47bd7a5cd280eae6cf384de8c4d63069a0"
                        ]
                    ],
                    "HISTORY.txt": [
                        [
                            "@@ -1,6 +1,11 @@\n VIS_Tasks changelog\n -------------------\n \n+* 20 Aug 2023 - matt.wander@open.ac.uk\n+** VIS_TrapPumping: fix various bugs found in first PV pipeline runs (#23511)\n+*** VIS_TrapPumping_Analysis: handle where dipole masked in too many frames, handle where only one trap is found\n+*** VIS_TrapPumping_IO: raise error if input files not valid, handle results with only bad model fits\n+\n * 17 Aug 2023 - herent@iap.fr\n ** VIS_PSF/auxdir/VIS_PSF/default.psfex: PSF_SIZE is now set to 21,21 to match the vignet size\n ** VIS_SourceExtraction/python/VIS_SourceExtraction/VIS_extract_sources.py: vignet size is now an odd number (21x21 pixels)\n",
                            "Merge branch 'release-13.0' into develop: [FIX]Bug #23511 Various bugs in VIS_TrapPumping",
                            "Catherine Grenet",
                            "2023-08-22T14:49:01.000+02:00",
                            "3c9781dd1cc91e5c1e65ba5ba7f3361f37bc706f"
                        ],
                        [
                            "@@ -1,6 +1,10 @@\n VIS_Tasks changelog\n -------------------\n \n+* 20 Aug 2023 - matt.wander@open.ac.uk\n+** VIS_TrapPumping: fix various bugs found in first PV pipeline runs (#23511)\n+*** VIS_TrapPumping_Analysis: handle where dipole masked in too many frames, handle where only one trap is found\n+*** VIS_TrapPumping_IO: raise error if input files not valid, handle results with only bad model fits\n \n * 15 Aug 2023 - mottet@iap.fr\n ** FromToXML.py: fix #23486, InputRawFrameReference default value doesn't exist in EUCLID, don't use it\n",
                            "Merge branch 'hotfix-pv_trap_pumping-23511' into 'release-13.0'",
                            "Catherine Grenet",
                            "2023-08-22T12:14:14.000+00:00",
                            "6ab9847510959d422b4d704bf1920e49909ac3f1"
                        ],
                        [
                            "@@ -1,6 +1,10 @@\n VIS_Tasks changelog\n -------------------\n \n+* 20 Aug 2023 - matt.wander@open.ac.uk\n+** VIS_TrapPumping: fix various bugs found in first PV pipeline runs (#23511)\n+*** VIS_TrapPumping_Analysis: handle where dipole masked in too many frames, handle where only one trap is found\n+*** VIS_TrapPumping_IO: raise error if input files not valid, handle results with only bad model fits\n \n * 15 Aug 2023 - mottet@iap.fr\n ** FromToXML.py: fix #23486, InputRawFrameReference default value doesn't exist in EUCLID, don't use it\n",
                            "VIS_TrapPumping: fix various bugs found in first PV pipeline runs (#23511)",
                            "Matt Wander",
                            "2023-08-20T11:03:10.000+02:00",
                            "af974ee04afcd74962cad19b26ac53c961ab0df9"
                        ],
                        [
                            "@@ -12,6 +12,9 @@ VIS_Tasks changelog\n ** VIS_gather_ccd.py: disable NoiseChisel background, which takes time but isn't used anywhere for now\n ** VIS_PRNU/VIS_CombinePRNU.py: remove file which superseded by VIS_PRNU/VIS_SmallScaleFlat/VIS_CombinePRNU.py\n \n+* 15 Aug 2023 - mottet@iap.fr\n+** FromToXML.py: fix #23486, InputRawFrameReference default value doesn't exist in EUCLID, don't use it\n+\n * 11 Aug 2023 - mottet@iap.fr\n ** VIS_science_xml_out.py: fix #23096, compress EUC_VIS_DET-SWL*.fits separately after data product creation\n \n",
                            "Merge branch 'release-13.0' into develop: #23486 #23449 #23513 #23522 #23522 #23227: RawFrame ref id, CTI pipeline, MasterDark exptime, Blooming",
                            "Catherine Grenet",
                            "2023-08-18T17:40:14.000+02:00",
                            "df77b0959fe5839832e9710c622dc75f0c781705"
                        ],
                        [
                            "@@ -1,6 +1,9 @@\n VIS_Tasks changelog\n -------------------\n \n+* 17 Aug 2023 - herent@iap.fr\n+** VIS_PSF/auxdir/VIS_PSF/default.psfex: PSF_SIZE is now set to 21,21 to match the vignet size\n+** VIS_SourceExtraction/python/VIS_SourceExtraction/VIS_extract_sources.py: vignet size is now an odd number (21x21 pixels)\n \n * 17 Aug 2023 - mottet@iap.fr\n ** FromToXML.py: fix #23266: stacking output product XML is empty when Stack_Photometry=False and stack PSF file is None\n",
                            "minor change: switch to on odd number of vignet size for the sextractor catalogues. Now set to 21x21 instead 20x20",
                            "Olivier Herent",
                            "2023-08-18T08:36:22.000+00:00",
                            "5bef2598378b16bc1f9a589dbc7a3fbe87dbfec5"
                        ],
                        [
                            "@@ -1,6 +1,17 @@\n VIS_Tasks changelog\n -------------------\n \n+\n+* 15 Aug 2023 - mottet@iap.fr\n+** FromToXML.py: fix #23486, InputRawFrameReference default value doesn't exist in EUCLID, don't use it\n+\n+* 11 Aug 2023 - mottet@iap.fr\n+** VIS_science_xml_out.py: fix #23096, compress EUC_VIS_DET-SWL*.fits separately after data product creation\n+\n+* 10 Aug 2023 - mottet@iap.fr\n+** VIS_SmallScaleFlat: add DQC ouptut, should now accept any combination of single-LED/single-fluence master flats\n+\n+\n * 04 Aug 2023 - herent@iap.fr\n ** VIS_Photometry/python/VIS_Photometry/VIS_Calibrate_Photometry.py: fix photometry issue #23277 for PDC dataset\n \n",
                            "Merge branch 'release-13.0' into 'feature_#23227_BloomingCalib'",
                            "Thomas Flanet",
                            "2023-08-17T15:43:48.000+00:00",
                            "9d236be45ec452966840965083cd59dc82102cf0"
                        ],
                        [
                            "@@ -2,6 +2,9 @@ VIS_Tasks changelog\n -------------------\n \n \n+* 17 Aug 2023 - mottet@iap.fr\n+** FromToXML.py: fix #23266: stacking output product XML is empty when Stack_Photometry=False and stack PSF file is None\n+\n * 17 Aug 2023 - mottet@iap.fr\n ** VIS_gather_ccd.py: disable NoiseChisel background, which takes time but isn't used anywhere for now\n ** VIS_PRNU/VIS_CombinePRNU.py: remove file which superseded by VIS_PRNU/VIS_SmallScaleFlat/VIS_CombinePRNU.py\n",
                            "FromToXML.py: fix #23266: stacking output product XML is empty when Stack_Photometry=False and stack PSF file is None",
                            "Sylvain Mottet",
                            "2023-08-17T16:38:27.000+02:00",
                            "1516bfee461de41dc3ea115eef59f5c8f22f543e"
                        ],
                        [
                            "@@ -3,7 +3,8 @@ VIS_Tasks changelog\n \n \n * 17 Aug 2023 - mottet@iap.fr\n-** VIS_gather_ccd.py: disabled NoiseChisel background, which takes time but isn't used anywhere for now\n+** VIS_gather_ccd.py: disable NoiseChisel background, which takes time but isn't used anywhere for now\n+** VIS_PRNU/VIS_CombinePRNU.py: remove file which superseded by VIS_PRNU/VIS_SmallScaleFlat/VIS_CombinePRNU.py\n \n * 11 Aug 2023 - mottet@iap.fr\n ** VIS_science_xml_out.py: fix #23096, compress EUC_VIS_DET-SWL*.fits separately after data product creation\n",
                            "VIS_PRNU/VIS_CombinePRNU.py: remove file which superseded by VIS_PRNU/VIS_SmallScaleFlat/VIS_CombinePRNU.py",
                            "Sylvain Mottet",
                            "2023-08-17T14:46:56.000+02:00",
                            "56de0a9ff38dff740fbcee7004562f5f30662ada"
                        ],
                        [
                            "@@ -2,13 +2,15 @@ VIS_Tasks changelog\n -------------------\n \n \n+* 17 Aug 2023 - mottet@iap.fr\n+** VIS_gather_ccd.py: disabled NoiseChisel background, which takes time but isn't used anywhere for now\n+\n * 11 Aug 2023 - mottet@iap.fr\n ** VIS_science_xml_out.py: fix #23096, compress EUC_VIS_DET-SWL*.fits separately after data product creation\n \n * 10 Aug 2023 - mottet@iap.fr\n ** VIS_SmallScaleFlat: add DQC ouptut, should now accept any combination of single-LED/single-fluence master flats\n \n-\n * 04 Aug 2023 - herent@iap.fr\n ** VIS_Photometry/python/VIS_Photometry/VIS_Calibrate_Photometry.py: fix photometry issue #23277 for PDC dataset\n \n",
                            "VIS_gather_ccd.py: disabled NoiseChisel background, which takes time but isn't used anywhere for now",
                            "Sylvain Mottet",
                            "2023-08-17T14:44:28.000+02:00",
                            "da5933d6ac9da9305f5742975f5910e87f9dfa28"
                        ],
                        [
                            "@@ -2,6 +2,9 @@ VIS_Tasks changelog\n -------------------\n \n \n+* 15 Aug 2023 - mottet@iap.fr\n+** FromToXML.py: fix #23486, InputRawFrameReference default value doesn't exist in EUCLID, don't use it\n+\n * 11 Aug 2023 - mottet@iap.fr\n ** VIS_science_xml_out.py: fix #23096, compress EUC_VIS_DET-SWL*.fits separately after data product creation\n \n",
                            "Merge branch 'release-14.0' of https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks into release-13.0",
                            "James Nightingale",
                            "2023-08-16T13:55:08.000+02:00",
                            "60250922c95bed9dd480e534c9064ec00867b8e7"
                        ],
                        [
                            "@@ -2,6 +2,9 @@ VIS_Tasks changelog\n -------------------\n \n \n+* 15 Aug 2023 - mottet@iap.fr\n+** FromToXML.py: fix #23486, InputRawFrameReference default value doesn't exist in EUCLID, don't use it\n+\n * 11 Aug 2023 - mottet@iap.fr\n ** VIS_science_xml_out.py: fix #23096, compress EUC_VIS_DET-SWL*.fits separately after data product creation\n \n",
                            "Merge branch 'hotfix_23486_rawrefid' into 'release-13.0'",
                            "Catherine Grenet",
                            "2023-08-15T15:01:47.000+00:00",
                            "5da7f29fe620e0f90f5ed152f6d02137a45a2aec"
                        ],
                        [
                            "@@ -2,6 +2,9 @@ VIS_Tasks changelog\n -------------------\n \n \n+* 15 Aug 2023 - mottet@iap.fr\n+** FromToXML.py: fix #23486, InputRawFrameReference default value doesn't exist in EUCLID, don't use it\n+\n * 11 Aug 2023 - mottet@iap.fr\n ** VIS_science_xml_out.py: fix #23096, compress EUC_VIS_DET-SWL*.fits separately after data product creation\n \n",
                            "FromToXML.py: fix #23486, InputRawFrameReference default value doesn't exist in EUCLID, don't use it",
                            "Sylvain Mottet",
                            "2023-08-15T12:16:24.000+02:00",
                            "fbb506691507f59dfaefdd55253aa0d95a45d144"
                        ],
                        [
                            "@@ -1,9 +1,14 @@\n VIS_Tasks changelog\n -------------------\n \n+\n+* 11 Aug 2023 - mottet@iap.fr\n+** VIS_science_xml_out.py: fix #23096, compress EUC_VIS_DET-SWL*.fits separately after data product creation\n+\n * 10 Aug 2023 - mottet@iap.fr\n ** VIS_SmallScaleFlat: add DQC ouptut, should now accept any combination of single-LED/single-fluence master flats\n \n+\n * 04 Aug 2023 - herent@iap.fr\n ** VIS_Photometry/python/VIS_Photometry/VIS_Calibrate_Photometry.py: fix photometry issue #23277 for PDC dataset\n \n",
                            "Merge branch 'release-13.0' into develop:[FIX]Bug #23096 FITS files are trucated when ZipOutputs = True",
                            "Catherine Grenet",
                            "2023-08-13T17:54:06.000+02:00",
                            "ccd0f48120d1eee4a9c11b54a074f7198023af99"
                        ],
                        [
                            "@@ -1,9 +1,14 @@\n VIS_Tasks changelog\n -------------------\n \n+\n+* 11 Aug 2023 - mottet@iap.fr\n+** VIS_science_xml_out.py: fix #23096, compress EUC_VIS_DET-SWL*.fits separately after data product creation\n+\n * 10 Aug 2023 - mottet@iap.fr\n ** VIS_SmallScaleFlat: add DQC ouptut, should now accept any combination of single-LED/single-fluence master flats\n \n+\n * 04 Aug 2023 - herent@iap.fr\n ** VIS_Photometry/python/VIS_Photometry/VIS_Calibrate_Photometry.py: fix photometry issue #23277 for PDC dataset\n \n",
                            "Merge branch 'hotfix_23096_truncatedzip' into 'release-13.0'",
                            "Catherine Grenet",
                            "2023-08-13T15:44:17.000+00:00",
                            "0b3b8f472386353b13cc8d7fc90bb1e3e7d91eae"
                        ]
                    ],
                    "VIS_TrapPumping/python/VIS_TrapPumping/VIS_TrapPumping_Analysis/fitting/results.py": [
                        [
                            "@@ -13,20 +13,21 @@ class Result:\n     row: Optional[int]\n     col: int\n     phase: int\n-    model_fit: ModelFit\n+    model_fit: Optional[ModelFit]\n     fitted_points: dict[float, float]\n     cr_flags: int\n \n     def asdict(self) -> dict[Union[str, float], Union[str, float]]:\n         result = {\"row\": self.row} if self.row is not None else {}\n-        result.update(\n-            {\n-                \"column\": self.col,\n-                \"phase\": self.phase,\n-                \"model_name\": self.model_fit.name,\n-                **self.model_fit.corrected_params,\n-                **self.fitted_points,\n-                \"cr_flags\": self.cr_flags,\n-            }\n-        )\n+        result.update({\"column\": self.col, \"phase\": self.phase})\n+\n+        if self.model_fit is not None:\n+            result.update(\n+                {\n+                    \"model_name\": self.model_fit.name,\n+                    **self.model_fit.corrected_params,\n+                }\n+            )\n+\n+        result.update({**self.fitted_points, \"cr_flags\": self.cr_flags})\n         return result\n",
                            "Merge branch 'release-13.0' into develop: [FIX]Bug #23511 Various bugs in VIS_TrapPumping",
                            "Catherine Grenet",
                            "2023-08-22T14:49:01.000+02:00",
                            "3c9781dd1cc91e5c1e65ba5ba7f3361f37bc706f"
                        ]
                    ],
                    "VIS_TrapPumping/python/VIS_TrapPumping/VIS_TrapPumping_Analysis/traps/abstract.py": [
                        [
                            "@@ -1,6 +1,7 @@\n from abc import ABC, abstractmethod\n from collections.abc import Iterator, Sized\n from dataclasses import dataclass\n+from functools import partial\n from typing import Union\n \n import numpy as np\n@@ -66,19 +67,26 @@ class Trap(ABC):\n         return 0\n \n     def run_model_fitting(self) -> Result:\n+        part_result = partial(\n+            Result,\n+            fitted_points=self.fitted_points,\n+            cr_flags=self.cr_flags,\n+        )\n+        if not self.models:  # no models to fit\n+            return part_result(\n+                row=self.row, col=self.col, phase=0, model_fit=None\n+            )\n+\n         model_fits = map(ModelFit.fit, self.models)\n         model_comparator = ModelComparator(\n             list(filter(lambda fit: fit.has_params, model_fits))\n         )\n         best_fit = model_comparator.get_best_model()\n+\n+        row, col = self.adjusted_row_col\n         phase = best_fit.get_phase(self.phase_options, self.is_low_high)\n-        return Result(\n-            *self.adjusted_row_col,\n-            phase,\n-            best_fit,\n-            self.fitted_points,\n-            self.cr_flags,\n-        )\n+\n+        return part_result(row=row, col=col, phase=phase, model_fit=best_fit)\n \n     @property\n     @abstractmethod\n",
                            "Merge branch 'release-13.0' into develop: [FIX]Bug #23511 Various bugs in VIS_TrapPumping",
                            "Catherine Grenet",
                            "2023-08-22T14:49:01.000+02:00",
                            "3c9781dd1cc91e5c1e65ba5ba7f3361f37bc706f"
                        ]
                    ],
                    "VIS_TrapPumping/python/VIS_TrapPumping/VIS_TrapPumping_Analysis/traps/parallel.py": [
                        [
                            "@@ -34,8 +34,13 @@ class ParallelTrap(Trap):\n     @property\n     def models(self) -> list[Model]:\n         if np.ma.is_masked(self.dipole_intensities):\n-            # Some values are masked by CR flagging. Mask corresponding t_ph\n-            # values and override Clock object.\n+            # Some values are masked by CR flagging.\n+            # Check if too many masked\n+            n_masked = np.ma.count_masked(self.dipole_intensities)\n+            if n_masked > round(len(self.clock.t_var) / 2):\n+                return []  # not worth trying to fit a model\n+\n+            # Mask corresponding t_ph values and override Clock object.\n             t_var = self.clock.t_var[~self.dipole_intensities.mask]\n             clock = Clock(self.clock.scheme, self.clock.cycles, t_var)\n             # Remove masked dipole intensities\n@@ -106,7 +111,9 @@ class ParallelTrapLocator(TrapLocator):\n         self, dipoles: ndarray, config: AnalysisConfig\n     ) -> ndarray:\n         cycles = self.data.clock.cycles\n-        dipole_intensities = np.diff(-dipoles).squeeze().T / (cycles * 2)\n+        dipole_intensities = np.diff(-dipoles).squeeze(axis=-1).T / (\n+            cycles * 2\n+        )\n \n         if config.mask_crs:\n             # Sum low side + high side of dipoles\n",
                            "Merge branch 'release-13.0' into develop: [FIX]Bug #23511 Various bugs in VIS_TrapPumping",
                            "Catherine Grenet",
                            "2023-08-22T14:49:01.000+02:00",
                            "3c9781dd1cc91e5c1e65ba5ba7f3361f37bc706f"
                        ]
                    ],
                    "VIS_TrapPumping/python/VIS_TrapPumping/VIS_TrapPumping_Analysis/traps/serial.py": [
                        [
                            "@@ -76,7 +76,7 @@ class SerialTrapLocator(TrapLocator):\n         self, dipoles: ndarray, config: AnalysisConfig\n     ) -> ndarray:\n         cycles = self.data.clock.cycles\n-        return np.diff(-dipoles, axis=1).squeeze().T / (cycles * 2)\n+        return np.diff(-dipoles, axis=1).squeeze(axis=-2).T / (cycles * 2)\n \n     def _get_image_row_col(\n         self, region_row: int, region_col: int\n",
                            "Merge branch 'release-13.0' into develop: [FIX]Bug #23511 Various bugs in VIS_TrapPumping",
                            "Catherine Grenet",
                            "2023-08-22T14:49:01.000+02:00",
                            "3c9781dd1cc91e5c1e65ba5ba7f3361f37bc706f"
                        ]
                    ],
                    "VIS_TrapPumping/python/VIS_TrapPumping/VIS_TrapPumping_IO/file_entry_point.py": [
                        [
                            "@@ -19,6 +19,7 @@ writes the output files.\n # 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n #\n \n+from functools import partial\n from pathlib import Path\n \n from fitsio import FITSHDR, read_header\n@@ -34,7 +35,7 @@ from ..VIS_TrapPumping_Analysis.fitting import fit_models\n from ..VIS_TrapPumping_Analysis.traps.parallel import ParallelTrapLocator\n from ..VIS_TrapPumping_Analysis.traps.serial import SerialTrapLocator\n \n-from .file_validation import input_fits_files_valid\n+from .file_validation import check_input_fits_files_valid\n from .pre_processing import prepare_tp_data\n from .qc_stats import get_frame_stats, get_output_stats\n \n@@ -83,35 +84,25 @@ def file_layer_entry_point(\n     logger.info(\"argument 'config': %s\", config)\n     logger.info(\"argument 'tp_params_csv': %s\", tp_params_csv)\n \n-    if input_fits_files_valid(input_files, serial):\n-        data = prepare_tp_data(input_files, serial)\n-        tp_params = run_tp_analysis(data, serial, config)\n-\n-        tp_params.insert(0, \"ccd\", ext_hdr[\"CCDID\"])\n-        tp_params.insert(1, \"quad\", ext_hdr[\"QUADID\"])\n-        tp_params.to_csv(tp_params_csv, index=False)\n-\n-        obs_id = read_header(input_files[-1])[\"OBS_ID\"]\n-        output_stats = get_output_stats(tp_params, config[\"mask_crs\"])\n-        save_peri(\n-            output_stats,\n-            str(tp_params_csv),\n-            \"VIS_TrapPumping_Output\",\n-            context_name=ext_hdr[\"EXTNAME\"],\n-            obs_id=obs_id,\n-        )\n-\n-        if not serial:\n-            frame_stats = get_frame_stats(data, input_files[1:])  # pumped only\n-            save_peri(\n-                frame_stats,\n-                str(tp_params_csv),\n-                \"VIS_TrapPumping_Frames\",\n-                context_name=ext_hdr[\"EXTNAME\"],\n-                obs_id=obs_id,\n-            )\n+    check_input_fits_files_valid(input_files, serial)\n \n-    else:\n-        logger.error(\"%s: input files failed validity tests\", __name__)\n+    data = prepare_tp_data(input_files, serial)\n+    tp_params = run_tp_analysis(data, serial, config)\n+\n+    tp_params.insert(0, \"ccd\", ext_hdr[\"CCDID\"])\n+    tp_params.insert(1, \"quad\", ext_hdr[\"QUADID\"])\n+    tp_params.to_csv(tp_params_csv, index=False)\n+\n+    write_stats = partial(\n+        save_peri,\n+        context_name=ext_hdr[\"EXTNAME\"],\n+        obs_id=read_header(input_files[-1])[\"OBS_ID\"],\n+    )\n+    output_stats = get_output_stats(tp_params, config[\"mask_crs\"])\n+    write_stats(output_stats, str(tp_params_csv), \"VIS_TrapPumping_Output\")\n+\n+    if not serial:\n+        frame_stats = get_frame_stats(data, input_files[1:])  # pumped only\n+        write_stats(frame_stats, str(tp_params_csv), \"VIS_TrapPumping_Frames\")\n \n     logger.info(\"%s complete.\", __name__)\n",
                            "Merge branch 'release-13.0' into develop: [FIX]Bug #23511 Various bugs in VIS_TrapPumping",
                            "Catherine Grenet",
                            "2023-08-22T14:49:01.000+02:00",
                            "3c9781dd1cc91e5c1e65ba5ba7f3361f37bc706f"
                        ]
                    ],
                    "VIS_TrapPumping/python/VIS_TrapPumping/VIS_TrapPumping_IO/file_validation.py": [
                        [
                            "@@ -21,10 +21,10 @@ import ElementsKernel.Logging as elog\n \n import VIS_PyLibrary_M.fits_validation as plfv\n \n-__all__ = [\"input_fits_files_valid\"]\n+__all__ = [\"check_input_fits_files_valid\"]\n \n \n-def input_fits_files_valid(input_files, serial):\n+def check_input_fits_files_valid(input_files, serial):\n     \"\"\"\n     Checks the validity of the input FITS files, for the purpose of flat-field calibration.\n \n@@ -36,20 +36,19 @@ def input_fits_files_valid(input_files, serial):\n     serial : bool\n         True if serial trap pumping, else false.\n \n-    Returns\n-    -------\n-    boolean\n-        True if the files pass all the checks.\n+    Raises\n+    ------\n+    ValueError\n+        If any check is failed.\n     \"\"\"\n     log = elog.getLogger(__name__)\n-    valid = True\n \n     if serial and len(input_files) > 2:\n-        valid = False\n         log.error(\n-            \"STP processing requires a maximum of 2 files: the main one being\"\n+            \"STP processing requires a maximum of 2 files: the main one being \"\n             \"processed and the counterpart with an extra dwell time.\"\n         )\n+        raise ValueError(\"STP processing can handle a maximum of 2 files.\")\n \n     # TODO check more than one of the files\n     handle = fio.FITS(input_files[0])\n@@ -61,9 +60,7 @@ def input_fits_files_valid(input_files, serial):\n         image_header = handle[0].read_header()\n     pre_or_overscan = plfv.contains_pre_or_over_scan(image_header)\n     if not pre_or_overscan:\n-        valid = False\n         log.error(\n             \"input_fits_files_valid(): input file does not contain prescan and/or overscan data\"\n         )\n-\n-    return valid\n+        raise ValueError(\"Frames must contain prescan and overscan.\")\n",
                            "Merge branch 'release-13.0' into develop: [FIX]Bug #23511 Various bugs in VIS_TrapPumping",
                            "Catherine Grenet",
                            "2023-08-22T14:49:01.000+02:00",
                            "3c9781dd1cc91e5c1e65ba5ba7f3361f37bc706f"
                        ]
                    ],
                    "VIS_TrapPumping/python/VIS_TrapPumping/VIS_TrapPumping_IO/plotting.py": [
                        [
                            "@@ -21,9 +21,10 @@ def write_plots(\n     if serial:\n         t_var += 4.75  # phase time\n \n-    fpa_data = results.loc[\n-        notnull(results.tau_e) & (results.tau_e < 1e6) & notnull(results.P_c)\n-    ]\n+    # Defend against tau_e, P_c not in results\n+    tau_e = results.get(\"tau_e\", Series(index=results.index))\n+    P_c = results.get(\"P_c\", Series(index=results.index))\n+    fpa_data = results.loc[notnull(tau_e) & (tau_e < 1e6) & notnull(P_c)]\n     plot_filepaths = []\n     for quad_id in (\"E\", \"F\", \"G\", \"H\"):\n         quad_data = fpa_data.loc[fpa_data.quad == quad_id]\n",
                            "Merge branch 'release-13.0' into develop: [FIX]Bug #23511 Various bugs in VIS_TrapPumping",
                            "Catherine Grenet",
                            "2023-08-22T14:49:01.000+02:00",
                            "3c9781dd1cc91e5c1e65ba5ba7f3361f37bc706f"
                        ]
                    ],
                    "VIS_TrapPumping/python/VIS_TrapPumping/VIS_TrapPumping_IO/qc_stats.py": [
                        [
                            "@@ -4,19 +4,17 @@ from pathlib import Path\n from types import SimpleNamespace as Namespace\n \n from numpy import count_nonzero\n-from pandas import DataFrame, notnull\n-\n-from ST_DM_FilenameProvider.FilenameProvider import FileNameProvider\n+from pandas import DataFrame, Series, notnull\n \n import VIS_PyLibrary_Common.common_definitions as commdef\n import VIS_PyLibrary_Common.pe_run_information as peri\n-import VIS_PyLibrary_Common.zip_tools as zip_tools\n \n from ..VIS_TrapPumping_Analysis.data import Data\n \n \n def get_output_stats(tp_params: DataFrame, mask_crs: bool) -> dict:\n-    valid = tp_params.loc[notnull(tp_params.tau_e)]\n+    tau_e = tp_params.get(\"tau_e\", Series(index=tp_params.index))\n+    valid = tp_params.loc[notnull(tau_e)]\n     stats = {\"num_traps\": valid.shape[0]}\n     if mask_crs:\n         stats[\"num_cr_affected\"] = count_nonzero(valid.cr_flags)\n",
                            "Merge branch 'release-13.0' into develop: [FIX]Bug #23511 Various bugs in VIS_TrapPumping",
                            "Catherine Grenet",
                            "2023-08-22T14:49:01.000+02:00",
                            "3c9781dd1cc91e5c1e65ba5ba7f3361f37bc706f"
                        ]
                    ],
                    "VIS_Blooming/python/VIS_Blooming/VIS_blooming_calib.py": [
                        [
                            "@@ -147,24 +147,7 @@ def mainMethod(args):\n        # so adding the extension number to the individual filename is the pile\n        detrended_quadrant_list = [filename + \".{:03}\".format(ext + 1) for filename in list_data_filename]\n        flag_quadrant_list = [filename + \".{:03}\".format(ext + 1) for filename in list_flg_filename]\n-\n-       # if the flagmap associated with a quadrant contains too much data,\n-       # it means that the quadrant has been too much flagged, possibly because it is too much saturated\n-       # so we remove the quadrant from the list (and remove the corresponding quadrant on the other list as well)\n-       for i in  range(len(flag_quadrant_list)-1, -1, -1):\n-           # open up fits filename\n-           hdu_flag = fits.open(flag_quadrant_list[i], memmap=False)\n-           # get the data\n-           hdu_data = hdu_flag[1].data\n-           mean_flag_quadrant = np.mean(hdu_data)\n-           # removing the quadrant from the list\n-           if mean_flag_quadrant > max_flat_invalid_pixels:\n-               logger.info(\"From detrended_quadrant_list, removing %s\", detrended_quadrant_list[i])\n-               detrended_quadrant_list.remove(detrended_quadrant_list[i])\n-               flag_quadrant_list.remove(flag_quadrant_list[i])\n-           hdu_flag.close()\n-\n-\n+       \n        # we call the pairing_flats function to get two lists\n        list1, list2 = pairing_flats(detrended_quadrant_list, config, False)\n        list1_flg, list2_flg = pairing_flats(flag_quadrant_list, config, True)\n@@ -285,8 +268,8 @@ def mainMethod(args):\n        ax_vic.plot(x_series, diff_nl, 'y', label = 'diff PTC - lin')\n        ax_vic.set_ylabel( \"error between PTC and lin\", color='y')\n \n-\n-       plt.axvline(x = blooming_threshold_per_quadrant[ext], color = 'b')\n+       # on the graph, we want the value in adu\n+       plt.axvline(x = blooming_threshold_per_quadrant[ext] / config.getfloat( \"GainPerQuad\", quadname), color = 'b')\n \n        plt.legend()\n        ax_scr.legend()\n@@ -300,7 +283,7 @@ def mainMethod(args):\n        #############################################################################################\n        \n        # log of results\n-       logger.info(f\"blooming threshold for quadrant {quadname} is : {blooming_threshold_per_quadrant[ext]}\")\n+       logger.info(f\"blooming threshold for quadrant {quadname} is : {blooming_threshold_per_quadrant[ext]} in electrons\")\n        \n        #### update json file with blooming threshold estimation ####\n        blooming_json_dict[quadname] = blooming_threshold_per_quadrant[ext]\n",
                            "Merge branch 'release-13.0' into develop: #23518 Blooming use object masks.",
                            "Catherine Grenet",
                            "2023-08-21T11:34:25.000+02:00",
                            "fb1d1ec4e65fc2d209f7ab891121775622be0f28"
                        ],
                        [
                            "@@ -125,19 +125,17 @@ def mainMethod(args):\n     # the more the value is high, the more the flagmap contains data, and the less the corresponding quadrant has\n     max_flat_invalid_pixels = config.getint( 'BloomingCalib', 'max_flat_invalid_pixels', fallback=97490)\n \n-    # 144 values, one per quadrant\n+    # 144 values, one per quadrant, representing the blooming threshold in electrons\n     blooming_threshold_per_quadrant = np.empty(144)\n-    blooming_threshold_per_quadrant[:] = 65535\n+    blooming_threshold_per_quadrant[:] = 192000.0\n \n     blooming_json_dict = dict()\n     blooming_json_dict['model_name'] = \"VIS_blooming_calib\"\n     blooming_json_dict['date'] = time.ctime()\n     blooming_json_dict['source'] = \"\"\n     blooming_json_dict['author'] = __file__\n-    blooming_json_dict['units'] = \"e-/ADU\"   \n+    blooming_json_dict['units'] = \"e-\"   \n \n-    ptc_json_dict = dict()\n-    \n     # contains the 144 json files that contain the PTC data\n     ptc_json_list = list()\n \n@@ -173,8 +171,8 @@ def mainMethod(args):\n \n        logger.info(list1)\n        logger.info(list2)\n-       image3D_flag_1 = fpe.file_layer_entry_point(list1, \"\", in_flagmap=list1_flg)\n-       image3D_flag_2 = fpe.file_layer_entry_point(list2, \"\", in_flagmap=list2_flg)\n+       image3D_flag_1, quadname = fpe.file_layer_entry_point(list1, \"\", in_flagmap=list1_flg)\n+       image3D_flag_2, _ = fpe.file_layer_entry_point(list2, \"\", in_flagmap=list2_flg)\n \n        signal, variance = ptc_compute.wharper(image3D_flag_1,\n                                               image3D_flag_2,\n@@ -202,15 +200,15 @@ def mainMethod(args):\n            if signal[i] < PTC_fit_xlimit:\n                signal_truncated.append(signal[i])\n                variance_truncated.append(variance[i])\n-       # straight line to show the non-linearity effect when comparing to PTC_fittee\n-       PTC_droite_fittee = np.polyfit(signal_truncated, variance_truncated, 1)\n+       # straight line to show the non-linearity effect when comparing to PTC_fit\n+       straight_PTC_fit = np.polyfit(signal_truncated, variance_truncated, 1)\n \n        #######################\n \n        # computing the distance to the straight line (polynome of deg 1), to get rid off outliners\n        list_distance_to_line = []\n        for i in range(len(signal_truncated)):\n-           list_distance_to_line.append(math.sqrt(np.power(([np.polyval(PTC_droite_fittee, signal[i])] - variance[i]), 2)))\n+           list_distance_to_line.append(math.sqrt(np.power(([np.polyval(straight_PTC_fit, signal[i])] - variance[i]), 2)))\n \n        # computing the std of list_distance_to_line\n        std_points_from_line = np.std(list_distance_to_line)\n@@ -230,19 +228,19 @@ def mainMethod(args):\n        #######################\n \n        # fit of the actual PTC\n-       PTC_fittee = np.polyfit(signal_without_outliers, variance_without_outliers, 3)\n+       PTC_fit = np.polyfit(signal_without_outliers, variance_without_outliers, 3)\n \n        #######################\n \n        # computing the distance of the points to the curved fitted PTC\n        threshold_distance = 0\n        for i in range(len(signal_without_outliers)):\n-           threshold_distance = PTC_blooming_threshold*np.polyval(PTC_fittee, signal[i])\n+           threshold_distance = PTC_blooming_threshold*np.polyval(PTC_fit, signal[i])\n            #logger.info(threshold_distance)\n-           distance_PTC = math.sqrt(np.power(([np.polyval(PTC_fittee, signal_without_outliers[i])] - variance_without_outliers[i]), 2))\n+           distance_PTC = math.sqrt(np.power(([np.polyval(PTC_fit, signal_without_outliers[i])] - variance_without_outliers[i]), 2))\n            if distance_PTC > threshold_distance and signal_without_outliers[i] > PTC_fit_xlimit:\n                logger.info(\"Blooming threshold found at : %s\", signal_without_outliers[i])\n-               blooming_threshold_per_quadrant[ext] = signal_without_outliers[i]\n+               blooming_threshold_per_quadrant[ext] = signal_without_outliers[i] * config.getfloat( \"GainPerQuad\", quadname)\n                break\n \n        #######################\n@@ -255,7 +253,7 @@ def mainMethod(args):\n \n        #######################\n \n-       # print PTC_fittee\n+       # print PTC_fit\n        subdir = workdir+\"/Truncated_PTCs_graph_fit/\"\n        if not os.path.exists(subdir):\n            os.mkdir(subdir)\n@@ -267,16 +265,16 @@ def mainMethod(args):\n        x_series = np.linspace(signal_without_outliers[0],55000,len(signal_without_outliers))\n \n        lin = res.slope*x_series+res.intercept\n-       diff_nl = ([np.polyval(PTC_fittee, i) for i in x_series] - lin) / lin * 100\n+       diff_nl = ([np.polyval(PTC_fit, i) for i in x_series] - lin) / lin * 100\n        #logger.info(diff_nl)\n        #logger.info(lin)\n-       #logger.info([np.polyval(PTC_fittee, i) for i in x_series])\n+       #logger.info([np.polyval(PTC_fit, i) for i in x_series])\n \n        #ax_scr.scatter(signal, variance, s = 10)\n        ax_scr.scatter(signal_without_outliers, variance_without_outliers, s = 10)\n \n        ax_scr.plot(x_series, lin, 'r', label='y={:.2f}x+{:.2f}'.format(res.slope,res.intercept))\n-       ax_scr.plot(x_series, [np.polyval(PTC_fittee, i) for i in x_series], 'g', label = 'Truncated PTC fitted')\n+       ax_scr.plot(x_series, [np.polyval(PTC_fit, i) for i in x_series], 'g', label = 'Truncated PTC fitted')\n        ax_scr.set_xlabel(\"signal\")\n        ax_scr.set_ylabel(\"variance\")\n \n@@ -300,11 +298,7 @@ def mainMethod(args):\n        #############################################################################################\n        # creation of the calibration product containing blooming threshold for all the quadrants\n        #############################################################################################\n-\n-       hdu = fits.open(detrended_quadrant_list[0], memmap=False)\n-       quadname = hdu[1].header[\"EXTNAME\"]\n-       hdu.close()\n-\n+       \n        # log of results\n        logger.info(f\"blooming threshold for quadrant {quadname} is : {blooming_threshold_per_quadrant[ext]}\")\n        \n@@ -312,6 +306,7 @@ def mainMethod(args):\n        blooming_json_dict[quadname] = blooming_threshold_per_quadrant[ext]\n        \n        # creation of a json file to be put in the data product\n+       ptc_json_dict = dict()\n        for elmt_signal, elmt_var in zip(signal_without_outliers, variance_without_outliers):\n          ptc_json_dict[elmt_signal] = elmt_var\n \n@@ -355,15 +350,13 @@ def mainMethod(args):\n \n     DmUtils.save_product_metadata( data_product, dpdcalib_blooming)\n \n-    # adding to the data_product, inside Data.QualityParameterStorage, the json file containing the list of the PTC data points\n-    ptc_file = FileNameProvider().get_allowed_filename( processing_function = 'VIS',\n-                                                                    type_name           = \"list-PTCs\",\n-                                                                    instance_id         = '',\n-                                                                    extension           = '.json')\n-    ptc_file = os.path.join( args.workdir, \"data\", ptc_file)    \n-    with open(ptc_file, 'w') as fp:\n-      fp.write(json.dumps(ptc_json_list, indent=2, default=np.ndarray.tolist))\n-    logger.info(f\"ptc_file is : {ptc_file}\")\n+    # we add all the ptcs files into a single tar file, to be accessible at the eas\n+    ptc_file = workdir+\"/data/list-PTCs.tar\"\n+    with tarfile.open(ptc_file, \"w:gz\") as tar:\n+      for filename in ptc_json_list:\n+        logger.info(f\"in ptc_json_list, filename is : {filename}\")\n+        tar.add(os.path.join(workdir + \"/data/\", filename), arcname=filename)\n+   \n     FromToXML.add_quality_parameter_file(data_product, ptc_file)\n \n     DmUtils.save_product_metadata( data_product, dpdcalib_blooming)\n@@ -373,4 +366,4 @@ def mainMethod(args):\n     logger.info( \"#\")\n     logger.info( \"# Exiting %s mainMethod()\", __name__)\n     logger.info( \"#\")\n-\n+    \n",
                            "Merge branch 'release-13.0' of https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks into release-13.0",
                            "James Nightingale",
                            "2023-08-18T17:51:24.000+02:00",
                            "4e9c5ce4e2d2d168d895e7a749f715a3f289f8ca"
                        ],
                        [
                            "@@ -125,19 +125,17 @@ def mainMethod(args):\n     # the more the value is high, the more the flagmap contains data, and the less the corresponding quadrant has\n     max_flat_invalid_pixels = config.getint( 'BloomingCalib', 'max_flat_invalid_pixels', fallback=97490)\n \n-    # 144 values, one per quadrant\n+    # 144 values, one per quadrant, representing the blooming threshold in electrons\n     blooming_threshold_per_quadrant = np.empty(144)\n-    blooming_threshold_per_quadrant[:] = 65535\n+    blooming_threshold_per_quadrant[:] = 192000.0\n \n     blooming_json_dict = dict()\n     blooming_json_dict['model_name'] = \"VIS_blooming_calib\"\n     blooming_json_dict['date'] = time.ctime()\n     blooming_json_dict['source'] = \"\"\n     blooming_json_dict['author'] = __file__\n-    blooming_json_dict['units'] = \"e-/ADU\"   \n+    blooming_json_dict['units'] = \"e-\"   \n \n-    ptc_json_dict = dict()\n-    \n     # contains the 144 json files that contain the PTC data\n     ptc_json_list = list()\n \n@@ -173,8 +171,8 @@ def mainMethod(args):\n \n        logger.info(list1)\n        logger.info(list2)\n-       image3D_flag_1 = fpe.file_layer_entry_point(list1, \"\", in_flagmap=list1_flg)\n-       image3D_flag_2 = fpe.file_layer_entry_point(list2, \"\", in_flagmap=list2_flg)\n+       image3D_flag_1, quadname = fpe.file_layer_entry_point(list1, \"\", in_flagmap=list1_flg)\n+       image3D_flag_2, _ = fpe.file_layer_entry_point(list2, \"\", in_flagmap=list2_flg)\n \n        signal, variance = ptc_compute.wharper(image3D_flag_1,\n                                               image3D_flag_2,\n@@ -202,15 +200,15 @@ def mainMethod(args):\n            if signal[i] < PTC_fit_xlimit:\n                signal_truncated.append(signal[i])\n                variance_truncated.append(variance[i])\n-       # straight line to show the non-linearity effect when comparing to PTC_fittee\n-       PTC_droite_fittee = np.polyfit(signal_truncated, variance_truncated, 1)\n+       # straight line to show the non-linearity effect when comparing to PTC_fit\n+       straight_PTC_fit = np.polyfit(signal_truncated, variance_truncated, 1)\n \n        #######################\n \n        # computing the distance to the straight line (polynome of deg 1), to get rid off outliners\n        list_distance_to_line = []\n        for i in range(len(signal_truncated)):\n-           list_distance_to_line.append(math.sqrt(np.power(([np.polyval(PTC_droite_fittee, signal[i])] - variance[i]), 2)))\n+           list_distance_to_line.append(math.sqrt(np.power(([np.polyval(straight_PTC_fit, signal[i])] - variance[i]), 2)))\n \n        # computing the std of list_distance_to_line\n        std_points_from_line = np.std(list_distance_to_line)\n@@ -230,19 +228,19 @@ def mainMethod(args):\n        #######################\n \n        # fit of the actual PTC\n-       PTC_fittee = np.polyfit(signal_without_outliers, variance_without_outliers, 3)\n+       PTC_fit = np.polyfit(signal_without_outliers, variance_without_outliers, 3)\n \n        #######################\n \n        # computing the distance of the points to the curved fitted PTC\n        threshold_distance = 0\n        for i in range(len(signal_without_outliers)):\n-           threshold_distance = PTC_blooming_threshold*np.polyval(PTC_fittee, signal[i])\n+           threshold_distance = PTC_blooming_threshold*np.polyval(PTC_fit, signal[i])\n            #logger.info(threshold_distance)\n-           distance_PTC = math.sqrt(np.power(([np.polyval(PTC_fittee, signal_without_outliers[i])] - variance_without_outliers[i]), 2))\n+           distance_PTC = math.sqrt(np.power(([np.polyval(PTC_fit, signal_without_outliers[i])] - variance_without_outliers[i]), 2))\n            if distance_PTC > threshold_distance and signal_without_outliers[i] > PTC_fit_xlimit:\n                logger.info(\"Blooming threshold found at : %s\", signal_without_outliers[i])\n-               blooming_threshold_per_quadrant[ext] = signal_without_outliers[i]\n+               blooming_threshold_per_quadrant[ext] = signal_without_outliers[i] * config.getfloat( \"GainPerQuad\", quadname)\n                break\n \n        #######################\n@@ -255,7 +253,7 @@ def mainMethod(args):\n \n        #######################\n \n-       # print PTC_fittee\n+       # print PTC_fit\n        subdir = workdir+\"/Truncated_PTCs_graph_fit/\"\n        if not os.path.exists(subdir):\n            os.mkdir(subdir)\n@@ -267,16 +265,16 @@ def mainMethod(args):\n        x_series = np.linspace(signal_without_outliers[0],55000,len(signal_without_outliers))\n \n        lin = res.slope*x_series+res.intercept\n-       diff_nl = ([np.polyval(PTC_fittee, i) for i in x_series] - lin) / lin * 100\n+       diff_nl = ([np.polyval(PTC_fit, i) for i in x_series] - lin) / lin * 100\n        #logger.info(diff_nl)\n        #logger.info(lin)\n-       #logger.info([np.polyval(PTC_fittee, i) for i in x_series])\n+       #logger.info([np.polyval(PTC_fit, i) for i in x_series])\n \n        #ax_scr.scatter(signal, variance, s = 10)\n        ax_scr.scatter(signal_without_outliers, variance_without_outliers, s = 10)\n \n        ax_scr.plot(x_series, lin, 'r', label='y={:.2f}x+{:.2f}'.format(res.slope,res.intercept))\n-       ax_scr.plot(x_series, [np.polyval(PTC_fittee, i) for i in x_series], 'g', label = 'Truncated PTC fitted')\n+       ax_scr.plot(x_series, [np.polyval(PTC_fit, i) for i in x_series], 'g', label = 'Truncated PTC fitted')\n        ax_scr.set_xlabel(\"signal\")\n        ax_scr.set_ylabel(\"variance\")\n \n@@ -300,11 +298,7 @@ def mainMethod(args):\n        #############################################################################################\n        # creation of the calibration product containing blooming threshold for all the quadrants\n        #############################################################################################\n-\n-       hdu = fits.open(detrended_quadrant_list[0], memmap=False)\n-       quadname = hdu[1].header[\"EXTNAME\"]\n-       hdu.close()\n-\n+       \n        # log of results\n        logger.info(f\"blooming threshold for quadrant {quadname} is : {blooming_threshold_per_quadrant[ext]}\")\n        \n@@ -312,6 +306,7 @@ def mainMethod(args):\n        blooming_json_dict[quadname] = blooming_threshold_per_quadrant[ext]\n        \n        # creation of a json file to be put in the data product\n+       ptc_json_dict = dict()\n        for elmt_signal, elmt_var in zip(signal_without_outliers, variance_without_outliers):\n          ptc_json_dict[elmt_signal] = elmt_var\n \n@@ -355,15 +350,13 @@ def mainMethod(args):\n \n     DmUtils.save_product_metadata( data_product, dpdcalib_blooming)\n \n-    # adding to the data_product, inside Data.QualityParameterStorage, the json file containing the list of the PTC data points\n-    ptc_file = FileNameProvider().get_allowed_filename( processing_function = 'VIS',\n-                                                                    type_name           = \"list-PTCs\",\n-                                                                    instance_id         = '',\n-                                                                    extension           = '.json')\n-    ptc_file = os.path.join( args.workdir, \"data\", ptc_file)    \n-    with open(ptc_file, 'w') as fp:\n-      fp.write(json.dumps(ptc_json_list, indent=2, default=np.ndarray.tolist))\n-    logger.info(f\"ptc_file is : {ptc_file}\")\n+    # we add all the ptcs files into a single tar file, to be accessible at the eas\n+    ptc_file = workdir+\"/data/list-PTCs.tar\"\n+    with tarfile.open(ptc_file, \"w:gz\") as tar:\n+      for filename in ptc_json_list:\n+        logger.info(f\"in ptc_json_list, filename is : {filename}\")\n+        tar.add(os.path.join(workdir + \"/data/\", filename), arcname=filename)\n+   \n     FromToXML.add_quality_parameter_file(data_product, ptc_file)\n \n     DmUtils.save_product_metadata( data_product, dpdcalib_blooming)\n@@ -373,4 +366,4 @@ def mainMethod(args):\n     logger.info( \"#\")\n     logger.info( \"# Exiting %s mainMethod()\", __name__)\n     logger.info( \"#\")\n-\n+    \n",
                            "Merge branch 'release-13.0' into develop: #23486 #23449 #23513 #23522 #23522 #23227: RawFrame ref id, CTI pipeline, MasterDark exptime, Blooming",
                            "Catherine Grenet",
                            "2023-08-18T17:40:14.000+02:00",
                            "df77b0959fe5839832e9710c622dc75f0c781705"
                        ],
                        [
                            "@@ -136,8 +136,6 @@ def mainMethod(args):\n     blooming_json_dict['author'] = __file__\n     blooming_json_dict['units'] = \"e-\"   \n \n-    ptc_json_dict = dict()\n-    \n     # contains the 144 json files that contain the PTC data\n     ptc_json_list = list()\n \n@@ -202,15 +200,15 @@ def mainMethod(args):\n            if signal[i] < PTC_fit_xlimit:\n                signal_truncated.append(signal[i])\n                variance_truncated.append(variance[i])\n-       # straight line to show the non-linearity effect when comparing to PTC_fittee\n-       PTC_droite_fittee = np.polyfit(signal_truncated, variance_truncated, 1)\n+       # straight line to show the non-linearity effect when comparing to PTC_fit\n+       straight_PTC_fit = np.polyfit(signal_truncated, variance_truncated, 1)\n \n        #######################\n \n        # computing the distance to the straight line (polynome of deg 1), to get rid off outliners\n        list_distance_to_line = []\n        for i in range(len(signal_truncated)):\n-           list_distance_to_line.append(math.sqrt(np.power(([np.polyval(PTC_droite_fittee, signal[i])] - variance[i]), 2)))\n+           list_distance_to_line.append(math.sqrt(np.power(([np.polyval(straight_PTC_fit, signal[i])] - variance[i]), 2)))\n \n        # computing the std of list_distance_to_line\n        std_points_from_line = np.std(list_distance_to_line)\n@@ -230,16 +228,16 @@ def mainMethod(args):\n        #######################\n \n        # fit of the actual PTC\n-       PTC_fittee = np.polyfit(signal_without_outliers, variance_without_outliers, 3)\n+       PTC_fit = np.polyfit(signal_without_outliers, variance_without_outliers, 3)\n \n        #######################\n \n        # computing the distance of the points to the curved fitted PTC\n        threshold_distance = 0\n        for i in range(len(signal_without_outliers)):\n-           threshold_distance = PTC_blooming_threshold*np.polyval(PTC_fittee, signal[i])\n+           threshold_distance = PTC_blooming_threshold*np.polyval(PTC_fit, signal[i])\n            #logger.info(threshold_distance)\n-           distance_PTC = math.sqrt(np.power(([np.polyval(PTC_fittee, signal_without_outliers[i])] - variance_without_outliers[i]), 2))\n+           distance_PTC = math.sqrt(np.power(([np.polyval(PTC_fit, signal_without_outliers[i])] - variance_without_outliers[i]), 2))\n            if distance_PTC > threshold_distance and signal_without_outliers[i] > PTC_fit_xlimit:\n                logger.info(\"Blooming threshold found at : %s\", signal_without_outliers[i])\n                blooming_threshold_per_quadrant[ext] = signal_without_outliers[i] * config.getfloat( \"GainPerQuad\", quadname)\n@@ -255,7 +253,7 @@ def mainMethod(args):\n \n        #######################\n \n-       # print PTC_fittee\n+       # print PTC_fit\n        subdir = workdir+\"/Truncated_PTCs_graph_fit/\"\n        if not os.path.exists(subdir):\n            os.mkdir(subdir)\n@@ -267,16 +265,16 @@ def mainMethod(args):\n        x_series = np.linspace(signal_without_outliers[0],55000,len(signal_without_outliers))\n \n        lin = res.slope*x_series+res.intercept\n-       diff_nl = ([np.polyval(PTC_fittee, i) for i in x_series] - lin) / lin * 100\n+       diff_nl = ([np.polyval(PTC_fit, i) for i in x_series] - lin) / lin * 100\n        #logger.info(diff_nl)\n        #logger.info(lin)\n-       #logger.info([np.polyval(PTC_fittee, i) for i in x_series])\n+       #logger.info([np.polyval(PTC_fit, i) for i in x_series])\n \n        #ax_scr.scatter(signal, variance, s = 10)\n        ax_scr.scatter(signal_without_outliers, variance_without_outliers, s = 10)\n \n        ax_scr.plot(x_series, lin, 'r', label='y={:.2f}x+{:.2f}'.format(res.slope,res.intercept))\n-       ax_scr.plot(x_series, [np.polyval(PTC_fittee, i) for i in x_series], 'g', label = 'Truncated PTC fitted')\n+       ax_scr.plot(x_series, [np.polyval(PTC_fit, i) for i in x_series], 'g', label = 'Truncated PTC fitted')\n        ax_scr.set_xlabel(\"signal\")\n        ax_scr.set_ylabel(\"variance\")\n \n@@ -308,6 +306,7 @@ def mainMethod(args):\n        blooming_json_dict[quadname] = blooming_threshold_per_quadrant[ext]\n        \n        # creation of a json file to be put in the data product\n+       ptc_json_dict = dict()\n        for elmt_signal, elmt_var in zip(signal_without_outliers, variance_without_outliers):\n          ptc_json_dict[elmt_signal] = elmt_var\n \n@@ -351,15 +350,13 @@ def mainMethod(args):\n \n     DmUtils.save_product_metadata( data_product, dpdcalib_blooming)\n \n-    # adding to the data_product, inside Data.QualityParameterStorage, the json file containing the list of the PTC data points\n-    ptc_file = FileNameProvider().get_allowed_filename( processing_function = 'VIS',\n-                                                                    type_name           = \"list-PTCs\",\n-                                                                    instance_id         = '',\n-                                                                    extension           = '.json')\n-    ptc_file = os.path.join( args.workdir, \"data\", ptc_file)    \n-    with open(ptc_file, 'w') as fp:\n-      fp.write(json.dumps(ptc_json_list, indent=2, default=np.ndarray.tolist))\n-    logger.info(f\"ptc_file is : {ptc_file}\")\n+    # we add all the ptcs files into a single tar file, to be accessible at the eas\n+    ptc_file = workdir+\"/data/list-PTCs.tar\"\n+    with tarfile.open(ptc_file, \"w:gz\") as tar:\n+      for filename in ptc_json_list:\n+        logger.info(f\"in ptc_json_list, filename is : {filename}\")\n+        tar.add(os.path.join(workdir + \"/data/\", filename), arcname=filename)\n+   \n     FromToXML.add_quality_parameter_file(data_product, ptc_file)\n \n     DmUtils.save_product_metadata( data_product, dpdcalib_blooming)\n@@ -369,4 +366,4 @@ def mainMethod(args):\n     logger.info( \"#\")\n     logger.info( \"# Exiting %s mainMethod()\", __name__)\n     logger.info( \"#\")\n-\n+    \n",
                            "Merge branch 'feature_#23227_BloomingCalib' into 'release-13.0'",
                            "Catherine Grenet",
                            "2023-08-18T08:54:23.000+00:00",
                            "86b9126254e61be00921c6b685077f61c0904c32"
                        ],
                        [
                            "@@ -125,17 +125,17 @@ def mainMethod(args):\n     # the more the value is high, the more the flagmap contains data, and the less the corresponding quadrant has\n     max_flat_invalid_pixels = config.getint( 'BloomingCalib', 'max_flat_invalid_pixels', fallback=97490)\n \n-    # 144 values, one per quadrant\n+    # 144 values, one per quadrant, representing the blooming threshold in electrons\n     blooming_threshold_per_quadrant = np.empty(144)\n-    blooming_threshold_per_quadrant[:] = 65535\n+    blooming_threshold_per_quadrant[:] = 192000.0\n \n     blooming_json_dict = dict()\n     blooming_json_dict['model_name'] = \"VIS_blooming_calib\"\n     blooming_json_dict['date'] = time.ctime()\n     blooming_json_dict['source'] = \"\"\n     blooming_json_dict['author'] = __file__\n-    blooming_json_dict['units'] = \"e-/ADU\"   \n-    \n+    blooming_json_dict['units'] = \"e-\"   \n+\n     # contains the 144 json files that contain the PTC data\n     ptc_json_list = list()\n \n@@ -171,8 +171,8 @@ def mainMethod(args):\n \n        logger.info(list1)\n        logger.info(list2)\n-       image3D_flag_1 = fpe.file_layer_entry_point(list1, \"\", in_flagmap=list1_flg)\n-       image3D_flag_2 = fpe.file_layer_entry_point(list2, \"\", in_flagmap=list2_flg)\n+       image3D_flag_1, quadname = fpe.file_layer_entry_point(list1, \"\", in_flagmap=list1_flg)\n+       image3D_flag_2, _ = fpe.file_layer_entry_point(list2, \"\", in_flagmap=list2_flg)\n \n        signal, variance = ptc_compute.wharper(image3D_flag_1,\n                                               image3D_flag_2,\n@@ -240,7 +240,7 @@ def mainMethod(args):\n            distance_PTC = math.sqrt(np.power(([np.polyval(PTC_fit, signal_without_outliers[i])] - variance_without_outliers[i]), 2))\n            if distance_PTC > threshold_distance and signal_without_outliers[i] > PTC_fit_xlimit:\n                logger.info(\"Blooming threshold found at : %s\", signal_without_outliers[i])\n-               blooming_threshold_per_quadrant[ext] = signal_without_outliers[i]\n+               blooming_threshold_per_quadrant[ext] = signal_without_outliers[i] * config.getfloat( \"GainPerQuad\", quadname)\n                break\n \n        #######################\n@@ -298,11 +298,7 @@ def mainMethod(args):\n        #############################################################################################\n        # creation of the calibration product containing blooming threshold for all the quadrants\n        #############################################################################################\n-\n-       hdu = fits.open(detrended_quadrant_list[0], memmap=False)\n-       quadname = hdu[1].header[\"EXTNAME\"]\n-       hdu.close()\n-\n+       \n        # log of results\n        logger.info(f\"blooming threshold for quadrant {quadname} is : {blooming_threshold_per_quadrant[ext]}\")\n        \n",
                            "Merge branch 'release-13.0' into 'feature_#23227_BloomingCalib'",
                            "Thomas Flanet",
                            "2023-08-17T15:43:48.000+00:00",
                            "9d236be45ec452966840965083cd59dc82102cf0"
                        ],
                        [
                            "@@ -135,8 +135,6 @@ def mainMethod(args):\n     blooming_json_dict['source'] = \"\"\n     blooming_json_dict['author'] = __file__\n     blooming_json_dict['units'] = \"e-/ADU\"   \n-\n-    ptc_json_dict = dict()\n     \n     # contains the 144 json files that contain the PTC data\n     ptc_json_list = list()\n@@ -202,15 +200,15 @@ def mainMethod(args):\n            if signal[i] < PTC_fit_xlimit:\n                signal_truncated.append(signal[i])\n                variance_truncated.append(variance[i])\n-       # straight line to show the non-linearity effect when comparing to PTC_fittee\n-       PTC_droite_fittee = np.polyfit(signal_truncated, variance_truncated, 1)\n+       # straight line to show the non-linearity effect when comparing to PTC_fit\n+       straight_PTC_fit = np.polyfit(signal_truncated, variance_truncated, 1)\n \n        #######################\n \n        # computing the distance to the straight line (polynome of deg 1), to get rid off outliners\n        list_distance_to_line = []\n        for i in range(len(signal_truncated)):\n-           list_distance_to_line.append(math.sqrt(np.power(([np.polyval(PTC_droite_fittee, signal[i])] - variance[i]), 2)))\n+           list_distance_to_line.append(math.sqrt(np.power(([np.polyval(straight_PTC_fit, signal[i])] - variance[i]), 2)))\n \n        # computing the std of list_distance_to_line\n        std_points_from_line = np.std(list_distance_to_line)\n@@ -230,16 +228,16 @@ def mainMethod(args):\n        #######################\n \n        # fit of the actual PTC\n-       PTC_fittee = np.polyfit(signal_without_outliers, variance_without_outliers, 3)\n+       PTC_fit = np.polyfit(signal_without_outliers, variance_without_outliers, 3)\n \n        #######################\n \n        # computing the distance of the points to the curved fitted PTC\n        threshold_distance = 0\n        for i in range(len(signal_without_outliers)):\n-           threshold_distance = PTC_blooming_threshold*np.polyval(PTC_fittee, signal[i])\n+           threshold_distance = PTC_blooming_threshold*np.polyval(PTC_fit, signal[i])\n            #logger.info(threshold_distance)\n-           distance_PTC = math.sqrt(np.power(([np.polyval(PTC_fittee, signal_without_outliers[i])] - variance_without_outliers[i]), 2))\n+           distance_PTC = math.sqrt(np.power(([np.polyval(PTC_fit, signal_without_outliers[i])] - variance_without_outliers[i]), 2))\n            if distance_PTC > threshold_distance and signal_without_outliers[i] > PTC_fit_xlimit:\n                logger.info(\"Blooming threshold found at : %s\", signal_without_outliers[i])\n                blooming_threshold_per_quadrant[ext] = signal_without_outliers[i]\n@@ -255,7 +253,7 @@ def mainMethod(args):\n \n        #######################\n \n-       # print PTC_fittee\n+       # print PTC_fit\n        subdir = workdir+\"/Truncated_PTCs_graph_fit/\"\n        if not os.path.exists(subdir):\n            os.mkdir(subdir)\n@@ -267,16 +265,16 @@ def mainMethod(args):\n        x_series = np.linspace(signal_without_outliers[0],55000,len(signal_without_outliers))\n \n        lin = res.slope*x_series+res.intercept\n-       diff_nl = ([np.polyval(PTC_fittee, i) for i in x_series] - lin) / lin * 100\n+       diff_nl = ([np.polyval(PTC_fit, i) for i in x_series] - lin) / lin * 100\n        #logger.info(diff_nl)\n        #logger.info(lin)\n-       #logger.info([np.polyval(PTC_fittee, i) for i in x_series])\n+       #logger.info([np.polyval(PTC_fit, i) for i in x_series])\n \n        #ax_scr.scatter(signal, variance, s = 10)\n        ax_scr.scatter(signal_without_outliers, variance_without_outliers, s = 10)\n \n        ax_scr.plot(x_series, lin, 'r', label='y={:.2f}x+{:.2f}'.format(res.slope,res.intercept))\n-       ax_scr.plot(x_series, [np.polyval(PTC_fittee, i) for i in x_series], 'g', label = 'Truncated PTC fitted')\n+       ax_scr.plot(x_series, [np.polyval(PTC_fit, i) for i in x_series], 'g', label = 'Truncated PTC fitted')\n        ax_scr.set_xlabel(\"signal\")\n        ax_scr.set_ylabel(\"variance\")\n \n@@ -312,6 +310,7 @@ def mainMethod(args):\n        blooming_json_dict[quadname] = blooming_threshold_per_quadrant[ext]\n        \n        # creation of a json file to be put in the data product\n+       ptc_json_dict = dict()\n        for elmt_signal, elmt_var in zip(signal_without_outliers, variance_without_outliers):\n          ptc_json_dict[elmt_signal] = elmt_var\n \n@@ -355,15 +354,13 @@ def mainMethod(args):\n \n     DmUtils.save_product_metadata( data_product, dpdcalib_blooming)\n \n-    # adding to the data_product, inside Data.QualityParameterStorage, the json file containing the list of the PTC data points\n-    ptc_file = FileNameProvider().get_allowed_filename( processing_function = 'VIS',\n-                                                                    type_name           = \"list-PTCs\",\n-                                                                    instance_id         = '',\n-                                                                    extension           = '.json')\n-    ptc_file = os.path.join( args.workdir, \"data\", ptc_file)    \n-    with open(ptc_file, 'w') as fp:\n-      fp.write(json.dumps(ptc_json_list, indent=2, default=np.ndarray.tolist))\n-    logger.info(f\"ptc_file is : {ptc_file}\")\n+    # we add all the ptcs files into a single tar file, to be accessible at the eas\n+    ptc_file = workdir+\"/data/list-PTCs.tar\"\n+    with tarfile.open(ptc_file, \"w:gz\") as tar:\n+      for filename in ptc_json_list:\n+        logger.info(f\"in ptc_json_list, filename is : {filename}\")\n+        tar.add(os.path.join(workdir + \"/data/\", filename), arcname=filename)\n+   \n     FromToXML.add_quality_parameter_file(data_product, ptc_file)\n \n     DmUtils.save_product_metadata( data_product, dpdcalib_blooming)\n@@ -373,4 +370,4 @@ def mainMethod(args):\n     logger.info( \"#\")\n     logger.info( \"# Exiting %s mainMethod()\", __name__)\n     logger.info( \"#\")\n-\n+    \n",
                            "VIS_BloomingCalib : all outputs ptc data json files into list-ptc.tar file",
                            "Thomas Flanet",
                            "2023-08-17T17:18:18.000+02:00",
                            "e746dcb63185deec8678e8452020efe40bc3010d"
                        ],
                        [
                            "@@ -125,16 +125,16 @@ def mainMethod(args):\n     # the more the value is high, the more the flagmap contains data, and the less the corresponding quadrant has\n     max_flat_invalid_pixels = config.getint( 'BloomingCalib', 'max_flat_invalid_pixels', fallback=97490)\n \n-    # 144 values, one per quadrant\n+    # 144 values, one per quadrant, representing the blooming threshold in electrons\n     blooming_threshold_per_quadrant = np.empty(144)\n-    blooming_threshold_per_quadrant[:] = 65535\n+    blooming_threshold_per_quadrant[:] = 192000.0\n \n     blooming_json_dict = dict()\n     blooming_json_dict['model_name'] = \"VIS_blooming_calib\"\n     blooming_json_dict['date'] = time.ctime()\n     blooming_json_dict['source'] = \"\"\n     blooming_json_dict['author'] = __file__\n-    blooming_json_dict['units'] = \"e-/ADU\"   \n+    blooming_json_dict['units'] = \"e-\"   \n \n     ptc_json_dict = dict()\n     \n@@ -173,8 +173,8 @@ def mainMethod(args):\n \n        logger.info(list1)\n        logger.info(list2)\n-       image3D_flag_1 = fpe.file_layer_entry_point(list1, \"\", in_flagmap=list1_flg)\n-       image3D_flag_2 = fpe.file_layer_entry_point(list2, \"\", in_flagmap=list2_flg)\n+       image3D_flag_1, quadname = fpe.file_layer_entry_point(list1, \"\", in_flagmap=list1_flg)\n+       image3D_flag_2, _ = fpe.file_layer_entry_point(list2, \"\", in_flagmap=list2_flg)\n \n        signal, variance = ptc_compute.wharper(image3D_flag_1,\n                                               image3D_flag_2,\n@@ -242,7 +242,7 @@ def mainMethod(args):\n            distance_PTC = math.sqrt(np.power(([np.polyval(PTC_fittee, signal_without_outliers[i])] - variance_without_outliers[i]), 2))\n            if distance_PTC > threshold_distance and signal_without_outliers[i] > PTC_fit_xlimit:\n                logger.info(\"Blooming threshold found at : %s\", signal_without_outliers[i])\n-               blooming_threshold_per_quadrant[ext] = signal_without_outliers[i]\n+               blooming_threshold_per_quadrant[ext] = signal_without_outliers[i] * config.getfloat( \"GainPerQuad\", quadname)\n                break\n \n        #######################\n@@ -300,11 +300,7 @@ def mainMethod(args):\n        #############################################################################################\n        # creation of the calibration product containing blooming threshold for all the quadrants\n        #############################################################################################\n-\n-       hdu = fits.open(detrended_quadrant_list[0], memmap=False)\n-       quadname = hdu[1].header[\"EXTNAME\"]\n-       hdu.close()\n-\n+       \n        # log of results\n        logger.info(f\"blooming threshold for quadrant {quadname} is : {blooming_threshold_per_quadrant[ext]}\")\n        \n",
                            "Merge branch 'hotfix_23522_Blooming_unit' into 'release-13.0'",
                            "Catherine Grenet",
                            "2023-08-17T12:23:28.000+00:00",
                            "a48d6323d70857952b93630df42d84aac1144a4b"
                        ],
                        [
                            "@@ -142,7 +142,7 @@ def mainMethod(args):\n     ptc_json_list = list()\n \n     blooming_model_file = \"\"\n-    for ext in range(nquad-10, nquad):\n+    for ext in range(0, nquad):\n        logger.info (\"==>Processing quadrant %s\", ext)\n \n        # Here we need the pile of n exposures in input\n",
                            "Removing beginning of loop at nquad-10 done for testing",
                            "Thomas Flanet",
                            "2023-08-17T12:34:07.000+02:00",
                            "2cb46b0c9add7efe0f7e0c97f4d460382183fc00"
                        ],
                        [
                            "@@ -125,16 +125,16 @@ def mainMethod(args):\n     # the more the value is high, the more the flagmap contains data, and the less the corresponding quadrant has\n     max_flat_invalid_pixels = config.getint( 'BloomingCalib', 'max_flat_invalid_pixels', fallback=97490)\n \n-    # 144 values, one per quadrant\n+    # 144 values, one per quadrant, representing the blooming threshold in electrons\n     blooming_threshold_per_quadrant = np.empty(144)\n-    blooming_threshold_per_quadrant[:] = 65535\n+    blooming_threshold_per_quadrant[:] = 192000.0\n \n     blooming_json_dict = dict()\n     blooming_json_dict['model_name'] = \"VIS_blooming_calib\"\n     blooming_json_dict['date'] = time.ctime()\n     blooming_json_dict['source'] = \"\"\n     blooming_json_dict['author'] = __file__\n-    blooming_json_dict['units'] = \"e-/ADU\"   \n+    blooming_json_dict['units'] = \"e-\"   \n \n     ptc_json_dict = dict()\n     \n@@ -142,7 +142,7 @@ def mainMethod(args):\n     ptc_json_list = list()\n \n     blooming_model_file = \"\"\n-    for ext in range(0, nquad):\n+    for ext in range(nquad-10, nquad):\n        logger.info (\"==>Processing quadrant %s\", ext)\n \n        # Here we need the pile of n exposures in input\n@@ -173,8 +173,8 @@ def mainMethod(args):\n \n        logger.info(list1)\n        logger.info(list2)\n-       image3D_flag_1 = fpe.file_layer_entry_point(list1, \"\", in_flagmap=list1_flg)\n-       image3D_flag_2 = fpe.file_layer_entry_point(list2, \"\", in_flagmap=list2_flg)\n+       image3D_flag_1, quadname = fpe.file_layer_entry_point(list1, \"\", in_flagmap=list1_flg)\n+       image3D_flag_2, _ = fpe.file_layer_entry_point(list2, \"\", in_flagmap=list2_flg)\n \n        signal, variance = ptc_compute.wharper(image3D_flag_1,\n                                               image3D_flag_2,\n@@ -242,7 +242,7 @@ def mainMethod(args):\n            distance_PTC = math.sqrt(np.power(([np.polyval(PTC_fittee, signal_without_outliers[i])] - variance_without_outliers[i]), 2))\n            if distance_PTC > threshold_distance and signal_without_outliers[i] > PTC_fit_xlimit:\n                logger.info(\"Blooming threshold found at : %s\", signal_without_outliers[i])\n-               blooming_threshold_per_quadrant[ext] = signal_without_outliers[i]\n+               blooming_threshold_per_quadrant[ext] = signal_without_outliers[i] * config.getfloat( \"GainPerQuad\", quadname)\n                break\n \n        #######################\n@@ -300,11 +300,7 @@ def mainMethod(args):\n        #############################################################################################\n        # creation of the calibration product containing blooming threshold for all the quadrants\n        #############################################################################################\n-\n-       hdu = fits.open(detrended_quadrant_list[0], memmap=False)\n-       quadname = hdu[1].header[\"EXTNAME\"]\n-       hdu.close()\n-\n+       \n        # log of results\n        logger.info(f\"blooming threshold for quadrant {quadname} is : {blooming_threshold_per_quadrant[ext]}\")\n        \n",
                            "Hotfix #23522 : blooming unit passed to electrons",
                            "Thomas Flanet",
                            "2023-08-17T12:29:55.000+02:00",
                            "443f4d80864e2a839890ee1454fc3980deb0de69"
                        ]
                    ],
                    "VIS_Tasks_M/python/VIS_Tasks_M/VIS_CTI_Calibration.py": [
                        [
                            "@@ -89,6 +89,12 @@ def mainMethod(args):\n     pipe_tools.log_task_environment(logger)\n     logger.info(\"#\")\n \n+    os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n+    os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n+    os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n+    os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n+    os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n+\n     workdir = args.workdir + \"/\"\n     logdir = args.logdir\n     config_filename = workdir + args.config_filename\n",
                            "enviroment variables",
                            "James Nightingale",
                            "2023-08-21T10:15:35.000+01:00",
                            "9685640f2e7b05324b8623c9a80867322e7da0bc"
                        ]
                    ],
                    "VIS_Blooming/python/VIS_Blooming/file_entry_point.py": [
                        [
                            "@@ -107,4 +107,4 @@ def file_layer_entry_point(input_files, interm_dir, quadrant_id=None, in_flagmap\n         '''\n     image_stack = ma.array(image_stack32, mask=flagmap, copy=False)    \n     log.info(\"file_layer_entry_point(): end\")\n-    return image_stack\n+    return image_stack, quad_name\n",
                            "Merge branch 'release-13.0' of https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks into release-13.0",
                            "James Nightingale",
                            "2023-08-18T17:51:24.000+02:00",
                            "4e9c5ce4e2d2d168d895e7a749f715a3f289f8ca"
                        ]
                    ],
                    "VIS_Tasks_Common/python/VIS_Tasks_Common/FromToXML.py": [
                        [
                            "@@ -806,6 +806,7 @@ def master_dark_dp(fits_file):\n \n     # Open the FITS file\n     fits = fitsio.FITS(fits_file, 'r')\n+    pri_header = fits[0].read_header()\n     nhdu = fits[-1].get_extnum()\n     header = fits[1]. read_header()\n \n@@ -818,6 +819,8 @@ def master_dark_dp(fits_file):\n     data.DataLength  = header[\"NAXIS1\"] * header[\"NAXIS2\"]\n     data.ValidityRange = create_validity_range()\n     data.Filter        = vis_filter()\n+    data.ExposureTime = exposure_time(pri_header[\"EXPTIME\"], \"s\")\n+\n     # DataStorage\n     data.DataStorage = DmUtils.create_fits_storage(\n                            vis_stub.visMasterDarkStorageFitsFile,\n@@ -897,6 +900,9 @@ def master_flat_dp(fits_file):\n     data.ValidityRange = create_validity_range()\n     data.Filter        = vis_filter()\n \n+    #Do not do. see comment 23513\n+    #data.ExposureTime = exposure_time(prim_hdr[\"EXPTIME\"], \"s\")\n+\n     calib_unit = vis_stub.visLedForFlat()\n     # fail if keyword absent\n     calib_unit.LedId   = str( prim_hdr[\"LEDID\"])\n",
                            "Merge branch 'release-13.0' of https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks into release-13.0",
                            "James Nightingale",
                            "2023-08-18T17:51:24.000+02:00",
                            "4e9c5ce4e2d2d168d895e7a749f715a3f289f8ca"
                        ],
                        [
                            "@@ -806,6 +806,7 @@ def master_dark_dp(fits_file):\n \n     # Open the FITS file\n     fits = fitsio.FITS(fits_file, 'r')\n+    pri_header = fits[0].read_header()\n     nhdu = fits[-1].get_extnum()\n     header = fits[1]. read_header()\n \n@@ -818,6 +819,8 @@ def master_dark_dp(fits_file):\n     data.DataLength  = header[\"NAXIS1\"] * header[\"NAXIS2\"]\n     data.ValidityRange = create_validity_range()\n     data.Filter        = vis_filter()\n+    data.ExposureTime = exposure_time(pri_header[\"EXPTIME\"], \"s\")\n+\n     # DataStorage\n     data.DataStorage = DmUtils.create_fits_storage(\n                            vis_stub.visMasterDarkStorageFitsFile,\n@@ -897,6 +900,9 @@ def master_flat_dp(fits_file):\n     data.ValidityRange = create_validity_range()\n     data.Filter        = vis_filter()\n \n+    #Do not do. see comment 23513\n+    #data.ExposureTime = exposure_time(prim_hdr[\"EXPTIME\"], \"s\")\n+\n     calib_unit = vis_stub.visLedForFlat()\n     # fail if keyword absent\n     calib_unit.LedId   = str( prim_hdr[\"LEDID\"])\n@@ -917,7 +923,7 @@ def master_flat_dp(fits_file):\n # Single exposure catalog data product\n #-------------------------------------\n \n-def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs_date_time, raw_frame_id):\n+def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs_date_time, raw_frame_id=None):\n     \"\"\"Creates a VisCalibratedFrameCatalog from a FITS catalog\n \n     Parameters\n@@ -957,9 +963,10 @@ def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs\n     data.ObservationSequence= observation_sequence\n     data.ObservationDateTime = obs_date_time\n     data.Instrument = base_instrument()\n-    data.InputRawFrameReference = sys_stub.dataProductReference()\n-    data.InputRawFrameReference.ProductID = raw_frame_id\n-    data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n+    if raw_frame_id is not None:\n+      data.InputRawFrameReference = sys_stub.dataProductReference()\n+      data.InputRawFrameReference.ProductID = raw_frame_id\n+      data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n \n     # DataStorage\n     data_storage = DmUtils.create_fits_storage(vis_stub.visCalibratedCatalogFitsFile,\n@@ -976,7 +983,7 @@ def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs\n # Stack catalog data product\n #---------------------------\n \n-def stack_cat_dp(fits_catalog, spatial_footprint, observation_id, raw_frame_id=UNKNOWN_STRING):\n+def stack_cat_dp(fits_catalog, spatial_footprint, observation_id, raw_frame_id=None):\n     \"\"\"Creates a VisStackedFrameCatalog from a FITS catalog\n \n     Parameters\n@@ -1012,9 +1019,10 @@ def stack_cat_dp(fits_catalog, spatial_footprint, observation_id, raw_frame_id=U\n     # from cat:observationCatalog\n     data.ObservationId = observation_id\n     data.Instrument = base_instrument()\n-    data.InputRawFrameReference = sys_stub.dataProductReference()\n-    data.InputRawFrameReference.ProductID = raw_frame_id\n-    data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n+    if raw_frame_id is not None:\n+      data.InputRawFrameReference = sys_stub.dataProductReference()\n+      data.InputRawFrameReference.ProductID = raw_frame_id\n+      data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n \n     # DataStorage\n     data_storage = DmUtils.create_fits_storage(vis_stub.visStackedCatalogFitsFile,\n@@ -1483,12 +1491,10 @@ def create_analysis_dp( result_passed: bool, aux_file: str, raw_frame_id=None,\n \n \n     # InputRawFrameReference\n-    if raw_frame_id is None:\n-      # SM 3 apr 2023: dummy value waiting for \"InputRawFrameReference\" being optional in DM > 9.1.5\n-      raw_frame_id = \"PPO_VIS_TEST_PV-001_R0-2-outputSIM-0_MIGRATED_1679500947.7778997\"\n-    data.InputRawFrameReference = sys_stub.dataProductReference()\n-    data.InputRawFrameReference.ProductID = raw_frame_id\n-    data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n+    if raw_frame_id is not None:\n+      data.InputRawFrameReference = sys_stub.dataProductReference()\n+      data.InputRawFrameReference.ProductID = raw_frame_id\n+      data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n \n     if analysis_data is not None:\n        for filename in analysis_data:\n",
                            "Merge branch 'release-13.0' into develop: #23486 #23449 #23513 #23522 #23522 #23227: RawFrame ref id, CTI pipeline, MasterDark exptime, Blooming",
                            "Catherine Grenet",
                            "2023-08-18T17:40:14.000+02:00",
                            "df77b0959fe5839832e9710c622dc75f0c781705"
                        ],
                        [
                            "@@ -66,6 +66,8 @@ from ST_DataModelBindings.dpd.vis import vismasterdarkframe_stub\n from ST_DataModelBindings.dpd.vis import vismasterflatframe_stub\n from ST_DataModelBindings.dpd.vis import visstackedframe_stub\n from ST_DataModelBindings.dpd.vis import visnonlinearitymodel_stub\n+from ST_DataModelBindings.dpd.vis import visctimodel_stub\n+from ST_DataModelBindings.dpd.vis import viscticalibrationresults_stub\n from ST_DataModelBindings.dpd.vis import vispsfmodel_stub\n from ST_DataModelBindings.dpd.vis import visdistortionmodel_stub\n from ST_DataModelBindings.dpd.vis import vislargeflatcalibration_stub\n@@ -620,7 +622,8 @@ def create_visFileContainerDataContainer( file_name,\n     # Fill it with the given values\n     data_container.FileName   = file_name\n     data_container.filestatus = file_status\n-    data_container.FileType   = file_type\n+# SM 7 aug. 2023: deprecated, or maybe never existed?\n+#    data_container.FileType   = file_type\n     return data_container\n \n \n@@ -803,6 +806,7 @@ def master_dark_dp(fits_file):\n \n     # Open the FITS file\n     fits = fitsio.FITS(fits_file, 'r')\n+    pri_header = fits[0].read_header()\n     nhdu = fits[-1].get_extnum()\n     header = fits[1]. read_header()\n \n@@ -815,6 +819,8 @@ def master_dark_dp(fits_file):\n     data.DataLength  = header[\"NAXIS1\"] * header[\"NAXIS2\"]\n     data.ValidityRange = create_validity_range()\n     data.Filter        = vis_filter()\n+    data.ExposureTime = exposure_time(pri_header[\"EXPTIME\"], \"s\")\n+\n     # DataStorage\n     data.DataStorage = DmUtils.create_fits_storage(\n                            vis_stub.visMasterDarkStorageFitsFile,\n@@ -894,6 +900,9 @@ def master_flat_dp(fits_file):\n     data.ValidityRange = create_validity_range()\n     data.Filter        = vis_filter()\n \n+    #Do not do. see comment 23513\n+    #data.ExposureTime = exposure_time(prim_hdr[\"EXPTIME\"], \"s\")\n+\n     calib_unit = vis_stub.visLedForFlat()\n     # fail if keyword absent\n     calib_unit.LedId   = str( prim_hdr[\"LEDID\"])\n@@ -914,7 +923,7 @@ def master_flat_dp(fits_file):\n # Single exposure catalog data product\n #-------------------------------------\n \n-def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs_date_time, raw_frame_id):\n+def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs_date_time, raw_frame_id=None):\n     \"\"\"Creates a VisCalibratedFrameCatalog from a FITS catalog\n \n     Parameters\n@@ -954,9 +963,10 @@ def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs\n     data.ObservationSequence= observation_sequence\n     data.ObservationDateTime = obs_date_time\n     data.Instrument = base_instrument()\n-    data.InputRawFrameReference = sys_stub.dataProductReference()\n-    data.InputRawFrameReference.ProductID = raw_frame_id\n-    data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n+    if raw_frame_id is not None:\n+      data.InputRawFrameReference = sys_stub.dataProductReference()\n+      data.InputRawFrameReference.ProductID = raw_frame_id\n+      data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n \n     # DataStorage\n     data_storage = DmUtils.create_fits_storage(vis_stub.visCalibratedCatalogFitsFile,\n@@ -973,7 +983,7 @@ def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs\n # Stack catalog data product\n #---------------------------\n \n-def stack_cat_dp(fits_catalog, spatial_footprint, observation_id, raw_frame_id=UNKNOWN_STRING):\n+def stack_cat_dp(fits_catalog, spatial_footprint, observation_id, raw_frame_id=None):\n     \"\"\"Creates a VisStackedFrameCatalog from a FITS catalog\n \n     Parameters\n@@ -1009,9 +1019,10 @@ def stack_cat_dp(fits_catalog, spatial_footprint, observation_id, raw_frame_id=U\n     # from cat:observationCatalog\n     data.ObservationId = observation_id\n     data.Instrument = base_instrument()\n-    data.InputRawFrameReference = sys_stub.dataProductReference()\n-    data.InputRawFrameReference.ProductID = raw_frame_id\n-    data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n+    if raw_frame_id is not None:\n+      data.InputRawFrameReference = sys_stub.dataProductReference()\n+      data.InputRawFrameReference.ProductID = raw_frame_id\n+      data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n \n     # DataStorage\n     data_storage = DmUtils.create_fits_storage(vis_stub.visStackedCatalogFitsFile,\n@@ -1210,6 +1221,40 @@ def stack_dp( stack: str, survey_type: str, obsid: int, calblock_id: str,\n     return data_product\n \n \n+def cti_model_dp():\n+    \"\"\"\n+    Creates a DpdVisCTICalibrationResultsobject\n+\n+    Parameters\n+    ----------\n+    fits_file: filename containing cti calibration results (e.g. .zip files)\n+\n+    Returns\n+    -------\n+    DpdVisCTICalibrationResults object\n+    \"\"\"\n+\n+    import ST_DataModelBindings.ins_stub as ins_dict\n+\n+    # Create the data product\n+    data_product = viscticalibrationresults_stub.DpdVisCTICalibrationResults()\n+\n+    # Add Header\n+    data_product.Header = vis_generic_header(\"DpdVisCTICalibrationResults\", UNKNOWN_STRING)\n+\n+    # Add Data\n+    data = vis_stub.visCTICalibrationResults.Factory()\n+    # data.visCTICalibrationResults = storage\n+\n+    date_range = ins_dict.calibrationValidPeriod()\n+    date_range.TimestampStart = \"2023-02-21T00:00:00.000Z\"\n+    date_range.TimestampEnd = \"2023-02-22T00:00:00.000Z\"\n+\n+    data.ValidityRange = create_validity_range()\n+    data_product.Data = data\n+    return data_product\n+\n+\n def psfmodel_dp(fits_file: str, fits_file_grid: str):\n     \"\"\"Creates a DpdVisPSFModel\n \n@@ -1402,7 +1447,9 @@ def create_validation_requirementresult(requirement_id, requirement_result_passe\n \n     return requirement_result\n \n-def create_analysis_dp(result_passed: bool, aux_file: str, raw_frame_id=None, analysis_id=None, obs_seq_foranalysis=None, analysis_data=None):\n+\n+def create_analysis_dp( result_passed: bool, aux_file: str, raw_frame_id=None,\n+                        analysis_id=None, obs_seq_foranalysis=None, analysis_data=None):\n     \"\"\"Create a new DpdVisAnalysisResult data product, normally with an associated tar/zip file.\n     Parameters\n     ----------\n@@ -1444,21 +1491,19 @@ def create_analysis_dp(result_passed: bool, aux_file: str, raw_frame_id=None, an\n \n \n     # InputRawFrameReference\n-    if raw_frame_id is None:\n-      # SM 3 apr 2023: dummy value waiting for \"InputRawFrameReference\" being optional in DM > 9.1.5\n-      raw_frame_id = \"PPO_VIS_TEST_PV-001_R0-2-outputSIM-0_MIGRATED_1679500947.7778997\"\n-    data.InputRawFrameReference = sys_stub.dataProductReference()\n-    data.InputRawFrameReference.ProductID = raw_frame_id\n-    data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n+    if raw_frame_id is not None:\n+      data.InputRawFrameReference = sys_stub.dataProductReference()\n+      data.InputRawFrameReference.ProductID = raw_frame_id\n+      data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n \n     if analysis_data is not None:\n        for filename in analysis_data:\n-         analysis_data = vis_stub.visAnalysisData.Factory()\n-         analysis_data.DataContainer = dss_stub.dataContainer.Factory()\n-         analysis_data.DataContainer.FileName = os.path.basename(filename)\n-         analysis_data.DataContainer.filestatus = \"PROPOSED\"\n-         analysis_data.DataContainer.FileType = \"fits\"\n-         data.AnalysisData.append(analysis_data)\n+         if (filename is not None) and (len( filename.strip()) > 0):\n+           vis_analysis_data = vis_stub.visAnalysisData.Factory()\n+           vis_analysis_data.DataContainer = dss_stub.dataContainer.Factory()\n+           vis_analysis_data.DataContainer.FileName = os.path.basename( filename)\n+           vis_analysis_data.DataContainer.filestatus = \"PROPOSED\"\n+           data.AnalysisData.append( vis_analysis_data)\n \n     data_product.Data = data\n     return data_product\n",
                            "Merge branch 'release-13.0' into 'feature_#23227_BloomingCalib'",
                            "Thomas Flanet",
                            "2023-08-17T15:43:48.000+00:00",
                            "9d236be45ec452966840965083cd59dc82102cf0"
                        ],
                        [
                            "@@ -1198,16 +1198,16 @@ def stack_dp( stack: str, survey_type: str, obsid: int, calblock_id: str,\n     data.DataStorage = DmUtils.create_fits_storage(\n                                vis_stub.visStackedStorageFitsFile,\n                                os.path.basename(stack), \"vis.stackedImage\", \"0.1\")\n-    if len( fits) > 1:\n+    data.BackgroundStorage = DmUtils.create_fits_storage(\n+                               vis_stub.visBackgroundStorageFitsFile,\n+                               os.path.basename(background), \"vis.backgroundMap\", \"0.1\")\n+    data.WeightStorage = DmUtils.create_fits_storage(\n+                               vis_stub.visWeightStorageFitsFile,\n+                               os.path.basename(weightmap), \"vis.weightMap\", \"0.1\")\n+    if psf is not None:\n       data.PsfModelStorage = DmUtils.create_fits_storage(\n                                  vis_stub.visPsfModelStorageFitsFile,\n-                                 psf, \"vis.psfModel\", \"0.1\")\n-      data.BackgroundStorage = DmUtils.create_fits_storage(\n-                                 vis_stub.visBackgroundStorageFitsFile,\n-                                 background, \"vis.backgroundMap\", \"0.1\")\n-      data.WeightStorage = DmUtils.create_fits_storage(\n-                                 vis_stub.visWeightStorageFitsFile,\n-                                 weightmap, \"vis.weightMap\", \"0.1\")\n+                                 os.path.basename(psf), \"vis.psfModel\", \"0.1\")\n     data_product.Data = data\n \n     return data_product\n",
                            "FromToXML.py: fix #23266: stacking output product XML is empty when Stack_Photometry=False and stack PSF file is None",
                            "Sylvain Mottet",
                            "2023-08-17T16:38:27.000+02:00",
                            "1516bfee461de41dc3ea115eef59f5c8f22f543e"
                        ],
                        [
                            "@@ -900,7 +900,8 @@ def master_flat_dp(fits_file):\n     data.ValidityRange = create_validity_range()\n     data.Filter        = vis_filter()\n \n-    data.ExposureTime = exposure_time(prim_header[\"EXPTIME\"], \"s\")\n+    #Do not do. see comment 23513\n+    #data.ExposureTime = exposure_time(prim_hdr[\"EXPTIME\"], \"s\")\n \n     calib_unit = vis_stub.visLedForFlat()\n     # fail if keyword absent\n",
                            "commented out line in regars to exptime on master_flat",
                            "Kevin Benson",
                            "2023-08-16T22:20:56.000+02:00",
                            "47786e7b9fd2230541f63c8c414b4994a0320869"
                        ],
                        [
                            "@@ -806,6 +806,7 @@ def master_dark_dp(fits_file):\n \n     # Open the FITS file\n     fits = fitsio.FITS(fits_file, 'r')\n+    pri_header = fits[0].read_header()\n     nhdu = fits[-1].get_extnum()\n     header = fits[1]. read_header()\n \n@@ -818,6 +819,8 @@ def master_dark_dp(fits_file):\n     data.DataLength  = header[\"NAXIS1\"] * header[\"NAXIS2\"]\n     data.ValidityRange = create_validity_range()\n     data.Filter        = vis_filter()\n+    data.ExposureTime = exposure_time(pri_header[\"EXPTIME\"], \"s\")\n+\n     # DataStorage\n     data.DataStorage = DmUtils.create_fits_storage(\n                            vis_stub.visMasterDarkStorageFitsFile,\n@@ -897,6 +900,8 @@ def master_flat_dp(fits_file):\n     data.ValidityRange = create_validity_range()\n     data.Filter        = vis_filter()\n \n+    data.ExposureTime = exposure_time(prim_header[\"EXPTIME\"], \"s\")\n+\n     calib_unit = vis_stub.visLedForFlat()\n     # fail if keyword absent\n     calib_unit.LedId   = str( prim_hdr[\"LEDID\"])\n",
                            "Added Exposure time to the MasterDark data product",
                            "Kevin Benson",
                            "2023-08-16T20:16:38.000+02:00",
                            "b566251e2dd523158fabcc5f01e347161c8370f2"
                        ],
                        [
                            "@@ -917,7 +917,7 @@ def master_flat_dp(fits_file):\n # Single exposure catalog data product\n #-------------------------------------\n \n-def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs_date_time, raw_frame_id):\n+def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs_date_time, raw_frame_id=None):\n     \"\"\"Creates a VisCalibratedFrameCatalog from a FITS catalog\n \n     Parameters\n@@ -957,9 +957,10 @@ def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs\n     data.ObservationSequence= observation_sequence\n     data.ObservationDateTime = obs_date_time\n     data.Instrument = base_instrument()\n-    data.InputRawFrameReference = sys_stub.dataProductReference()\n-    data.InputRawFrameReference.ProductID = raw_frame_id\n-    data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n+    if raw_frame_id is not None:\n+      data.InputRawFrameReference = sys_stub.dataProductReference()\n+      data.InputRawFrameReference.ProductID = raw_frame_id\n+      data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n \n     # DataStorage\n     data_storage = DmUtils.create_fits_storage(vis_stub.visCalibratedCatalogFitsFile,\n@@ -976,7 +977,7 @@ def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs\n # Stack catalog data product\n #---------------------------\n \n-def stack_cat_dp(fits_catalog, spatial_footprint, observation_id, raw_frame_id=UNKNOWN_STRING):\n+def stack_cat_dp(fits_catalog, spatial_footprint, observation_id, raw_frame_id=None):\n     \"\"\"Creates a VisStackedFrameCatalog from a FITS catalog\n \n     Parameters\n@@ -1012,9 +1013,10 @@ def stack_cat_dp(fits_catalog, spatial_footprint, observation_id, raw_frame_id=U\n     # from cat:observationCatalog\n     data.ObservationId = observation_id\n     data.Instrument = base_instrument()\n-    data.InputRawFrameReference = sys_stub.dataProductReference()\n-    data.InputRawFrameReference.ProductID = raw_frame_id\n-    data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n+    if raw_frame_id is not None:\n+      data.InputRawFrameReference = sys_stub.dataProductReference()\n+      data.InputRawFrameReference.ProductID = raw_frame_id\n+      data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n \n     # DataStorage\n     data_storage = DmUtils.create_fits_storage(vis_stub.visStackedCatalogFitsFile,\n@@ -1483,12 +1485,10 @@ def create_analysis_dp( result_passed: bool, aux_file: str, raw_frame_id=None,\n \n \n     # InputRawFrameReference\n-    if raw_frame_id is None:\n-      # SM 3 apr 2023: dummy value waiting for \"InputRawFrameReference\" being optional in DM > 9.1.5\n-      raw_frame_id = \"PPO_VIS_TEST_PV-001_R0-2-outputSIM-0_MIGRATED_1679500947.7778997\"\n-    data.InputRawFrameReference = sys_stub.dataProductReference()\n-    data.InputRawFrameReference.ProductID = raw_frame_id\n-    data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n+    if raw_frame_id is not None:\n+      data.InputRawFrameReference = sys_stub.dataProductReference()\n+      data.InputRawFrameReference.ProductID = raw_frame_id\n+      data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n \n     if analysis_data is not None:\n        for filename in analysis_data:\n",
                            "Merge branch 'release-14.0' of https://gitlab.euclid-sgs.uk/PF-VIS/VIS_Tasks into release-13.0",
                            "James Nightingale",
                            "2023-08-16T13:55:08.000+02:00",
                            "60250922c95bed9dd480e534c9064ec00867b8e7"
                        ],
                        [
                            "@@ -917,7 +917,7 @@ def master_flat_dp(fits_file):\n # Single exposure catalog data product\n #-------------------------------------\n \n-def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs_date_time, raw_frame_id):\n+def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs_date_time, raw_frame_id=None):\n     \"\"\"Creates a VisCalibratedFrameCatalog from a FITS catalog\n \n     Parameters\n@@ -957,9 +957,10 @@ def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs\n     data.ObservationSequence= observation_sequence\n     data.ObservationDateTime = obs_date_time\n     data.Instrument = base_instrument()\n-    data.InputRawFrameReference = sys_stub.dataProductReference()\n-    data.InputRawFrameReference.ProductID = raw_frame_id\n-    data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n+    if raw_frame_id is not None:\n+      data.InputRawFrameReference = sys_stub.dataProductReference()\n+      data.InputRawFrameReference.ProductID = raw_frame_id\n+      data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n \n     # DataStorage\n     data_storage = DmUtils.create_fits_storage(vis_stub.visCalibratedCatalogFitsFile,\n@@ -976,7 +977,7 @@ def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs\n # Stack catalog data product\n #---------------------------\n \n-def stack_cat_dp(fits_catalog, spatial_footprint, observation_id, raw_frame_id=UNKNOWN_STRING):\n+def stack_cat_dp(fits_catalog, spatial_footprint, observation_id, raw_frame_id=None):\n     \"\"\"Creates a VisStackedFrameCatalog from a FITS catalog\n \n     Parameters\n@@ -1012,9 +1013,10 @@ def stack_cat_dp(fits_catalog, spatial_footprint, observation_id, raw_frame_id=U\n     # from cat:observationCatalog\n     data.ObservationId = observation_id\n     data.Instrument = base_instrument()\n-    data.InputRawFrameReference = sys_stub.dataProductReference()\n-    data.InputRawFrameReference.ProductID = raw_frame_id\n-    data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n+    if raw_frame_id is not None:\n+      data.InputRawFrameReference = sys_stub.dataProductReference()\n+      data.InputRawFrameReference.ProductID = raw_frame_id\n+      data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n \n     # DataStorage\n     data_storage = DmUtils.create_fits_storage(vis_stub.visStackedCatalogFitsFile,\n@@ -1483,12 +1485,10 @@ def create_analysis_dp( result_passed: bool, aux_file: str, raw_frame_id=None,\n \n \n     # InputRawFrameReference\n-    if raw_frame_id is None:\n-      # SM 3 apr 2023: dummy value waiting for \"InputRawFrameReference\" being optional in DM > 9.1.5\n-      raw_frame_id = \"PPO_VIS_TEST_PV-001_R0-2-outputSIM-0_MIGRATED_1679500947.7778997\"\n-    data.InputRawFrameReference = sys_stub.dataProductReference()\n-    data.InputRawFrameReference.ProductID = raw_frame_id\n-    data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n+    if raw_frame_id is not None:\n+      data.InputRawFrameReference = sys_stub.dataProductReference()\n+      data.InputRawFrameReference.ProductID = raw_frame_id\n+      data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n \n     if analysis_data is not None:\n        for filename in analysis_data:\n",
                            "Merge branch 'hotfix_23486_rawrefid' into 'release-13.0'",
                            "Catherine Grenet",
                            "2023-08-15T15:01:47.000+00:00",
                            "5da7f29fe620e0f90f5ed152f6d02137a45a2aec"
                        ],
                        [
                            "@@ -917,7 +917,7 @@ def master_flat_dp(fits_file):\n # Single exposure catalog data product\n #-------------------------------------\n \n-def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs_date_time, raw_frame_id):\n+def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs_date_time, raw_frame_id=None):\n     \"\"\"Creates a VisCalibratedFrameCatalog from a FITS catalog\n \n     Parameters\n@@ -957,9 +957,10 @@ def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs\n     data.ObservationSequence= observation_sequence\n     data.ObservationDateTime = obs_date_time\n     data.Instrument = base_instrument()\n-    data.InputRawFrameReference = sys_stub.dataProductReference()\n-    data.InputRawFrameReference.ProductID = raw_frame_id\n-    data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n+    if raw_frame_id is not None:\n+      data.InputRawFrameReference = sys_stub.dataProductReference()\n+      data.InputRawFrameReference.ProductID = raw_frame_id\n+      data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n \n     # DataStorage\n     data_storage = DmUtils.create_fits_storage(vis_stub.visCalibratedCatalogFitsFile,\n@@ -976,7 +977,7 @@ def single_exp_cat_dp(fits_catalog, spatial_footprint, observation_sequence, obs\n # Stack catalog data product\n #---------------------------\n \n-def stack_cat_dp(fits_catalog, spatial_footprint, observation_id, raw_frame_id=UNKNOWN_STRING):\n+def stack_cat_dp(fits_catalog, spatial_footprint, observation_id, raw_frame_id=None):\n     \"\"\"Creates a VisStackedFrameCatalog from a FITS catalog\n \n     Parameters\n@@ -1012,9 +1013,10 @@ def stack_cat_dp(fits_catalog, spatial_footprint, observation_id, raw_frame_id=U\n     # from cat:observationCatalog\n     data.ObservationId = observation_id\n     data.Instrument = base_instrument()\n-    data.InputRawFrameReference = sys_stub.dataProductReference()\n-    data.InputRawFrameReference.ProductID = raw_frame_id\n-    data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n+    if raw_frame_id is not None:\n+      data.InputRawFrameReference = sys_stub.dataProductReference()\n+      data.InputRawFrameReference.ProductID = raw_frame_id\n+      data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n \n     # DataStorage\n     data_storage = DmUtils.create_fits_storage(vis_stub.visStackedCatalogFitsFile,\n@@ -1483,12 +1485,10 @@ def create_analysis_dp( result_passed: bool, aux_file: str, raw_frame_id=None,\n \n \n     # InputRawFrameReference\n-    if raw_frame_id is None:\n-      # SM 3 apr 2023: dummy value waiting for \"InputRawFrameReference\" being optional in DM > 9.1.5\n-      raw_frame_id = \"PPO_VIS_TEST_PV-001_R0-2-outputSIM-0_MIGRATED_1679500947.7778997\"\n-    data.InputRawFrameReference = sys_stub.dataProductReference()\n-    data.InputRawFrameReference.ProductID = raw_frame_id\n-    data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n+    if raw_frame_id is not None:\n+      data.InputRawFrameReference = sys_stub.dataProductReference()\n+      data.InputRawFrameReference.ProductID = raw_frame_id\n+      data.InputRawFrameReference.ProductType = \"DpdVisRawFrame\"\n \n     if analysis_data is not None:\n        for filename in analysis_data:\n",
                            "FromToXML.py: fix #23486, InputRawFrameReference default value doesn't exist in EUCLID, don't use it",
                            "Sylvain Mottet",
                            "2023-08-15T12:16:24.000+02:00",
                            "fbb506691507f59dfaefdd55253aa0d95a45d144"
                        ]
                    ],
                    "VIS_Tasks_M/python/VIS_Tasks_M/VIS_cti_xml_out.py": [
                        [
                            "@@ -9,6 +9,7 @@ import argparse\n import os\r\n import json\r\n from pathlib import Path\r\n+import tarfile\r\n from typing import Union\r\n \r\n \r\n@@ -34,7 +35,8 @@ def defineSpecificProgramOptions():\n     parser.add_argument( '--workdir',                    required=True,  help='absolute path to the workdir')\r\n     parser.add_argument( '--logdir',                     required=True,  help='path to the logdir, relative to the workdir')\r\n     parser.add_argument('--config',                                      help='configuration file path')\r\n-    parser.add_argument( '--calibrate_cti_results_list', required=True,  help='Path to the CTI calibration results json file')\r\n+    parser.add_argument( '--parallel_calibrate_cti_results_list', required=True,  help='Path to the parallel CTI calibration results json file')\r\n+    parser.add_argument( '--serial_calibrate_cti_results_list', required=True,  help='Path to the serial CTI calibration results json file')\r\n     # outputs\r\n     parser.add_argument( '--parallel_cti_xml_out',                required=True,  help='output parallel CTI results xml filename')\r\n     parser.add_argument( '--serial_cti_xml_out',                required=True,  help='output serial CTI results xml filename')\r\n@@ -42,8 +44,10 @@ def defineSpecificProgramOptions():\n \r\n ################################################################################\r\n \r\n-def write_tar_zip(in_files: list[Union[Path, str]], out_file: Path) -> None:\r\n-  tar_zip_files(\" \".join(map(str, in_files)), str(out_file), False)\r\n+def create_tar_gz(output_filename, folders_to_compress):\r\n+  with tarfile.open(output_filename, \"w:gz\") as tar:\r\n+    for folder in folders_to_compress:\r\n+      tar.add(folder, arcname=os.path.basename(folder))\r\n \r\n \r\n def mainMethod( args):\r\n@@ -59,6 +63,9 @@ def mainMethod( args):\n   if not os.path.isabs( args.parallel_cti_xml_out):\r\n     args.parallel_cti_xml_out = os.path.join( args.workdir, args.parallel_cti_xml_out)\r\n \r\n+  if not os.path.isabs( args.serial_cti_xml_out):\r\n+    args.serial_cti_xml_out = os.path.join( args.workdir, args.serial_cti_xml_out)\r\n+\r\n   out_dir = os.path.split(args.parallel_cti_xml_out )[0]\r\n   os.makedirs(out_dir, exist_ok=True)\r\n \r\n@@ -73,18 +80,22 @@ def mainMethod( args):\n   # {\"ModelInfo\": \"/sps/euclid/Users/jnightin/workspaces/ctical/ppo_root/workdir//output/2022-10-13T11:37:14.399Z_CCD6-4/parallel[x1]/2f929b8acbe296cfb1102229221a7438/model.info\"}\r\n   \"\"\"\r\n \r\n-  with open(args.calibrate_cti_results_list, \"r\") as f:\r\n-    cti_per_ccd_list = json.load(f)\r\n+  with open(args.parallel_calibrate_cti_results_list, \"r\") as f:\r\n+    parallel_cti_per_ccd_list = json.load(f)\r\n+\r\n+  with open(args.serial_calibrate_cti_results_list, \"r\") as f:\r\n+    serial_cti_per_ccd_list = json.load(f)\r\n+\r\n+  cti_per_ccd_list = parallel_cti_per_ccd_list + serial_cti_per_ccd_list\r\n \r\n   cti_result_list = []\r\n \r\n   for cti_for_ccd_list in cti_per_ccd_list:\r\n-    for cti_direction in cti_for_ccd_list:\r\n \r\n-        with open(cti_direction, \"r\") as f:\r\n+     with open(cti_for_ccd_list, \"r\") as f:\r\n \r\n-          cti_result = json.load(f)\r\n-          cti_result_list.append(cti_result)\r\n+        cti_result = json.load(f)\r\n+        cti_result_list.append(cti_result)\r\n \r\n \r\n   logger.info( f\"reading {len( cti_per_ccd_list)} CCD CTI calibration files\")\r\n@@ -207,9 +218,14 @@ def mainMethod( args):\n     instance_id='',\r\n     extension='.tar.gz'\r\n   )\r\n+\r\n+  # parallel_dq_tar_path contains a list of folders, which are now zipped into a .tar.gz file:\r\n   parallel_dq_tar_path = os.path.join(args.workdir, \"data\", parallel_dq_file)\r\n \r\n-  write_tar_zip(parallel_dq_file_list, parallel_dq_tar_path)\r\n+  create_tar_gz(\r\n+    output_filename=parallel_dq_tar_path,\r\n+    folders_to_compress=parallel_dq_file_list\r\n+  )\r\n   add_quality_parameter_file(data_product, parallel_dq_file)\r\n \r\n   dqc_params_dm = vis_stub.visDqcParams.Factory()\r\n@@ -258,7 +274,10 @@ def mainMethod( args):\n \r\n   serial_dq_tar_path = os.path.join(args.workdir, \"data\", serial_dq_file)\r\n \r\n-  write_tar_zip(serial_dq_file_list, serial_dq_tar_path)\r\n+  create_tar_gz(\r\n+    output_filename=serial_dq_tar_path,\r\n+    folders_to_compress=serial_dq_file_list\r\n+  )\r\n   add_quality_parameter_file(data_product, serial_dq_file)\r\n   \r\n   dqc_params_dm = vis_stub.visDqcParams.Factory()\r\n",
                            "Merge branch 'release-13.0' into develop: #23486 #23449 #23513 #23522 #23522 #23227: RawFrame ref id, CTI pipeline, MasterDark exptime, Blooming",
                            "Catherine Grenet",
                            "2023-08-18T17:40:14.000+02:00",
                            "df77b0959fe5839832e9710c622dc75f0c781705"
                        ],
                        [
                            "@@ -1,5 +1,5 @@\n \"\"\"\r\n-@file: python/Tasks/VIS_cti_xml_out.py\r\n+@file: python/Tasks/VIS_parallel_cti_xml_out.py\r\n @author: user\r\n @date: 21/02/2023\r\n \"\"\"\r\n@@ -7,24 +7,19 @@\n #Standard library imports\r\n import argparse\r\n import os\r\n-import shutil\r\n import json\r\n+from pathlib import Path\r\n import tarfile\r\n-import time\r\n-\r\n-from types import SimpleNamespace as Namespace\r\n+from typing import Union\r\n \r\n \r\n # Euclid specific imports\r\n from ST_DM_FilenameProvider.FilenameProvider import FileNameProvider\r\n-from ST_DM_DmUtils import DmUtils\r\n-from ST_DataModelBindings.dpd.vis import visctimodel_stub\r\n from ST_DataModelBindings.pro import vis_stub\r\n-import ST_DataModelBindings.ins_stub as ins_dict\r\n from ST_DM_DmUtils.DmUtils import create_data_container, save_product_metadata\r\n-from VIS_Tasks_Common.FromToXML import vis_generic_header, UNKNOWN_STRING\r\n+from VIS_Tasks_Common.FromToXML import create_validity_range, vis_generic_header, UNKNOWN_STRING, add_quality_parameter_file\r\n \r\n-from VIS_Tasks_Common import FromToXML\r\n+from VIS_PyLibrary_Common.zip_tools import tar_zip_files\r\n from VIS_PyLibrary_Common import pipe_tools\r\n \r\n import ElementsKernel.Logging\r\n@@ -39,13 +34,22 @@ def defineSpecificProgramOptions():\n     # inputs\r\n     parser.add_argument( '--workdir',                    required=True,  help='absolute path to the workdir')\r\n     parser.add_argument( '--logdir',                     required=True,  help='path to the logdir, relative to the workdir')\r\n-    parser.add_argument( '--calibrate_cti_results_list', required=True,  help='Path to the CTI calibration results json file')\r\n+    parser.add_argument('--config',                                      help='configuration file path')\r\n+    parser.add_argument( '--parallel_calibrate_cti_results_list', required=True,  help='Path to the parallel CTI calibration results json file')\r\n+    parser.add_argument( '--serial_calibrate_cti_results_list', required=True,  help='Path to the serial CTI calibration results json file')\r\n     # outputs\r\n-    parser.add_argument( '--cti_xml_out',                required=True,  help='output CTI results xml filename')\r\n+    parser.add_argument( '--parallel_cti_xml_out',                required=True,  help='output parallel CTI results xml filename')\r\n+    parser.add_argument( '--serial_cti_xml_out',                required=True,  help='output serial CTI results xml filename')\r\n     return parser\r\n \r\n ################################################################################\r\n \r\n+def create_tar_gz(output_filename, folders_to_compress):\r\n+  with tarfile.open(output_filename, \"w:gz\") as tar:\r\n+    for folder in folders_to_compress:\r\n+      tar.add(folder, arcname=os.path.basename(folder))\r\n+\r\n+\r\n def mainMethod( args):\r\n \r\n   logger.info( '#')\r\n@@ -56,93 +60,235 @@ def mainMethod( args):\n   \r\n   # Create workdir folders for XML files if not present:\r\n   \r\n-  if not os.path.isabs( args.cti_xml_out):\r\n-    args.cti_xml_out = os.path.join( args.workdir, args.cti_xml_out)\r\n+  if not os.path.isabs( args.parallel_cti_xml_out):\r\n+    args.parallel_cti_xml_out = os.path.join( args.workdir, args.parallel_cti_xml_out)\r\n+\r\n+  if not os.path.isabs( args.serial_cti_xml_out):\r\n+    args.serial_cti_xml_out = os.path.join( args.workdir, args.serial_cti_xml_out)\r\n \r\n-  out_dir = os.path.split(args.cti_xml_out )[0]\r\n+  out_dir = os.path.split(args.parallel_cti_xml_out )[0]\r\n   os.makedirs(out_dir, exist_ok=True)\r\n \r\n-  # get an Euclid compliant filename to store XML\r\n+  \"\"\"\r\n+  calibrate_cti_results_list: is a .json file containing strings with the names of 72.json files in the workdir, \r\n+  each are parallel and serial fits per ccd.\r\n   \r\n-  # TODO : Need to check if type_name is a good name or not\r\n-  \r\n-  datafile_out = FileNameProvider().get_allowed_filename( processing_function='VIS',\r\n-                                                          type_name          =\"MDL-CTICORR-000-000000-0000000\",\r\n-                                                          instance_id        ='',\r\n-                                                          extension          ='.json')\r\n-  datafile_out = os.path.join( args.workdir, \"data\", datafile_out)\r\n-  \r\n-  # concatenate the CTI models in datafile_out\r\n+  cti_per_ccd is a list of 72 .json files, where each .json files is a dictionary of the results of the CTI calibration p\r\n+  ipeline. For each, the first .json file is called CCD1-1_parallel.json, which will look something like the following:\r\n \r\n-  # calibrate_cti_results_list: is a .json file containing strings with the names of 72.json files in the workdir, each are parallel and serial fits per ccd.\r\n-  # cti_per_ccd is a list of 72 .json files, where each .json files is a dictionary of the results of the CTI calibration pipeline.\r\n-  # For each, the first .json file is called CCD1-1_parallel.json, which will look something like the following:\r\n-\r\n-  # {\"MultiNestZip\": \"/sps/euclid/Users/jnightin/workspaces/ctical/ppo_root/workdir//output/2022-10-13T11:37:14.399Z_CCD6-4/parallel[x1]/2f929b8acbe296cfb1102229221a7438.zip\",\r\n+  # {\"ModelResult\": \"/sps/euclid/Users/jnightin/workspaces/ctical/ppo_root/workdir//output/2022-10-13T11:37:14.399Z_CCD6-4/parallel[x1]/2f929b8acbe296cfb1102229221a7438.zip\",\r\n   # {\"ModelInfo\": \"/sps/euclid/Users/jnightin/workspaces/ctical/ppo_root/workdir//output/2022-10-13T11:37:14.399Z_CCD6-4/parallel[x1]/2f929b8acbe296cfb1102229221a7438/model.info\"}\r\n+  \"\"\"\r\n \r\n-  cti_per_ccd = FromToXML.load_list_from_file( args.calibrate_cti_results_list)\r\n+  with open(args.parallel_calibrate_cti_results_list, \"r\") as f:\r\n+    parallel_cti_per_ccd_list = json.load(f)\r\n \r\n-  logger.info( f\"reading {len( cti_per_ccd)} CCD CTI calibration files\")\r\n+  with open(args.serial_calibrate_cti_results_list, \"r\") as f:\r\n+    serial_cti_per_ccd_list = json.load(f)\r\n \r\n-  cti_out = dict()\r\n-  cti_out[\"creator\"]     = __file__\r\n-  cti_out[\"date\"]        = time.ctime()\r\n-  cti_out[\"description\"] = \"The CTI Calibration results contains for each CCD the results of a Dynesty model-fit to charge injection data and other datasets. \"\r\n+  cti_per_ccd_list = parallel_cti_per_ccd_list + serial_cti_per_ccd_list\r\n \r\n-  # This loop updates the cti_out dictionary with each key of the .json file containing the 72 model fits.\r\n+  cti_result_list = []\r\n \r\n-  # For example, the first iteration loads the result:\r\n+  for cti_for_ccd_list in cti_per_ccd_list:\r\n \r\n-  # {\"Something\":/sps/euclid/Users/jnightin/workspaces/ctical/ppo_root/workdir/cti_calibration_results/CCD1-1_parallel.json\"}\r\n+     with open(cti_for_ccd_list, \"r\") as f:\r\n \r\n-  for cti_file in cti_per_ccd:\r\n-    with open( cti_file, \"r\") as f:\r\n-      cti_out.update( json.load( f))\r\n-  logger.info( \"writing CTI calibration data product to \" + datafile_out)\r\n+        cti_result = json.load(f)\r\n+        cti_result_list.append(cti_result)\r\n \r\n-  # This loop dumps each result in this dictionary to a new .json file, for some reason.\r\n \r\n-  with open( datafile_out, \"w\") as f:\r\n-    json.dump( cti_out, f, indent=2)\r\n+  logger.info( f\"reading {len( cti_per_ccd_list)} CCD CTI calibration files\")\r\n \r\n-  # create and write the xml data product encapsulating the datafile_out json file\r\n-  logger.info( \"writing data product XML to \" + args.cti_xml_out)\r\n-  data_product = FromToXML.cti_model_dp()\r\n+  from ST_DM_DmUtils import DmUtils\r\n+  from ST_DataModelBindings.dpd.vis import viscticalibrationresults_stub\r\n+  import ST_DataModelBindings.ins_stub as ins_dict\r\n \r\n+  \"\"\"Create the date range\"\"\"\r\n   date_range = ins_dict.calibrationValidPeriod()\r\n   date_range.TimestampStart = \"2023-02-21T00:00:00.000Z\"\r\n   date_range.TimestampEnd = \"2023-02-22T00:00:00.000Z\"\r\n \r\n-  phase = vis_stub.visCTIModelPhaseData()\r\n-  phase.MultiNestZIP = create_data_container(\"multinestzip.zip\")\r\n-  phase.ModelInfo = create_data_container(\"modelinfo.json\")\r\n-  phase.ModelResults = create_data_container(\"modelresults.json\")\r\n-  phase.DetectorId = \"1-1\"\r\n-  phase.DateRange = date_range\r\n-  phase.ValidityRange = date_range\r\n-  phase.PhaseNumber = 1\r\n-  phase.PhaseMetaData = create_data_container(\"blah.json\")\r\n-  phase.OptimizerPickle = create_data_container(\"blah.json\")\r\n-  phase.ModelPickle = create_data_container(\"blah.json\")\r\n-  phase.TrimmingLevel = create_data_container(\"blah.json\")\r\n-\r\n-  qualPramStorage = vis_stub.visQualityParameterStorageFitsFile()\r\n+  \"\"\"Create a CTI model fit entry\"\"\"\r\n+  parallel_fit_list = []\r\n+  serial_fit_list = []\r\n+\r\n+  \"\"\"\r\n+  __Fit Results__\r\n+  \r\n+  The cti_result_list contains the results of all 72 CTI calibrations performed in this pipeline\r\n+  run (36 x parallel CTI, 36 x serial CTI).\r\n+\r\n+  This loop iterates over all results, creates a visCTIModelFitData() object for each\r\n+  and then stores in them data.Fits at the end.\r\n+  \"\"\"\r\n+\r\n+  for cti_result in cti_result_list:\r\n+\r\n+    fit = vis_stub.visCTIModelFitData()\r\n+\r\n+    fit.ValidityRange = date_range\r\n+    fit.DateRange = date_range\r\n+    fit.DetectorId = cti_result[\"DetectorId\"]\r\n+\r\n+    fit.FitMetaData = create_data_container(cti_result[\"FitMetaData\"])\r\n+    fit.SearchPickle = create_data_container(cti_result[\"SearchPickle\"])\r\n+    fit.ModelPickle = create_data_container(cti_result[\"ModelPickle\"])\r\n+    fit.ModelInfo = create_data_container(cti_result[\"ModelInfo\"])\r\n+    fit.Model = create_data_container(cti_result[\"Model\"])\r\n+\r\n+    fit.ModelResults = create_data_container(cti_result[\"ModelResults\"])\r\n+    fit.SearchInfo = create_data_container(cti_result[\"SearchInfo\"])\r\n+\r\n+    fit.MaxLikelihoodInstance = create_data_container(cti_result[\"MaxLikelihoodInstance\"])\r\n+\r\n+    fit.CovarianceMatrix = create_data_container(cti_result[\"CovarianceMatrix\"])\r\n+\r\n+    fit.ExtractedEPERs = create_data_container(str(cti_result[\"ExtractedEPERs\"]))\r\n+\r\n+    fit.TotalTraps = cti_result[\"TotalTraps\"]\r\n+    fit.TrapType = cti_result[\"TrapType\"]\r\n+    fit.CCDType = cti_result[\"CCDType\"]\r\n+    fit.IsFitBinned = cti_result[\"IsFitBinned\"]\r\n+    fit.IsParallelSerialSimultaneous = cti_result[\"IsParallelSerialSimultaneous\"]\r\n+    fit.IsraelDeltaEllipticity = cti_result[\"IsraelDeltaEllipticity\"]\r\n+    fit.TimeFromZero = cti_result[\"TimeFromZero\"]\r\n+\r\n+    if cti_result[\"IsParallel\"]:\r\n+      parallel_fit_list.append(fit)\r\n+      cti_result_parallel = cti_result\r\n+    else:\r\n+      serial_fit_list.append(fit)\r\n+      cti_result_serial = cti_result  \r\n+\r\n+  \"\"\"\r\n+  __Data Quality Files__\r\n+  \r\n+  Create a list of the Data Quality image folders which contain all .png images of the fits \r\n+  for parallel and serial CTI.\r\n+  \r\n+  There are 72 folders in total, 36 for parallel and 36 for serial, which will be collectively\r\n+  zipped into two .tar files.\r\n+  \"\"\"\r\n+\r\n+  parallel_dq_file_list = []\r\n+  serial_dq_file_list = []\r\n+\r\n+  for cti_result in cti_result_list:\r\n+\r\n+    file = os.path.join(args.workdir, \"data\", cti_result[\"DQImage\"])\r\n+\r\n+    if cti_result[\"IsParallel\"]:\r\n+      parallel_dq_file_list.append(file)\r\n+    else:\r\n+      serial_dq_file_list.append(file)\r\n+\r\n+  \"\"\"PARALLEL Data Product\"\"\"\r\n+\r\n+  # Create the data product\r\n+  data_product = viscticalibrationresults_stub.DpdVisCTICalibrationResults()\r\n+\r\n+  # Add Header\r\n+  data_product.Header = vis_generic_header(\"DpdVisCTICalibrationResults\", UNKNOWN_STRING)\r\n+\r\n+  # Create the Data\r\n+  data = vis_stub.visCTICalibrationResults.Factory()\r\n+  data.ValidityRange = create_validity_range()\r\n+  data.DateRange = date_range\r\n+  data.PreviousCTIModelsUsedID = \"0\"\r\n+\r\n+  trap = cti_result_parallel[\"TrapType\"]\r\n+  ccd = cti_result_parallel[\"CCDType\"]\r\n+  time_from_zero = cti_result_parallel[\"TimeFromZero\"]\r\n+  \r\n+  data.FitID = f'Par_{time_from_zero}_{trap}_{ccd}'\r\n+\r\n+  # Add fit to data\r\n+  data.Fits = parallel_fit_list\r\n+\r\n+  # Add data to data product\r\n+  data_product.Data = data\r\n+\r\n+  # All data quality images (.png files) are in the folder workdir/data/parallel_images_***\r\n+  # We zip this folder into a .tar file and add it to the data product\r\n+\r\n+  parallel_dq_file = FileNameProvider().get_allowed_filename(\r\n+    processing_function='VIS',\r\n+    type_name=\"QC-PLOTS-CTI-PARALLEL\",\r\n+    instance_id='',\r\n+    extension='.tar.gz'\r\n+  )\r\n+\r\n+  # parallel_dq_tar_path contains a list of folders, which are now zipped into a .tar.gz file:\r\n+  parallel_dq_tar_path = os.path.join(args.workdir, \"data\", parallel_dq_file)\r\n+\r\n+  create_tar_gz(\r\n+    output_filename=parallel_dq_tar_path,\r\n+    folders_to_compress=parallel_dq_file_list\r\n+  )\r\n+  add_quality_parameter_file(data_product, parallel_dq_file)\r\n+\r\n+  dqc_params_dm = vis_stub.visDqcParams.Factory()\r\n+\r\n+  data_product.QualityParams = dqc_params_dm\r\n+\r\n+  # Output to XML^M                                                                                   \r\n+\r\n+  DmUtils.save_product_metadata(data_product, args.parallel_cti_xml_out)\r\n+\r\n+  \"\"\"SERIAL Data Product\"\"\"\r\n+\r\n+  # Create the data product\r\n+  data_product = viscticalibrationresults_stub.DpdVisCTICalibrationResults()\r\n+\r\n+  # Add Header\r\n+  data_product.Header = vis_generic_header(\"DpdVisCTICalibrationResults\", UNKNOWN_STRING)\r\n+\r\n+  # Create the Data\r\n+  data = vis_stub.visCTICalibrationResults.Factory()\r\n+  data.ValidityRange = create_validity_range()\r\n+  data.DateRange = date_range\r\n+  data.PreviousCTIModelsUsedID = \"0\"\r\n+  \r\n+  trap = cti_result_serial[\"TrapType\"]\r\n+  ccd = cti_result_serial[\"CCDType\"]\r\n+  time_from_zero = cti_result_serial[\"TimeFromZero\"]\r\n+  \r\n+  data.FitID = f'Ser_{time_from_zero}_{trap}_{ccd}'\r\n+\r\n+  # Add fit to data\r\n+  data.Fits = serial_fit_list\r\n+\r\n+  # Add data to data product\r\n+  data_product.Data = data\r\n+\r\n+  # All data quality images (.png files) are in the folder workdir/data/serial_images_***\r\n+  # We zip this folder into a .tar file and add it to the data product\r\n+\r\n+  serial_dq_file = FileNameProvider().get_allowed_filename(\r\n+    processing_function='VIS',\r\n+    type_name=\"QC-PLOTS-CTI-SERIAL\",\r\n+    instance_id='',\r\n+    extension='.tar.gz'\r\n+  )\r\n+\r\n+  serial_dq_tar_path = os.path.join(args.workdir, \"data\", serial_dq_file)\r\n+\r\n+  create_tar_gz(\r\n+    output_filename=serial_dq_tar_path,\r\n+    folders_to_compress=serial_dq_file_list\r\n+  )\r\n+  add_quality_parameter_file(data_product, serial_dq_file)\r\n+  \r\n   dqc_params_dm = vis_stub.visDqcParams.Factory()\r\n \r\n-  data_product.ValidityRange = date_range\r\n-  data_product.DateRange = date_range\r\n-  data_product.PreviousCTIModelsUsedID = 0\r\n-  data_product.PhaseTotal = 1\r\n-  data_product.PhaseID = 123\r\n-  data_product.Phases = [phase]\r\n-  data_product.CILFrames = 0\r\n-  data_product.visCTIModelPhaseData = 0\r\n-  data_product.cilFrameRefList = 0\r\n-  data_product.QualityParameterStorage = qualPramStorage\r\n+#  data_product.QualityParameterStorage = qualPramStorage\r\n   data_product.QualityParams = dqc_params_dm\r\n \r\n-  DmUtils.save_product_metadata( data_product, args.cti_xml_out)\r\n+  # Output to XML\r\n+\r\n+  DmUtils.save_product_metadata(data_product, args.serial_cti_xml_out)\r\n+\r\n \r\n   logger.info( \"#\")\r\n   logger.info( \"# Exiting %s mainMethod()\" % __name__)\r\n",
                            "Merge branch 'release-13.0' into 'feature_#23227_BloomingCalib'",
                            "Thomas Flanet",
                            "2023-08-17T15:43:48.000+00:00",
                            "9d236be45ec452966840965083cd59dc82102cf0"
                        ],
                        [
                            "@@ -222,7 +222,10 @@ def mainMethod( args):\n   # parallel_dq_tar_path contains a list of folders, which are now zipped into a .tar.gz file:\r\n   parallel_dq_tar_path = os.path.join(args.workdir, \"data\", parallel_dq_file)\r\n \r\n-  create_tar_gz(parallel_dq_tar_path, parallel_dq_file_list)\r\n+  create_tar_gz(\r\n+    output_filename=parallel_dq_tar_path,\r\n+    folders_to_compress=parallel_dq_file_list\r\n+  )\r\n   add_quality_parameter_file(data_product, parallel_dq_file)\r\n \r\n   dqc_params_dm = vis_stub.visDqcParams.Factory()\r\n@@ -271,7 +274,10 @@ def mainMethod( args):\n \r\n   serial_dq_tar_path = os.path.join(args.workdir, \"data\", serial_dq_file)\r\n \r\n-  create_tar_gz(serial_dq_file_list, serial_dq_tar_path)\r\n+  create_tar_gz(\r\n+    output_filename=serial_dq_tar_path,\r\n+    folders_to_compress=serial_dq_file_list\r\n+  )\r\n   add_quality_parameter_file(data_product, serial_dq_file)\r\n   \r\n   dqc_params_dm = vis_stub.visDqcParams.Factory()\r\n",
                            "input parameters into create_tar_gz for serial CTI in correct order",
                            "James Nightingale",
                            "2023-08-15T09:16:36.000+01:00",
                            "d1bfa7d096d39a15c26d3f42a667aa7f27c42fa7"
                        ],
                        [
                            "@@ -9,6 +9,7 @@ import argparse\n import os\r\n import json\r\n from pathlib import Path\r\n+import tarfile\r\n from typing import Union\r\n \r\n \r\n@@ -43,8 +44,10 @@ def defineSpecificProgramOptions():\n \r\n ################################################################################\r\n \r\n-def write_tar_zip(in_files: list[Union[Path, str]], out_file: Path) -> None:\r\n-  tar_zip_files(\" \".join(map(str, in_files)), str(out_file), False)\r\n+def create_tar_gz(output_filename, folders_to_compress):\r\n+  with tarfile.open(output_filename, \"w:gz\") as tar:\r\n+    for folder in folders_to_compress:\r\n+      tar.add(folder, arcname=os.path.basename(folder))\r\n \r\n \r\n def mainMethod( args):\r\n@@ -77,20 +80,22 @@ def mainMethod( args):\n   # {\"ModelInfo\": \"/sps/euclid/Users/jnightin/workspaces/ctical/ppo_root/workdir//output/2022-10-13T11:37:14.399Z_CCD6-4/parallel[x1]/2f929b8acbe296cfb1102229221a7438/model.info\"}\r\n   \"\"\"\r\n \r\n-  calibrate_cti_results_list = args.parallel_args.calibrate_cti_results_list + args.serial_args.calibrate_cti_results_list\r\n+  with open(args.parallel_calibrate_cti_results_list, \"r\") as f:\r\n+    parallel_cti_per_ccd_list = json.load(f)\r\n \r\n-  with open(calibrate_cti_results_list, \"r\") as f:\r\n-    cti_per_ccd_list = json.load(f)\r\n+  with open(args.serial_calibrate_cti_results_list, \"r\") as f:\r\n+    serial_cti_per_ccd_list = json.load(f)\r\n+\r\n+  cti_per_ccd_list = parallel_cti_per_ccd_list + serial_cti_per_ccd_list\r\n \r\n   cti_result_list = []\r\n \r\n   for cti_for_ccd_list in cti_per_ccd_list:\r\n-    for cti_direction in cti_for_ccd_list:\r\n \r\n-        with open(cti_direction, \"r\") as f:\r\n+     with open(cti_for_ccd_list, \"r\") as f:\r\n \r\n-          cti_result = json.load(f)\r\n-          cti_result_list.append(cti_result)\r\n+        cti_result = json.load(f)\r\n+        cti_result_list.append(cti_result)\r\n \r\n \r\n   logger.info( f\"reading {len( cti_per_ccd_list)} CCD CTI calibration files\")\r\n@@ -213,14 +218,11 @@ def mainMethod( args):\n     instance_id='',\r\n     extension='.tar.gz'\r\n   )\r\n-#  parallel_dq_tar_path = os.path.join(args.workdir, \"data\", parallel_dq_file)\r\n \r\n   # parallel_dq_tar_path contains a list of folders, which are now zipped into a .tar.gz file:\r\n+  parallel_dq_tar_path = os.path.join(args.workdir, \"data\", parallel_dq_file)\r\n \r\n-\r\n-\r\n-\r\n-#  write_tar_zip(parallel_dq_file_list, parallel_dq_tar_path)\r\n+  create_tar_gz(parallel_dq_tar_path, parallel_dq_file_list)\r\n   add_quality_parameter_file(data_product, parallel_dq_file)\r\n \r\n   dqc_params_dm = vis_stub.visDqcParams.Factory()\r\n@@ -269,7 +271,7 @@ def mainMethod( args):\n \r\n   serial_dq_tar_path = os.path.join(args.workdir, \"data\", serial_dq_file)\r\n \r\n-  write_tar_zip(serial_dq_file_list, serial_dq_tar_path)\r\n+  create_tar_gz(serial_dq_file_list, serial_dq_tar_path)\r\n   add_quality_parameter_file(data_product, serial_dq_file)\r\n   \r\n   dqc_params_dm = vis_stub.visDqcParams.Factory()\r\n",
                            "file .tar.gz creation",
                            "James Nightingale",
                            "2023-08-15T09:14:08.000+01:00",
                            "400518ce70dd9b1526ff6d73d6bff735ab81eaef"
                        ],
                        [
                            "@@ -213,9 +213,14 @@ def mainMethod( args):\n     instance_id='',\r\n     extension='.tar.gz'\r\n   )\r\n-  parallel_dq_tar_path = os.path.join(args.workdir, \"data\", parallel_dq_file)\r\n+#  parallel_dq_tar_path = os.path.join(args.workdir, \"data\", parallel_dq_file)\r\n \r\n-  write_tar_zip(parallel_dq_file_list, parallel_dq_tar_path)\r\n+  # parallel_dq_tar_path contains a list of folders, which are now zipped into a .tar.gz file:\r\n+\r\n+\r\n+\r\n+\r\n+#  write_tar_zip(parallel_dq_file_list, parallel_dq_tar_path)\r\n   add_quality_parameter_file(data_product, parallel_dq_file)\r\n \r\n   dqc_params_dm = vis_stub.visDqcParams.Factory()\r\n",
                            "minor changes formatting",
                            "James Nightingale",
                            "2023-08-15T09:11:56.000+01:00",
                            "1a6a9969ebd015a11b66c5ea39f827e9226de5f6"
                        ],
                        [
                            "@@ -9,6 +9,7 @@ import argparse\n import os\r\n import json\r\n from pathlib import Path\r\n+import tarfile\r\n from typing import Union\r\n \r\n \r\n@@ -77,20 +78,22 @@ def mainMethod( args):\n   # {\"ModelInfo\": \"/sps/euclid/Users/jnightin/workspaces/ctical/ppo_root/workdir//output/2022-10-13T11:37:14.399Z_CCD6-4/parallel[x1]/2f929b8acbe296cfb1102229221a7438/model.info\"}\r\n   \"\"\"\r\n \r\n-  calibrate_cti_results_list = args.parallel_args.calibrate_cti_results_list + args.serial_args.calibrate_cti_results_list\r\n+  with open(args.parallel_calibrate_cti_results_list, \"r\") as f:\r\n+    parallel_cti_per_ccd_list = json.load(f)\r\n \r\n-  with open(calibrate_cti_results_list, \"r\") as f:\r\n-    cti_per_ccd_list = json.load(f)\r\n+  with open(args.serial_calibrate_cti_results_list, \"r\") as f:\r\n+    serial_cti_per_ccd_list = json.load(f)\r\n+\r\n+  cti_per_ccd_list = parallel_cti_per_ccd_list + serial_cti_per_ccd_list\r\n \r\n   cti_result_list = []\r\n \r\n   for cti_for_ccd_list in cti_per_ccd_list:\r\n-    for cti_direction in cti_for_ccd_list:\r\n \r\n-        with open(cti_direction, \"r\") as f:\r\n+     with open(cti_for_ccd_list, \"r\") as f:\r\n \r\n-          cti_result = json.load(f)\r\n-          cti_result_list.append(cti_result)\r\n+        cti_result = json.load(f)\r\n+        cti_result_list.append(cti_result)\r\n \r\n \r\n   logger.info( f\"reading {len( cti_per_ccd_list)} CCD CTI calibration files\")\r\n@@ -215,7 +218,19 @@ def mainMethod( args):\n   )\r\n   parallel_dq_tar_path = os.path.join(args.workdir, \"data\", parallel_dq_file)\r\n \r\n-  write_tar_zip(parallel_dq_file_list, parallel_dq_tar_path)\r\n+  print(parallel_dq_file_list)\r\n+  print(parallel_dq_tar_path)\r\n+\r\n+  def create_tar_gz(output_filename, folders_to_compress):\r\n+\r\n+      with tarfile.open(output_filename, \"w:gz\") as tar:\r\n+          for folder in folders_to_compress:\r\n+              tar.add(folder, arcname=os.path.basename(folder))\r\n+\r\n+  create_tar_gz(parallel_dq_tar_path, parallel_dq_file_list)\r\n+\r\n+#  write_tar_zip(parallel_dq_file_list, parallel_dq_tar_path)\r\n+  sss\r\n   add_quality_parameter_file(data_product, parallel_dq_file)\r\n \r\n   dqc_params_dm = vis_stub.visDqcParams.Factory()\r\n",
                            "tar file zip now works",
                            "James Nightingale",
                            "2023-08-15T10:11:21.000+02:00",
                            "6cdf58bd9f95601b9ebe5845601af2af12f79d1e"
                        ],
                        [
                            "@@ -34,7 +34,8 @@ def defineSpecificProgramOptions():\n     parser.add_argument( '--workdir',                    required=True,  help='absolute path to the workdir')\r\n     parser.add_argument( '--logdir',                     required=True,  help='path to the logdir, relative to the workdir')\r\n     parser.add_argument('--config',                                      help='configuration file path')\r\n-    parser.add_argument( '--calibrate_cti_results_list', required=True,  help='Path to the CTI calibration results json file')\r\n+    parser.add_argument( '--parallel_calibrate_cti_results_list', required=True,  help='Path to the parallel CTI calibration results json file')\r\n+    parser.add_argument( '--serial_calibrate_cti_results_list', required=True,  help='Path to the serial CTI calibration results json file')\r\n     # outputs\r\n     parser.add_argument( '--parallel_cti_xml_out',                required=True,  help='output parallel CTI results xml filename')\r\n     parser.add_argument( '--serial_cti_xml_out',                required=True,  help='output serial CTI results xml filename')\r\n@@ -59,6 +60,9 @@ def mainMethod( args):\n   if not os.path.isabs( args.parallel_cti_xml_out):\r\n     args.parallel_cti_xml_out = os.path.join( args.workdir, args.parallel_cti_xml_out)\r\n \r\n+  if not os.path.isabs( args.serial_cti_xml_out):\r\n+    args.serial_cti_xml_out = os.path.join( args.workdir, args.serial_cti_xml_out)\r\n+\r\n   out_dir = os.path.split(args.parallel_cti_xml_out )[0]\r\n   os.makedirs(out_dir, exist_ok=True)\r\n \r\n@@ -73,7 +77,9 @@ def mainMethod( args):\n   # {\"ModelInfo\": \"/sps/euclid/Users/jnightin/workspaces/ctical/ppo_root/workdir//output/2022-10-13T11:37:14.399Z_CCD6-4/parallel[x1]/2f929b8acbe296cfb1102229221a7438/model.info\"}\r\n   \"\"\"\r\n \r\n-  with open(args.calibrate_cti_results_list, \"r\") as f:\r\n+  calibrate_cti_results_list = args.parallel_args.calibrate_cti_results_list + args.serial_args.calibrate_cti_results_list\r\n+\r\n+  with open(calibrate_cti_results_list, \"r\") as f:\r\n     cti_per_ccd_list = json.load(f)\r\n \r\n   cti_result_list = []\r\n",
                            "split inputs for parallel and serial",
                            "James Nightingale",
                            "2023-08-14T12:25:45.000+01:00",
                            "5eeb2eee3c0202d80d63d67384a9737fcfa47d92"
                        ]
                    ],
                    "VIS_PSF/auxdir/VIS_PSF/default.psfex": [
                        [
                            "@@ -14,7 +14,7 @@ NEWBASIS_NUMBER 8               # Number of new basis vectors\n PSF_SAMPLING    1.0             # Sampling step in pixel units (0.0 = auto)\n PSF_PIXELSIZE   1.0             # Effective pixel size in pixel step units\n PSF_ACCURACY    0.015           # Accuracy to expect from PSF \"pixel\" values\n-PSF_SIZE        20,20           # Image size of the PSF model\n+PSF_SIZE        21,21           # Image size of the PSF model\n PSF_DGEOCORRECT N               # Use diff. geom. maps (if provided) Y/N?\n PSF_RECENTER    N               # Allow recentering of PSF-candidates Y/N ?\n MEF_TYPE        INDEPENDENT     # INDEPENDENT or COMMON\n",
                            "minor change: switch to on odd number of vignet size for the sextractor catalogues. Now set to 21x21 instead 20x20",
                            "Olivier Herent",
                            "2023-08-18T08:36:22.000+00:00",
                            "5bef2598378b16bc1f9a589dbc7a3fbe87dbfec5"
                        ]
                    ],
                    "VIS_SourceExtraction/python/VIS_SourceExtraction/VIS_extract_sources.py": [
                        [
                            "@@ -104,7 +104,7 @@ def mainMethod(args):\n            'X_IMAGE','Y_IMAGE','XWIN_IMAGE','YWIN_IMAGE','ERRAWIN_IMAGE',\\\n            'ERRBWIN_IMAGE','ERRTHETAWIN_IMAGE','FLUX_APER(1)','FLUXERR_APER(1)',\\\n            'FLUX_APER(2)','FLUXERR_APER(2)','FLUX_APER(3)','FLUXERR_APER(3)',\\\n-           'BACKGROUND','ELONGATION','SNR_WIN','VIGNET(20,20)','FLAGS','FLAGS_WIN']\n+           'BACKGROUND','ELONGATION','SNR_WIN','VIGNET(21,21)','FLAGS','FLAGS_WIN']\n   if inflagmap is not None:\n     param += ['IMAFLAGS_ISO','NIMAFLAGS_ISO']\n \n",
                            "minor change: switch to on odd number of vignet size for the sextractor catalogues. Now set to 21x21 instead 20x20",
                            "Olivier Herent",
                            "2023-08-18T08:36:22.000+00:00",
                            "5bef2598378b16bc1f9a589dbc7a3fbe87dbfec5"
                        ]
                    ],
                    "CMakeLists.txt": [
                        [
                            "@@ -8,11 +8,11 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.8)\n #===============================================================================\n \n-elements_project( VIS_Tasks 13.0.11\n+elements_project( VIS_Tasks 13.0.14\n                   USE Elements 6.2.1\n                       VIS_PyLibrary 3.20.2\n                       VIS_ImageTools 3.16.0\n-                      VIS_CTI 5.8.1\n+                      VIS_CTI 5.9.0\n                       VIS_Instrument_Tools 0.7.0\n                       EL_Utils 1.4.0\n                       ST_DataModelTools 9.2.0\n",
                            "Merge branch 'release-13.0' into 'feature_#23227_BloomingCalib'",
                            "Thomas Flanet",
                            "2023-08-17T15:43:48.000+00:00",
                            "9d236be45ec452966840965083cd59dc82102cf0"
                        ],
                        [
                            "@@ -8,11 +8,11 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.8)\n #===============================================================================\n \n-elements_project( VIS_Tasks 13.0.13\n+elements_project( VIS_Tasks 13.0.14\n                   USE Elements 6.2.1\n                       VIS_PyLibrary 3.20.2\n                       VIS_ImageTools 3.16.0\n-                      VIS_CTI 5.9.0\n+                      VIS_CTI 5.9.1\n                       VIS_Instrument_Tools 0.7.0\n                       EL_Utils 1.4.0\n                       ST_DataModelTools 9.2.0\n",
                            "CMake",
                            "James Nightingale",
                            "2023-08-16T21:01:30.000+02:00",
                            "e30fcd92bf0e9e85de72769619aef88f8cf398c4"
                        ],
                        [
                            "@@ -8,7 +8,7 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.8)\n #===============================================================================\n \n-elements_project( VIS_Tasks 13.0.13\n+elements_project( VIS_Tasks 13.0.14\n                   USE Elements 6.2.1\n                       VIS_PyLibrary 3.20.2\n                       VIS_ImageTools 3.16.0\n",
                            "Bump version to 13.0.14",
                            "Catherine Grenet",
                            "2023-08-16T15:39:03.000+02:00",
                            "9986147c3952dd4bdd2bb8c97f304e62a6f2ede1"
                        ],
                        [
                            "@@ -8,7 +8,7 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.8)\n #===============================================================================\n \n-elements_project( VIS_Tasks 13.0.14\n+elements_project( VIS_Tasks 13.0.13\n                   USE Elements 6.2.1\n                       VIS_PyLibrary 3.20.2\n                       VIS_ImageTools 3.16.0\n",
                            "hot fix tested in end-to-end run",
                            "James Nightingale",
                            "2023-08-16T13:48:06.000+02:00",
                            "c48be615afd552ed7e8ae29c8c94b9416cc80954"
                        ],
                        [
                            "@@ -8,7 +8,7 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.8)\n #===============================================================================\n \n-elements_project( VIS_Tasks 13.0.12\n+elements_project( VIS_Tasks 13.0.14\n                   USE Elements 6.2.1\n                       VIS_PyLibrary 3.20.2\n                       VIS_ImageTools 3.16.0\n",
                            "file .tar.gz creation",
                            "James Nightingale",
                            "2023-08-15T09:14:08.000+01:00",
                            "400518ce70dd9b1526ff6d73d6bff735ab81eaef"
                        ],
                        [
                            "@@ -8,7 +8,7 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.8)\n #===============================================================================\n \n-elements_project( VIS_Tasks 13.0.13\n+elements_project( VIS_Tasks 13.0.14\n                   USE Elements 6.2.1\n                       VIS_PyLibrary 3.20.2\n                       VIS_ImageTools 3.16.0\n",
                            "tar file zip now works",
                            "James Nightingale",
                            "2023-08-15T10:11:21.000+02:00",
                            "6cdf58bd9f95601b9ebe5845601af2af12f79d1e"
                        ],
                        [
                            "@@ -8,7 +8,7 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.8)\n #===============================================================================\n \n-elements_project( VIS_Tasks 13.0.12\n+elements_project( VIS_Tasks 13.0.13\n                   USE Elements 6.2.1\n                       VIS_PyLibrary 3.20.2\n                       VIS_ImageTools 3.16.0\n",
                            "Bump version to 13.0.13",
                            "Catherine Grenet",
                            "2023-08-14T16:30:55.000+02:00",
                            "47257bafbbbabc1e5e4b1e48b8cf18abef84eb1e"
                        ],
                        [
                            "@@ -8,7 +8,7 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.8)\n #===============================================================================\n \n-elements_project( VIS_Tasks 13.0.12\n+elements_project( VIS_Tasks 13.0.13\n                   USE Elements 6.2.1\n                       VIS_PyLibrary 3.20.2\n                       VIS_ImageTools 3.16.0\n",
                            "sigh",
                            "James Nightingale",
                            "2023-08-14T15:36:31.000+02:00",
                            "7d49a86dc26bf6e721598b3acf6fc5507f6bd215"
                        ]
                    ],
                    "VIS_PRNU/python/VIS_PRNU/VIS_SmallScaleFlat/VIS_CombinePRNU.py": [
                        [
                            "@@ -77,7 +77,7 @@ def combine_flagmaps( flagin_list, flagmap_out):\n   hdul0 = fits.open( flagin_list[0], memmap=False)\n \n   # create output flagmap\n-  logger.info( \"writing output flagmap \" + flagmap_out)\n+  logger.info( \"creating output flagmap \" + flagmap_out)\n   fits.writeto( flagmap_out, data=None, header=hdul0[0].header, overwrite=True)\n \n   # scan and combine flagmaps extensions\n@@ -102,18 +102,23 @@ def combine_PRNU( prnu_filelist, combine_model, timestamp):\n   # get LED identifiant of each input monochromatic PRNU\n   # and create a primary header storing the combined PRNU file names and coefficients\n   prnu_dict = dict()\n-  prim_hdr = dict()\n+  fluences = set()\n+  prim_hdr = None\n   for prnu_filename in prnu_filelist:\n     hdul_in = fits.open( prnu_filename, memmap=False)\n+    if prim_hdr is None:\n+      prim_hdr = hdul_in[0].header\n     led_id, fluence = VIS_SmallScaleFlat_xml_in.get_PRNU_metadata( prnu_filename)\n-    logger.info( f\"{prnu_filename}, LED{led_id}\")\n+    logger.info( f\"{prnu_filename}: LEDID={led_id}, FLUENCE={fluence}\")\n     prnu_dict[led_id] = hdul_in\n+    fluences.add( fluence)\n     prim_hdr[led_id + \"FILE\"] = os.path.basename( prnu_filename)\n     prim_hdr[led_id + \"COEF\"] = combine_model[\"LED\"+led_id]\n \n   led_ids = sorted( list( set( prnu_dict.keys())))\n   assert len( led_ids) == len( prnu_dict.keys()), \\\n     f\"ERROR: there must be only one input zero-signal PRNU per LED\"\n+  prim_hdr[\"LEDID\"] = ''.join( led_ids)\n \n   norm = 0\n   for led_id in led_ids:\n@@ -121,8 +126,13 @@ def combine_PRNU( prnu_filelist, combine_model, timestamp):\n   logger.info( f\"model norm for leds {led_ids}: {norm}\")\n \n   # create the output combined PRNU FITS file primary HDU\n-  small_scale_flat_out = os.path.join( DATADIR, f\"EUC_VIS_MSR-FLA_LED{''.join( led_ids)}-000ADU__{timestamp}.fits\")\n-  logger.info( \"create output combined PRNU file: \" + small_scale_flat_out)\n+  led_id = ''.join( led_ids)\n+  if len( fluences) == 1:\n+    fluence = VIS_SmallScaleFlat_xml_in.fluence_to_str( list( fluences)[0])\n+  else:\n+    fluence = \"000\"\n+  small_scale_flat_out = os.path.join( DATADIR, f\"EUC_VIS_MSR-FLA_LED{led_id}-{fluence}ADU__{timestamp}.fits\")\n+  logger.info( \"creating output combined PRNU \" + small_scale_flat_out)\n   prim_hdu = fits.HDUList( [fits.PrimaryHDU( header=fits.Header( prim_hdr))])\n   prim_hdu.writeto( small_scale_flat_out, overwrite=True)\n \n@@ -159,7 +169,7 @@ def defineSpecificProgramOptions():\n   # outputs\n   ap.add_argument( \"--smallscaleflat_out\", help=\"output SmallScaleFlat data product XML file path\")\n   ap.add_argument( \"--prnuflagmap_out\",    help=\"output flagmap data product XML file path\")\n-  ap.add_argument( \"--dqc_data_out\",       help=\"output data quality control data product XML file path\")\n+  ap.add_argument( \"--dqc_out\",       help=\"output data quality control data product XML file path\")\n   return ap\n \n \n@@ -190,7 +200,7 @@ def mainMethod( args):\n   xml_list = FromToXML.load_list_from_file( args.flagmaps_in)\n   for xml in xml_list:\n     flagmaps_in.append( os.path.join( DATADIR, FromToXML.get_xml_data_file_list( xml)[0]))\n-  flagmap_out = small_scale_flat_out.replace(\"EUC_VIS_MSR-FLA_LED\", \"EUC_VIS_MSR-FLA-FLAGMAP_LED\")\n+  flagmap_out = small_scale_flat_out.replace( \"EUC_VIS_MSR-FLA_LED\", \"EUC_VIS_MSR-FLA-FLAGMAP_LED\")\n   combine_flagmaps( flagmaps_in, flagmap_out)\n \n   # create SmallScaleFlat data product\n@@ -203,6 +213,13 @@ def mainMethod( args):\n \n   # create data quality control data product\n   # encapsulating extrapolated master flats and standard errors and slopes\n+  dp_dqc_out = FromToXML.create_analysis_dp( result_passed=True,\n+                                             aux_file=None,\n+                                             raw_frame_id=None,\n+                                             analysis_id=None,\n+                                             obs_seq_foranalysis=None,\n+                                             analysis_data=all_flatfiles)\n+  DmUtils.save_product_metadata( dp_dqc_out, args.dqc_out)\n \n   logger.info( \"#\")\n   logger.info( \"# Exiting %s mainMethod()\" % __name__)\n",
                            "Merge branch 'release-13.0' into 'feature_#23227_BloomingCalib'",
                            "Thomas Flanet",
                            "2023-08-17T15:43:48.000+00:00",
                            "9d236be45ec452966840965083cd59dc82102cf0"
                        ]
                    ],
                    "VIS_PRNU/python/VIS_PRNU/VIS_SmallScaleFlat/VIS_ExtrapolatePRNU.py": [
                        [
                            "@@ -38,6 +38,7 @@ logger = logging.getLogger( __name__)\n from astropy.io import fits\n \n from VIS_Tasks_Common import FromToXML\n+from VIS_PyLibrary_Common.common_definitions import DATADIR\n from VIS_PyLibrary_Common import pipe_tools\n from VIS_PRNU.VIS_SmallScaleFlat import VIS_SmallScaleFlat_xml_in\n \n@@ -91,15 +92,16 @@ def extrapolate_prnu( ledid, prnulist_in, fluences, out_fitsname, err_fitsname,\n         b = (n*Sxy - Sx*Sy) / nSxx_SxSx\n         # intercept\n         a = Sy/n - b * Sx/n\n-        # standard errors\n-        # https://en.wikipedia.org/wiki/Standard_error\n-        Se2 = (n*Syy - Sy*Sy - b*b*nSxx_SxSx) / (n * (n-2))\n-        Sb2 = n*Se2 / nSxx_SxSx\n-        Sa2 = Sb2 * Sxx / n\n         # save outputs\n         data_out[row, col]  = a\n-        error_out[row, col] = np.sqrt( Sa2)\n         slope_out[row, col] = b\n+        # standard errors\n+        # https://en.wikipedia.org/wiki/Standard_error\n+        if n>2:\n+          Se2 = (n*Syy - Sy*Sy - b*b*nSxx_SxSx) / (n * (n-2))\n+          Sb2 = n*Se2 / nSxx_SxSx\n+          Sa2 = Sb2 * Sxx / n\n+          error_out[row, col] = np.sqrt( Sa2)\n     hdu.data = None\n     fits.append( out_fitsname,   data_out,  header=hdu.header, verify=False)\n     fits.append( err_fitsname,   error_out, header=hdu.header, verify=False)\n@@ -150,10 +152,19 @@ def mainMethod( args):\n     fluences.append( fluence)\n \n   timestamp = FromToXML.microsec_timestamp()\n-  out_fitsname   = f\"EUC_VIS_MSR-FLA_LED{ledid}-000ADU__{timestamp}.fits\"\n-  err_fitsname   = f\"EUC_VIS_MSR-FLA_LED{ledid}-000ADU-stderr__{timestamp}.fits\"\n-  slope_fitsname = f\"EUC_VIS_MSR-FLA_LED{ledid}-000ADU-slope__{timestamp}.fits\"\n-  extrapolate_prnu( ledid, prnu_list, fluences, out_fitsname, err_fitsname, slope_fitsname)\n+\n+  if len( fluences) > 1:\n+    out_fitsname   = os.path.join( DATADIR, f\"EUC_VIS_MSR-FLA_LED{ledid}-000ADU__{timestamp}.fits\")\n+    err_fitsname   = os.path.join( DATADIR, f\"EUC_VIS_MSR-FLA_LED{ledid}-000ADU-stderr__{timestamp}.fits\")\n+    slope_fitsname = os.path.join( DATADIR, f\"EUC_VIS_MSR-FLA_LED{ledid}-000ADU-slope__{timestamp}.fits\")\n+    extrapolate_prnu( ledid, prnu_list, fluences, out_fitsname, err_fitsname, slope_fitsname)\n+  else:\n+    # only one fluence, can't extrapolate masterflat, just use it as is\n+    fluence        = VIS_SmallScaleFlat_xml_in.fluence_to_str( fluences[0])\n+    out_fitsname   = os.path.join( DATADIR, f\"EUC_VIS_MSR-FLA_LED{ledid}-{fluence}ADU__{timestamp}.fits\")\n+    err_fitsname   = None\n+    slope_fitsname = None\n+    FromToXML.failsafe_symlink( prnu_list[0], out_fitsname)\n \n   # write to output\n   FromToXML.write_json( (out_fitsname, err_fitsname, slope_fitsname), args.prnulist_out)\n",
                            "Merge branch 'release-13.0' into 'feature_#23227_BloomingCalib'",
                            "Thomas Flanet",
                            "2023-08-17T15:43:48.000+00:00",
                            "9d236be45ec452966840965083cd59dc82102cf0"
                        ]
                    ],
                    "VIS_PRNU/python/VIS_PRNU/VIS_SmallScaleFlat/VIS_SmallScaleFlat_xml_in.py": [
                        [
                            "@@ -62,6 +62,16 @@ def get_PRNU_metadata( prnu_filename):\n   return str( prim_hdr[\"LEDID\"]), float( prim_hdr[\"FLUENCE\"])\n \n \n+################################################################################\n+\n+def fluence_to_str( fluence):\n+  \"\"\"convert fluence from float to string using the kilo prefix when needed\"\"\"\n+  if fluence < 1000:\n+    return f\"{int( fluence)}\"\n+  else:\n+    return f\"{int( fluence/1000)}K\"\n+\n+\n ################################################################################\n \n def defineSpecificProgramOptions():\n",
                            "Merge branch 'release-13.0' into 'feature_#23227_BloomingCalib'",
                            "Thomas Flanet",
                            "2023-08-17T15:43:48.000+00:00",
                            "9d236be45ec452966840965083cd59dc82102cf0"
                        ]
                    ],
                    "VIS_Tasks_M/CMakeLists.txt": [
                        [
                            "@@ -71,6 +71,7 @@ elements_add_python_program(VIS_process_flat_quad VIS_Tasks_M.VIS_process_flat_q\n elements_add_python_program(VIS_process_dark_quad VIS_Tasks_M.VIS_process_dark_quad)\n elements_add_python_program(VIS_calib_xml_out VIS_Tasks_M.VIS_calib_xml_out)\n elements_add_python_program(VIS_cti_xml_out VIS_Tasks_M.VIS_cti_xml_out)\n+elements_add_python_program(VIS_cti_master_ci_xml_out VIS_Tasks_M.VIS_cti_master_ci_xml_out)\n elements_add_python_program(VIS_science_xml_out VIS_Tasks_M.VIS_science_xml_out)\n elements_add_python_program(VIS_xml_in VIS_Tasks_M.VIS_xml_in)\n elements_add_python_program(VIS_process_extract_exp VIS_Tasks_M.VIS_process_extract_exp)\n@@ -81,7 +82,6 @@ elements_add_python_program(VIS_Astrometry_calib VIS_Tasks_M.VIS_Astrometry_cali\n elements_add_python_program(VIS_PSF_calib VIS_Tasks_M.VIS_PSF_calib)\n elements_add_python_program(VIS_LargeFlat_calib VIS_Tasks_M.VIS_LargeFlat_calib)\n elements_add_python_program(VIS_CTI_Calibration VIS_Tasks_M.VIS_CTI_Calibration)\n-elements_add_python_program(VIS_CTI_Data_Visualize VIS_Tasks_M.VIS_CTI_Data_Visualize)\n elements_add_python_program(VIS_CTI_Master_CI VIS_Tasks_M.VIS_CTI_Master_CI)\n elements_add_python_program(VIS_process_astro_field_largeflat VIS_Tasks_M.VIS_process_astro_field_largeflat)\n elements_add_python_program(VIS_gain_calib VIS_Tasks_M.VIS_gain_calib)\n",
                            "Merge branch 'release-13.0' into 'feature_#23227_BloomingCalib'",
                            "Thomas Flanet",
                            "2023-08-17T15:43:48.000+00:00",
                            "9d236be45ec452966840965083cd59dc82102cf0"
                        ]
                    ],
                    "VIS_Tasks_M/python/VIS_Tasks_M/VIS_CTI_Data_Visualize.py": [
                        [
                            "@@ -1,175 +0,0 @@\n-# Copyright (C) 2012-2020 Euclid Science Ground Segment\r\n-#\r\n-# This library is free software; you can redistribute it and/or modify it under the terms of the GNU Lesser General\r\n-# Public License as published by the Free Software Foundation; either version 3.0 of the License, or (at your option)\r\n-# any later version.\r\n-#\r\n-# This library is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied\r\n-# warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\r\n-# details.\r\n-#\r\n-# You should have received a copy of the GNU Lesser General Public License along with this library; if not, write to\r\n-# the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\r\n-#\r\n-import argparse\r\n-import os\r\n-import sys\r\n-\r\n-if sys.version_info[0] < 3:\r\n-    from ConfigParser import RawConfigParser\r\n-else:\r\n-    from configparser import RawConfigParser\r\n-import shutil\r\n-\r\n-# Euclid specific imports\r\n-import ElementsKernel.Logging as log\r\n-from astropy.io import fits\r\n-import numpy as np\r\n-import re\r\n-\r\n-# Local imports\r\n-from VIS_PyLibrary_Common import pe_run_information\r\n-\r\n-from VIS_Tasks_Common.FromToXML import read_json, write_json\r\n-from VIS_PyLibrary_Common import pipe_tools\r\n-\r\n-# initialise global logger\r\n-import ElementsKernel.Logging\r\n-\r\n-logger = ElementsKernel.Logging.getLogger(__name__)\r\n-\r\n-\r\n-def defineSpecificProgramOptions():\r\n-    \"\"\"\r\n-    @brief Allows to define the (command line and configuration file) options\r\n-    specific to this program\r\n-\r\n-    @details\r\n-    See the Elements documentation for more details.\r\n-    @return\r\n-    An  ArgumentParser.\r\n-    \"\"\"\r\n-\r\n-    # Inputs\r\n-    parser = argparse.ArgumentParser()\r\n-\r\n-    parser.add_argument(\"--workdir\", type=str, help=\"absolute path to the workdir\")\r\n-    parser.add_argument(\r\n-        \"--logdir\", type=str, help=\"path to the logdir, relative to the workdir\"\r\n-    )\r\n-    parser.add_argument(\"--config\", type=str, help=\"configuration file path\")\r\n-    parser.add_argument(\"--input_quads\", type=str)\r\n-    # Outputs\r\n-    parser.add_argument(\"--visualize_output\", type=str, help=\"Visualize json file\")\r\n-\r\n-    return parser\r\n-\r\n-\r\n-def mainMethod(args):\r\n-\r\n-    logger.info(\"#\")\r\n-    logger.info(\"# Entering %s mainMethod()\" % __name__)\r\n-    logger.info(\"# command line: \" + pipe_tools.get_erun_commandline())\r\n-    pipe_tools.log_task_environment(logger)\r\n-    logger.info(\"#\")\r\n-\r\n-    logdir = os.path.join(args.workdir, args.logdir)\r\n-    config_filename = os.path.join(args.workdir, args.config)\r\n-    input_quads = os.path.join(args.workdir, args.input_quads)\r\n-    visualize_output_name = os.path.join(args.workdir, args.visualize_output)\r\n-\r\n-    logger.info(\"ccdlistname: \" + visualize_output_name)\r\n-\r\n-    # Check that configuration file exists\r\n-    if os.path.isfile(config_filename) == False:\r\n-        logger.error(\"%s does not exist or is not readable\", config_filename)\r\n-        exit(1)\r\n-    # Instantiate the configuration file parser\r\n-    config = RawConfigParser()\r\n-    # Make it case-sensitive for parameter names\r\n-    config.optionxform = str\r\n-    # Open the configuration file\r\n-    config.read(config_filename)\r\n-\r\n-    # Set up logger\r\n-    logger.setLevel(\"DEBUG\")\r\n-\r\n-    logger.info(input_quads)\r\n-\r\n-    # Read parameters from config file\r\n-    # initialise PERunInformation dictionary for Data Quality Control\r\n-    # To be done later.\r\n-    peri = dict()\r\n-\r\n-    # Load quad name files.\r\n-    # NOTE: This is NOT 8*144 yet but 8 files/tuplelist.  These 8 files contain the 144 quads\r\n-    # I thin because of how we defined it in IAL Pip/Pkg these 8 files are in a file as a list of list\r\n-    # Basically a list of 8x1 where 1 is the file name.  Probably could be fixed in IAL definition.\r\n-    # Just in case it is 8x? higher than 1, will load up everything below.\r\n-    quad_name_files = [read_json(input_quads)]\r\n-    logger.info(\"Names of Quad Files:\")\r\n-    [logger.info(quad_name) for quad_name in quad_name_files]\r\n-\r\n-    visualize_output = []\r\n-\r\n-    # prefix file names with workdir\r\n-    all_quads = []\r\n-    print(f\"NUM FILES (FPARef_A): {quad_name_files}\")\r\n-    for i in range(len(quad_name_files)):\r\n-\r\n-        logger.info(\r\n-            f\"Quad Name file {i}: \"\r\n-            + str(quad_name_files[i])\r\n-            + \" len: \"\r\n-            + str(len(quad_name_files[i]))\r\n-        )\r\n-\r\n-        logger.info(\"quad name files[][]: \" + str(quad_name_files[i][0]))\r\n-\r\n-        for qname_tuple_file in quad_name_files[i]:\r\n-\r\n-            logger.info(\"Print QuadName TupleList: \" + qname_tuple_file)\r\n-            quad_144_list = read_json(qname_tuple_file)\r\n-            logger.info(\"Len quad_144_list: \" + str(quad_144_list))\r\n-            all_quads.append(quad_144_list)\r\n-\r\n-    # In a perfect world this [8][144] should be the same size and we don't bother opening fits files.\r\n-    # we just make file references from these lists. We are going for now to assume were in a perfect world\r\n-    # also a big assumption that every 4 quadrants are part of the same CCD.\r\n-    num_quads = len(all_quads[0])\r\n-\r\n-    # print(\"NUM FILES (FPARef_B): \" + str(all_quads))\r\n-    logger.info(\r\n-        \"NUM Quads in index 0: \"\r\n-        + str(num_quads)\r\n-        + \" Num of indexes: \"\r\n-        + str(len(all_quads[0]))\r\n-    )\r\n-\r\n-    print(all_quads)\r\n-    dddd\r\n-\r\n-    ccd_num = int(num_quads / 4)\r\n-    logger.info(\"Number of ccd to do: \" + str(ccd_num))\r\n-    for i in range(ccd_num):\r\n-        # For now lets store these names and everything in the gater_ccd directory instead of workdir.\r\n-        # Note it has .json names to this file we should do a strip or something here.\r\n-\r\n-        # file_name = visualize_output_name + \"_cti.\" + str(i) + \".json\"\r\n-        file_name = os.path.basename(visualize_output_name) + \"fpa_quad_\" + str(i) + \".png\"\r\n-\r\n-        ccd_quads = []\r\n-        visualize_output.append(file_name)\r\n-        for j in range(len(all_quads)):\r\n-            start_range = i * 4\r\n-            end_range = i * 4 + 4\r\n-            for k in range(start_range, end_range):\r\n-                ccd_quads.append(all_quads[j][k])\r\n-\r\n-\r\n-    logger.info(\"Writing to: \" + os.path.basename(visualize_output_name))\r\n-    write_json(visualize_output, visualize_output_name)\r\n-\r\n-    logger.info(\"#\")\r\n-    logger.info(\"# Exiting %s mainMethod()\" % __name__)\r\n-    logger.info(\"#\")\r\n",
                            "Merge branch 'release-13.0' into 'feature_#23227_BloomingCalib'",
                            "Thomas Flanet",
                            "2023-08-17T15:43:48.000+00:00",
                            "9d236be45ec452966840965083cd59dc82102cf0"
                        ]
                    ],
                    "VIS_Tasks_M/python/VIS_Tasks_M/VIS_cti_master_ci_xml_out.py": [
                        [
                            "@@ -0,0 +1,147 @@\n+\"\"\"\r\n+@file: python/Tasks/VIS_master_ci_xml_out.py\r\n+@author: user\r\n+@date: 21/02/2023\r\n+\"\"\"\r\n+\r\n+#Standard library imports\r\n+import argparse\r\n+import os\r\n+import fitsio\r\n+import json\r\n+from pathlib import Path\r\n+import shutil\r\n+from typing import Union\r\n+\r\n+\r\n+# Euclid specific imports\r\n+from ST_DM_FilenameProvider.FilenameProvider import FileNameProvider\r\n+from ST_DM_DmUtils import DmUtils\r\n+from ST_DataModelBindings.bas import img_stub\r\n+from ST_DataModelBindings.pro import vis_stub\r\n+from ST_DataModelBindings.dpd.vis import vismasterciframe_stub\r\n+from VIS_Tasks_Common.FromToXML import (\r\n+  vis_filter,\r\n+  create_validity_range,\r\n+  vis_generic_header,\r\n+  create_img_type,\r\n+  UNKNOWN_STRING,\r\n+  add_quality_parameter_file\r\n+)\r\n+\r\n+from VIS_PyLibrary_Common.zip_tools import tar_zip_files\r\n+from VIS_PyLibrary_Common import pipe_tools\r\n+\r\n+import ElementsKernel.Logging\r\n+logger = ElementsKernel.Logging.getLogger( __name__)\r\n+\r\n+\r\n+################################################################################\r\n+\r\n+def defineSpecificProgramOptions():\r\n+\r\n+    parser = argparse.ArgumentParser()\r\n+    # inputs\r\n+    parser.add_argument( '--workdir',                    required=True,  help='absolute path to the workdir')\r\n+    parser.add_argument( '--logdir',                     required=True,  help='path to the logdir, relative to the workdir')\r\n+    parser.add_argument('--config',                                      help='configuration file path')\r\n+    parser.add_argument( '--cti_master_ci_list', required=True,  help='Path to the master CI results json file')\r\n+    # outputs\r\n+    parser.add_argument( '--master_ci_xml_out',                required=True,  help='output master CI results xml filename')\r\n+    return parser\r\n+\r\n+################################################################################\r\n+\r\n+def write_tar_zip(in_files: list[Union[Path, str]], out_file: Path) -> None:\r\n+  tar_zip_files(\" \".join(map(str, in_files)), str(out_file), False)\r\n+\r\n+def mainMethod( args):\r\n+\r\n+  logger.info( '#')\r\n+  logger.info( '# Entering %s mainMethod()' % __name__)\r\n+  logger.info( '# command line: ' + pipe_tools.get_erun_commandline())\r\n+  pipe_tools.log_task_environment( logger)\r\n+  logger.info( '#')\r\n+  \r\n+  # Create workdir folders for XML files if not present:\r\n+  \r\n+  if not os.path.isabs( args.master_ci_xml_out):\r\n+    args.master_ci_xml_out = os.path.join( args.workdir, args.master_ci_xml_out)\r\n+\r\n+  out_dir = os.path.split(args.master_ci_xml_out )[0]\r\n+  os.makedirs(out_dir, exist_ok=True)\r\n+\r\n+  with open(args.cti_master_ci_list, \"r\") as f:\r\n+    master_ci_filename_fits = json.load(f)\r\n+\r\n+  workdir_master_path = os.path.join(args.workdir, master_ci_filename_fits)\r\n+  data_path = os.path.join(args.workdir, \"data\")\r\n+  shutil.copy(workdir_master_path, data_path)\r\n+\r\n+  master_ci_data_path_fits = os.path.join(data_path, master_ci_filename_fits)\r\n+\r\n+  # Create the data product\r\n+  data_product = vismasterciframe_stub.DpdVisMasterCIFrame()\r\n+\r\n+  # Add Header\r\n+  data_product.Header = vis_generic_header(\"DpdVisMasterCIFrame\")\r\n+\r\n+  # Add Data\r\n+  data = vis_stub.visMasterCIFrame.Factory()\r\n+\r\n+  # Open the FITS file\r\n+  fits = fitsio.FITS(master_ci_data_path_fits, 'r')\r\n+  nhdu = fits[-1].get_extnum()\r\n+  header = fits[1].read_header()\r\n+\r\n+  data.ImgType = create_img_type(\"CALIB\", \"CHARGE_INJECTION\", \"OTHER\", \"CALIBRATION\")\r\n+  data.ImgArea = img_stub.imgArea(Name=\"QUADRANT\")\r\n+  data.ImgNumber = nhdu\r\n+  data.AxisNumber = header[\"NAXIS\"]\r\n+\r\n+  data.AxisLengths = [header[\"NAXIS1\"], header[\"NAXIS2\"]]\r\n+  data.DataSize = header[\"BITPIX\"]\r\n+  data.DataLength = header[\"NAXIS1\"] * header[\"NAXIS2\"]\r\n+  data.ValidityRange = create_validity_range()\r\n+  data.Filter = vis_filter()\r\n+  # DataStorage\r\n+  data.DataStorage = DmUtils.create_fits_storage(\r\n+    vis_stub.visMasterCIStorageFitsFile,\r\n+    os.path.basename(master_ci_filename_fits), \"vis.masterCI\", \"0.1\"\r\n+  )\r\n+\r\n+  fits.close()\r\n+\r\n+\r\n+  # Add data to data product\r\n+  data_product.Data = data\r\n+\r\n+\r\n+  # All data quality images (.png files) are in the folder workdir/data/parallel_images_***\r\n+  # We zip this folder into a .tar file and add it to the data product\r\n+\r\n+  dq_file = FileNameProvider().get_allowed_filename(\r\n+    processing_function='VIS',\r\n+    type_name=\"QC-PLOTS-MASTER-CI\",\r\n+    instance_id='',\r\n+    extension='.tar.gz'\r\n+  )\r\n+\r\n+  dq_folder = os.path.join(args.workdir, \"data\", \"images\")\r\n+  dq_tar_path = os.path.join(args.workdir, \"data\", dq_file)\r\n+\r\n+  write_tar_zip([dq_folder], dq_tar_path)\r\n+\r\n+  add_quality_parameter_file(data_product, dq_file)\r\n+\r\n+  dqc_params_dm = vis_stub.visDqcParams.Factory()\r\n+\r\n+  data_product.QualityParams = dqc_params_dm\r\n+\r\n+  # Output to XML^M                                                                                   \r\n+\r\n+  DmUtils.save_product_metadata(data_product, args.master_ci_xml_out)\r\n+\r\n+  logger.info( \"#\")\r\n+  logger.info( \"# Exiting %s mainMethod()\" % __name__)\r\n+  logger.info( \"#\")\r\n",
                            "Merge branch 'release-13.0' into 'feature_#23227_BloomingCalib'",
                            "Thomas Flanet",
                            "2023-08-17T15:43:48.000+00:00",
                            "9d236be45ec452966840965083cd59dc82102cf0"
                        ]
                    ],
                    "VIS_Tasks_M/python/VIS_Tasks_M/VIS_science_xml_out.py": [
                        [
                            "@@ -335,10 +335,12 @@ def mainMethod(args):\n         update_background_zodimodel( background, config, int( primhdr['EXPTIME']))\n \n         # Get Euclid filenames\n+        # SWL-DET has 3 extensions per detector, bug in fitsio prevents from generating it compressed\n+        # so generate it uncompressed and compress it after data product creation\n         euc_det_file = filename_provider_obj.get_allowed_filename(processing_function='VIS',\n                                                           type_name=\"SWL-DET-\" + exp_id + \"-0000000\",\n                                                           instance_id='',\n-                                                          extension=fits_ext)\n+                                                          extension=\".fits\")\n         euc_bkg_file = filename_provider_obj.get_allowed_filename(processing_function='VIS',\n                                                              type_name=\"SWL-BKG-\" + exp_id + \"-0000000\",\n                                                              instance_id='',\n@@ -380,6 +382,14 @@ def mainMethod(args):\n                                                    euc_bkg_file,\n                                                    euc_wgt_file,\n                                                    raw_meta = exposure_config_section)\n+        if ZIP_OUTPUTS:\n+          # compress SWL-DET FITS file and put its compressed name in data product\n+          zip_tools.zip_file( os.path.join( datadir, euc_det_file),\n+                              os.path.join( datadir, euc_det_file + \".gz\"),\n+                              options=\"\")\n+          euc_det_file += \".gz\"\n+          vis_cal_frame_dp.Data.DataStorage.DataContainer.FileName = euc_det_file\n+\n         # Spatial footprint observation sequence and observation date will be needed for single exposure catalog\n         spatial_footprint = vis_cal_frame_dp.Data.ImgSpatialFootprint\n         observation_sequence = vis_cal_frame_dp.Data.ObservationSequence\n",
                            "Merge branch 'release-13.0' into 'feature_#23227_BloomingCalib'",
                            "Thomas Flanet",
                            "2023-08-17T15:43:48.000+00:00",
                            "9d236be45ec452966840965083cd59dc82102cf0"
                        ]
                    ],
                    "VIS_PRNU/python/VIS_PRNU/VIS_CombinePRNU.py": [
                        [
                            "@@ -1,222 +0,0 @@\n-#\n-# Copyright (C) 2012-2020 Euclid Science Ground Segment\n-#\n-# This library is free software; you can redistribute it and/or modify it under\n-# the terms of the GNU Lesser General Public License as published by the Free\n-# Software Foundation; either version 3.0 of the License, or (at your option)\n-# any later version.\n-#\n-# This library is distributed in the hope that it will be useful, but WITHOUT\n-# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n-# FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more\n-# details.\n-#\n-# You should have received a copy of the GNU Lesser General Public License\n-# along with this library; if not, write to the Free Software Foundation, Inc.,\n-# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n-#\n-\n-\n-\"\"\"\n-:file: python/VIS_PRNU/VIS_CombinePRNU.py\n-\n-:date: 05 Jul. 22\n-:author: mottet@iap.fr\n-\n-\"\"\"\n-\n-import argparse\n-import os\n-from astropy.io import fits\n-import json\n-import logging\n-logger = logging.getLogger( __name__)\n-\n-from ST_DM_DmUtils import DmUtils\n-from ST_DM_FilenameProvider.FilenameProvider import FileNameProvider\n-from VIS_Tasks_Common import FromToXML\n-\n-\n-################################################################################\n-# global definitions\n-\n-LED_IDS = (\"LED1\", \"LED2\", \"LED3\", \"LED4\", \"LED5\", \"LED6\")\n-\n-\n-################################################################################\n-\n-def example_flat_model():\n-  \"\"\"Create a flat linear combination model:\n-model = {\n-  \"LED1\": 0.16666666666666667,\n-  \"LED2\": 0.16666666666666667,\n-  \"LED3\": 0.16666666666666667,\n-  \"LED4\": 0.16666666666666667,\n-  \"LED5\": 0.16666666666666667,\n-  \"LED6\": 0.16666666666666667\n-}\n-\"\"\"\n-\n-  model = dict()\n-  for led_id in LED_IDS:\n-    model[led_id] = 1.0 / len( LED_IDS)\n-  return model\n-\n-\n-################################################################################\n-\n-def write_combine_model( combination_model, filename):\n-  \"\"\"Write the 'combination_model' to 'filename' JSON file\"\"\"\n-\n-  with open( filename, \"w\") as f:\n-    json.dump( combination_model, f, indent=2)\n-  return\n-\n-\n-################################################################################\n-\n-def read_combine_model( filename):\n-  \"\"\"Read a PRNU combination model from 'filename' JSON file\n-  and test it contains exactly one element per LED\"\"\"\n-\n-  with open( filename, \"r\") as f:\n-    model = json.load( f)\n-  for led_id in LED_IDS:\n-    assert led_id in model\n-  return model\n-\n-\n-################################################################################\n-\n-def get_PRNU_LED( prnu_filename, prim_hdr):\n-  \"\"\"Return the number of the first LED which status is 'On' in 'prnu_filename' primary header, eg.:\n-CULEDDUR = 0.2 / If CU on: pulse duration in (s)\n-LED1STA  = Off / If CU on: LED 1 status: On or Off\n-LED1CUR  = 0   / If LED1 on: current (mA)\n-LED2STA  = On  / If CU on: LED 2 status: On or Off\n-LED2CUR  = 19  / If LED2 on: current (mA)\n-LED3STA  = Off / If CU on: LED 3 status: On or Off\n-LED3CUR  = 0   / If LED3 on: current (mA)\n-LED4STA  = Off / If CU on: LED 4 status: On or Off\n-LED4CUR  = 0   / If LED4 on: current (mA)\n-LED5STA  = Off / If CU on: LED 5 status: On or Off\n-LED5CUR  = 0   / If LED5 on: current (mA)\n-LED6STA  = Off / If CU on: LED 6 status: On or Off\n-LED6CUR  = 0   / If LED6 on: current (mA)\n-\"\"\"\n-\n-  for led_id in LED_IDS:\n-    card = f\"{led_id}STA\"\n-    if (card in prim_hdr) and (prim_hdr[card].strip().lower() == \"on\"):\n-      return led_id\n-  raise Exception( f\"No active LED found in input monochromatic PRNU {prnu_filename}\")\n-  return\n-\n-\n-################################################################################\n-\n-def combine_PRNU( prnu_filelist, combine_model, prnu_file_out):\n-  \"\"\"Linearly combine all quadrants in PRNU files in 'prnu_filelist'\n-  with coefficients in 'combine_model' and write the result in 'prnu_file_out' FITS file\n-\"\"\"\n-\n-  # get LED identifiant of each input monochromatic PRNU\n-  # and create a primary header storing the combined PRNU file names and coefficients\n-  prnu_dict = dict()\n-  prim_hdr = dict()\n-  for prnu_filename in prnu_filelist:\n-    hdul_in = fits.open( prnu_filename, memmap=False)\n-    led_id = get_PRNU_LED( prnu_filename, hdul_in[0].header)\n-    prnu_dict[led_id] = hdul_in\n-    prim_hdr[led_id + \"FILE\"] = os.path.basename( prnu_filename)\n-    prim_hdr[led_id + \"COEF\"] = combine_model[led_id]\n-\n-  assert set( prnu_dict.keys()) == set( LED_IDS), \\\n-    f\"ERROR: there must be exactly one input monochromatic PRNU for each LED ({len( LED_IDS)})\"\n-\n-  # create the output combined PRNU FITS file primary HDU\n-  logger.info( \"create output combined PRNU file: \" + prnu_file_out)\n-  fits.HDUList( [fits.PrimaryHDU( header=prim_hdr)]).writeto( prnu_file_out, overwrite=True)\n-\n-  # combine each quadrant and append it to ouput FITS file\n-  hdul0 = prnu_dict[LED_IDS[0]]\n-  for hdu in hdul0[1:]:\n-    combined_quad = np.zeros_like( hdu.data)\n-    extname = hdu.header[\"EXTNAME\"]\n-    logger.info( \"combine \" + extname)\n-    for led_id in LED_IDS:\n-      combined_quad += combine_model[led_id] * prnu_dict[led_id][extname].data\n-      prnu_dict[led_id][extname].data = None\n-    fits.append( prnu_file_out, fits.ImageHDU( data=combined_quad, name=extname), verify=False)\n-  return\n-\n-\n-################################################################################\n-\n-def defineSpecificProgramOptions():\n-\n-  ap = argparse.ArgumentParser( description=\"Monochromatic PRNU combination pipeline\")\n-\n-  # https://euclid.roe.ac.uk/projects/codeen-users/wiki/Pipeline_Interfaces#Arguments\n-  # \"The workdir and logdir parameters are mandatory - any task to be run as part of a pipeline needs to support these parameters\"\n-  ap.add_argument( \"--workdir\",        required=True, help=\"absolute path to the working directory\")\n-  ap.add_argument( \"--logdir\",         required=True, help=\"path to the log directory, relative to 'workdir'\")\n-  # parameters\n-  ap.add_argument( \"--MDB\",            required=True, help=\"MDB XML file path relative to 'workdir'\")\n-  # input\n-  ap.add_argument( \"--monoprnu_list\",  required=True, help=\"list of input monochromatic PRNU to combine\")\n-  # output\n-  ap.add_argument( \"--masterflat_out\", required=True, help=\"output model XML file path, relative to workdir\")\n-  return ap\n-\n-\n-################################################################################\n-\n-def mainMethod( args):\n-\n-  logger.info( \"#\")\n-  logger.info( \"# Entering %s mainMethod()\" % __name__)\n-  logger.info( \"# command line: \" + pipe_tools.get_erun_commandline())\n-  pipe_tools.log_task_environment( logger)\n-  logger.info( \"#\")\n-\n-  data_dir = os.path.join( args.workdir, \"data\")\n-\n-  # get input monochromatic PRNU files list\n-  prnu_filelist = list()\n-  prnu_xml_list = FromToXML.load_list_from_file( os.path.join( args.workdir, args.monoprnu_list))\n-  for xml_file in prnu_xml_list:\n-    prnu = FromToXML.get_xml_data_file_list( os.path.join( workdir, xml_file))[0]\n-    prnu_filelist.append( os.path.join( data_dir, prnu))\n-  assert len( prnu_filelist) == len( LED_IDS), \\\n-    f\"ERROR: there must be one input monochromatic PRNU file per LED ({len( LED_IDS)})\"\n-\n-  # get PRNU combination model from MDB\n-  if not os.path.isabs( args.MDB):\n-    args.MDB = os.path.join( args.workdir, args.MDB)\n-  mdb = ST_DM_MDBTools.Mdb.Mdb( args.MDB)\n-  combine_model_key = \"SpaceSegment.Instrument.VIS.PRNUCombineModel\"\n-  if combine_model_key in mdb:\n-    combine_model = read_combine_model( mdb.get_value( combine_model_key))\n-  else:\n-    # dev-only, to be removed when actual combination model put in MDB\n-    logger.error( f\"!!! '{combine_model_key}' not found in MDB, using flat model instead\")\n-    combine_model = example_flat_model()\n-\n-  # produce the output combined PRNU file\n-  combined_PRNU = FileNameProvider().get_allowed_filename( processing_function=\"VIS\",\n-                                                           type_name=\"MSR-FLA-\",\n-                                                           instance_id=\"\",\n-                                                           extension=\".fits\")\n-  combined_PRNU = os.path.join( data_dir, combined_PRNU)\n-  logger.info( \"writing output combined PRNU FITS file to \" + combined_PRNU)\n-  combine_PRNU( prnu_filelist, combine_model, combined_PRNU)\n-\n-  # create and write output XML file encapsulating combined PRNU FITS file\n-  xml_out = FromToXML.master_flat_dp( combined_PRNU)\n-  logger.info( \"writing output XML file to \" + args.masterflat_out)\n-  DmUtils.save_product_metadata( xml_out, args.masterflat_out)\n-\n-  logger.info( \"#\")\n-  logger.info( \"# Exiting %s mainMethod()\" % __name__)\n-  logger.info( \"#\")\n",
                            "VIS_PRNU/VIS_CombinePRNU.py: remove file which superseded by VIS_PRNU/VIS_SmallScaleFlat/VIS_CombinePRNU.py",
                            "Sylvain Mottet",
                            "2023-08-17T14:46:56.000+02:00",
                            "56de0a9ff38dff740fbcee7004562f5f30662ada"
                        ]
                    ],
                    "VIS_Tasks_M/python/VIS_Tasks_M/VIS_gather_ccd.py": [
                        [
                            "@@ -330,12 +330,14 @@ def mainMethod(args):\n       # and adds the CCD to the FPA plot image\n       fpa_plot.plot_ext( ccd_science.data, ccd_science.header)\n       # and produce a background FITS using NoiseChisel\n-      try:\n-        # ignore exceptions, this is just test code for now\n-        bkg, det = VIS_Gnuastro.NoiseChisel_array_to_array( ccd_science.data)\n-        fits.append( ncbkg_filename, bkg, header=ccd_science.header, verify=False)\n-      except:\n-        logger.info( \"CAUGHT AN EXCEPTION IN VIS_Gnuastro.NoiseChisel_array_to_array\")\n+\n+# SM 17 aug 23: disabled until useful\n+#      try:\n+#        # ignore exceptions, this is just test code for now\n+#        bkg, det = VIS_Gnuastro.NoiseChisel_array_to_array( ccd_science.data)\n+#        fits.append( ncbkg_filename, bkg, header=ccd_science.header, verify=False)\n+#      except:\n+#        logger.info( \"CAUGHT AN EXCEPTION IN VIS_Gnuastro.NoiseChisel_array_to_array\")\n \n \n     # remove temporary files\n",
                            "VIS_gather_ccd.py: disabled NoiseChisel background, which takes time but isn't used anywhere for now",
                            "Sylvain Mottet",
                            "2023-08-17T14:44:28.000+02:00",
                            "da5933d6ac9da9305f5742975f5910e87f9dfa28"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "13.0.12",
                        "created_at": "2023-08-13T15:44:17.000+00:00",
                        "author_name": "Catherine Grenet"
                    },
                    {
                        "name": "13.0.13",
                        "created_at": "2023-08-16T12:27:54.000+00:00",
                        "author_name": "Catherine Grenet"
                    },
                    {
                        "name": "13.0.14",
                        "created_at": "2023-08-22T13:27:01.000+00:00",
                        "author_name": "Catherine Grenet"
                    }
                ]
            },
            "PF-VIS/VIS_SatPixels": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_Photometry": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_NonLinCalibration": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_RemovePRNU": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_PyLibrary": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_MeasurePRNU": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_RemoveLamp": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_MeasureLamp": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_MasterBias": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_ImageTools": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_Ghosts": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_CTICalibrate": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_CTICorrect": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_CTIAdd": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_CTI_from_Git": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_Background": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-VIS/VIS_Astrometry": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            }
        },
        "PF-NIR": {
            "PF-NIR/NIR_Baseline": {
                "start date": "-",
                "end date": "2023-08-22T10:31:15",
                "start tag": "",
                "end tag": "2.4.1",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_Documentation": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_DQC_Pipeline": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_TransientDetection": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_Dependencies": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_SelfCalib": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_IAL_Pipelines": {
                "start date": "2023-08-09T21:58:44",
                "end date": "2023-08-22T16:51:07",
                "start tag": "2.3.1",
                "end tag": "2.4.1",
                "count_files_modified": "6",
                "modifications_by_file": {
                    "CMakeLists.txt": [
                        [
                            "@@ -12,7 +12,7 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(NIR_IAL_Pipelines 2.4\n+elements_project(NIR_IAL_Pipelines 2.5\n                  USE\n                  Elements 6.2.1\n                  ST_DataModel 9.2.0\n",
                            "Bumping version after tagging",
                            "Marco Frailis",
                            "2023-08-18T12:03:02.000+00:00",
                            "41b7063756f02bb1431ebfb02f0b1f43e4bfb1b3"
                        ],
                        [
                            "@@ -12,7 +12,7 @@ find_package(ElementsProject)\n #                         elements_project(MyProject 1.0 USE Element 3.9)\n #===============================================================================\n \n-elements_project(NIR_IAL_Pipelines 2.3\n+elements_project(NIR_IAL_Pipelines 2.4\n                  USE\n                  Elements 6.2.1\n                  ST_DataModel 9.2.0\n",
                            "Bumping version after tagging",
                            "Marco Frailis",
                            "2023-08-10T09:49:42.000+00:00",
                            "17351505403b404f88031c3019befa2129398431"
                        ]
                    ],
                    "NIR_IAL_Pipelines/auxdir/NIR_Pipelines/PackageDef_NIR.py": [
                        [
                            "@@ -1,75 +1,78 @@\n from euclidwf.framework.taskdefs import Executable, Input, Output, ComputingResources\n \n-extractLists2 = Executable(command='E-Run NIR_Utilities  NIR_ExtractLists',\n+\n+proj_version = \"\"\n+\n+extractLists2 = Executable(command=f'E-Run NIR_Utilities {proj_version} NIR_ExtractLists',\n                            inputs=[Input('inlist', content_type='listfile')],\n                            outputs=[Output('outlist1', content_type='listfile', mime_type='json'),\n                                     Output('outlist2', content_type='listfile', mime_type='json')],\n                            resources=ComputingResources(cores=1, ram=1.0, walltime=1.0))\n \n-combineLists2 = Executable(command='E-Run NIR_Utilities  NIR_CombineLists',\n+combineLists2 = Executable(command=f'E-Run NIR_Utilities {proj_version} NIR_CombineLists',\n                            inputs=[Input('inlist1', content_type='listfile'),\n                                    Input('inlist2', content_type='listfile')],\n                            outputs=[Output('outlist', content_type='listfile', mime_type='json')],\n                            resources=ComputingResources(cores=1, ram=4.0, walltime=1.0))\n \n-runInitialize = Executable(command='E-Run NIR_Init  NIR_runInitialize',\n+runInitialize = Executable(command=f'E-Run NIR_Init {proj_version} NIR_runInitialize',\n                            inputs=[Input('infile'), Input('mdbfile')],\n                            outputs=[Output('outfile', mime_type='fits')],\n                            resources=ComputingResources(cores=1, ram=2.0, walltime=1.0))\n \n # To be used only for Baseline Map pre-processing\n-runInitializeBaseline = Executable(command='E-Run NIR_Init  NIR_runInitialize --no_trim',\n+runInitializeBaseline = Executable(command=f'E-Run NIR_Init {proj_version} NIR_runInitialize --no_trim',\n                            inputs=[Input('infile'), Input('mdbfile')],\n                            outputs=[Output('outfile', mime_type='fits')],\n                            resources=ComputingResources(cores=1, ram=2.0, walltime=1.0))\n \n-badPixMasking = Executable(command='E-Run NIR_BadPixelMasking  maskBadpixels',\n+badPixMasking = Executable(command=f'E-Run NIR_BadPixelMasking {proj_version} maskBadpixels',\n                            inputs=[Input('infile'), Input('xmlfile')],\n                            outputs=[Output('outfile', mime_type='fits')],\n                            resources=ComputingResources(cores=1, ram=2.0, walltime=1.0))\n \n-saturation = Executable(command='E-Run NIR_NonLinearSaturation  maskSaturation',\n+saturation = Executable(command=f'E-Run NIR_NonLinearSaturation {proj_version} maskSaturation',\n                         inputs=[Input('infile'), Input('xmlfile')],\n                         outputs=[Output('outfile', mime_type='fits')],\n                         resources=ComputingResources(cores=1, ram=2.0, walltime=1.0))\n \n-nonLinearity = Executable(command='E-Run NIR_NonLinearSaturation  correctNonlinearity',\n+nonLinearity = Executable(command=f'E-Run NIR_NonLinearSaturation {proj_version} correctNonlinearity',\n                           inputs=[Input('infile'), Input('xmlfile'), Input('config')],\n                           outputs=[Output('outfile', mime_type='fits')],\n                           resources=ComputingResources(cores=1, ram=20.0, walltime=1.0))\n \n-darkSubtract = Executable(command='E-Run NIR_DarkBiasSubtraction  darkSubtraction',\n+darkSubtract = Executable(command=f'E-Run NIR_DarkBiasSubtraction {proj_version} darkSubtraction',\n                           inputs=[Input('infile'), Input('masterdark')],\n                           outputs=[Output('outfile', mime_type='fits')],\n                           resources=ComputingResources(cores=1, ram=3.0, walltime=1.0))\n \n-crRejectionSF = Executable(command='E-Run NIR_CrRejectionSingleFrame  NIR_cr_rejection',\n+crRejectionSF = Executable(command=f'E-Run NIR_CrRejectionSingleFrame {proj_version} NIR_cr_rejection',\n                            inputs=[Input('infile'), Input('config')],\n                            outputs=[Output('output', mime_type='fits')],\n                            resources=ComputingResources(cores=1, ram=2.0, walltime=1.0))\n \n-smallFlatCorrect = Executable(command='E-Run NIR_FlatFieldCorrection  NIR_apply_flat_field_correction',\n+smallFlatCorrect = Executable(command=f'E-Run NIR_FlatFieldCorrection {proj_version} NIR_apply_flat_field_correction',\n                               inputs=[Input('infile'), Input('masterflat')],\n                               outputs=[Output('output', mime_type='fits')],\n                               resources=ComputingResources(cores=1, ram=3.0, walltime=1.0))\n \n-largeFlatCorrect = Executable(command='E-Run NIR_SelfCalib  NIR_Apply',\n+largeFlatCorrect = Executable(command=f'E-Run NIR_SelfCalib {proj_version} NIR_Apply',\n                               inputs=[Input('infile'), Input('flat')],\n                               outputs=[Output('outfile', mime_type='fits')],\n                               resources=ComputingResources(cores=1, ram=3.0, walltime=1.0))\n \n-backEstimate = Executable(command='E-Run NIR_BackgroundEstimation  NIR_estimate_background',\n+backEstimate = Executable(command=f'E-Run NIR_BackgroundEstimation {proj_version} NIR_estimate_background',\n                           inputs=[Input('input')],\n                           outputs=[Output('outputbkg', mime_type='fits')],\n                           resources=ComputingResources(cores=1, ram=2.0, walltime=1.0))\n \n-psfForDither = Executable(command='E-Run NIR_PointSpreadFunction NIR_PSFModelling --imagetype=dither --psfex_cpp False',\n+psfForDither = Executable(command=f'E-Run NIR_PointSpreadFunction {proj_version} NIR_PSFModelling --imagetype=dither --psfex_cpp False',\n                           inputs=[Input('listofimages', content_type='listfile'),\n                                   Input('mdbfile'), Input('cal_data'), Input('config')],\n                           outputs=[Output('listofpsflists', content_type='listfile', mime_type='json')],\n                           resources=ComputingResources(cores=1, ram=3.0, walltime=3.0))\n \n-psfForDitherAbsCal = Executable(command='E-Run NIR_PointSpreadFunction NIR_PSFModelling --imagetype=dither --psflistcontent all_dithers --psfex_cpp False',\n+psfForDitherAbsCal = Executable(command=f'E-Run NIR_PointSpreadFunction {proj_version} NIR_PSFModelling --imagetype=dither --psflistcontent all_dithers --psfex_cpp False',\n                           inputs=[\n                                 Input('listofimages', content_type='listfile'),\n                                 Input('mdbfile'),\n@@ -78,7 +81,7 @@ psfForDitherAbsCal = Executable(command='E-Run NIR_PointSpreadFunction NIR_PSFMo\n                           resources=ComputingResources(cores=1, ram=3.0, walltime=4.0))\n \n \n-doAstrom = Executable(command='E-Run NIR_AstrometricCalibration  NIR_DoastromProgram',\n+doAstrom = Executable(command=f'E-Run NIR_AstrometricCalibration {proj_version} NIR_DoastromProgram',\n                       inputs=[Input('listofdithers', content_type='listfile'),\n                               Input('listofpsflists', content_type='listfile'),\n                               Input('ref_catalog', content_type='listfile'),\n@@ -88,23 +91,23 @@ doAstrom = Executable(command='E-Run NIR_AstrometricCalibration  NIR_DoastromPro\n                                Output('fullcatalog', mime_type='fits')],\n                       resources=ComputingResources(cores=1, ram=3.0, walltime=2.0))\n \n-crRejectionMF = Executable(command='E-Run NIR_CrRejectionMultiFrame  CrRejectMulti',\n+crRejectionMF = Executable(command=f'E-Run NIR_CrRejectionMultiFrame {proj_version} CrRejectMulti',\n                            inputs=[Input('dith_file', content_type='listfile')],\n                            outputs=[Output('dith_file_out', content_type='listfile', mime_type='json')],\n                            resources=ComputingResources(cores=1, ram=4.0, walltime=3.0))\n \n-crDeflag = Executable(command='E-Run NIR_CrRejectionMultiFrame  Deflagging',\n+crDeflag = Executable(command=f'E-Run NIR_CrRejectionMultiFrame {proj_version} Deflagging',\n                            inputs=[Input('input_list', content_type='listfile')],\n                            outputs=[Output('output_list', content_type='listfile', mime_type='json')],\n                            resources=ComputingResources(cores=1, ram=4.0, walltime=2.0))\n \n-relPhotoExp = Executable(command='E-Run NIR_RelativePhotometry  NIR_calculate_relative_exposures',\n+relPhotoExp = Executable(command=f'E-Run NIR_RelativePhotometry {proj_version} NIR_calculate_relative_exposures',\n                          inputs=[Input('in_full_catalog'),\n                                  Input('in_calibration_detectors')],\n                          outputs=[Output('rel_exposure_xml')],\n                          resources=ComputingResources(cores=1, ram=6.0, walltime=4.0))\n \n-relPhotoCalib = Executable(command='E-Run NIR_RelativePhotometry  NIR_apply_relative_calibrations',\n+relPhotoCalib = Executable(command=f'E-Run NIR_RelativePhotometry {proj_version} NIR_apply_relative_calibrations',\n                            inputs=[Input('infile'),\n                                    Input('in_calibration_detectors'),\n                                    Input('in_calibration_exposure'),\n@@ -112,48 +115,48 @@ relPhotoCalib = Executable(command='E-Run NIR_RelativePhotometry  NIR_apply_rela\n                            outputs=[Output('outfile', mime_type='fits')],\n                            resources=ComputingResources(cores=1, ram=2.0, walltime=1.0))\n \n-absPhotoCalib = Executable(command='E-Run NIR_AbsolutePhotometry  NIR_ApplyAbsolutePhotometry',\n+absPhotoCalib = Executable(command=f'E-Run NIR_AbsolutePhotometry {proj_version} NIR_ApplyAbsolutePhotometry',\n                            inputs=[Input('infile'), Input('cal_data')],\n                            outputs=[Output('outfile', mime_type='fits')],\n                            resources=ComputingResources(cores=1, ram=2.0, walltime=1.0))\n \n-gsclMasking = Executable(command='E-Run NIR_GhostBusters  NIR_mask_gscl',\n+gsclMasking = Executable(command=f'E-Run NIR_GhostBusters {proj_version} NIR_mask_gscl',\n                            inputs=[Input('infile'), Input('mdbxml'),\n                                    Input('ref_catalog', content_type='listfile')],\n                            outputs=[Output('outfile', mime_type='fits')],\n                            resources=ComputingResources(cores=1, ram=3.0, walltime=2.0))\n \n-catalogPhotDither = Executable(command='E-Run NIR_CatalogExtraction  DitherCatalogExtraction',\n+catalogPhotDither = Executable(command=f'E-Run NIR_CatalogExtraction {proj_version} DitherCatalogExtraction',\n                                inputs=[Input('infile'), Input('listofpsffiles')],\n                                outputs=[Output('outputcat', mime_type='fits')],\n                                resources=ComputingResources(cores=1, ram=2.0, walltime=1.0))\n \n-doResampling = Executable(command='E-Run NIR_Resampling  NIR_DoresamplProgram',\n+doResampling = Executable(command=f'E-Run NIR_Resampling {proj_version} NIR_DoresamplProgram',\n                           inputs=[Input('listofcaldithers', content_type='listfile'),\n                                   Input('listofbackgrounds', content_type='listfile'),\n                                   Input('config')],\n                           outputs=[Output('listofresampled', content_type='listfile', mime_type='json')],\n                           resources=ComputingResources(cores=1, ram=4.0, walltime=3.0))\n \n-doStacking = Executable(command='E-Run NIR_Stacking  NIR_DostackProgram',\n+doStacking = Executable(command=f'E-Run NIR_Stacking {proj_version} NIR_DostackProgram',\n                         inputs=[Input('listofresampled', content_type='listfile'),\n                                 Input('config')],\n                         outputs=[Output('stackedimage', content_type='listfile', mime_type='json')],\n                         resources=ComputingResources(cores=1, ram=10.0, walltime=2.0))\n \n-psfForStack = Executable(command='E-Run NIR_PointSpreadFunction  NIR_PSFModelling --imagetype=stack --psfex_cpp False',\n+psfForStack = Executable(command=f'E-Run NIR_PointSpreadFunction {proj_version} NIR_PSFModelling --imagetype=stack --psfex_cpp False',\n                          inputs=[Input('listofimages', content_type='listfile'),\n                                  Input('mdbfile'), Input('cal_data'), Input('config')],\n                          outputs=[Output('listofpsflists', content_type='listfile', mime_type='json')],\n                          resources=ComputingResources(cores=1, ram=10.0, walltime=1.0))\n \n-catalogPhotStack = Executable(command='E-Run NIR_CatalogExtraction  StackedCatalogExtraction',\n+catalogPhotStack = Executable(command=f'E-Run NIR_CatalogExtraction {proj_version} StackedCatalogExtraction',\n                               inputs=[Input('infile'),\n                                       Input('listofpsflists', content_type='listfile')],\n                               outputs=[Output('outputcat', mime_type='fits')],\n                               resources=ComputingResources(cores=1, ram=6.0, walltime=1.0))\n \n-createScientificDpds = Executable(command='E-Run NIR_Utilities  NIR_CreateScientificDpds',\n+createScientificDpds = Executable(command=f'E-Run NIR_Utilities {proj_version} NIR_CreateScientificDpds',\n                                   inputs=[Input('cal_images', content_type='listfile'),\n                                           Input('cal_background', content_type='listfile'),\n                                           Input('cal_psf', content_type='listfile'),\n@@ -168,7 +171,7 @@ createScientificDpds = Executable(command='E-Run NIR_Utilities  NIR_CreateScient\n                                   resources=ComputingResources(cores=1, ram=6.0, walltime=1.0))\n \n # - New executables - #\n-doAstromAbsCal = Executable(command='E-Run NIR_AstrometricCalibration  NIR_DoastromProgram --create-catalogs --create-scamp-plots False --create-check-plots False',\n+doAstromAbsCal = Executable(command=f'E-Run NIR_AstrometricCalibration {proj_version} NIR_DoastromProgram --create-catalogs --create-scamp-plots False --create-check-plots False',\n                             inputs=[Input('listofdithers', content_type='listfile'),\n                                     Input('ref_catalog', content_type='listfile'),\n                                     Input('listofpsflists', content_type='listfile'),\n@@ -179,7 +182,7 @@ doAstromAbsCal = Executable(command='E-Run NIR_AstrometricCalibration  NIR_Doast\n                                      Output('fullcatalog', mime_type='fits')],\n                             resources=ComputingResources(cores=1, ram=6.0, walltime=24.0))\n \n-doAstromSelfCal = Executable(command='E-Run NIR_AstrometricCalibration  NIR_DoastromProgram --create-catalogs',\n+doAstromSelfCal = Executable(command=f'E-Run NIR_AstrometricCalibration {proj_version} NIR_DoastromProgram --create-catalogs',\n                              inputs=[Input('listofdithers', content_type='listfile'),\n                                      Input('ref_catalog', content_type='listfile'),\n                                      Input('presolution', content_type='listfile'),\n@@ -189,7 +192,7 @@ doAstromSelfCal = Executable(command='E-Run NIR_AstrometricCalibration  NIR_Doas\n                                       Output('fullcatalog', mime_type='fits')],\n                              resources=ComputingResources(cores=1, ram=3.0, walltime=3.0))\n \n-makeAbsoluteCalib = Executable(command=\"E-Run NIR_AbsolutePhotometry  NIR_ComputeAbsolutePhotometry\",\n+makeAbsoluteCalib = Executable(command=f\"E-Run NIR_AbsolutePhotometry {proj_version} NIR_ComputeAbsolutePhotometry\",\n                              inputs=[Input(\"inlist\", content_type=\"listfile\"),\n                                      Input(\"mdbfile\"),\n                                      Input(\"indetcoeff\"),\n@@ -198,7 +201,7 @@ makeAbsoluteCalib = Executable(command=\"E-Run NIR_AbsolutePhotometry  NIR_Comput\n                             outputs=[Output(\"product\")],\n                             resources=ComputingResources(cores=1, ram=3.0, walltime=1.0))\n \n-doAstromDistortion = Executable(command='E-Run NIR_AstrometricCalibration  NIR_DoastromProgram --create-distortion-model',\n+doAstromDistortion = Executable(command=f'E-Run NIR_AstrometricCalibration {proj_version} NIR_DoastromProgram --create-distortion-model',\n                       inputs=[Input('listofdithers', content_type='listfile'),\n                               Input('ref_catalog', content_type='listfile'),\n                               Input('presolution', content_type='listfile'),\n@@ -207,12 +210,12 @@ doAstromDistortion = Executable(command='E-Run NIR_AstrometricCalibration  NIR_D\n                                Output(\"listofcaldithers\",  content_type=\"listfile\", mime_type=\"json\")],\n                       resources=ComputingResources(cores=1, ram=3.0, walltime=2.0))\n \n-makeMasterDark = Executable(command=\"E-Run NIR_DarkBiasSubtraction  makeNirMasterDark\",\n+makeMasterDark = Executable(command=f\"E-Run NIR_DarkBiasSubtraction {proj_version} makeNirMasterDark\",\n                           inputs=[Input(\"darklist\", content_type=\"listfile\"), Input(\"config\")],\n                           outputs=[Output(\"outfile\")],\n                           resources=ComputingResources(cores=1, ram=10.0, walltime=8.0))\n \n-makeSmallScaleFlat = Executable(command=\"E-Run NIR_FlatFieldCorrection  NIR_construct_master_flat\",\n+makeSmallScaleFlat = Executable(command=f\"E-Run NIR_FlatFieldCorrection {proj_version} NIR_construct_master_flat\",\n                                 inputs=[Input(\"rawflatproducts\", content_type=\"listfile\"),\n                                         Input(\"calibratedrawflats\", content_type=\"listfile\"),\n                                         Input(\"config\"),\n@@ -222,35 +225,35 @@ makeSmallScaleFlat = Executable(command=\"E-Run NIR_FlatFieldCorrection  NIR_cons\n                                 outputs=[Output(\"outputfile\")],\n                                 resources=ComputingResources(cores=1, ram=13.0, walltime=2.0))\n \n-makeNirNLCoefs = Executable(command=\"E-Run NIR_NonLinearSaturation makeNLCoefs\",\n+makeNirNLCoefs = Executable(command=f\"E-Run NIR_NonLinearSaturation {proj_version} makeNLCoefs\",\n                             inputs=[Input(\"mdbfile\"), Input(\"xmllistfile\")],\n                             outputs=[Output(\"nl_coef_xml\"),\n                                      Output(\"nl_cov_xml\")],\n                             resources=ComputingResources(cores=1, ram=20.0, walltime=45.0))\n \n-selectExpos = Executable(command='E-Run NIR_Persistence selectTargetExpos',\n+selectExpos = Executable(command=f'E-Run NIR_Persistence {proj_version} selectTargetExpos',\n                          inputs=[Input('expolist', content_type='listfile'), \n                                  Input('masklist', content_type='listfile')],\n                          outputs=[Output(\"targetlist\",  content_type=\"listfile\", mime_type=\"json\")],\n                          resources=ComputingResources(cores=1, ram=4.0, walltime=1.0))\n \n-persistenceMask = Executable(command='E-Run NIR_Persistence  createPersistenceImage',\n+persistenceMask = Executable(command=f'E-Run NIR_Persistence {proj_version} createPersistenceImage',\n                              inputs=[Input('infile'), Input('prevlist'), Input('mdbxml')],\n                              outputs=[Output('maskfits', mime_type='fits')],\n                              resources=ComputingResources(cores=1, ram=4.0, walltime=1.0))\n \n-createPersistenceXml = Executable(command='E-Run NIR_Utilities  NIR_CreateDpds',\n+createPersistenceXml = Executable(command=f'E-Run NIR_Utilities {proj_version} NIR_CreateDpds',\n                                   inputs=[Input('persistence_mask')],\n                                   outputs=[Output('persistence_mask_xml')],\n                                   resources=ComputingResources(cores=1, ram=4.0, walltime=1.0))\n \n \n-persistenceApply = Executable(command='E-Run NIR_Persistence  applyPersistenceMask',\n+persistenceApply = Executable(command=f'E-Run NIR_Persistence {proj_version} applyPersistenceMask',\n                           inputs=[Input('infile'), Input('masklist')],\n                           outputs=[Output('outfile', mime_type='fits')],\n                           resources=ComputingResources(cores=1, ram=5.0, walltime=1.0))\n \n-makeSelfCalib = Executable(command='E-Run NIR_SelfCalib  NIR_Compute',\n+makeSelfCalib = Executable(command=f'E-Run NIR_SelfCalib {proj_version} NIR_Compute',\n                            inputs=[\n                                 Input('inlist', content_type='listfile'),\n                                 Input('inopt'),\n@@ -259,26 +262,26 @@ makeSelfCalib = Executable(command='E-Run NIR_SelfCalib  NIR_Compute',\n                            resources=ComputingResources(cores=1, ram=6.0, walltime=2.0))\n \n # - Duplicated executables - #\n-relPhotoExpSciSelfCal = Executable(command='E-Run NIR_RelativePhotometry  NIR_calculate_relative_exposures',\n+relPhotoExpSciSelfCal = Executable(command=f'E-Run NIR_RelativePhotometry {proj_version} NIR_calculate_relative_exposures',\n                                    inputs=[Input('in_full_catalog'),\n                                            Input('in_calibration_detectors')],\n                                    outputs=[Output('rel_exposure_xml')],\n                                    resources=ComputingResources(cores=1, ram=20.0, walltime=9.0))\n \n-crRejectionMFSciSelfCal = Executable(command='E-Run NIR_CrRejectionMultiFrame  CrRejectMulti',\n+crRejectionMFSciSelfCal = Executable(command=f'E-Run NIR_CrRejectionMultiFrame {proj_version} CrRejectMulti',\n                                      inputs=[Input('dith_file', content_type='listfile')],\n                                      outputs=[Output('dith_file_out', content_type='listfile', mime_type='json')],\n                                      resources=ComputingResources(cores=1, ram=5.0, walltime=6.0))\n \n \n \n-catalogPhotStackSciSelfCal = Executable(command='E-Run NIR_CatalogExtraction  StackedCatalogExtraction',\n+catalogPhotStackSciSelfCal = Executable(command=f'E-Run NIR_CatalogExtraction {proj_version} StackedCatalogExtraction',\n                                         inputs=[Input('infile'),\n                                                 Input('listofpsflists', content_type='listfile')],\n                                         outputs=[Output('outputcat', mime_type='fits')],\n                                         resources=ComputingResources(cores=1, ram=10.0, walltime=1.0))\n \n-createScientificDpdsSciSelfCal = Executable(command='E-Run NIR_Utilities  NIR_CreateScientificDpds',\n+createScientificDpdsSciSelfCal = Executable(command=f'E-Run NIR_Utilities {proj_version} NIR_CreateScientificDpds',\n                                             inputs=[Input('cal_images', content_type='listfile'),\n                                                     Input('cal_background', content_type='listfile'),\n                                                     Input('cal_psf', content_type='listfile'),\n@@ -292,12 +295,12 @@ createScientificDpdsSciSelfCal = Executable(command='E-Run NIR_Utilities  NIR_Cr\n                                                      Output('stk_catalog_xml')],\n                                             resources=ComputingResources(cores=1, ram=10.0, walltime=1.0))\n \n-combineLists1=Executable(command=\"E-Run NIR_Utilities NIR_CombineLists\",\n+combineLists1=Executable(command=f\"E-Run NIR_Utilities {proj_version} NIR_CombineLists\",\n                          inputs=[Input(\"inlist1\", content_type=\"listfile\")],\n                          outputs=[Output(\"outlist\", content_type=\"listfile\", mime_type=\"json\")],\n                          resources=ComputingResources(cores=1, ram=2.0, walltime=1.0))\n \n-combineLists4=Executable(command=\"E-Run NIR_Utilities NIR_CombineLists\",\n+combineLists4=Executable(command=f\"E-Run NIR_Utilities {proj_version} NIR_CombineLists\",\n                          inputs=[Input(\"inlist1\", content_type=\"listfile\"),\n                                  Input(\"inlist2\", content_type=\"listfile\"),\n                                  Input(\"inlist3\", content_type=\"listfile\"),\n@@ -305,12 +308,12 @@ combineLists4=Executable(command=\"E-Run NIR_Utilities NIR_CombineLists\",\n                          outputs=[Output(\"outlist\", content_type=\"listfile\", mime_type=\"json\")],\n                          resources=ComputingResources(cores=1, ram=2.0, walltime=1.0))\n \n-makeList1 = Executable(command=\"E-Run NIR_Utilities NIR_MakeList\",\n+makeList1 = Executable(command=f\"E-Run NIR_Utilities {proj_version} NIR_MakeList\",\n                        inputs=[Input(\"infile1\")],\n                        outputs=[Output(\"outlist\", content_type=\"listfile\", mime_type=\"json\")],\n                        resources=ComputingResources(cores=1, ram=2.0, walltime=1.0))\n \n-makeList4 = Executable(command=\"E-Run NIR_Utilities NIR_MakeList\",\n+makeList4 = Executable(command=f\"E-Run NIR_Utilities {proj_version} NIR_MakeList\",\n                        inputs=[Input(\"infile1\"),\n                                Input(\"infile2\"),\n                                Input(\"infile3\"),\n@@ -318,14 +321,14 @@ makeList4 = Executable(command=\"E-Run NIR_Utilities NIR_MakeList\",\n                        outputs=[Output(\"outlist\", content_type=\"listfile\", mime_type=\"json\")],\n                        resources=ComputingResources(cores=1, ram=2.0, walltime=1.0))\n \n-makeNirBadPixelsMask = Executable(command=\"E-Run NIR_BadPixelMasking makeNirBadPixels\",\n+makeNirBadPixelsMask = Executable(command=f\"E-Run NIR_BadPixelMasking {proj_version} makeNirBadPixels\",\n                             inputs=[Input(\"mdbfile\"),\n                                     Input(\"inputdatalist\")],\n                             outputs=[Output(\"outfile\")],\n                             resources=ComputingResources(cores=1, ram=4.0, walltime=2.0)\n                            )\n \n-findDeadPixels = Executable(command=\"E-Run NIR_BadPixelMasking findDeadPixels\",\n+findDeadPixels = Executable(command=f\"E-Run NIR_BadPixelMasking {proj_version} findDeadPixels\",\n                             inputs=[Input(\"mdbfile\"),\n                                     Input(\"config\"),\n                                     Input(\"exposurelist\")],\n@@ -333,7 +336,7 @@ findDeadPixels = Executable(command=\"E-Run NIR_BadPixelMasking findDeadPixels\",\n                             resources=ComputingResources(cores=1, ram=4.0, walltime=2.0)\n                            )\n  \n-findHotPixels = Executable(command=\"E-Run NIR_BadPixelMasking findHotPixels\",\n+findHotPixels = Executable(command=f\"E-Run NIR_BadPixelMasking {proj_version} findHotPixels\",\n                             inputs=[Input(\"mdbfile\"),\n                                     Input(\"config\"),\n                                     Input(\"exposurelist\")],\n@@ -341,35 +344,35 @@ findHotPixels = Executable(command=\"E-Run NIR_BadPixelMasking findHotPixels\",\n                             resources=ComputingResources(cores=1, ram=4.0, walltime=2.0)\n                            )\n                                     \n-findZeroQEPixels = Executable(command=\"E-Run NIR_BadPixelMasking findZeroQEPixels\",\n+findZeroQEPixels = Executable(command=f\"E-Run NIR_BadPixelMasking {proj_version} findZeroQEPixels\",\n                             inputs=[Input(\"mdbfile\"),\n                                     Input(\"config\")],\n                             outputs=[Output(\"outfile\")],\n                             resources=ComputingResources(cores=1, ram=4.0, walltime=2.0)\n                            )\n                                     \n-findLowQEPixels = Executable(command=\"E-Run NIR_BadPixelMasking findLowQEPixels\",\n+findLowQEPixels = Executable(command=f\"E-Run NIR_BadPixelMasking {proj_version} findLowQEPixels\",\n                             inputs=[Input(\"mdbfile\"),\n                                     Input(\"config\")],\n                             outputs=[Output(\"outfile\")],\n                             resources=ComputingResources(cores=1, ram=4.0, walltime=2.0)\n                            )\n                                     \n-findSuperQEPixels = Executable(command=\"E-Run NIR_BadPixelMasking findSuperQEPixels\",\n+findSuperQEPixels = Executable(command=f\"E-Run NIR_BadPixelMasking {proj_version} findSuperQEPixels\",\n                             inputs=[Input(\"mdbfile\"),\n                                     Input(\"config\")],\n                             outputs=[Output(\"outfile\")],\n                             resources=ComputingResources(cores=1, ram=4.0, walltime=2.0)\n                            )\n                                     \n-findHighLowBaselinePixels = Executable(command=\"E-Run NIR_BadPixelMasking findHighLowBaselinePixels\",\n+findHighLowBaselinePixels = Executable(command=f\"E-Run NIR_BadPixelMasking {proj_version} findHighLowBaselinePixels\",\n                             inputs=[Input(\"mdbfile\"),\n                                     Input(\"config\")],\n                             outputs=[Output(\"outfile\")],\n                             resources=ComputingResources(cores=1, ram=4.0, walltime=2.0)\n                            )\n \n-makeBaseline = Executable(command=\"E-Run NIR_Baseline  makeNirBaseline\",\n+makeBaseline = Executable(command=f\"E-Run NIR_Baseline {proj_version} makeNirBaseline\",\n                           inputs=[Input(\"darklist\", content_type=\"listfile\"), Input(\"config\")],\n                           outputs=[Output(\"outfile\")],\n                           resources=ComputingResources(cores=1, ram=6.0, walltime=8.0))\n",
                            "Adding proj_version macro to all executables",
                            "Marco Frailis",
                            "2023-08-17T21:29:55.000+00:00",
                            "131c362713001470234df3c4e8f59c3b828ea5b4"
                        ],
                        [
                            "@@ -75,7 +75,7 @@ psfForDitherAbsCal = Executable(command='E-Run NIR_PointSpreadFunction NIR_PSFMo\n                                 Input('mdbfile'),\n                                 Input('config')],\n                           outputs=[Output('listofpsflists', content_type='listfile', mime_type='json')],\n-                          resources=ComputingResources(cores=1, ram=3.0, walltime=3.0))\n+                          resources=ComputingResources(cores=1, ram=3.0, walltime=4.0))\n \n \n doAstrom = Executable(command='E-Run NIR_AstrometricCalibration  NIR_DoastromProgram',\n@@ -187,7 +187,7 @@ doAstromSelfCal = Executable(command='E-Run NIR_AstrometricCalibration  NIR_Doas\n                              outputs=[Output(\"listofcaldithers\",  content_type=\"listfile\", mime_type=\"json\"),\n                                       Output(\"listofcalcatalogs\", content_type=\"listfile\", mime_type=\"json\"),\n                                       Output('fullcatalog', mime_type='fits')],\n-                             resources=ComputingResources(cores=1, ram=3.0, walltime=2.0))\n+                             resources=ComputingResources(cores=1, ram=3.0, walltime=3.0))\n \n makeAbsoluteCalib = Executable(command=\"E-Run NIR_AbsolutePhotometry  NIR_ComputeAbsolutePhotometry\",\n                              inputs=[Input(\"inlist\", content_type=\"listfile\"),\n@@ -256,7 +256,7 @@ makeSelfCalib = Executable(command='E-Run NIR_SelfCalib  NIR_Compute',\n                                 Input('inopt'),\n                                 Input('mdbfile')],\n                            outputs=[Output('outflat'), Output('outdetcoeff')],\n-                           resources=ComputingResources(cores=1, ram=4.0, walltime=1.0))\n+                           resources=ComputingResources(cores=1, ram=6.0, walltime=2.0))\n \n # - Duplicated executables - #\n relPhotoExpSciSelfCal = Executable(command='E-Run NIR_RelativePhotometry  NIR_calculate_relative_exposures',\n",
                            "Incrementing some tasks resources, based on recent profiling",
                            "Marco Frailis",
                            "2023-08-17T21:16:42.000+00:00",
                            "ab093f991daa884ca8aa0ff96a5cc3477163b066"
                        ],
                        [
                            "@@ -250,6 +250,12 @@ persistenceApply = Executable(command='E-Run NIR_Persistence  applyPersistenceMa\n                           outputs=[Output('outfile', mime_type='fits')],\n                           resources=ComputingResources(cores=1, ram=5.0, walltime=1.0))\n \n+persistenceDiff = Executable(command='E-Run NIR_Persistence computeDiffImage',\n+                             inputs=[Input('darkfile'),\n+                                     Input('persfile')],\n+                             outputs=[Output('outfile', mime_type='fits')],\n+                             resources=ComputingResources(cores=1, ram=4.0, walltime=1.0))\n+\n makeSelfCalib = Executable(command='E-Run NIR_SelfCalib  NIR_Compute',\n                            inputs=[\n                                 Input('inlist', content_type='listfile'),\n@@ -310,6 +316,12 @@ makeList1 = Executable(command=\"E-Run NIR_Utilities NIR_MakeList\",\n                        outputs=[Output(\"outlist\", content_type=\"listfile\", mime_type=\"json\")],\n                        resources=ComputingResources(cores=1, ram=2.0, walltime=1.0))\n \n+makeList2 = Executable(command=\"E-Run NIR_Utilities NIR_MakeList\",\n+                       inputs=[Input(\"infile1\"), \n+                               Input(\"infile2\")],\n+                       outputs=[Output(\"outlist\", content_type=\"listfile\", mime_type=\"json\")],\n+                       resources=ComputingResources(cores=1, ram=2.0, walltime=1.0))\n+\n makeList4 = Executable(command=\"E-Run NIR_Utilities NIR_MakeList\",\n                        inputs=[Input(\"infile1\"),\n                                Input(\"infile2\"),\n",
                            "first test of a Persistence pipeline for CALBLOCK-016",
                            "Thomas Gasparetto",
                            "2023-08-17T11:44:00.000+02:00",
                            "7f3fcbbe0690af2389b5c530e2380a26002c4448"
                        ],
                        [
                            "@@ -250,9 +250,10 @@ persistenceApply = Executable(command='E-Run NIR_Persistence  applyPersistenceMa\n                           outputs=[Output('outfile', mime_type='fits')],\n                           resources=ComputingResources(cores=1, ram=5.0, walltime=1.0))\n \n-makeSelfCalib = Executable(command='E-Run NIR_SelfCalib  NIR_Compute --disableinterpolation 1 --ncoeff 10',\n+makeSelfCalib = Executable(command='E-Run NIR_SelfCalib  NIR_Compute',\n                            inputs=[\n                                 Input('inlist', content_type='listfile'),\n+                                Input('inopt'),\n                                 Input('mdbfile')],\n                            outputs=[Output('outflat'), Output('outdetcoeff')],\n                            resources=ComputingResources(cores=1, ram=4.0, walltime=1.0))\n",
                            "Merge branch 'feature_selfcal' into 'develop'",
                            "Thomas Gasparetto",
                            "2023-08-14T15:23:11.000+00:00",
                            "c949c3a03a45164a056f5e50203071807027929e"
                        ],
                        [
                            "@@ -189,7 +189,7 @@ doAstromSelfCal = Executable(command='E-Run NIR_AstrometricCalibration  NIR_Doas\n                                       Output('fullcatalog', mime_type='fits')],\n                              resources=ComputingResources(cores=1, ram=3.0, walltime=2.0))\n \n-makeAbsoluteCalib = Executable(command=\"E-Run NIR_AbsolutePhotometry  NIR_ComputeAbsolutePhotometry --colorcorrect No --abmagrange 'TU_MAG_H_2MASS,15.0,18.5'\",\n+makeAbsoluteCalib = Executable(command=\"E-Run NIR_AbsolutePhotometry  NIR_ComputeAbsolutePhotometry\",\n                              inputs=[Input(\"inlist\", content_type=\"listfile\"),\n                                      Input(\"mdbfile\"),\n                                      Input(\"indetcoeff\"),\n",
                            "Merge branch 'jeff_remove_abmagrange' into 'develop'",
                            "Marco Frailis",
                            "2023-08-14T07:04:49.000+00:00",
                            "dd79f0dd23bc5563f4756ddc071053d2fbfd07ab"
                        ],
                        [
                            "@@ -36,7 +36,7 @@ saturation = Executable(command='E-Run NIR_NonLinearSaturation  maskSaturation',\n nonLinearity = Executable(command='E-Run NIR_NonLinearSaturation  correctNonlinearity',\n                           inputs=[Input('infile'), Input('xmlfile'), Input('config')],\n                           outputs=[Output('outfile', mime_type='fits')],\n-                          resources=ComputingResources(cores=1, ram=5.0, walltime=1.0))\n+                          resources=ComputingResources(cores=1, ram=20.0, walltime=1.0))\n \n darkSubtract = Executable(command='E-Run NIR_DarkBiasSubtraction  darkSubtraction',\n                           inputs=[Input('infile'), Input('masterdark')],\n",
                            "update RAM usage of Non Linearity application task",
                            "Thomas Gasparetto",
                            "2023-08-11T17:05:14.000+00:00",
                            "f76c44d0fec4f95e8ccd22af2bafec95d0f8d287"
                        ],
                        [
                            "@@ -189,7 +189,7 @@ doAstromSelfCal = Executable(command='E-Run NIR_AstrometricCalibration  NIR_Doas\n                                       Output('fullcatalog', mime_type='fits')],\n                              resources=ComputingResources(cores=1, ram=3.0, walltime=2.0))\n \n-makeAbsoluteCalib = Executable(command=\"E-Run NIR_AbsolutePhotometry  NIR_ComputeAbsolutePhotometry --colorcorrect No --abmagrange 'TU_MAG_H_2MASS,15.0,18.5'\",\n+makeAbsoluteCalib = Executable(command=\"E-Run NIR_AbsolutePhotometry  NIR_ComputeAbsolutePhotometry\",\n                              inputs=[Input(\"inlist\", content_type=\"listfile\"),\n                                      Input(\"mdbfile\"),\n                                      Input(\"indetcoeff\"),\n",
                            "Remove abmagrange and colorcorrect options from NIR_AbsolutePhotometry package defs",
                            "Jeffery Jacobson",
                            "2023-08-10T06:59:11.000-07:00",
                            "5ddc1b866dbfa256eefa21f71e32b838a3c2422c"
                        ]
                    ],
                    "NIR_IAL_Pipelines/auxdir/NIR_Pipelines/NIR_Persistence_Pipeline/PipDef_NIR_Persistence_Model_Check.xml": [
                        [
                            "@@ -0,0 +1,111 @@\n+<tsk1:PipelineDef xmlns:tsk1=\"http://ecdm.euclid-ec.org/schema/interfaces/sys/orc\">\n+    <Id>PipDef_NIR_CALIB_PERSISTENCE_CHECK_2023.08.17</Id>\n+    <ArchiveProcessingFlag>PROCESSING_ONLY</ArchiveProcessingFlag> \n+    <PipelineScriptPath>NIR_Persistence_Pipeline/PipScript_NIR_Persistence_Model_Check.py</PipelineScriptPath>\n+    <PipelineRootPath>@ELEMENTS_BASE_DIR@/@PROJECT_NAME@/@PROJECT_VERSION@/InstallArea/@BINARY_TAG@/auxdir/NIR_Pipelines/</PipelineRootPath>\n+    <InputDataSetPlan>\n+        <KeyProductInputDataPlan>\n+            <InputPortName>flatinput</InputPortName>\n+            <DataProductType>DpdNispRawFrame</DataProductType>\n+            <InputQuerySpecPlan> (flatinput.Data.ObservationSequence.CalblockId == \"UNKNOWN\")\n+            AND (flatinput.Data.ObservationSequence.CalblockVariant == \"UNKNOWN\") \n+            AND (flatinput.Data.FilterWheelPos.FilterWheelPosition == \"CLOSED\") \n+            AND (flatinput.Data.ImgType.FirstType == \"FLAT\") \n+            AND (flatinput.Data.ImgType.Technique == \"IMAGE\") \n+            AND (flatinput.Data.ObservationSequence.PointingId == \"UNKNOWN\")\n+            AND (flatinput.Data.ObservationSequence.Exposure == 1)\n+            AND (rawBaseline.Header.ManualValidationStatus.ManualValidationStatus != \"INVALID\")</InputQuerySpecPlan>\n+            <Cardinality>\n+                <Optionality>MANDATORY</Optionality>\n+                <Min>1</Min>\n+                <Max>600</Max>\n+            </Cardinality>\n+        </KeyProductInputDataPlan>\n+        <InputDataPlan>\n+            <InputPortName>darkinput</InputPortName>\n+            <DataProductType>DpdNispRawFrame</DataProductType>\n+            <InputQuerySpecPlan> (darkinput.Data.ObservationSequence.CalblockVariant == \"UNKNOWN\") \n+            AND (darkinput.Data.FilterWheelPos.FilterWheelPosition == \"CLOSED\") \n+            AND (darkinput.Data.ImgType.FirstType == \"DARK\") \n+            AND (darkinput.Data.ImgType.Technique == \"IMAGE\") \n+            AND (darkinput.Data.ObservationSequence.Exposure == 2)\n+            AND (darkinput.Header.ManualValidationStatus.ManualValidationStatus != \"INVALID\")</InputQuerySpecPlan>\n+             <LinkedBy>\n+                <Query>(flatinput.Data.ObservationSequence.CalblockId == darkinput.Data.ObservationSequence.CalblockId) \n+                AND (flatinput.Data.ObservationSequence.CalblockVariant == darkinput.Data.ObservationSequence.CalblockVariant) \n+                AND (flatinput.Data.ObservationSequence.PointingId == darkinput.Data.ObservationSequence.PointingId) \n+                </Query>\n+            </LinkedBy>\n+            <Cardinality>\n+                <Optionality>MANDATORY</Optionality>\n+                <Min>1</Min>\n+                <Max>600</Max>\n+            </Cardinality>\n+        </InputDataPlan>\n+        <InputDataPlan>\n+            <InputPortName>nirConfig</InputPortName>\n+            <DataProductType>DpdNirConfigurationSet</DataProductType>\n+            <InputQuerySpecPlan>nirConfig.Header.ProductId.LimitedString == \"UNKNOWN\"</InputQuerySpecPlan>\n+            <Cardinality>\n+                <Optionality>MANDATORY</Optionality>\n+                <Min>1</Min>\n+                <Max>1</Max>\n+            </Cardinality>\n+        </InputDataPlan>\n+        <InputDataPlan>\n+            <InputPortName>mdb</InputPortName>\n+            <DataProductType>DpdMdbDataBase</DataProductType>\n+            <InputQuerySpecPlan>mdb.Header.ProductId.LimitedString == \"UNKNOWN\"</InputQuerySpecPlan>\n+            <FileFiltering>\n+                <FilesToInclude>\"EUC_NISP_Satu*\",\"EUC_NISP_SINGLE*\",\"EUC_NISP_NLPHOTO*\",\"EUC_NIR_DISTOR*\",\"NISPDetectorTable*\",\"NISPDetectorSlots*\",\"EUC_NISP_GAIN-*\",\"EUC_NISP_PERSISTENCE*\"</FilesToInclude>\n+            </FileFiltering>\n+            <Cardinality>\n+                <Optionality>MANDATORY</Optionality>\n+                <Min>1</Min>\n+                <Max>1</Max>\n+            </Cardinality>\n+        </InputDataPlan>\n+        <InputDataPlan>\n+            <InputPortName>badpixel</InputPortName>\n+            <DataProductType>DpdNirBadPixelMask</DataProductType>\n+            <InputQuerySpecPlan>badpixel.Header.ProductId.LimitedString == \"UNKNOWN\"</InputQuerySpecPlan>\n+            <Cardinality>\n+                <Optionality>MANDATORY</Optionality>\n+                <Min>1</Min>\n+                <Max>1</Max>\n+            </Cardinality>\n+        </InputDataPlan>\n+        <InputDataPlan>\n+            <InputPortName>masterdark</InputPortName>\n+            <DataProductType>DpdNirMasterDarkFrame</DataProductType>\n+            <InputQuerySpecPlan>masterdark.Header.ProductId.LimitedString == \"UNKNOWN\"</InputQuerySpecPlan>\n+            <Cardinality>\n+                <Optionality>MANDATORY</Optionality>\n+                <Min>1</Min>\n+                <Max>1</Max>\n+            </Cardinality>\n+        </InputDataPlan>\n+    </InputDataSetPlan>\n+    <OutputDataSet>\n+        <OutputDataProduct>\n+            <OutputPortName>persistence_mask_output</OutputPortName>\n+            <DataProductType>DpdNirPersistenceMask</DataProductType>\n+            <Cardinality>\n+                <Optionality>MANDATORY</Optionality>\n+                <Min>1</Min>\n+                <Max>1</Max>\n+            </Cardinality>\n+        </OutputDataProduct>\n+        <OutputDataProduct>\n+            <OutputPortName>diff_image_xml</OutputPortName>\n+            <DataProductType>DpdNirPersistenceMask</DataProductType>\n+            <Cardinality>\n+                <Optionality>MANDATORY</Optionality>\n+                <Min>1</Min>\n+                <Max>1</Max>\n+            </Cardinality>\n+        </OutputDataProduct>\n+    </OutputDataSet>\n+    <EstimatedWorkdirSizeGB>10</EstimatedWorkdirSizeGB>\n+</tsk1:PipelineDef>\n+\n",
                            "adding PipDef. TO BE CHECKED",
                            "Thomas Gasparetto",
                            "2023-08-17T13:01:17.000+02:00",
                            "3b3cdf17bc9f5c75ad118ec5bba816b116ea487d"
                        ],
                        [
                            "",
                            "first test of a Persistence pipeline for CALBLOCK-016",
                            "Thomas Gasparetto",
                            "2023-08-17T11:44:00.000+02:00",
                            "7f3fcbbe0690af2389b5c530e2380a26002c4448"
                        ]
                    ],
                    "NIR_IAL_Pipelines/auxdir/NIR_Pipelines/NIR_Persistence_Pipeline/PipScript_NIR_Persistence_Model_Check.py": [
                        [
                            "@@ -13,7 +13,7 @@ def nir_calib_dither(nirConfig, rawfile, mdb, masterdark, badpixel):\n     darkExposure = darkSubtract(infile=nonlinExposure, masterdark=masterdark)\n     return darkExposure\n \n-@pipeline(outputs=('persistence_mask_output', 'diff_image_xml')) #, 'raw_cal_dark')) #, 'diffimage', 'cal_image_xml'))\n+@pipeline(outputs=('persistence_mask_output', 'diff_image_xml'))\n def nir_persistence_model(nirConfig, darkinput, flatinput, mdb, masterdark, badpixel):\n \n     \n@@ -52,9 +52,8 @@ def nir_persistence_model(nirConfig, darkinput, flatinput, mdb, masterdark, badp\n \n     diff_image_xml = createPersistenceXml(persistence_mask=diff_image)\n \n-    # raw_cal_dark = createPersistenceXml(persistence_mask=calibrated_raw_dark)\n \n-    return persistence_mask_output, diff_image_xml #, raw_cal_dark\n+    return persistence_mask_output, diff_image_xml\n \n \n if __name__ == '__main__':\n",
                            "cleaning commented code",
                            "Thomas Gasparetto",
                            "2023-08-17T11:56:50.000+02:00",
                            "b2232d4f99b9dec767c00f615b7022c3b429af35"
                        ],
                        [
                            "@@ -0,0 +1,67 @@\n+from euclidwf.framework.workflow_dsl import pipeline, parallel\n+\n+from PackageDef_NIR import (\n+    runInitialize, badPixMasking, saturation, nonLinearity, darkSubtract,\n+    persistenceMask, createPersistenceXml, persistenceDiff, makeList1, makeList2)\n+\n+\n+def nir_calib_dither(nirConfig, rawfile, mdb, masterdark, badpixel):\n+    initExposure = runInitialize(infile=rawfile, mdbfile=mdb)\n+    badPixelMasked = badPixMasking(infile=initExposure, xmlfile=badpixel)\n+    satExposure = saturation(infile=badPixelMasked, xmlfile=mdb)\n+    nonlinExposure = nonLinearity(infile=satExposure, xmlfile=mdb, config=nirConfig)\n+    darkExposure = darkSubtract(infile=nonlinExposure, masterdark=masterdark)\n+    return darkExposure\n+\n+@pipeline(outputs=('persistence_mask_output', 'diff_image_xml')) #, 'raw_cal_dark')) #, 'diffimage', 'cal_image_xml'))\n+def nir_persistence_model(nirConfig, darkinput, flatinput, mdb, masterdark, badpixel):\n+\n+    \n+    calibrated_raw_flat = nir_calib_dither(\n+        nirConfig=nirConfig,\n+        rawfile=flatinput,\n+        mdb=mdb,\n+        masterdark=masterdark,\n+        badpixel=badpixel\n+        )\n+\n+    calibrated_raw_dark = nir_calib_dither(\n+        nirConfig=nirConfig,\n+        rawfile=darkinput,\n+        mdb=mdb,\n+        masterdark=masterdark,\n+        badpixel=badpixel\n+    )\n+\n+    preprocessed_flat_plus_dark = makeList2(\n+        infile1=calibrated_raw_flat,\n+        infile2=calibrated_raw_dark\n+        )\n+\n+    persistence_flat_fits = persistenceMask(\n+        infile=darkinput,\n+        prevlist=preprocessed_flat_plus_dark,\n+        mdbxml=mdb)\n+\n+    persistence_mask_output  = createPersistenceXml(persistence_mask=persistence_flat_fits)\n+\n+    diff_image = persistenceDiff(\n+        darkfile=calibrated_raw_dark,\n+        persfile=persistence_flat_fits\n+        )\n+\n+    diff_image_xml = createPersistenceXml(persistence_mask=diff_image)\n+\n+    # raw_cal_dark = createPersistenceXml(persistence_mask=calibrated_raw_dark)\n+\n+    return persistence_mask_output, diff_image_xml #, raw_cal_dark\n+\n+\n+if __name__ == '__main__':\n+    from euclidwf.framework.graph_builder import build_graph\n+    from euclidwf.utilities import visualizer\n+    pydron_graph=build_graph(nir_persistence_model)\n+    print(str(pydron_graph))\n+    visualizer.visualize_graph(pydron_graph)\n+\n+\n",
                            "first test of a Persistence pipeline for CALBLOCK-016",
                            "Thomas Gasparetto",
                            "2023-08-17T11:44:00.000+02:00",
                            "7f3fcbbe0690af2389b5c530e2380a26002c4448"
                        ]
                    ],
                    ".gitignore": [
                        [
                            "@@ -0,0 +1,183 @@\n+# ==============================================\n+# Euclid Science Ground Segment .gitignore file\n+# ---\n+# Adapted from\n+# https://github.com/github/gitignore\n+# and\n+# http://goel.io/joe\n+# ==============================================\n+\n+#####=== Data ===#####\n+# Fits files\n+*.[fF][iI][tT]\n+*.[fF][iI][tT][sS]\n+*.fits-hash-stamp\n+\n+# CSV\n+*.[cC][sS][vV]\n+\n+# Dat\n+*.[dD][aA][Tt]\n+*.[dD][aA][tT][aA]\n+\n+#####=== Elements ===#####\n+\n+# Building area\n+build.*/\n+\n+# Install area\n+InstallArea/\n+\n+# CMake products\n+CMakeCache.txt\n+\n+#####=== System ===#####\n+\n+# SVN\n+.svn/\n+\n+# Apple\n+*.DS_Store\n+\n+# Windows\n+Desktop.ini\n+Thumbs.db\n+\n+#####=== Editors ===#####\n+\n+## Eclipse\n+.metadata\n+bin/\n+tmp/\n+*.tmp\n+*.bak\n+*.swp\n+*~.nib\n+local.properties\n+.settings/\n+.loadpath\n+.recommenders\n+\n+# Eclipse Core\n+.project\n+\n+# External tool builders\n+.externalToolBuilders/\n+\n+# Locally stored \"Eclipse launch configurations\"\n+*.launch\n+\n+# PyDev specific (Python IDE for Eclipse)\n+*.pydevproject\n+\n+# CDT-specific (C/C++ Development Tooling)\n+.cproject\n+\n+# PyCharm\n+.idea\n+\n+## VIM\n+*.swp\n+\n+## Emacs\n+*~\n+.projectile\n+\n+## SublimeText\n+*.sublime-workspace\n+*.sublime-project\n+\n+#####=== C++ ===#####\n+\n+# Compiled Object files\n+*.slo\n+*.lo\n+*.o\n+*.obj\n+\n+# Precompiled Headers\n+*.gch\n+*.pch\n+\n+# Compiled Dynamic libraries\n+*.so\n+*.dylib\n+*.dll\n+\n+# Fortran module files\n+*.mod\n+\n+# Compiled Static libraries\n+*.lai\n+*.la\n+*.a\n+*.lib\n+\n+# Executables\n+*.exe\n+*.out\n+*.app\n+\n+#####=== Python ===#####\n+\n+# Byte-compiled / optimized / DLL files\n+__pycache__/\n+*.py[cod]\n+*$py.class\n+\n+# C extensions\n+*.so\n+\n+# Distribution / packaging\n+.Python\n+env/\n+build/\n+develop-eggs/\n+dist/\n+downloads/\n+eggs/\n+.eggs/\n+lib/\n+lib64/\n+parts/\n+sdist/\n+var/\n+*.egg-info/\n+.installed.cfg\n+*.egg\n+\n+# PyInstaller\n+#  Usually these files are written by a python script from a template\n+#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n+*.manifest\n+*.spec\n+\n+# Installer logs\n+pip-log.txt\n+pip-delete-this-directory.txt\n+\n+# Unit test / coverage reports\n+htmlcov/\n+.tox/\n+.coverage\n+.coverage.*\n+.cache\n+nosetests.xml\n+coverage.xml\n+*,cover\n+\n+# Translations\n+*.mo\n+*.pot\n+\n+# Django stuff:\n+*.log\n+\n+# Sphinx documentation\n+docs/_build/\n+\n+# PyBuilder\n+target/\n+\n+MD5/\n+*.md5-stamp\n",
                            "first test of a Persistence pipeline for CALBLOCK-016",
                            "Thomas Gasparetto",
                            "2023-08-17T11:44:00.000+02:00",
                            "7f3fcbbe0690af2389b5c530e2380a26002c4448"
                        ]
                    ],
                    "NIR_IAL_Pipelines/auxdir/NIR_Pipelines/NIR_SelfCalib_Pipeline/PipScript_NIR_SelfCalib.py": [
                        [
                            "@@ -29,7 +29,7 @@ def nir_selfcalib(nirConfig, dithers, mdb, masterdark, masterflat, badpixel,\n                                   presolution=presolution,\n                                   config=nirConfig)\n \n-    largeflat, detcoeff = makeSelfCalib(inlist=astrometricCatalogs, mdbfile=mdb)\n+    largeflat, detcoeff = makeSelfCalib(inlist=astrometricCatalogs, mdbfile=mdb, inopt=nirConfig)\n \n     return largeflat,detcoeff\n \n",
                            "Merge branch 'feature_selfcal' into 'develop'",
                            "Thomas Gasparetto",
                            "2023-08-14T15:23:11.000+00:00",
                            "c949c3a03a45164a056f5e50203071807027929e"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "2.3.1",
                        "created_at": "2023-08-09T21:58:44.000+00:00",
                        "author_name": "Marco Frailis"
                    },
                    {
                        "name": "2.4.0",
                        "created_at": "2023-08-17T21:34:04.000+00:00",
                        "author_name": "Marco Frailis"
                    },
                    {
                        "name": "2.4.1",
                        "created_at": "2023-08-22T16:51:07.000+02:00",
                        "author_name": "Marco Frailis"
                    }
                ]
            },
            "PF-NIR/NIR_MovingObjectsMasking": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_LargeScaleFlat": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_GhostBusters": {
                "start date": "2023-08-09T21:11:29",
                "end date": "-",
                "start tag": "2.3.1",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "2.3.1",
                        "created_at": "2023-08-09T21:11:29.000+02:00",
                        "author_name": "Marco Frailis"
                    },
                    {
                        "name": "2.4.0",
                        "created_at": "2023-08-17T13:34:15.000+00:00",
                        "author_name": "Marco Frailis"
                    },
                    {
                        "name": "2.5.0",
                        "created_at": "2023-09-04T14:34:23.000+02:00",
                        "author_name": "Marco Frailis"
                    }
                ]
            },
            "PF-NIR/NIR_Persistence": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_Pipelines_Deprecated": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_NonLinearSaturation": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_DarkBiasSubtraction": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_BadPixelMasking": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_Testing": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_Stacking": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_Resampling": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_PointSpreadFunction": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_AbsolutePhotometry": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_SuperflatCalibration": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_Utilities": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_RelativePhotometry": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_FlatFieldCorrection": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_BackgroundEstimation": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_CrRejectionSingleFrame": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_Init": {
                "start date": "-",
                "end date": "2023-08-22T10:11:30",
                "start tag": "",
                "end tag": "2.4.1",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_AstrometricCalibration": {
                "start date": "2023-08-09T19:03:00",
                "end date": "2023-08-28T10:43:13",
                "start tag": "2.3.1",
                "end tag": "2.4.1",
                "count_files_modified": "5",
                "modifications_by_file": {
                    "NIR_Doastrom/python/NIR_Doastrom/NIR_DoastromProgram.py": [
                        [
                            "@@ -42,7 +42,7 @@ def defineSpecificProgramOptions():\n     parser = argparse.ArgumentParser()\n \n     parser.add_argument('--ref_catalog', type=str, dest='ref_catalog',\n-                        help='JSON list containing the XML files of the reference catalogs (SIM, VIS, or GAIA )')\n+                        help='JSON list containing the XML files of the reference catalogs (SIM, VIS, NIR, or GAIA )')\n \n     parser.add_argument('--listofdithers', type=str, dest='listofdithers',\n                         help='JSON file containing the list of input dithers')\n",
                            "Merge branch 'supporting_NIR_cat' into 'develop'",
                            "Thomas Gasparetto",
                            "2023-08-25T09:28:40.000+00:00",
                            "86c9f787e5a1e4cdbc5c02df0a7c6f2ad2839198"
                        ]
                    ],
                    "NIR_Doastrom/python/NIR_Doastrom/NIR_DoastromUtils.py": [
                        [
                            "@@ -122,6 +122,8 @@ class DoastromClass(object):\n \n         if refcat_bind.Header.ProductType == 'DpdVisStackedFrameCatalog':\n             refcat_orig = 'VIS'\n+        elif refcat_bind.Header.ProductType == 'DpdNirStackedFrameCatalog':\n+            refcat_orig = 'NIR'\n         elif refcat_bind.Header.ProductType == 'DpdExtGaiaCutout':\n             refcat_orig = 'GAIA'\n         elif refcat_bind.Header.ProductType == 'DpdTrueUniverseOutput':\n@@ -132,6 +134,8 @@ class DoastromClass(object):\n         for refcat_xml in reference_catalog:\n             if refcat_orig == 'VIS':\n                 refcat_fits.append(xr.get_vis_stacked_catalog_fits(xml_file=refcat_xml))\n+            elif refcat_orig == 'NIR':\n+                refcat_fits.append(xr.get_vis_stacked_catalog_fits(xml_file=refcat_xml))\n             elif refcat_orig == 'GAIA':\n                 refcat_fits.append(xr.get_ext_gaia_cutout_fits(xml_file=refcat_xml))\n             else:\n@@ -152,7 +156,7 @@ class DoastromClass(object):\n         @param refcat_paths\n              The path(s) of the reference catalog(s).\n         @param refcat_orig\n-             The origin of the catalog of reference stars (SIM, VIS, GAIA).\n+             The origin of the catalog of reference stars (SIM, VIS, NIR, GAIA).\n \n         @returns t\n             A table with the modified reference catalog.\n@@ -211,6 +215,35 @@ class DoastromClass(object):\n \n             t = table.unique(vstack(tn), keys='NUMBER')\n \n+        elif refcat_orig == 'NIR':\n+\n+            for refcat_path in refcat_paths:\n+\n+                t1 = Table.read(refcat_path, hdu=1)\n+\n+                t1.keep_columns(['OBJECT_ID',\n+                                 'FLUX_RADIUS',\n+                                 'MAG_APER', 'MAGERR_APER',\n+                                 'XWIN_WORLD', 'YWIN_WORLD',\n+                                 'AWIN_WORLD', 'BWIN_WORLD', 'THETAWIN_WORLD',\n+                                 'ERRAWIN_WORLD', 'ERRBWIN_WORLD', 'ERRTHETAWIN_WORLD',\n+                                 'FLAGS'])\n+\n+                t1 = t1[~np.isnan(t1['AWIN_WORLD'])]\n+                t1 = t1[~np.isnan(t1['BWIN_WORLD'])]\n+\n+                # Select unflagged and close-to-circular point sources\n+                t1 = t1[np.where((t1['FLAGS'] == 0))]\n+                t1 = t1[np.where(((1. - t1['BWIN_WORLD']/t1['AWIN_WORLD']) < self.ellipticity_max))]\n+                t1 = t1[np.where((t1['FLUX_RADIUS'] > self.flux_radius_min) &\n+                                 (t1['FLUX_RADIUS'] < self.flux_radius_max))]\n+\n+                t1.meta['EXTNAME'] = 'LDAC_OBJECTS'\n+\n+                tn.append(t1)\n+\n+            t = table.unique(vstack(tn), keys='OBJECT_ID')\n+\n         elif refcat_orig == 'GAIA':\n \n             nir_filter = fits.getval(self.dithers[0], Keywords.FILTER, ext=0)\n@@ -1000,6 +1033,12 @@ class DoastromClass(object):\n                                '-ASTREFMAG_KEY': 'MAG_APER',\n                                '-ASTREFMAGERR_KEY': 'MAGERR_APER'}\n \n+        if refcat_orig == 'NIR':\n+            optional_refcat = {'-ASTREFCENT_KEYS': 'XWIN_WORLD,YWIN_WORLD',\n+                               '-ASTREFERR_KEYS': 'ERRAWIN_WORLD,ERRBWIN_WORLD,ERRTHETAWIN_WORLD',\n+                               '-ASTREFMAG_KEY': 'MAG_APER',\n+                               '-ASTREFMAGERR_KEY': 'MAGERR_APER'}\n+\n         if refcat_orig == 'GAIA':\n             optional_refcat = {'-ASTREFCENT_KEYS': 'RA,DEC',\n                                '-ASTREFERR_KEYS': 'RAERR,DECERR,POSANGLEERR',\n",
                            "Merge branch 'supporting_NIR_cat' into 'develop'",
                            "Thomas Gasparetto",
                            "2023-08-25T09:28:40.000+00:00",
                            "86c9f787e5a1e4cdbc5c02df0a7c6f2ad2839198"
                        ]
                    ],
                    ".bumpversion.cfg": [
                        [
                            "@@ -1,5 +1,5 @@\n [bumpversion]\n-current_version = 2.4\n+current_version = 2.5\n commit = False\n tag = False\n \n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-NIR/NIR_AstrometricCalibration into develop",
                            "Gianluca Polenta",
                            "2023-08-18T15:54:11.000+00:00",
                            "30da697172af7aec8d11f29b64efcbb3f6458f38"
                        ]
                    ],
                    "CMakeLists.txt": [
                        [
                            "@@ -6,6 +6,6 @@ find_package(ElementsProject)\n #---------------------------------------------------------------\n \n # Declare project name and version\n-elements_project(NIR_AstrometricCalibration 2.4\n+elements_project(NIR_AstrometricCalibration 2.5\n                  USE\n-                 NIR_Utilities 2.4)\n+                 NIR_Utilities 2.5)\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-NIR/NIR_AstrometricCalibration into develop",
                            "Gianluca Polenta",
                            "2023-08-18T15:54:11.000+00:00",
                            "30da697172af7aec8d11f29b64efcbb3f6458f38"
                        ]
                    ],
                    "NIR_Doastrom/python/NIR_Doastrom/NIR_AstromQualityParameters.py": [
                        [
                            "@@ -26,7 +26,8 @@ class AstromQualityParameters(object):\n         # Get keywords from the SCAMP configuration file:\n         scamp_parameters = DoastromClass.read_conf_file(scamp_conf_path)\n         if 'SN_THRESHOLDS' in scamp_parameters:\n-            self.sn_thresh = scamp_parameters['SN_THRESHOLDS']\n+            sn_thresh = scamp_parameters['SN_THRESHOLDS'].split(',')\n+            self.sn_thresh = list(map(float, sn_thresh))\n         else:\n             self.sn_thresh = [10.0, 100.0]\n         if 'ASTRCLIP_NSIGMA' in scamp_parameters:\n",
                            "Merge branch 'develop' of https://gitlab.euclid-sgs.uk/PF-NIR/NIR_AstrometricCalibration into develop",
                            "Gianluca Polenta",
                            "2023-08-18T15:54:11.000+00:00",
                            "30da697172af7aec8d11f29b64efcbb3f6458f38"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "2.3.1",
                        "created_at": "2023-08-09T19:03:00.000+00:00",
                        "author_name": "Marco Frailis"
                    },
                    {
                        "name": "2.4.0",
                        "created_at": "2023-08-17T13:34:14.000+00:00",
                        "author_name": "Marco Frailis"
                    },
                    {
                        "name": "2.4.1",
                        "created_at": "2023-08-28T10:43:13.000+02:00",
                        "author_name": "Marco Frailis"
                    }
                ]
            },
            "PF-NIR/NIR_Workflow": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_CatalogExtraction": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "PF-NIR/NIR_CrRejectionMultiFrame": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            }
        }
    }
}