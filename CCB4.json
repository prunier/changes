{
    "INFRA": {
        "ST-IAL": {
            "ST-IAL/st_metascheduler_utils": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/st_centraldashboard": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_INFRA_SDC_DE_DEV": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_PR_INSTALLER": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/st_ial_sitecustomize": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_INFRA_SDC_IAL": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_INFRA_SDC_US": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_INFRA_SDC_IT": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_INFRA_SDC_NL": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_INFRA_SDC_FI": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_INFRA_SDC_DE": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_INFRA_SDC_ES": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_INFRA_SDC_UK": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_INFRA_SDC_DEV": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_INFRA_SDC_CH": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_INFRA_SDC_FR": {
                "start date": "2023-07-17T14:42:49",
                "end date": "2023-07-19T13:21:33",
                "start tag": "3.1.6",
                "end tag": "3.2.0",
                "count_files_modified": "2",
                "modifications_by_file": {
                    "ppo/sdc-fr-dev.properties": [
                        [
                            "@@ -79,7 +79,6 @@ drm.defaultQueue.extraCommandsBefore=source /usr/share/Modules/init/bash;module\n # High mem \n drm.highMemQueue.scheduler=SLURM\n drm.highMemQueue.submitCommandParams=--account euclid --job-name SDC-FR-DEV -L sps -p htc_highmem # [str]\n-drm.highMemQueue.supportedEdenVersions=.*3\\.1.*\n drm.highMemQueue.extraCommandsBefore=source /usr/share/Modules/init/bash;module load Containers/apptainer/1.0.1;. /cvmfs/euclid.in2p3.fr/CentOS7/INFRA/SINGULARITY/opt/CT_SINGULARITY_IMAGE/scripts/SDC-FR_run_singularity \\\n \n \n",
                            "genral update for PROD and DEV IAL3.2",
                            "Aur\u00e9lien CARLE",
                            "2023-07-19T13:21:33.000+02:00",
                            "00cf3cc541f7e7d4fc09cfacc4bdbfd31d86c79f"
                        ],
                        [
                            "@@ -107,7 +107,7 @@ pipelinerunner.pilots.c4m12.CPUcores=4\n pipelinerunner.pilots.c4m12.rssInMB=12000\n pipelinerunner.pilots.c4m12.walltimeInMin=10080\n pipelinerunner.pilots.c4m12.maxInstances=1000\n-pipelinerunner.pilots.c4m12.diskspaceInGB=100\n+pipelinerunner.pilots.c4m12.diskspaceInGB=120\n pipelinerunner.pilots.c4m12.tmpPath=$TMPDIR\n pipelinerunner.pilots.c4m12.drmQueue=defaultQueue\n \n@@ -116,7 +116,7 @@ pipelinerunner.pilots.c4m16.CPUcores=4\n pipelinerunner.pilots.c4m16.rssInMB=16000\n pipelinerunner.pilots.c4m16.walltimeInMin=10080\n pipelinerunner.pilots.c4m16.maxInstances=1000\n-pipelinerunner.pilots.c4m16.diskspaceInGB=100\n+pipelinerunner.pilots.c4m16.diskspaceInGB=120\n pipelinerunner.pilots.c4m16.tmpPath=$TMPDIR\n pipelinerunner.pilots.c4m16.drmQueue=defaultQueue\n \n@@ -125,7 +125,7 @@ pipelinerunner.pilots.c4m24.CPUcores=4\n pipelinerunner.pilots.c4m24.rssInMB=24000\n pipelinerunner.pilots.c4m24.walltimeInMin=10080\n pipelinerunner.pilots.c4m24.maxInstances=1000\n-pipelinerunner.pilots.c4m24.diskspaceInGB=100\n+pipelinerunner.pilots.c4m24.diskspaceInGB=120\n pipelinerunner.pilots.c4m24.tmpPath=$TMPDIR\n pipelinerunner.pilots.c4m24.drmQueue=defaultQueue\n \n@@ -134,7 +134,7 @@ pipelinerunner.pilots.c8m24.CPUcores=8\n pipelinerunner.pilots.c8m24.rssInMB=24000\n pipelinerunner.pilots.c8m24.walltimeInMin=10080\n pipelinerunner.pilots.c8m24.maxInstances=1000\n-pipelinerunner.pilots.c8m24.diskspaceInGB=100\n+pipelinerunner.pilots.c8m24.diskspaceInGB=120\n pipelinerunner.pilots.c8m24.tmpPath=$TMPDIR\n pipelinerunner.pilotfitness.c8m24.rssInMB=3.0\n pipelinerunner.pilots.c8m24.drmQueue=defaultQueue\n@@ -145,7 +145,7 @@ pipelinerunner.pilots.c4m100.CPUcores=4\n pipelinerunner.pilots.c4m100.rssInMB=100000\n pipelinerunner.pilots.c4m100.walltimeInMin=10080\n pipelinerunner.pilots.c4m100.maxInstances=10\n-pipelinerunner.pilots.c4m100.diskspaceInGB=100\n+pipelinerunner.pilots.c4m100.diskspaceInGB=120\n pipelinerunner.pilots.c4m100.tmpPath=$TMPDIR\n pipelinerunner.pilotfitness.c4m100.rssInMB=5.0\n pipelinerunner.pilots.c4m100.drmQueue=highMemQueue    # [str]     Name of DRM queue if not use the default one (DefaultQueue).\n",
                            "change tmp dir space 100 -> 120G",
                            "Aur\u00e9lien CARLE",
                            "2023-07-17T14:42:49.000+02:00",
                            "ba93fb204f907f463f14658793eac05d550d962f"
                        ]
                    ],
                    "ppo/sdc-fr.properties": [
                        [
                            "@@ -70,32 +70,17 @@ metascheduler.db.filepath=/opt/euclid-ial/data/db/ial_db.mv.db\n # The corresponsding name (here: defaultQueue) needs to be set at the specific Pilot templates.\n # IMPORTANT: NO UNDERSCORE (_) ALLOWED IN THE TEMPLATE NAME\n #Only set the items you need, not all of them need to be defined for each Queueing system.\n-drm.defaultQueue.scheduler=SLURM                                                             # [str]     Scheduler used [SGE | PBS | SLURM | LOCAL | HTCONDOR] - use SGE also for UGE\n-drm.defaultQueue.submitCommandParams=--account euclid --job-name SDC-FR-PROD -L sps # [str]     Specifies additional options to be passed to the batch system submission command (e.g. -P euclid)\n-drm.defaultQueue.supportedEdenVersions=.*3\\.0.*\n-drm.defaultQueue.extraCommandsBefore=source /usr/share/Modules/init/bash;module load Containers/apptainer/1.0.1;. /cvmfs/euclid.in2p3.fr/CentOS7/INFRA/SINGULARITY/opt/CT_SINGULARITY_IMAGE/scripts/SDC-FR_run_singularity \\\n-\n-\n # Copy the Queues for a new base sigularity\n-drm.defaultQueue31.scheduler=SLURM\n-drm.defaultQueue31.submitCommandParams=--account euclid --job-name SDC-FR-PROD -L sps\n-drm.defaultQueue31.supportedEdenVersions=.*3\\.1.*\n-drm.defaultQueue31.extraCommandsBefore=source /usr/share/Modules/init/bash;module load Containers/apptainer/1.0.1;. /cvmfs/euclid-dev.in2p3.fr/WORKNODE/SDC_FR/eden.3.1/SDC-FR_run_singularity \\\n \n+drm.defaultQueue.scheduler=SLURM\n+drm.defaultQueue.submitCommandParams=--account euclid --job-name SDC-FR-DEV -L sps\n+drm.defaultQueue.extraCommandsBefore=source /usr/share/Modules/init/bash;module load Containers/apptainer/1.0.1;. /cvmfs/euclid.in2p3.fr/CentOS7/INFRA/SINGULARITY/opt/CT_SINGULARITY_IMAGE/scripts/SDC-FR_run_singularity \\\n \n-# High mem\n+# High mem \n drm.highMemQueue.scheduler=SLURM\n-drm.highMemQueue.submitCommandParams=--account euclid --job-name SDC-FR-PROD -L sps -p htc_highmem # [str]\n-drm.highMemQueue.supportedEdenVersions=.*3\\.0.*\n+drm.highMemQueue.submitCommandParams=--account euclid --job-name SDC-FR-DEV -L sps -p htc_highmem # [str]\n drm.highMemQueue.extraCommandsBefore=source /usr/share/Modules/init/bash;module load Containers/apptainer/1.0.1;. /cvmfs/euclid.in2p3.fr/CentOS7/INFRA/SINGULARITY/opt/CT_SINGULARITY_IMAGE/scripts/SDC-FR_run_singularity \\\n \n-\n-# High mem 31\n-drm.highMemQueue31.scheduler=SLURM\n-drm.highMemQueue31.submitCommandParams=--account euclid --job-name SDC-FR-PROD -L sps -p htc_highmem # [str]\n-drm.highMemQueue31.supportedEdenVersions=.*3\\.1.*\n-drm.highMemQueue31.extraCommandsBefore=source /usr/share/Modules/init/bash;module load Containers/apptainer/1.0.1;. /cvmfs/euclid-dev.in2p3.fr/WORKNODE/SDC_FR/eden.3.1/SDC-FR_run_singularity \\\n-\n ####################################\n # Rubin stage 1 environment\n ####################################\n@@ -157,56 +142,3 @@ pipelinerunner.pilots.c4m100.diskspaceInGB=120\n pipelinerunner.pilots.c4m100.tmpPath=$TMPDIR\n pipelinerunner.pilotfitness.c4m100.rssInMB=5.0\n pipelinerunner.pilots.c4m100.drmQueue=highMemQueue    # [str]     Name of DRM queue if not use the default one (DefaultQueue).\n-\n-##################\n-# template for 3.1\n-##################\n-\n-# 4:12 template maxInstances=0 to disable\n-pipelinerunner.pilots.e31c4m12.CPUcores=4\n-pipelinerunner.pilots.e31c4m12.rssInMB=12000\n-pipelinerunner.pilots.e31c4m12.walltimeInMin=10080\n-pipelinerunner.pilots.e31c4m12.maxInstances=1000\n-pipelinerunner.pilots.e31c4m12.diskspaceInGB=120\n-pipelinerunner.pilots.e31c4m12.tmpPath=$TMPDIR\n-pipelinerunner.pilots.e31c4m12.drmQueue=defaultQueue31\n-\n-# 4:16 template maxInstances=0 to disable\n-pipelinerunner.pilots.e31c4m16.CPUcores=4\n-pipelinerunner.pilots.e31c4m16.rssInMB=16000\n-pipelinerunner.pilots.e31c4m16.walltimeInMin=10080\n-pipelinerunner.pilots.e31c4m16.maxInstances=1000\n-pipelinerunner.pilots.e31c4m16.diskspaceInGB=120\n-pipelinerunner.pilots.e31c4m16.tmpPath=$TMPDIR\n-pipelinerunner.pilots.e31c4m16.drmQueue=defaultQueue31\n-\n-# 4:24 template maxInstances=0 to disable\n-pipelinerunner.pilots.e31c4m24.CPUcores=4\n-pipelinerunner.pilots.e31c4m24.rssInMB=24000\n-pipelinerunner.pilots.e31c4m24.walltimeInMin=10080\n-pipelinerunner.pilots.e31c4m24.maxInstances=1000\n-pipelinerunner.pilots.e31c4m24.diskspaceInGB=120\n-pipelinerunner.pilots.e31c4m24.tmpPath=$TMPDIR\n-pipelinerunner.pilots.e31c4m24.drmQueue=defaultQueue31\n-\n-# 8:24 template maxInstances=0 to disable\n-pipelinerunner.pilots.e31c8m24.CPUcores=8\n-pipelinerunner.pilots.e31c8m24.rssInMB=24000\n-pipelinerunner.pilots.e31c8m24.walltimeInMin=10080\n-pipelinerunner.pilots.e31c8m24.maxInstances=1000\n-pipelinerunner.pilots.e31c8m24.diskspaceInGB=120\n-pipelinerunner.pilots.e31c8m24.tmpPath=$TMPDIR\n-pipelinerunner.pilotfitness.e31c8m24.rssInMB=3.0\n-pipelinerunner.pilots.e31c8m24.drmQueue=defaultQueue31\n-\n-\n-# 4:100 template maxInstances=0 to disable\n-pipelinerunner.pilots.e31c4m100.CPUcores=4\n-pipelinerunner.pilots.e31c4m100.rssInMB=100000\n-pipelinerunner.pilots.e31c4m100.walltimeInMin=10080\n-pipelinerunner.pilots.e31c4m100.maxInstances=10\n-pipelinerunner.pilots.e31c4m100.diskspaceInGB=120\n-pipelinerunner.pilots.e31c4m100.tmpPath=$TMPDIR\n-pipelinerunner.pilotfitness.e31c4m100.rssInMB=5.0\n-pipelinerunner.pilots.e31c4m100.drmQueue=highMemQueue31                # [str]     Name of DRM queue if not use the default one (DefaultQueue).\n-\n",
                            "genral update for PROD and DEV IAL3.2",
                            "Aur\u00e9lien CARLE",
                            "2023-07-19T13:21:33.000+02:00",
                            "00cf3cc541f7e7d4fc09cfacc4bdbfd31d86c79f"
                        ],
                        [
                            "@@ -115,7 +115,7 @@ pipelinerunner.pilots.c4m12.CPUcores=4\n pipelinerunner.pilots.c4m12.rssInMB=12000\n pipelinerunner.pilots.c4m12.walltimeInMin=10080\n pipelinerunner.pilots.c4m12.maxInstances=1000\n-pipelinerunner.pilots.c4m12.diskspaceInGB=100\n+pipelinerunner.pilots.c4m12.diskspaceInGB=120\n pipelinerunner.pilots.c4m12.tmpPath=$TMPDIR\n pipelinerunner.pilots.c4m12.drmQueue=defaultQueue\n \n@@ -124,7 +124,7 @@ pipelinerunner.pilots.c4m16.CPUcores=4\n pipelinerunner.pilots.c4m16.rssInMB=16000\n pipelinerunner.pilots.c4m16.walltimeInMin=10080\n pipelinerunner.pilots.c4m16.maxInstances=1000\n-pipelinerunner.pilots.c4m16.diskspaceInGB=100\n+pipelinerunner.pilots.c4m16.diskspaceInGB=120\n pipelinerunner.pilots.c4m16.tmpPath=$TMPDIR\n pipelinerunner.pilots.c4m16.drmQueue=defaultQueue\n \n@@ -133,7 +133,7 @@ pipelinerunner.pilots.c4m24.CPUcores=4\n pipelinerunner.pilots.c4m24.rssInMB=24000\n pipelinerunner.pilots.c4m24.walltimeInMin=10080\n pipelinerunner.pilots.c4m24.maxInstances=1000\n-pipelinerunner.pilots.c4m24.diskspaceInGB=100\n+pipelinerunner.pilots.c4m24.diskspaceInGB=120\n pipelinerunner.pilots.c4m24.tmpPath=$TMPDIR\n pipelinerunner.pilots.c4m24.drmQueue=defaultQueue\n \n@@ -142,7 +142,7 @@ pipelinerunner.pilots.c8m24.CPUcores=8\n pipelinerunner.pilots.c8m24.rssInMB=24000\n pipelinerunner.pilots.c8m24.walltimeInMin=10080\n pipelinerunner.pilots.c8m24.maxInstances=1000\n-pipelinerunner.pilots.c8m24.diskspaceInGB=100\n+pipelinerunner.pilots.c8m24.diskspaceInGB=120\n pipelinerunner.pilots.c8m24.tmpPath=$TMPDIR\n pipelinerunner.pilotfitness.c8m24.rssInMB=3.0\n pipelinerunner.pilots.c8m24.drmQueue=defaultQueue\n@@ -153,7 +153,7 @@ pipelinerunner.pilots.c4m100.CPUcores=4\n pipelinerunner.pilots.c4m100.rssInMB=100000\n pipelinerunner.pilots.c4m100.walltimeInMin=10080\n pipelinerunner.pilots.c4m100.maxInstances=10\n-pipelinerunner.pilots.c4m100.diskspaceInGB=100\n+pipelinerunner.pilots.c4m100.diskspaceInGB=120\n pipelinerunner.pilots.c4m100.tmpPath=$TMPDIR\n pipelinerunner.pilotfitness.c4m100.rssInMB=5.0\n pipelinerunner.pilots.c4m100.drmQueue=highMemQueue    # [str]     Name of DRM queue if not use the default one (DefaultQueue).\n@@ -167,7 +167,7 @@ pipelinerunner.pilots.e31c4m12.CPUcores=4\n pipelinerunner.pilots.e31c4m12.rssInMB=12000\n pipelinerunner.pilots.e31c4m12.walltimeInMin=10080\n pipelinerunner.pilots.e31c4m12.maxInstances=1000\n-pipelinerunner.pilots.e31c4m12.diskspaceInGB=100\n+pipelinerunner.pilots.e31c4m12.diskspaceInGB=120\n pipelinerunner.pilots.e31c4m12.tmpPath=$TMPDIR\n pipelinerunner.pilots.e31c4m12.drmQueue=defaultQueue31\n \n@@ -176,7 +176,7 @@ pipelinerunner.pilots.e31c4m16.CPUcores=4\n pipelinerunner.pilots.e31c4m16.rssInMB=16000\n pipelinerunner.pilots.e31c4m16.walltimeInMin=10080\n pipelinerunner.pilots.e31c4m16.maxInstances=1000\n-pipelinerunner.pilots.e31c4m16.diskspaceInGB=100\n+pipelinerunner.pilots.e31c4m16.diskspaceInGB=120\n pipelinerunner.pilots.e31c4m16.tmpPath=$TMPDIR\n pipelinerunner.pilots.e31c4m16.drmQueue=defaultQueue31\n \n@@ -185,7 +185,7 @@ pipelinerunner.pilots.e31c4m24.CPUcores=4\n pipelinerunner.pilots.e31c4m24.rssInMB=24000\n pipelinerunner.pilots.e31c4m24.walltimeInMin=10080\n pipelinerunner.pilots.e31c4m24.maxInstances=1000\n-pipelinerunner.pilots.e31c4m24.diskspaceInGB=100\n+pipelinerunner.pilots.e31c4m24.diskspaceInGB=120\n pipelinerunner.pilots.e31c4m24.tmpPath=$TMPDIR\n pipelinerunner.pilots.e31c4m24.drmQueue=defaultQueue31\n \n@@ -194,7 +194,7 @@ pipelinerunner.pilots.e31c8m24.CPUcores=8\n pipelinerunner.pilots.e31c8m24.rssInMB=24000\n pipelinerunner.pilots.e31c8m24.walltimeInMin=10080\n pipelinerunner.pilots.e31c8m24.maxInstances=1000\n-pipelinerunner.pilots.e31c8m24.diskspaceInGB=100\n+pipelinerunner.pilots.e31c8m24.diskspaceInGB=120\n pipelinerunner.pilots.e31c8m24.tmpPath=$TMPDIR\n pipelinerunner.pilotfitness.e31c8m24.rssInMB=3.0\n pipelinerunner.pilots.e31c8m24.drmQueue=defaultQueue31\n@@ -205,7 +205,7 @@ pipelinerunner.pilots.e31c4m100.CPUcores=4\n pipelinerunner.pilots.e31c4m100.rssInMB=100000\n pipelinerunner.pilots.e31c4m100.walltimeInMin=10080\n pipelinerunner.pilots.e31c4m100.maxInstances=10\n-pipelinerunner.pilots.e31c4m100.diskspaceInGB=100\n+pipelinerunner.pilots.e31c4m100.diskspaceInGB=120\n pipelinerunner.pilots.e31c4m100.tmpPath=$TMPDIR\n pipelinerunner.pilotfitness.e31c4m100.rssInMB=5.0\n pipelinerunner.pilots.e31c4m100.drmQueue=highMemQueue31                # [str]     Name of DRM queue if not use the default one (DefaultQueue).\n",
                            "change tmp dir space 100 -> 120G",
                            "Aur\u00e9lien CARLE",
                            "2023-07-17T14:42:49.000+02:00",
                            "ba93fb204f907f463f14658793eac05d550d962f"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "3.1.6",
                        "created_at": "2023-07-17T14:42:49.000+02:00",
                        "author_name": "Aur\u00e9lien CARLE"
                    },
                    {
                        "name": "3.2.0",
                        "created_at": "2023-07-19T13:21:33.000+02:00",
                        "author_name": "Aur\u00e9lien CARLE"
                    }
                ]
            },
            "ST-IAL/ST_INFRA_GENERIC": {
                "start date": "2023-02-28T22:01:44",
                "end date": "2023-03-29T19:29:10",
                "start tag": "3.0.5",
                "end tag": "3.2.0",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "3.0.5",
                        "created_at": "2023-02-28T22:01:44.000+00:00",
                        "author_name": "Simon Marcin"
                    },
                    {
                        "name": "3.2.0",
                        "created_at": "2023-03-29T19:29:10.000+00:00",
                        "author_name": "Simon Marcin"
                    }
                ]
            },
            "ST-IAL/ST_Bootstrap": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_IalConfiguration": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_Dashboard": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_PipelineRunner_Pilot_Agent": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_PipelineRunner_Pilot_Common": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_PipelineRunner_Pilot_Core": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_IALDRM": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            },
            "ST-IAL/ST_PipelineRunner": {
                "start date": "2023-05-02T13:40:35",
                "end date": "2023-05-10T08:28:44",
                "start tag": "3.1.2",
                "end tag": "3.2.0",
                "count_files_modified": "40",
                "modifications_by_file": {
                    "ST_PipelineRunner.spec.in": [
                        [
                            "@@ -101,6 +101,12 @@ source @RPM_INSTALL_PREFIX@/bin/activate && conda-unpack\n @CMAKE_INSTALL_PREFIX@/lib/python3.10/idlelib/util.py\n @CMAKE_INSTALL_PREFIX@/lib/python3.10/lib2to3/Grammar3.10.9.final.0.pickle\n @CMAKE_INSTALL_PREFIX@/lib/python3.10/lib2to3/PatternGrammar3.10.9.final.0.pickle\n+@CMAKE_INSTALL_PREFIX@/lib/python3.10/site-packages/certifi-2022.9.24-py3.10.egg-info/PKG-INFO\n+@CMAKE_INSTALL_PREFIX@/lib/python3.10/site-packages/certifi-2022.9.24-py3.10.egg-info/SOURCES.txt\n+@CMAKE_INSTALL_PREFIX@/lib/python3.10/site-packages/certifi-2022.9.24-py3.10.egg-info/dependency_links.txt\n+@CMAKE_INSTALL_PREFIX@/lib/python3.10/site-packages/certifi-2022.9.24-py3.10.egg-info/installed-files.txt\n+@CMAKE_INSTALL_PREFIX@/lib/python3.10/site-packages/certifi-2022.9.24-py3.10.egg-info/not-zip-safe\n+@CMAKE_INSTALL_PREFIX@/lib/python3.10/site-packages/certifi-2022.9.24-py3.10.egg-info/top_level.txt\n @CMAKE_INSTALL_PREFIX@/lib/python3.10/site-packages/cffi-1.15.1.dist-info/INSTALLER\n @CMAKE_INSTALL_PREFIX@/lib/python3.10/site-packages/cffi-1.15.1.dist-info/LICENSE\n @CMAKE_INSTALL_PREFIX@/lib/python3.10/site-packages/cffi-1.15.1.dist-info/METADATA\n",
                            "Add missing files - will it fix the deployment?",
                            "smarcin",
                            "2023-05-10T08:28:44.000+02:00",
                            "472bcfc0a82cb9d3c45d5195c0698d393790bd79"
                        ]
                    ],
                    "python/euclidwf/utils/md5_util.py": [
                        [
                            "@@ -0,0 +1,135 @@\n+\"\"\"Util functions used to implement a scalable mechanism to gather all md5sums of output files.\"\"\"\n+\n+# Copyright (C) 2012-2022 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under the terms of the\n+# GNU Lesser General Public License as published by the Free Software Foundation; either version\n+# 3.0 of the License, or (at your option) any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without\n+# even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n+# Lesser General Public License for more details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License along with this library;\n+# if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,\n+# MA 02110-1301 USA.\n+\n+__author__ = \"Simon Marcin\"\n+__license__ = 'LGPL-3.0'\n+__status__ = 'Production'\n+__copyright__ = 'Copyright (C) 2012-2022 Euclid Science Ground Segment'\n+\n+import json\n+import os\n+import contextlib\n+import pathlib\n+import logging\n+import dataclasses\n+import time\n+import hashlib\n+import typing\n+from collections import deque\n+\n+import json_stream\n+from xml.dom import minidom\n+\n+\n+LOGGER = logging.getLogger(__name__)\n+\n+\n+@dataclasses.dataclass\n+class Md5Helper:\n+    \"\"\"Holding internal structures for creating md5 jobs.\"\"\"\n+    workdir: str\n+    jobid: str\n+    chunk_size_MB: int\n+    out_name: str\n+    out_file: str\n+    payloadjobid: str = ''\n+    out_is_list: bool = False\n+    all_files: typing.Set[str] = dataclasses.field(default_factory=set)\n+\n+    def __post_init__(self):\n+        \"\"\"Distinguish between jobid and payloadjobid\"\"\"\n+        try:\n+            jobid, ret = self.jobid.rsplit(\"__\", maxsplit=1)\n+            if ret.startswith(\"retry_\"):\n+                self.payloadjobid = self.jobid\n+                self.jobid = jobid\n+            else:\n+                raise ValueError(\"No payloadjobid\")\n+        except ValueError:\n+            self.payloadjobid = self.jobid\n+\n+    def populate_all_files(self):\n+        \"\"\"Read (list-/xml-)file and get all referenced files into self.all_files\"\"\"\n+        self.load_listfile(self.out_file)\n+\n+    def get_chunk_path(self, chunk_nbr: int) -> pathlib.Path:\n+        \"\"\"Get the path of a chunk.\"\"\"\n+        f_name = f\"{self.payloadjobid}__md5helper_{self.out_name}_{chunk_nbr}.json\"\n+        return pathlib.Path(os.path.join(self.workdir, \"data\", f_name))\n+\n+    def create_md5_chunks(self) -> None:\n+        \"\"\"Spit all files into md5 chunks of ~ chunk_size_MB.\"\"\"\n+        ws_path = pathlib.Path(self.workdir)\n+        chunk_size: int = 0\n+        chunk_nbr: int = 0\n+        chunk = list()\n+        for file in self.all_files:\n+            if not file.startswith(\"data/\"):\n+                continue\n+            f_path = pathlib.Path(file)\n+            f_size = (ws_path / f_path).stat().st_size // 1048576\n+\n+            if len(chunk) > 0 and chunk_size + f_size > self.chunk_size_MB:\n+                self.get_chunk_path(chunk_nbr).write_text(json.dumps(chunk))\n+                chunk_size = 0\n+                chunk_nbr += 1\n+            chunk_size += f_size\n+            chunk.append(file)\n+\n+        if len(chunk) > 0:\n+            self.get_chunk_path(chunk_nbr).write_text(json.dumps(chunk))\n+\n+\n+    def _grab_json_item(self, item, path):\n+        \"\"\"Node visitor for json stream\"\"\"\n+        self.all_files.add(item)\n+        if not isinstance(path[-1], int):\n+            raise ValueError(\"Not a valid JSON list.\")\n+        if not isinstance(item, str):\n+            raise ValueError(\"Item in JSON list is not valid.\")\n+        self.load_file(item, check_for_lists=True)\n+\n+    def load_file(self, file, check_for_lists=False):\n+        self.all_files.add(file)\n+        try:\n+            if os.path.splitext(file)[1].lower() == \".xml\":\n+                xml_path = os.path.join(self.workdir, file)\n+                xml = minidom.parse(xml_path)\n+                name_elm_candidates = xml.getElementsByTagName('FileName')\n+                for name_elm in name_elm_candidates:\n+                    self.all_files.add(f\"data/{name_elm.firstChild.nodeValue}\")\n+            elif check_for_lists:\n+                self.load_listfile(file, silent=True)\n+\n+        except Exception as err:  # Shared FS is involved, pylint: disable=broad-except\n+            LOGGER.warning(f\"Could not load file {str(file)} for staging/md5checks, msg: {str(err)}\",\n+                           extra={'runid': self.payloadjobid})\n+\n+    def load_listfile(self, file, silent=False):\n+        \"\"\"Load a json list file and attach all recursive found files to file_list.\"\"\"\n+        try:\n+            path = os.path.join(self.workdir, file)\n+            if os.path.splitext(path)[1].lower() != '.json':\n+                self.all_files.add(file)\n+                return\n+\n+            with open(path, 'r') as tmp_file:\n+                self.all_files.add(file)\n+                json_stream.visit(tmp_file, self._grab_json_item)\n+        except Exception as err:  # Shared FS is involved, pylint: disable=broad-except\n+            if not silent:\n+                LOGGER.warning(f\"Could not load or interpret listfile {str(file)} for staging/md5checks,\"\n+                               f\" msg: {str(err)}\", extra={'runid': self.payloadjobid})\n",
                            "WIP: md5refactoring",
                            "smarcin",
                            "2023-05-05T11:37:54.000+02:00",
                            "0dbeb8dbee1fe000f09040ebdf9496050159cde5"
                        ]
                    ],
                    "python/euclidwf/_version.py": [
                        [
                            "@@ -1,2 +1,2 @@\n-__version__ = \"3.1.2\"\n-__dbversion__ = \"3.1.2\"\n+__version__ = \"3.2.0\"\n+__dbversion__ = \"3.2.0\"\n",
                            "version bump",
                            "smarcin",
                            "2023-05-04T09:37:15.000+02:00",
                            "587ffe1081c24a5c7a7a7b94140ae3a55de56420"
                        ],
                        [
                            "@@ -1,2 +1,2 @@\n-__version__ = \"3.0.5\"\n-__dbversion__ = \"3.0.0\"\n+__version__ = \"3.1.2\"\n+__dbversion__ = \"3.1.2\"\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    ".gitmodules": [
                        [
                            "@@ -1,4 +0,0 @@\n-[submodule \"ST_IalTestPipelines\"]\n-\tpath = ST_IalTestPipelines\n-\turl = https://gitlab.euclid-sgs.uk/Pipelines/ST_IalTestPipelines.git\n-\tbranch = develop\n",
                            "remove of submodule ST_IalTestPipelines",
                            "smarcin",
                            "2023-05-04T09:34:16.000+02:00",
                            "fff303ebdc3e01f87c564f1fea98652243725420"
                        ]
                    ],
                    "ST_IalTestPipelines": [
                        [
                            "@@ -1 +0,0 @@\n-Subproject commit 564c76b52442ac0092cce6166f9758d73be9a18b\n",
                            "remove of submodule ST_IalTestPipelines",
                            "smarcin",
                            "2023-05-04T09:34:16.000+02:00",
                            "fff303ebdc3e01f87c564f1fea98652243725420"
                        ]
                    ],
                    "Makefile": [
                        [
                            "@@ -1,4 +1,4 @@\n-SGS_SEARCH := /opt/SGS /cvmfs/euclid-dev.in2p3.fr/SGS \n+SGS_SEARCH := /opt/SGS /cvmfs/euclid-dev.in2p3.fr/SGS /cvmfs/euclid.in2p3.fr/SGS\n \n ifndef SGS_MAKEFILE\n _makefile := share/sgsenv/make/SGSTargets.makefile\n@@ -12,3 +12,4 @@ endif\n SGS := $(dir $(SGS_MAKEFILE))/../../../\n \n include $(SGS_MAKEFILE)\n+\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/database_service/database_service.py": [
                        [
                            "@@ -50,9 +50,10 @@ class DatabaseService(WatchdogService):\n     pid: subprocess.Popen = dataclasses.field(init=False)\n     db_log: typing.TextIO = dataclasses.field(init=False)\n     db_log_file: str = dataclasses.field(init=False)\n+    report_init_done_using_signal1: bool = False\n \n     def __post_init__(self):\n-        super(DatabaseService, self).__post_init__()\n+        super().__post_init__()\n         signal.signal(signal.SIGCHLD, signal.SIG_DFL)\n         atexit.register(self._kill_db)\n \n@@ -78,7 +79,8 @@ class DatabaseService(WatchdogService):\n         self._initdb(db_dir)\n         self._exec_postgres(db_dir, db_sock_dir)\n         self._create_db(db_sock_dir)\n-        os.kill(os.getppid(), signal.SIGUSR1)\n+        if self.report_init_done_using_signal1:\n+            os.kill(os.getppid(), signal.SIGUSR1)\n \n     def print_log_raise(self, msg, write_to_log: bool = True) -> None:\n         \"\"\"Raises RuntimeError(msg) and also prints and logs the msg.\"\"\"\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/drm_service/drm_service.py": [
                        [
                            "@@ -389,6 +389,7 @@ class DRMService(service.WatchdogService):\n         os.environ['PIPELINERUNNER_PILOT_RSS_IN_MB_PER_CORE'] = str(template.rssInMB // template.CPUcores)\n         os.environ['PIPELINERUNNER_PILOT_WALLTIME_IN_MIN'] = str(template.walltimeInMin)\n         os.environ['PIPELINERUNNER_PILOT_DISKSPACE_IN_GB'] = str(template.diskspaceInGB)\n+        os.environ['PIPELINERUNNER_PILOT_DISKSPACE_IN_GB_PER_CORE'] = str(template.diskspaceInGB // template.CPUcores)\n         os.environ['PIPELINERUNNER_PILOT_USER_DEFINED_ENV_VAR'] = str(template.userDefinedEnvVar)\n         if template.vmsInMB is None:\n             os.environ.pop('PIPELINERUNNER_PILOT_VMS_IN_MB', None)\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/engine/run_engine.py": [
                        [
                            "@@ -45,7 +45,7 @@ from euclidwf.messaging.log_utils import UnsetLogLevelForRunMessage, SetLogLevel\n     init_log_client, RequestAllLogLevelsReply, RequestAllLogLevels\n from euclidwf.messaging.messaging import Message, MessagingError\n from euclidwf.model.config import ConfigMessage, ConfigRequest, Config\n-from euclidwf.model.common import PRMaintenance\n+from euclidwf.model.common import PRMaintenance, DrainMode, GenericACK, DrainServices, DrainState, GetDrainState\n from euclidwf.model.payload_job import PayloadJobPersistence\n from euclidwf.model.run import PipelineRun, PipelineRunPersistence, StopRunMessage, \\\n     RunSummaryMessage, RunSummaryReply, create_run_summary\n@@ -224,9 +224,10 @@ class PipelineRunService(service.WatchdogService):\n     _maintenance_timer: float = 0.0\n     start_delay: float = 10.0\n     start_services: bool = True\n+    drain_deadline: float = 0.0\n \n     def __post_init__(self) -> None:\n-        \"\"\" \"\"\"\n+        \"\"\"Start the PR engine which coordinates other services and commands.\"\"\"\n         super().__post_init__()\n         time.sleep(1)  # slow joiner: move to Messaging itself.\n         self._session_id = int(time.time())\n@@ -252,6 +253,7 @@ class PipelineRunService(service.WatchdogService):\n         self.messaging.register_callback_for_message(RequestAllLogLevels, self._send_all_loglevels)\n         self.messaging.register_callback_for_message(SessionIdMessage, self._get_session)\n         self.messaging.register_callback_for_message(RunSummaryMessage, self._create_run_summary)\n+        self.messaging.register_callback_for_message(DrainMode, self._register_drain)\n         self.messaging.register_callback_for_message(SetPriorityPipelineRun,\n                                                      self.update_run_priority)\n         self.messaging.register_callback_for_message(ResetPipelineRun,\n@@ -304,18 +306,21 @@ class PipelineRunService(service.WatchdogService):\n \n     def _run_loop_body(self) -> None:\n         \"\"\"Processing loop body.\"\"\"\n+        with utils.log_except_all(LOGGER, \"Error in drain_system.\", exc_info=True):\n+            self._drain_system()\n         with utils.log_except_all(LOGGER, \"Error in update_runs.\", exc_info=True):\n             self.update_runs()\n-        with utils.log_except_all(LOGGER, \"Error in init_new_runs.\", exc_info=True):\n-            self.init_new_runs()\n-        with utils.log_except_all(LOGGER, \"Error in start_new_runs.\", exc_info=True):\n-            self.start_new_runs()\n-        with utils.log_except_all(LOGGER, \"Error in persistence_cleanup.\", exc_info=True):\n-            self.persistence_cleanup()\n         with utils.log_except_all(LOGGER, \"Error in DRM Keepalive\", exc_info=True):\n             self._drm_keeplaive()\n-        with utils.log_except_all(LOGGER, \"ERROR in maintenance procedure.\", exc_info=True):\n-            self._maintenance_mode()\n+        if not self.in_drain:\n+            with utils.log_except_all(LOGGER, \"Error in init_new_runs.\", exc_info=True):\n+                self.init_new_runs()\n+            with utils.log_except_all(LOGGER, \"Error in start_new_runs.\", exc_info=True):\n+                self.start_new_runs()\n+            with utils.log_except_all(LOGGER, \"Error in persistence_cleanup.\", exc_info=True):\n+                self.persistence_cleanup()\n+            with utils.log_except_all(LOGGER, \"ERROR in maintenance procedure.\", exc_info=True):\n+                self._maintenance_mode()\n \n     def _maintenance_mode(self) -> None:\n         \"\"\"Restart Traverser and PayloadJobQueue to get the ultimate gc.\"\"\"\n@@ -326,6 +331,41 @@ class PipelineRunService(service.WatchdogService):\n                 self.run_persistence.maintenance_procedure()\n                 self._restart_services()\n \n+    def _drain_msg(self, _msg: DrainServices) -> None:\n+        \"\"\"Overwrite super class to ignor message, as we are the sender.\"\"\"\n+        pass\n+\n+    def _drain_system(self) -> None:\n+        \"\"\"If requested, orchestrate the DRAIN of the system.\"\"\"\n+        if not self.in_drain:\n+            return\n+\n+        # pilots spawn, web workers spaw, ... let them know\n+        self.messaging.send_message_pub(DrainServices(self.drain_mode, self.drain_timeout_min))\n+\n+        if self.drain_mode in [\"SHORT\", \"MEDIUM\"]:\n+            with utils.log_except_all(LOGGER, \"Could not get DRAIN state of JobScheduler.\", log_level=\"WARNING\"):\n+                reply: DrainState = self.messaging.send_message_req(GetDrainState())\n+                if reply.state == \"DONE\":\n+                    LOGGER.info(f\"DRAIN {self.drain_mode} successful, ready to shutdown.\")\n+                    self.drain_state = \"DONE\"\n+        else:\n+            if len([1 for run in self.runs.values() if run.status == 'EXECUTING']) == 0:\n+                LOGGER.info(f\"DRAIN {self.drain_mode} successful, ready to shutdown.\")\n+                self.drain_state = \"DONE\"\n+\n+        if not self.drain_started:\n+            self.set_drain_started()\n+            if self.drain_timeout_min > 0:\n+                self.drain_deadline = time.time() + self.drain_timeout_min * 60\n+        if 0.0 < self.drain_deadline < time.time():\n+\n+            LOGGER.error(f\"DRAIN {self.drain_mode} reached timeout ({self.drain_timeout_min}min),\"\n+                         f\"init shutdown.\")\n+            self.drain_state = \"DONE\"\n+        if self.drain_state == \"DONE\":\n+            self.messaging.send_message_pub(service.WatchdogServiceShutdown())\n+\n     def _restart_services(self, init=False) -> None:\n         \"\"\"(Re)start Traverser and payloadJobQueue Service.\"\"\"\n         failed = False\n@@ -747,6 +787,17 @@ class PipelineRunService(service.WatchdogService):\n             except (PersistenceError, TypeError):\n                 LOGGER.error(\"Not able to get pipelineRun from persistence.\", extra={\"runid\": msg.runid})\n \n+    def _register_drain(self, msg: DrainMode) -> None:\n+        \"\"\"Callback of Drain message, send back GenericACK.\"\"\"\n+        if self.in_drain:\n+            LOGGER.debug(\"DRAIN is already set, refuse Message.\")\n+            self.messaging.send_reply(GenericACK(1, \"DRAIN already in progress\"), msg)\n+        else:\n+            self.in_drain = True\n+            self.drain_mode = msg.mode\n+            self.drain_timeout_min = msg.timeoutInMin\n+            self.messaging.send_reply(GenericACK(0), msg)\n+\n     def _get_run(self, msg: GetPipelineRun) -> None:\n         \"\"\"Send PipelineRun as GetPipelineRunReply message back.\"\"\"\n         with utils.log_except_all(LOGGER, \"Could not get PipelineRun.\", runid=msg.runid):\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/framework/taskdefs.py": [
                        [
                            "@@ -15,9 +15,11 @@ Module that defines the elements (classes) of a package definition:\n import copy\n import inspect\n import importlib.util\n+import logging\n import os.path\n+import typing\n import sys\n-from euclidwf.framework.workflow_dsl import invoke_task, ParallelSplit\n+from euclidwf.framework.workflow_dsl import invoke_task, ParallelSplit, THREAD_LOCAL_WORKAROUND\n from euclidwf.model.error_handling import PipelineSpecificationError\n \n MIME_XML = \"xml\"\n@@ -28,6 +30,9 @@ TYPE_FILE = \"simplefile\"\n TYPE_LISTFILE = \"listfile\"\n \n \n+LOGGER = logging.getLogger(__name__)\n+\n+\n class OneByOne(str):\n     \"\"\"Lineage OneByOne specification class - pass name of input_port.\n \n@@ -291,7 +296,8 @@ class Executable(object):\n      be translated into Input objects at instantiation time. \n      * `resources`: minimum computing resources to be acquired from HPC \n      when submitting jobs. \n-    \n+     * `env_variables`: additional environment variables for this job.\n+\n     The executable object is callable. It returns a tuple of so-called \n     Source objects - each Source provides the means to track provenance. \n     IMPORTANT NOTE: The elements in the output array are associated in \n@@ -300,16 +306,19 @@ class Executable(object):\n     \"\"\"\n \n     def __init__(self, command=None, inputs=None, outputs=None, resources=None,\n-                 environment_overwrite=''):\n+                 environment_overwrite='', env_variables=None):\n         self.command = command\n-        if inputs == None:\n+        if inputs is None:\n             inputs = []\n         self.inputs = self._input_array(inputs)\n-        if outputs == None:\n+        if outputs is None:\n             outputs = []\n         self.outputs = self._output_array(outputs)\n-        if resources == None:\n+        if resources is None:\n             resources = ComputingResources()\n+        self.env_variables = dict() if env_variables is None else env_variables\n+        for key, val in self.env_variables.items():\n+            self.env_variables[key] = os.path.expandvars(os.path.expandvars(str(val)))\n         self.resources = resources\n         pkgname, pkgfile = _pkgname()\n         self.pkgname = pkgname\n@@ -344,11 +353,37 @@ class Executable(object):\n                                                  \"or of type 'Output'.\")\n         return arr\n \n+    def disable_ports(self, kwargs: typing.Dict) -> None:\n+        \"\"\"Remove input/output ports which are disabled by port=None in kwargs\"\"\"\n+        disabled_in = []\n+        for inport in self.inputs:\n+            if inport.name in kwargs:\n+                LOGGER.info(f\"Remove input port {inport.name} from executable {self.name}\",\n+                            extra={'runid': THREAD_LOCAL_WORKAROUND.current_runid})\n+                disabled_in.append(inport)\n+                kwargs.pop(inport.name)\n+        [self.inputs.remove(item) for item in disabled_in]\n+        disabled_out = []\n+        for outport in self.outputs:\n+            if outport.name in kwargs:\n+                LOGGER.info(f\"Remove output port {outport.name} from executable {self.name}\",\n+                            extra={'runid': THREAD_LOCAL_WORKAROUND.current_runid})\n+                disabled_out.append(outport)\n+                kwargs.pop(outport.name)\n+        [self.outputs.remove(item) for item in disabled_out]\n+        for key in kwargs:\n+            msg = f\"Unknown port {key} set to None in executable {self.name}\"\n+            LOGGER.error(msg)\n+            raise ValueError(f\"Unknown port {key} set to None in executable {self.name}\")\n+\n     def __call__(self, *args, **kwargs):\n         self._check_name()\n         executable = copy.deepcopy(self)  # Exec gets eventually modified, so we need a unique object\n+        disable_ports = {key: val for key, val in kwargs.items() if val is None}\n+        executable.disable_ports(disable_ports)\n         props = TaskProperties(name=self.name, executable=executable, package=Package(self.pkgname))\n-        return invoke_task(props, *args, **kwargs)\n+        enabled_ports = {key: val for key, val in kwargs.items() if val is not None}\n+        return invoke_task(props, *args, **enabled_ports)\n \n     def _check_name(self):\n         # TODO: The following only works if the executable instance is called only after it is assigned to a variable.\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/framework/workflow_dsl.py": [
                        [
                            "@@ -282,22 +282,25 @@ def parallel(iterable, outputs=(\"tuplelist\",), flatten_all=False, one_list_per_o\n     return wrapped\n \n \n-def pipeline(outputs, properties=None):\n+def pipeline(outputs=None, properties=None, dynamic_outputs=False):\n     \"\"\"\n     Function defining the `@pipeline` decorator used as a marker to declare the \n     main pipeline function. As required argument, you must specify the \n     portnames associated with each of the output variables. These portnames \n-    will then constitute the unique reference for the output files. \n+    will then constitute the unique reference for the output files.\n+    Using dynamic_outputs=True allows to skip the \"outputs\" definition. One\n+    has to make sure that the output ports from the tasks have unique names.\n     \"\"\"    \n     def wrapped(function):\n         function.ispipeline = True\n         _outputs = outputs\n-        if not outputs:\n-            raise PipelineSpecificationError(\"Specify output names - to be associated with the variables returned by \" +\n-                                             \"the pipeline function.\")\n-\n-        if isinstance(_outputs, str):\n-            _outputs = (_outputs,)\n+        function.dynamic_outputs = dynamic_outputs\n+        if not dynamic_outputs:\n+            if outputs is None:\n+                raise PipelineSpecificationError(\"Specify output names - to be associated with the variables returned by \" +\n+                                                 \"the pipeline function.\")\n+            if isinstance(_outputs, str):\n+                _outputs = (_outputs,)\n \n         function.dsl_outputs = _outputs\n         function.dsl_properties = properties\n@@ -809,6 +812,18 @@ class MethodInvocation(Invocation):\n     def _create_output_sources(self, body_output):\n         sources = []\n         outputnames = tuple([elm.name for elm in body_output])        \n+        if hasattr(self.body_method, \"dynamic_outputs\") and self.body_method.dynamic_outputs:\n+            check_dumplicates = defaultdict(int)\n+            for i in range(len(body_output)):\n+                sources.append(Source(outputnames[i], self, body_output[i], outputnames[i]))\n+                check_dumplicates[outputnames[i]] += 1\n+            if len(check_dumplicates) != len(body_output):\n+                for key, val in check_dumplicates.items():\n+                    if val > 1:\n+                        raise PipelineSpecificationError(\n+                            f\"dynamic_output found duplicate output port name: {key}\")\n+            return tuple(sources)\n+\n         if hasattr(self.body_method, 'dsl_outputs') and self.body_method.dsl_outputs:\n             aliases=self.body_method.dsl_outputs\n \n@@ -824,7 +839,6 @@ class MethodInvocation(Invocation):\n             for i in range(len(body_output)):\n                 sources.append(Source(outputnames[i], self, body_output[i]))\n         return tuple(sources)\n-    \n \n     def __hash__(self):\n         return  1\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/job_scheduling/job_queue.py": [
                        [
                            "@@ -24,7 +24,6 @@ import copy\n import contextlib\n import dataclasses\n import datetime\n-import gc\n import json\n import logging\n import re\n@@ -47,9 +46,6 @@ from euclidwf.utils.simple_profiling import SimpleProfiling\n LOGGER = logging.getLogger(__name__)\n DT_OPTIONAL = typing.Optional[datetime.datetime]\n \n-import cProfile, pstats, io\n-from pstats import SortKey\n-\n \n @dataslots.dataslots\n @dataclasses.dataclass\n@@ -94,6 +90,9 @@ class PayloadJobQueue:\n     allJobsPerRun: typing.Dict[str, typing.Dict[str, PayloadJob]] = \\\n         dataclasses.field(default_factory=dict)\n \n+    totalStates: typing.Dict[str, int] = \\\n+        dataclasses.field(default_factory=lambda: defaultdict(int))\n+\n     runidsToCleanup: typing.Set[str] = dataclasses.field(default_factory=set)\n \n     totalDiskspaceNeeded: float = 0.0\n@@ -101,13 +100,6 @@ class PayloadJobQueue:\n \n     persistence: PayloadJobPersistence = dataclasses.field(default=None)\n     skip_n_runs: int = 0\n-    _profiler: cProfile.Profile = dataclasses.field(default_factory=cProfile.Profile)\n-    _profiler_state: int = -1\n-    _profiler_start: float = dataclasses.field(default_factory=time.time)\n-    _prof_t_get: float = 0.0\n-    _prof_t_get_update: float = 0.0\n-    _prof_t_status: float = 0.0\n-    _prof_t_status_update: float = 0.0\n \n     def __post_init__(self) -> None:\n         \"\"\"Init the DB connection and load all jobs in state PENDING, QUEUED and EXECUTING.\"\"\"\n@@ -225,7 +217,7 @@ class PayloadJobQueue:\n \n     def _add_diskspace(self, job: PayloadJob) -> None:\n         \"\"\"Keep track of total needed diskspace, do not track jobs which anyway do not match a pilot.\"\"\"\n-        if 0.0 < job.resources.diskspaceInGB <= self.config.max_diskspace_single_pilot:\n+        if job.resources.diskspaceInGB > 0 and not self._is_profile_fitting_any_tmp(job.resources):\n             self.totalDiskspaceNeeded += job.resources.diskspaceInGB\n             self.jobsWaitingForDiskspace.add(job.payloadjobid)\n \n@@ -280,14 +272,13 @@ class PayloadJobQueue:\n                         break\n                     ignore_diskspace_job = True\n \n-                if best_job_profile.diskspaceInGB > self.config.max_diskspace_single_pilot:\n-                    ignore_diskspace_job = True\n-\n                 job = self._get_job_based_on_profile_fast(best_job_profile, pilotid, update_db=False,\n                                                           ignore_diskspace=ignore_diskspace_job)\n                 if job is None:\n                     raise RuntimeError(f\"No job found for {best_job_profile}.\")\n                 job_list.append(job)\n+                if best_job_profile.diskspaceInGB > 0 and not self._is_profile_fitting_any_tmp(best_job_profile):\n+                    ignore_diskspace_job = True\n                 pilot_resources.decrease_resources(best_job_profile, ignore_diskspace=ignore_diskspace_job)\n             except Exception as err:\n                 LOGGER.error(f\"Get a matching job for job request failed: {str(err)}\", exc_info=True)\n@@ -295,34 +286,31 @@ class PayloadJobQueue:\n                 if i_error > 2:\n                     break\n \n-        self._prof_t_get += (time.time() - t)\n-        t = time.time()\n         await self.persistence.async_update_payloadjobs(job_list, fields=['status', 'pilotid', 'submissionTime'])\n-        self._prof_t_get_update += (time.time() - t)\n         return job_list\n \n     def update_valid_pilots(self, pilotids: typing.Set[str]) -> None:\n         \"\"\"Update valid pilots.\"\"\"\n         self._valid_pilots = pilotids\n \n+    async def check_for_stuck_pilots_headless(self, payloadjobid: str, runid:str) -> bool:\n+        \"\"\"Return True if payloadjob was COMPLETED in headless mode.\"\"\"\n+        with contextlib.suppress(Exception):  # pylint: disable=broad-except, shared FS involved\n+            job = self.allJobsPerRun[runid][payloadjobid]\n+            headless_dict = job.return_headless_info()\n+            if \"return_code\" in headless_dict and headless_dict[\"return_code\"] == 0:\n+                LOGGER.warning(\n+                    f\"Job state was {job.status} but headless return value was OK, set to completed.\",\n+                    extra={'runid': job.payloadjobid})\n+                await self.set_job_successful_async(job.payloadjobid, job.runid,\n+                                                    tmpdir_size=headless_dict[\"tmpdir_size\"],\n+                                                    start_time=headless_dict[\"startTime\"],\n+                                                    end_time=headless_dict[\"endTime\"])\n+                return True\n+        return False\n+\n     async def check_for_stuck_pilots(self, pilotids: typing.List[str]) -> typing.List[str]:\n         \"\"\"Check for stuck pilots and cleanup their payloadjobs.\"\"\"\n-\n-        if self._profiler_state == 0:\n-            self._profiler.enable()\n-            self._profiler_state = 1\n-\n-        if time.time() - self._profiler_start > 200 and self._profiler_state == 1:\n-            self._profiler.disable()\n-            s = io.StringIO()\n-            sortby = SortKey.CUMULATIVE\n-            ps = pstats.Stats(self._profiler, stream=s).sort_stats(sortby)\n-            ps.print_stats()\n-            print(s.getvalue())\n-            with open(\"/home/simon/cProfile.out\", \"w\") as f:\n-                f.write(s.getvalue())\n-            self._profiler_state = -1\n-\n         bad_pilots = []\n         for pilotid in list(self.active_jobs_per_pilot.keys()):\n             if pilotid not in pilotids:\n@@ -331,6 +319,12 @@ class PayloadJobQueue:\n                     bad_pilots.append(pilotid)\n                     for payloadjobid in list(self.active_jobs_per_pilot[pilotid]):\n                         runid = self._get_runid_from_payloadjobid(payloadjobid)\n+\n+                        # Try to recover state if pilot was running headless mode\n+                        did_complete = await self.check_for_stuck_pilots_headless(payloadjobid, runid)\n+                        if did_complete:\n+                            continue\n+\n                         with log_except_all(LOGGER, \"Could not set pilot-stuck job to error\",\n                                             runid=payloadjobid):\n                             await self.set_job_error(payloadjobid, runid, f\"Stuck {pilotid}\", True)\n@@ -373,12 +367,9 @@ class PayloadJobQueue:\n                 LOGGER.error(f\"Could not update job status to {msg.status} from {msg.pilotid}: {err}\",\n                              extra={'runid': msg.payloadjobid})\n \n-        self._prof_t_status += (time.time() - t)\n-        t = time.time()\n         await self.persistence.async_update_payloadjobs(\n             bulk_update_jobs, fields=['status', 'startTime', 'endTime', 'executionCmd',\n                                       'finishedTime', 'tmpdir_size'])\n-        self._prof_t_status_update += (time.time() - t)\n \n     def set_job_running(self, payloadjobid: str, runid: str, update_db: bool = True, cmd: str = '') -> None:\n         \"\"\"Set a PayloadJob to EXECUTING.\n@@ -442,6 +433,25 @@ class PayloadJobQueue:\n         if update_db:\n             self.persistence.update_payloadjob(job)\n \n+    async def set_job_successful_async(self, payloadjobid: str, runid: str,\n+                                       start_time: DT_OPTIONAL = None, end_time: DT_OPTIONAL = None,\n+                                       finished_time: DT_OPTIONAL = None, tmpdir_size: float = -1.0) -> None:\n+        \"\"\"Set a PayloadJob to COMPLETED.\n+\n+        Args:\n+            payloadjobid (str): payloadjobid of PayloadJob.\n+            runid (str): runid of PayloadJob.\n+            update_db (bool): execute update of persisitence layer or not\n+            start_time (datetime): Set exact start_time of executable\n+            end_time (datetime): Set exact end_time of executable\n+            finished_time (datetime): Set exact finished_time of job (after md5sum etc)\n+            tmpdir_size (float): Set tmpdir_size if used on node.\n+        \"\"\"\n+        self.set_job_successful(payloadjobid, runid, False, start_time, end_time, finished_time, tmpdir_size)\n+        with contextlib.suppress(KeyError):\n+            job = self.allJobsPerRun[runid][payloadjobid]\n+            await self.persistence.async_update_payloadjob(job)\n+\n     async def set_job_error(self, payloadjobid: str, runid: str, error_msg: str, infra: bool = False,\n                       start_time: DT_OPTIONAL = None, end_time: DT_OPTIONAL = None,\n                       tmpdir_size: float = -1.0) -> None:\n@@ -633,6 +643,16 @@ class PayloadJobQueue:\n                 continue\n             job = self.allJobsPerRun[runid][payloadjobid]\n \n+            headless_dict = job.return_headless_info()\n+            if \"return_code\" in headless_dict and headless_dict[\"return_code\"] == 0:\n+                LOGGER.warning(f\"Job state was {job.status} but headless return value was OK, set to completed.\",\n+                               extra={'runid': job.payloadjobid})\n+                await self.set_job_successful_async(job.payloadjobid, job.runid,\n+                                                    tmpdir_size=headless_dict[\"tmpdir_size\"],\n+                                                    start_time=headless_dict[\"startTime\"],\n+                                                    end_time=headless_dict[\"endTime\"])\n+                continue\n+\n             with contextlib.suppress(KeyError):\n                 self.scheduledJobsPerRun[runid].remove(payloadjobid)\n                 job.infraRetry += 1\n@@ -696,7 +716,7 @@ class PayloadJobQueue:\n             if not matching_env:\n                 continue\n \n-            if profile.diskspaceInGB > self.config.max_diskspace_single_pilot:\n+            if profile.diskspaceInGB > 0 and not self._is_profile_fitting_any_tmp(profile):\n                 ignore_diskspace = True\n \n             try:\n@@ -712,10 +732,19 @@ class PayloadJobQueue:\n \n         return best_job_profile[1]\n \n+    def _is_profile_fitting_any_tmp(self, profile) -> bool:\n+        \"\"\"Check if job profile is fitting on a /tmp enabled pilot at all\"\"\"\n+        if profile.is_fitting_any_tmp is None:\n+            profile.is_fitting_any_tmp = PilotSchedulerService.is_job_fitting_any_tmp(\n+                profile, self.config, self.config.pilots_initDelayInMin)\n+        return profile.is_fitting_any_tmp\n+\n     def _get_job_based_on_profile_fast(self, profile: Resources, pilotid: str, update_db: bool = True,\n                                        inner: bool = False,\n                                        ignore_diskspace: bool = False) -> typing.Optional[PayloadJob]:\n         \"\"\"Get a matching PayloadJob based on a ResourceProfile - fair chances for each run.\"\"\"\n+        if profile.diskspaceInGB > 0 and not self._is_profile_fitting_any_tmp(profile):\n+            ignore_diskspace = True  # Overwrite as it cannot run on disk anyway\n         if inner:\n             self.iterDequePerProfile[profile.key] = deque(\n                 [runid for runid, joblist in self.pendingJobsPerRun.items() if len(joblist[profile.key]) > 0])\n@@ -826,6 +855,7 @@ class PayloadJobQueueProfiling(SimpleProfiling):\n             csv_lines.append(f\"{sec},{state},{totals[state]}\\n\")\n             total_dict['value'] = totals[state]\n             total_dict['state'] = state\n+            self.job_queue.totalStates[state] = totals[state]\n             json_lines.append(f\"{json.dumps(total_dict)}\\n\")\n \n         return self._write_files(csv, csv_lines, json_lines, write_header)\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/job_scheduling/job_scheduler.py": [
                        [
                            "@@ -34,6 +34,7 @@ __copyright__ = 'Copyright (C) 2012-2022 Euclid Science Ground Segment'\n import contextlib\n import logging\n import os\n+import time\n from dataclasses import dataclass\n \n import euclidwf.job_scheduling.job_queue as payloadjobqueue\n@@ -41,6 +42,7 @@ import euclidwf.messaging.service as service\n import euclidwf.model.payload_job as payloadjobmodel\n import euclidwf.model.pilot as pilot\n import euclidwf.model.run as run\n+from euclidwf.model.common import GetDrainState, DrainState\n from euclidwf.engine.run_engine import CleanupRunMessage, ResetPipelineRun, SetPriorityPipelineRun, StopPayloadJobQueue\n from euclidwf.messaging.log_utils import init_log_client\n from euclidwf.utils.simple_profiling import SimplePIDProfiling\n@@ -52,6 +54,9 @@ LOGGER = logging.getLogger(__name__)\n class JobSchedulerService(service.WatchdogService):\n     \"\"\"JobSchedulerService which registers all callbacks and schedules the loop execution.\"\"\"\n     payloadjob_queue: payloadjobqueue = None\n+    job_add_backlog: int = 0\n+    job_get_backlog: int = 0\n+    last_drain_log: float = 0.0\n \n     def __post_init__(self) -> None:\n         \"\"\"\n@@ -90,11 +95,14 @@ class JobSchedulerService(service.WatchdogService):\n         self.messaging.register_callback_for_message(CleanupRunMessage, self._cleanup_run)\n         self.messaging.register_callback_for_message(SetPriorityPipelineRun, self._change_run_priority)\n         self.messaging.register_callback_for_message(StopPayloadJobQueue, self._graceful_shutdown)\n+        self.messaging.register_callback_for_message(GetDrainState, self._drain_state_msg)\n \n     def _run(self) -> None:\n         \"\"\"Run the processing loop of the JobScheduler.\"\"\"\n         while not self.event_shutdown.wait(2):\n-            self._send_job_ended_updates()\n+            if not (self.in_drain and self.drain_mode in [\"SHORT\", \"MEDIUM\"]):\n+                self._send_job_ended_updates()\n+            self.drain_iteration()\n         self.shutdown()\n \n     async def _graceful_shutdown(self, _msg) -> None:\n@@ -104,34 +112,49 @@ class JobSchedulerService(service.WatchdogService):\n         LOGGER.info(f\"Awaited {open_tasks} open async tasks.\")\n         self.event_shutdown.set()  # Will call shutdown\n \n+    def _drain_state_msg(self, msg: GetDrainState) -> None:\n+        \"\"\"Return DRAIN state.\"\"\"\n+        self.messaging.send_reply(DrainState(self.drain_state), msg)\n+\n     def _shutdown(self) -> None:\n         \"\"\"Cleanup of JobSchedulerService to shutdown gracefully.\"\"\"\n         self.payloadjob_queue.shutdown()\n \n-    async def _add_payloadjob(self, job_message: payloadjobmodel.AddConsolidatedPayloadJobMessage) -> None:\n+    async def _add_payloadjob(\n+        self, job_message: payloadjobmodel.AddConsolidatedPayloadJobMessage\n+    ) -> None:\n         \"\"\"Add a PayloadJob to the payloadjob_queue\n \n         Args:\n             job_message (payloadjobmodel.AddPayloadJobMessage): The payloadjob message.\n         \"\"\"\n-        all_jobs = dict()\n-        for runid, joblist in job_message.jobs.items():\n-            jobs = list()\n-            for job in joblist:\n-                jobs.append(payloadjobmodel.PayloadJob(jobid=job.jobid,\n-                                                       runid=job.runid,\n-                                                       taskcmd=job.taskcmd,\n-                                                       resources=job.resources,\n-                                                       workDir=job.workDir,\n-                                                       logDir=job.logDir,\n-                                                       outDir=job.outDir,\n-                                                       inputs=job.inputs,\n-                                                       outputs=job.outputs,\n-                                                       loglevel=job.loglevel,\n-                                                       profilingScript=job.profilingScript,\n-                                                       sourcingScript=job.sourcingScript))\n-            all_jobs[runid] = jobs\n-        await self.payloadjob_queue.add_jobs_multiple_runs(all_jobs)\n+        try:\n+            self.job_add_backlog += 1\n+            all_jobs = dict()\n+            for runid, joblist in job_message.jobs.items():\n+                jobs = list()\n+                for job in joblist:\n+                    jobs.append(\n+                        payloadjobmodel.PayloadJob(\n+                            jobid=job.jobid,\n+                            runid=job.runid,\n+                            taskcmd=job.taskcmd,\n+                            resources=job.resources,\n+                            workDir=job.workDir,\n+                            logDir=job.logDir,\n+                            outDir=job.outDir,\n+                            inputs=job.inputs,\n+                            outputs=job.outputs,\n+                            loglevel=job.loglevel,\n+                            profilingScript=job.profilingScript,\n+                            sourcingScript=job.sourcingScript,\n+                            env_variables=job.env_variables,\n+                        )\n+                    )\n+                all_jobs[runid] = jobs\n+            await self.payloadjob_queue.add_jobs_multiple_runs(all_jobs)\n+        finally:\n+            self.job_add_backlog -= 1\n \n     def _process_resource_request(self, msg: payloadjobmodel.OpenResourcesMessage) -> None:\n         \"\"\"Send back all open Resources of all PENDING payloadjobs as OpenResourcesMessageReply.\n@@ -143,18 +166,34 @@ class JobSchedulerService(service.WatchdogService):\n             self.payloadjob_queue.get_open_resources())\n         self.messaging.send_reply(reply, msg)\n \n-    async def _get_payloadjobs(self, job_message: payloadjobmodel.GetPayloadJobsMessage) -> None:\n+    async def _get_payloadjobs(\n+        self, job_message: payloadjobmodel.GetPayloadJobsMessage\n+    ) -> None:\n         \"\"\"Send a list of jobs as GetPayloadJobsMessageReply back - the jobs are now QUEUED.\n \n         Args:\n             job_message (payloadjobmodel.GetPayloadJobsMessage): The message.\n         \"\"\"\n-        with contextlib.suppress(AssertionError):\n-            jobs = await self.payloadjob_queue.get_jobs(pilot_resources=job_message.resources,\n-                                                        supportedEdenVersions=job_message.supportedEdenVersions,\n-                                                        fitness_factors=job_message.fitness_factors,\n-                                                        pilotid=job_message.pilotid)\n-            self.messaging.send_reply(payloadjobmodel.GetPayloadJobsMessageReply(jobs), job_message)\n+        if self.in_drain and not self.drain_mode == \"LONG\":\n+            # Pilots should not ask, but due to race conditions this is a safety path\n+            self.messaging.send_reply(\n+                payloadjobmodel.GetPayloadJobsMessageReply([]), job_message\n+            )\n+            return\n+        try:\n+            self.job_get_backlog += 1\n+            with contextlib.suppress(AssertionError):\n+                jobs = await self.payloadjob_queue.get_jobs(\n+                    pilot_resources=job_message.resources,\n+                    supportedEdenVersions=job_message.supportedEdenVersions,\n+                    fitness_factors=job_message.fitness_factors,\n+                    pilotid=job_message.pilotid,\n+                )\n+                self.messaging.send_reply(\n+                    payloadjobmodel.GetPayloadJobsMessageReply(jobs), job_message\n+                )\n+        finally:\n+            self.job_get_backlog -= 1\n \n     async def _stop_run(self, msg: run.StopRunMessage) -> None:\n         \"\"\"Cancel all jobs in payloadjob_queue and send for all running jobs a AbortPayloadJobMsg.\n@@ -217,6 +256,32 @@ class JobSchedulerService(service.WatchdogService):\n             status_msg = payloadjobmodel.PayloadJobEndedMessage(ended_jobs)\n             self.messaging.send_message_pub(status_msg)\n \n+    def drain_iteration(self) -> None:\n+        \"\"\"Iteration during DRAIN\"\"\"\n+        if not self.in_drain or self.drain_mode == \"LONG\":\n+            return\n+        if not self.drain_started:\n+            self.set_drain_started()\n+        if time.time() > self.drain_start_time + self.config.services_drainDelayInSec:\n+            if self.drain_mode == \"SHORT\":\n+                if self.job_get_backlog == 0 and self.job_add_backlog == 0:\n+                    LOGGER.info(\"DRAIN done, ready to shutdown.\")\n+                    self.drain_state = \"DONE\"\n+                else:\n+                    LOGGER.warning(f\"DRAIN not yet done. AddBacklog: {self.job_add_backlog} \"\n+                                   f\"GetBacklog: {self.job_get_backlog}\")\n+            elif self.drain_mode == \"MEDIUM\":\n+                if self.payloadjob_queue.totalStates[\"QUEUED\"] == 0 and \\\n+                        self.payloadjob_queue.totalStates[\"EXECUTING\"] == 0:\n+                    LOGGER.info(\"DRAIN done, ready to shutdown.\")\n+                    self.drain_state = \"DONE\"\n+                else:\n+                    if time.time() > self.last_drain_log + 120:\n+                        self.last_drain_log = time.time()\n+                        LOGGER.info(f\"DRAIN not yet done. \"\n+                                    f\"Jobs QUEUED: {self.payloadjob_queue.totalStates['QUEUED']} \"\n+                                    f\"Jobs EXECUTING: {self.payloadjob_queue.totalStates['EXECUTING']}.\")\n+\n     def _cleanup_run(self, msg: CleanupRunMessage) -> None:\n         \"\"\"Cleanup payload jobs of run.\"\"\"\n         self.payloadjob_queue.cleanup_run(msg.runid)\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/messaging/service.py": [
                        [
                            "@@ -47,6 +47,7 @@ import time\n import typing\n \n from euclidwf.model.config import Config\n+from euclidwf.model.common import DrainServices, GenericACK, DrainState, GetDrainState\n from euclidwf.messaging.messaging import Messaging, Message\n from euclidwf.utils.utils import silent_except_all\n \n@@ -71,7 +72,7 @@ class WatchdogServiceKeepalive(Message):\n \n @dataclasses.dataclass\n class WatchdogService:\n-    \"\"\"WatchdogService which listens to Shutdown messages over PUB/SUB and PPID changes.\"\"\"\n+    \"\"\"WatchdogService which listens to shutdown messages over PUB/SUB and PPID changes.\"\"\"\n     service_name: str\n     config: Config\n     propagate_shutdown: bool\n@@ -84,6 +85,12 @@ class WatchdogService:\n     event_shutdown: threading.Event = dataclasses.field(init=False)\n     _grace_time: float = dataclasses.field(init=False)\n     _start_grace_sleep_time: float = dataclasses.field(init=False)\n+    in_drain: bool = dataclasses.field(init=False)\n+    drain_mode: str = dataclasses.field(init=False)\n+    drain_timeout_min: int = dataclasses.field(init=False)\n+    drain_state: str = dataclasses.field(init=False)\n+    drain_started: bool = dataclasses.field(init=False)\n+    drain_start_time: float = dataclasses.field(init=False)\n \n     def __post_init__(self):\n         \"\"\"Init of messaging system, watchdog Messages and logging client.\"\"\"\n@@ -93,11 +100,18 @@ class WatchdogService:\n         self._start_grace_sleep_time = 0.0\n         self.event_shutdown = threading.Event()\n         self._last_keepalive = time.time()\n+        self.in_drain = False\n+        self.drain_mode = \"\"\n+        self.drain_timeout_min = 0\n+        self.drain_state = \"\"\n+        self.drain_started = False\n+        self.drain_start_time = 0.0\n         if self.messaging is None:\n             self.init_messaging()\n \n         self.messaging.register_callback_for_message(WatchdogServiceKeepalive, self._keepalive)\n         self.messaging.register_callback_for_message(WatchdogServiceShutdown, self._shutdown_msg)\n+        self.messaging.register_callback_for_message(DrainServices, self._drain_msg)\n \n         # If propagate shutdown, also propagate startup\n         if self.propagate_shutdown:\n@@ -153,8 +167,6 @@ class WatchdogService:\n             LOGGER.info(f\"Service {self.service_name} propagates Shutdown to other Services.\")\n             if self.messaging is not None:    # mypy guard\n                 self.messaging.send_message_pub(WatchdogServiceShutdown())\n-            if self.ppid_watchdog:\n-                os.kill(self._ppid, signal.SIGINT)\n         self._shutdown()\n \n     def _shutdown(self) -> None:\n@@ -171,9 +183,25 @@ class WatchdogService:\n             LOGGER.warning(f\"Service {self.service_name} keepalives have a drift of {int(drift)}s.\")\n         self._last_keepalive = time.time()\n \n+    def _drain_msg(self, msg: DrainServices) -> None:\n+        \"\"\"Set event_shutdown (threading.Event) to True in order to init a shutdown.\"\"\"\n+        if not self.in_drain:\n+            LOGGER.info(f\"Service {self.service_name} received DRAIN msg.\")\n+            self.drain_mode = msg.mode\n+            self.in_drain = True\n+            self.drain_timeout_min = msg.timeoutInMin\n+            self.drain_state = \"INIT\"\n+\n+    def set_drain_started(self):\n+        \"\"\"Set DRAIN attributes for start\"\"\"\n+        self.drain_started = True\n+        self.drain_state = \"INPROGRESS\"\n+        self.drain_start_time = time.time()\n+\n     def _shutdown_msg(self, _msg: WatchdogServiceShutdown) -> None:\n         \"\"\"Set event_shutdown (threading.Event) to True in order to init a shutdown.\"\"\"\n         LOGGER.info(f\"Service {self.service_name} received SHUTDOWN msg, init graceful shutdown.\")\n+        self.propagate_shutdown = False  # This is already a PUB msg\n         self.event_shutdown.set()\n \n     def _catch_shutdown_signal(self, _signum, _frame) -> None:\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/model/common.py": [
                        [
                            "@@ -68,11 +68,12 @@ class Resources:\n     queueTimeBinSizeinMin: typing.Optional[int] = None\n     pass_to_task_API: bool = dataclasses.field(default=False, hash=False)\n     environment: str = ''\n+    is_fitting_any_tmp: typing.Optional[bool] = dataclasses.field(default=None)\n     # pylint: enable=invalid-name\n \n     @property\n     def key(self):\n-        return ','.join([str(getattr(self, field.name)) for field in dataclasses.fields(self)])\n+        return ','.join([str(getattr(self, field.name)) for field in dataclasses.fields(self) if str(field.name) not in [\"is_fitting_any_tmp\"]])\n \n     @property\n     def correctedRssInMB(self) -> int:\n@@ -397,10 +398,55 @@ class PilotStatsMessage(Message):\n @dataslots.dataslots\n @dataclasses.dataclass\n class PRMaintenance(Message):\n-    \"\"\"Send timestamp of pr maintenance\"\"\"\n+    \"\"\"Send timestamp of PR maintenance\"\"\"\n     timestamp: float = dataclasses.field(default_factory=time.time)\n \n \n+@dataslots.dataslots\n+@dataclasses.dataclass\n+class DrainMode(Message):\n+    \"\"\"Send timestamp of pr maintenance\"\"\"\n+    mode: str\n+    timeoutInMin: int\n+\n+    def __post_init__(self):\n+        \"\"\"Validate DRAIN mode\"\"\"\n+        super(DrainMode, self).__post_init__()\n+        if self.mode not in [\"SHORT\", \"MEDIUM\", \"LONG\"]:\n+            raise ValueError(f\"DRAIN mode {self.mode} is not valid.\")\n+\n+\n+@dataslots.dataslots\n+@dataclasses.dataclass\n+class DrainServices(DrainMode):\n+    \"\"\"DRAIN command used internally for services.\"\"\"\n+\n+\n+@dataslots.dataslots\n+@dataclasses.dataclass\n+class GenericACK(Message):\n+    \"\"\"generic ACk message\"\"\"\n+    return_code: int\n+    message: str = dataclasses.field(default_factory=str)\n+\n+@dataslots.dataslots\n+@dataclasses.dataclass\n+class GetDrainState(Message):\n+    \"\"\"Ask for DRAIN state\"\"\"\n+\n+@dataslots.dataslots\n+@dataclasses.dataclass\n+class DrainState(Message):\n+    \"\"\"Current state of DRAIN\"\"\"\n+    state: str\n+\n+    def __post_init__(self):\n+        \"\"\"Validate DRAIN state\"\"\"\n+        super(DrainState, self).__post_init__()\n+        if self.state not in [\"DONE\", \"INPROGRESS\", \"INIT\"]:\n+            raise ValueError(f\"DRAIN state {self.mode} is not valid.\")\n+\n+\n def profile_process(proc: psutil.Process) -> ProfilingInfo:\n     \"\"\"Return ProfilingInfo object with psutil values of process.\"\"\"\n     with proc.oneshot():\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/model/config.py": [
                        [
                            "@@ -102,7 +102,7 @@ class Config:\n     This docstring loads all the following default values into the configuration at runtime.\n \n     ##### General properties\n-    pipelinerunner.rootDirectory=/home/${USER}/euclid-ial/${PIPELINERUNNER_RUNID}                 # [Path]    Directory where all internal application data (not the Workspace!) will be stored (if not further over-writen).\n+    pipelinerunner.rootDirectory=/home/${USER}/euclid-ial/${PIPELINERUNNER_RUNID}             # [Path]    Directory where all internal application data (not the Workspace!) will be stored (if not further over-writen).\n     pipelinerunner.socketDirectory=/tmp                                                       # [Path]    Directory where Unix socket files should be created.\n     pipelinerunner.concurrentRuns=10                                                          # [int]     Max number of concurrent running Pipelines.\n     metascheduler_instancename=No-SDC                                                         # [str]     Name of the SDC, reused property of metascheduler\n@@ -120,6 +120,7 @@ class Config:\n     ##### General service config items\n     pipelinerunner.services.maxShutdownDuration=10                                            # [int]     Max duration in seconds of shutdown routine.\n     pipelinerunner.services.keepaliveTimeout=30                                               # [int]     Max time in seconds without a keepalive message.\n+    pipelinerunner.services.drainDelayInSec=40                                                # [int]     Min time a SHORT DRAIN takes, needed for possible backlog in DB actions.\n     pipelinerunner.services.pathToBash=/bin/bash                                              # [Path]    Absolute path to bash on all used nodes (IAL node, DRM node, worker nodes)\n \n     ##### Logging properties\n@@ -212,6 +213,7 @@ class Config:\n \n     ##### Generic Pilot definitions\n     pipelinerunner.pilots.updateIntervalInSec=5                                               # [int]     Interval in seconds which the Pilot sends updates and asks for new jobs.\n+    pipelinerunner.pilots.schedulingIntervalInSec=5                                           # [int]     Interval in seconds which the scheduling for new pilots gets triggered\n     pipelinerunner.pilots.maxConnectionRetries=20                                             # [int]     Max retries to talk to the PipelineRunner. Should be gracefull to survivie a restart.\n     pipelinerunner.pilots.maxIdleTimeInSec=60                                                 # [int]     Max time in seconds before a pilot shutdown due to idle state.\n     pipelinerunner.pilots.maxConsecutiveFailedJobs=5                                          # [int]     Trigger shutdown of pilot if limit is reached - avoiding black hole pilots.\n@@ -222,6 +224,7 @@ class Config:\n     pipelinerunner.pilots.DevelopModeNoJobExecutionPattern=_empty                             # [str]     ONLY IAL DEV MODE: Job command must contain this pattern to get skipped.\n     pipelinerunner.pilots.PresourceJobEnvOnce=True                                            # [bool]    Presource the PayloadJob environment once instead of prepend it to the exec cmd everytime.\n     pipelinerunner.pilots.PresourcePythonToUse=python                                         # [str]     Python binary to use in presource manager\n+    pipelinerunner.pilots.initDelayInMin=5                                                    # [int]     Amount of time substracted in pilot_scheduling to prevent race-conditions if the walltime is 1:1 the same.\n \n     ##### Pilot <template> definitions\n     #pipelinerunner.pilots.<template>.CPUcores=                                               # [int]     CPU cores of <resources>.\n@@ -328,6 +331,7 @@ class Config:\n     # Service properties\n     services_maxShutdownDuration: int = field(init=False)\n     services_keepaliveTimeout: int = field(init=False)\n+    services_drainDelayInSec: int = field(init=False)\n     services_pathToBash: str = field(init=False)\n \n     # Logging properties\n@@ -404,6 +408,7 @@ class Config:\n \n     # Pilot Configuration\n     pilots_updateIntervalInSec: int = field(init=False)\n+    pilots_schedulingIntervalInSec: int = field(init=False)\n     pilots_maxConnectionRetries: int = field(init=False)\n     pilots_maxIdleTimeInSec: int = field(init=False)\n     pilots_maxConsecutiveFailedJobs: int = field(init=False)\n@@ -414,6 +419,7 @@ class Config:\n     pilots_DevelopModeNoJobExecutionPattern: str = field(init=False)\n     pilots_PresourceJobEnvOnce: bool = field(init=False)\n     pilots_PresourcePythonToUse: str = field(init=False)\n+    pilots_initDelayInMin: int = field(init=False)\n \n     # Pilot Templates\n     pilots: typing.DefaultDict[str, pilot_model.PilotTemplate] = field(\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/model/payload_job.py": [
                        [
                            "@@ -23,8 +23,10 @@ import contextlib\n import dataclasses\n import datetime\n import itertools\n+import json\n import logging\n import typing\n+import pathlib\n import pickle\n import os\n from collections import defaultdict\n@@ -94,6 +96,7 @@ class PayloadJob:\n     ForceStatelessTasks: bool = False\n     executionCmd: str = ''\n     tmpdir_size: float = -1.0\n+    env_variables: typing.Dict = dataclasses.field(default_factory=dict)\n \n     wsRoot: typing.ClassVar[typing.Optional[str]] = None  # Needs to be set before usage of any PipelineRun\n \n@@ -273,9 +276,32 @@ class PayloadJob:\n                             self.cmdidentifier + f\"_retry_{self.retry}.out\")\n \n     @property\n-    def cmdidentifier(self) -> str:\n-        return os.path.basename(self.taskcmd.split('--', maxsplit=1)[0].replace(\" \", \"_\").replace(\"=\", \"_\"))\n+    def return_code_file(self) -> str:\n+        \"\"\"Return path to file containing the return code.\"\"\"\n+        return os.path.join(self.absWorkDir, self.logDir,\n+                            self.cmdidentifier + f\"_retry_{self.retry}.return_code\")\n \n+    @property\n+    def cmdidentifier(self) -> str:\n+        cmd = self.taskcmd.rsplit(';', 1)[-1].rsplit('&&', 1)[-1].strip()\n+        return os.path.basename(cmd.split('--', maxsplit=1)[0].replace(\" \", \"_\").replace(\"=\", \"_\"))\n+\n+    def return_headless_info(self) -> dict:\n+        \"\"\"Check if the job was successful while the pilot was headless.\"\"\"\n+        with contextlib.suppress(Exception):\n+            ret_dict = json.loads(pathlib.Path(self.return_code_file).read_text())\n+            ret_dict[\"startTime\"] = datetime.datetime.fromisoformat(ret_dict[\"startTime\"])\n+            ret_dict[\"endTime\"] = datetime.datetime.fromisoformat(ret_dict[\"endTime\"])\n+            return ret_dict\n+        return {}\n+\n+    def write_headless_info(self, startTime, endTime, tmpdir_size, return_code):\n+        \"\"\"Write headless info to disk.\"\"\"\n+        info = {\"startTime\": startTime.isoformat(),\n+                \"endTime\": endTime.isoformat(),\n+                \"tmpdir_size\": tmpdir_size,\n+                \"return_code\": return_code}\n+        pathlib.Path(self.return_code_file).write_bytes(json.dumps(info).encode())\n \n @dataclasses.dataclass\n class PayloadJobPersistence(Persistence):\n@@ -594,7 +620,8 @@ class PayloadJobPersistence(Persistence):\n                                  Column('ForceStatelessTasks', Boolean),\n                                  Column('tmpdir', Text),\n                                  Column('executionCmd', Text),\n-                                 Column('tmpdir_size', sqlalchemy.FLOAT))\n+                                 Column('tmpdir_size', sqlalchemy.FLOAT),\n+                                 Column('env_variables', PickleType))\n         #sqlalchemy.Index(\"pip_jid\", table.c.payloadjobid, table.c.jobid)\n         return table\n \n@@ -615,6 +642,7 @@ class AddPayloadJobObject:\n     loglevel: str = ''\n     profilingScript: str = ''\n     sourcingScript: str = ''\n+    env_variables: typing.Dict[str, str] = dataclasses.field(default_factory=dict)\n \n \n @dataslots.dataslots\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/pilot/job.py": [
                        [
                            "@@ -26,6 +26,7 @@ import json\n import logging\n import os\n import re\n+import pathlib\n import signal\n import shutil\n import subprocess\n@@ -196,6 +197,13 @@ class ExecutionJob(PayloadJob):\n                                 self.cmdidentifier + f\"_retry_{self.retry}.out\")\n         return super(ExecutionJob, self).stdout_file\n \n+    @property\n+    def return_code_file(self) -> str:\n+        if self.use_staging:\n+            return os.path.join(self.stage_workDir, self.logDir,\n+                                self.cmdidentifier + f\"_retry_{self.retry}.return_code\")\n+        return super(ExecutionJob, self).return_code_file\n+\n     @property\n     def use_staging(self) -> bool:\n         return self.staging_nodedir != ''\n@@ -255,6 +263,8 @@ class ExecutionJob(PayloadJob):\n             job_env['PIPELINE_LOGLEVEL'] = self.loglevel\n         for item in self.expand_cpu_cores_vars:\n             job_env[item] = str(self.resources.CPUcores)\n+        for key, val in self.env_variables.items():\n+            job_env[key] = os.path.expandvars(os.path.expandvars(str(val)))\n \n         return job_env\n \n@@ -573,6 +583,9 @@ class ExecutionJob(PayloadJob):\n                 LOGGER.debug(f\"PayloadJob uses {tmpdir_size}GB TmpSize.\", extra={'runid': self.payloadjobid})\n             shutil.rmtree(self.tmpdir, ignore_errors=True)\n \n+        # Headless info to disk\n+        self.write_headless_info(self.startTime, self.endTime, self.tmpdir_size, return_code)\n+\n     def set_payloadjob_error(self, error_msg: str, infra: bool = False) -> None:\n         \"\"\"Set Job to ERROR - sends kill signal.\"\"\"\n         LOGGER.error(f\"Cancel PayloadJob on {self.pilotid}.\", extra={'runid': self.payloadjobid})\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/pilot/plots.py": [
                        [
                            "@@ -117,9 +117,9 @@ class ProfilingPlotter:\n                             msg=f\"Could not create {self.pilotid} profiling plot.\"):\n             self.get_full_stat_plot(pilot_csv, svg, self.req_cpu, self.req_rss, self.req_vms)\n \n-    def get_full_stat_plot(self, csv_file: str, png_file: str, req_cpu, req_rss, req_vms) -> None:\n+    def get_full_stat_plot(self, csv_file: str, png_file: str, req_cpu, req_rss, req_vms, title=\"\") -> None:\n         \"\"\"Create the profiling plot out of the csv file into the png file path.\"\"\"\n-        chart = altair.Chart(data=pandas.read_csv(csv_file)).transform_calculate(\n+        chart = altair.Chart(data=pandas.read_csv(csv_file), title=title).transform_calculate(\n             x_time=\"toDate(datum.sec_since_epoch * 1000)\",\n             req_cpu=str(req_cpu), req_rss=str(req_rss), req_vms=str(req_vms))\n \n@@ -129,10 +129,6 @@ class ProfilingPlotter:\n             altair.X('x_time', type='temporal', axis=base_line_axis),\n             altair.Y('CPU', type='quantitative', title='CPU [%]')).properties(width=530, height=150)\n \n-        cpu_rule = chart.mark_rule().encode(\n-            altair.Y('req_cpu', type='quantitative', aggregate='mean'),\n-            size=altair.value(2), color=altair.value('red'))\n-\n         cpu_area = chart.mark_area().transform_fold(\n             ['CPUuserPercent', 'CPUsystemPercent', 'CPUiowaitPercent'],\n             as_=[\"CPUtimeTypeKey\", \"CPUtimeTypeValue\"]).encode(\n@@ -142,26 +138,36 @@ class ProfilingPlotter:\n                 orient='none', direction='horizontal', legendX=700, legendY=170, title=''),\n                          scale=altair.Scale(scheme='set2'))).properties(width=530, height=150)\n \n-        cpu_plots = altair.hconcat(cpu_rule + cpu_line, cpu_area)\n+        if str(req_cpu) == \"0\":\n+            cpu_plots = altair.hconcat(cpu_line, cpu_area)\n+        else:\n+            cpu_rule = chart.mark_rule().encode(\n+                altair.Y('req_cpu', type='quantitative', aggregate='mean'),\n+                size=altair.value(2), color=altair.value('red'))\n+            cpu_plots = altair.hconcat(cpu_rule + cpu_line, cpu_area)\n \n         rss_line = chart.mark_line(color=\"#54A24B\").encode(\n             altair.X('x_time', type='temporal', axis=base_line_axis),\n             altair.Y('rssInMB', type='quantitative', title='rss [MB]')).properties(width=530, height=150)\n \n-        rss_rule = chart.mark_rule().encode(\n-            altair.Y('req_rss', type='quantitative', aggregate='mean'),\n-            size=altair.value(2), color=altair.value('red'))\n-\n         vms_line = chart.mark_line(color=\"#88D27A\").encode(\n             altair.X('x_time', type='temporal', axis=base_line_axis),\n             altair.Y('vmsInMB', type='quantitative', title='vms [MB]')).properties(\n             width=530, height=150)\n \n-        vms_rule = chart.mark_rule().encode(\n-            altair.Y('req_vms', type='quantitative', aggregate='mean'),\n-            size=altair.value(2), color=altair.value('red'))\n+        if str(req_rss) != \"0\":\n+            rss_rule = chart.mark_rule().encode(\n+                altair.Y('req_rss', type='quantitative', aggregate='mean'),\n+                size=altair.value(2), color=altair.value('red'))\n+            rss_line = rss_rule + rss_line\n+\n+        if str(req_vms) != \"0\":\n+            vms_rule = chart.mark_rule().encode(\n+                altair.Y('req_vms', type='quantitative', aggregate='mean'),\n+                size=altair.value(2), color=altair.value('red'))\n+            vms_line = vms_rule + vms_line\n \n-        mem_plots = altair.hconcat(rss_rule + rss_line, vms_rule + vms_line)\n+        mem_plots = altair.hconcat(rss_line, vms_line)\n \n         read_mb_line = chart.mark_line(color=\"#B79A20\").encode(\n             altair.X('x_time', type='temporal', axis=base_line_axis),\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/pilot_manager/pilot_scheduler.py": [
                        [
                            "@@ -94,8 +94,6 @@ class PilotSchedulerService(service.WatchdogService):\n \n         self._init_queued_pilots()\n         self._init_running_pilots()\n-        drm_pilots = [pilot for pilot in self.pilots.values() if pilot.drmid != '']\n-        self.messaging.send_message_pub(InitPilotsDRMStartup(drm_pilots), delay=10.0)  # Slow joiner\n \n         self.messaging.register_callback_for_message(PilotKeepaliveMessage, self._pilot_keepalive)\n         self.messaging.register_callback_for_message(DRMStatusMessage, self._drm_update)\n@@ -137,16 +135,19 @@ class PilotSchedulerService(service.WatchdogService):\n \n     def _run(self) -> None:\n         \"\"\"Run the processing loop of the PilotScheduler.\"\"\"\n-        while not self.event_shutdown.wait(5):\n+        while not self.event_shutdown.wait(self.config.pilots_schedulingIntervalInSec):\n \n             with utils.log_except_all(LOGGER, \"Error in pilot scheduling loop.\"):\n                 if self._pr_maintenance_time + 15 < time.time():\n-                    self._schedule_pilots()\n+                    if not (self.in_drain and self.drain_mode in [\"SHORT\", \"MEDIUM\"]):\n+                        self._schedule_pilots()\n \n             with utils.log_except_all(LOGGER, \"Error in pilot send AllPilotMsg\"):\n                 running_pilots = {key for key, val in self.pilots.items() if val.status != 'ERROR'}\n                 self.messaging.send_message_pub(AllRunningPilots(running_pilots))\n                 self.messaging.send_message_pub(AllRegisteredPilots(list(self.pilots.keys())))\n+                drm_pilots = [pilot for pilot in self.pilots.values() if pilot.drmid != '']\n+                self.messaging.send_message_pub(InitPilotsDRMStartup(drm_pilots))\n \n             with utils.log_except_all(LOGGER, \"Error in pilot check loop.\"):\n                 self._check_pilots()\n@@ -241,8 +242,12 @@ class PilotSchedulerService(service.WatchdogService):\n                 continue\n \n             ignore_diskspace = ignore_diskspace_global\n-            if resources.diskspaceInGB > self.config.max_diskspace_single_pilot:\n+            if resources.is_fitting_any_tmp is not None:\n+                ignore_diskspace_job = not resources.is_fitting_any_tmp\n+            elif not self.is_job_fitting_any_tmp(resources, self.config, self.config.pilots_initDelayInMin):\n                 ignore_diskspace_job = True\n+            #if resources.diskspaceInGB > self.config.max_diskspace_single_pilot:\n+            #    ignore_diskspace_job = True\n \n             # Amount of running and queued pilots get taken into account in _get_best_matching_pilot\n             pilot_templates = self._get_matching_pilots(resources, ignore_diskspace=ignore_diskspace_job)\n@@ -469,7 +474,7 @@ class PilotSchedulerService(service.WatchdogService):\n     @staticmethod\n     def get_fitness_score(pilot_template: PilotTemplate, job_resources: Resources,\n                           fitness_factors: FitnessFactors, allow_zero_resources: bool = False,\n-                          ignore_diskspace: bool = False) -> float:\n+                          ignore_diskspace: bool = False, pilot_delay: int = 0) -> float:\n         \"\"\"Calculate the fitness score form a specific PilotTemplate and a job resource.\n \n         Args:\n@@ -524,7 +529,7 @@ class PilotSchedulerService(service.WatchdogService):\n         fitness += PilotSchedulerService._fitness_function_usage(\n             pilot_template.correctedRssInMB, job_resources.rssInMB, fitness_factors.rssInMB)\n \n-        if pilot_template.walltimeInMin - job_resources.walltimeInMin < 0:\n+        if (pilot_template.walltimeInMin - pilot_delay) - job_resources.walltimeInMin < 0:\n             raise ValueError(\"Walltime constraint not fulfilled.\")\n         fitness += PilotSchedulerService._fitness_function_usage(\n             pilot_template.walltimeInMin, job_resources.walltimeInMin, fitness_factors.walltimeInMin)\n@@ -538,6 +543,52 @@ class PilotSchedulerService(service.WatchdogService):\n \n         return fitness\n \n+    @staticmethod\n+    def is_job_matching_pilot_envs(job_profile: Resources, pilot_template: PilotTemplate, config: Config) -> bool:\n+        \"\"\"Check if a job matches a pilots supported env.\"\"\"\n+        matching_env = False\n+        for reg_match in config.drm[pilot_template.drmQueue].supportedEdenVersions.split(\";\"):\n+            if reg_match == '':\n+                continue\n+            matched = re.match(reg_match, job_profile.environment)\n+            if matched is not None:\n+                matching_env = True\n+        return matching_env\n+\n+    @staticmethod\n+    def is_job_fitting_any_tmp(job_profile: Resources, config: Config, pilot_delay: int = 0) -> bool:\n+        \"\"\"Check if a job profile can be executed using /tmp or not.\"\"\"\n+        for pilot_tmplate in config.pilots.values():\n+            # Env\n+            if not PilotSchedulerService.is_job_matching_pilot_envs(job_profile, pilot_tmplate, config):\n+                continue\n+            # Diskspace\n+            if job_profile.diskspaceInGB > 0:\n+                if pilot_tmplate.diskspaceInGB == 0:\n+                    continue\n+                if pilot_tmplate.diskspaceInGB - job_profile.diskspaceInGB < 0:\n+                    continue\n+            # GPUs\n+            if pilot_tmplate.GPUs - job_profile.GPUs < 0:\n+                continue\n+            if pilot_tmplate.GPUJobExclusive and job_profile.GPUs < 1:\n+                continue\n+            # VMS\n+            if pilot_tmplate.vmsInMB is not None and pilot_tmplate.vmsInMB > 0:\n+                if pilot_tmplate.correctedVmsInMB - job_profile.vmsInMB < 0:\n+                    continue\n+            # CPU\n+            if pilot_tmplate.CPUcores - job_profile.CPUcores < 0:\n+                continue\n+            # RSS\n+            if pilot_tmplate.correctedRssInMB - job_profile.rssInMB < 0:\n+                continue\n+            # Walltime\n+            if (pilot_tmplate.walltimeInMin - pilot_delay) - job_profile.walltimeInMin < 0:\n+                continue\n+            return True\n+        return False\n+\n     def _get_matching_pilots(self, job_resources: Resources, ignore_diskspace=False) -> \\\n             typing.List[PilotTemplate]:\n         \"\"\"Get all matching PilotTemplates sorted by fitness for a specific job.\n@@ -549,14 +600,7 @@ class PilotSchedulerService(service.WatchdogService):\n         for template, pilot_set in self.used_pilot_templates.items():\n \n             # Filter pilots which do not support the EDEN version.\n-            matching_env = False\n-            for reg_match in self.config.drm[template.drmQueue].supportedEdenVersions.split(\";\"):\n-                if reg_match == '':\n-                    continue\n-                matched = re.match(reg_match, job_resources.environment)\n-                if matched is not None:\n-                    matching_env = True\n-            if not matching_env:\n+            if not self.is_job_matching_pilot_envs(job_resources, template, self.config):\n                 continue\n \n             # Filter out pilot templates which are already exceeded.\n@@ -574,7 +618,8 @@ class PilotSchedulerService(service.WatchdogService):\n \n             try:\n                 fitness = self.get_fitness_score(template, job_resources, fitness_factors,\n-                                                 ignore_diskspace=ignore_diskspace)\n+                                                 ignore_diskspace=ignore_diskspace,\n+                                                 pilot_delay=self.config.pilots_initDelayInMin)\n             except ValueError:\n                 continue\n \n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/pipeline_traverser/helper_model.py": [
                        [
                            "@@ -77,20 +77,25 @@ class LocalFileTransporter:\n         return defer.succeed(os.path.exists(path))\n \n     @staticmethod\n-    async def tar_dir(run, async_semaphore):\n-        async with async_semaphore:\n-            dirtotar = os.path.join(run.wsroot, run.workdir, run.logdir)\n-            tar_file = os.path.join(run.wsroot, run.workdir, 'data', f\"{run.runid}_logs.tar.gz\")\n-            start = time.time()\n-            proc = await asyncio.create_subprocess_shell(f\"tar --ignore-failed-read -hczf {tar_file} {dirtotar}\",\n-                                                         stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)\n-\n-            stdout, stderr = await proc.communicate()\n-            if proc.returncode != 0:\n-                logger.warning(f\"tar cmd failed with error code {proc.returncode}: {stderr.decode()}\",\n-                               extra={'runid': run.runid})\n-\n-            logger.debug(f\"Log-tar created {tar_file} (took {int(time.time() - start)}s)\", extra={'runid': run.runid})\n+    async def tar_dir(run, async_semaphore, tar_cmd=\"tar --ignore-failed-read -hczf\"):\n+        for retry in range(3):\n+            await asyncio.sleep(10)  # Some grace time to finish up open files\n+            async with async_semaphore:  # Don't run 100s of subprocesses\n+                dirtotar = os.path.join(run.wsroot, run.workdir, run.logdir)\n+                tar_file = os.path.join(run.wsroot, run.workdir, 'data', f\"{run.runid}_logs.tar.gz\")\n+                tar_cmd = f\"{tar_cmd} {tar_file} {dirtotar}\"\n+                start = time.time()\n+                proc = await asyncio.create_subprocess_shell(tar_cmd,\n+                                                             stdout=asyncio.subprocess.PIPE,\n+                                                             stderr=asyncio.subprocess.PIPE)\n+\n+                stdout, stderr = await proc.communicate()\n+                if proc.returncode != 0:\n+                    logger.warning(f\"tar cmd ({tar_cmd}) (retry {retry}) failed with error {proc.returncode}: {stderr.decode()}\",\n+                                   extra={'runid': run.runid})\n+                else:\n+                    logger.info(f\"Log-tar created {tar_file} (took {int(time.time() - start)}s)\", extra={'runid': run.runid})\n+                    break\n         return run\n \n     @staticmethod\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/pipeline_traverser/pipeline_executor.py": [
                        [
                            "@@ -158,8 +158,9 @@ class PipelineExecutor(object):\n             self.drmAccess.tree_dir(run, self.traverser_service.max_async_subprocesses)))\n \n     def tar_log_dir(self, run):\n+        pr_tar = f\"{self.config.pipeline_runner_py} {self.config.pipeline_runner_bin} utils tardir\"\n         return defer.Deferred.fromFuture(asyncio.ensure_future(\n-            self.drmAccess.tar_dir(run, self.traverser_service.max_async_subprocesses)))\n+            self.drmAccess.tar_dir(run, self.traverser_service.max_async_subprocesses, pr_tar)))\n \n     def handle_outputs(self, outputs, run):\n         \"\"\"Handles the outputs in form of a dictionary (portname, filepath) \n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/pipeline_traverser/traverser_callbacks.py": [
                        [
                            "@@ -197,6 +197,7 @@ class NodeCallbacks(object):\n                 inputs=input_as_fileport,\n                 outputs=output_as_fileport,\n                 sourcingScript=env,\n+                env_variables=executable.env_variables,\n                 profilingScript=self._run.profilingScript)\n \n             self._traverser_service.add_job_descr(job_desc)\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/pipeline_traverser/traverser_service.py": [
                        [
                            "@@ -194,13 +194,15 @@ class PipelineTraverserService(service.WatchdogService):\n         reactor.run()\n \n     def loop_call(self):\n+        if self.in_drain and self.drain_mode in [\"SHORT\", \"MEDIUM\"]:\n+            return\n         with log_except_all(logger, \"Error in pilot _init_new_runs loop.\", exc_info=True):\n             self._init_new_runs()\n-        with log_except_all(logger, \"Error in submit_jobs _init_new_runs loop.\", exc_info=True):\n+        with log_except_all(logger, \"Error in submit_jobs loop.\", exc_info=True):\n             self.submit_jobs()\n-        with log_except_all(logger, \"Error in pilot fetch_jobs loop.\", exc_info=True):\n+        with log_except_all(logger, \"Error in fetch_jobs loop.\", exc_info=True):\n             self.fetch_jobs()\n-        with log_except_all(logger, \"Error in pilot remove_finished_runs loop.\", exc_info=True):\n+        with log_except_all(logger, \"Error in remove_finished_runs loop.\", exc_info=True):\n             self.remove_finished_runs()\n \n     def remove_finished_runs(self):\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/scripts/pipeline_runner.py": [
                        [
                            "@@ -82,13 +82,16 @@ def _stderr_handling(conf: Config, module_name: str) -> None:\n \n \n def _start_basic_service(module, config_str: str, propagate_shutdown: bool = True,\n-                         ppid_watchdog: bool = True, keepalive_watchdog: bool = True):\n+                         ppid_watchdog: bool = True, keepalive_watchdog: bool = True,\n+                         kwds: typing.Optional[typing.Dict[str, typing.Any]] = None):\n     \"\"\"Start a basic service with a config string (passed as argument).\"\"\"\n     conf = Config(config_str)\n     increase_os_limits()\n     _stderr_handling(conf, module.__name__)\n+    if kwds is None:\n+        kwds = dict()\n     module = module(module.__name__, conf, propagate_shutdown,\n-                    ppid_watchdog, keepalive_watchdog)\n+                    ppid_watchdog, keepalive_watchdog, **kwds)\n     module.run()\n \n \n@@ -365,11 +368,13 @@ def utils():\n               help='vmsInMB requested by the Job, default is the same value as rssInMB.')\n @click.option('--walltimeInMin', required=True, type=int,\n               help='walltimeInMin requested by the Job.')\n-def pilotscheduling(config, cpucores, rssinmb, vmsinmb, walltimeinmin):\n+@click.option('--GPUs', required=False, type=int, default=0,\n+              help='Number of GPU cards required.')\n+def pilotscheduling(config, cpucores, rssinmb, vmsinmb, walltimeinmin, gpus):\n     \"\"\"Get the result of the basic pilot scheduling algorithm based on Job resources.\"\"\"\n     from euclidwf.utils.bin_utils import print_base_pilot_scheduling\n     print_base_pilot_scheduling(\n-        config, cpucores, rssinmb, vmsinmb, walltimeinmin)\n+        config, cpucores, rssinmb, vmsinmb, walltimeinmin, gpus)\n \n \n @utils.command()\n@@ -381,6 +386,59 @@ def create_messaging_certs(directory):\n     create_zmq_certs(os.path.realpath(directory))\n \n \n+@utils.command()\n+@click.argument('tarfile')\n+@click.argument('directory')\n+def tardir(tarfile, directory):\n+    \"\"\"A graceful implementation of tar with built-in retries.\"\"\"\n+    from euclidwf.utils.tar_util import Tar\n+    Tar(tarfile, directory).run()\n+\n+\n+@utils.command()\n+@click.argument('pid')\n+@click.option('--name', required=False, type=str,\n+              help='Name of output file, if not set PID will be used.')\n+@click.option('--interval', required=False, type=int, default=10,\n+              help='Profiling interval in sec, default 10s.')\n+@click.option('--children', required=False, is_flag=True,\n+              help='Profile also child processes.')\n+@click.option('--grandchildren', required=False, is_flag=True,\n+              help='Profile also grandchild processes. Will overwrite --children.')\n+@click.option('--recursive', required=False, is_flag=True,\n+              help='Profile also great grandchild processes and more. Will overwrite --children and --grandchildren')\n+@click.option('--doDailyRollover', required=False, is_flag=True,\n+              help='Create a new csv file log file every day (rollover at midnight).')\n+@click.option('--outdir', required=False, type=str, default=\"\",\n+              help='Output directory to store the csv files. Default PWD.')\n+@click.option('--maxVmsInMB', required=False, type=int, default=0,\n+              help='vmsInMB requested by the Job. Used to draw a red line on this level.')\n+@click.option('--maxRssInMB', required=False, type=int, default=0,\n+              help='rssInMB requested by the Job. Used to draw a red line on this level.')\n+@click.option('--maxCpu', required=False, type=int, default=0,\n+              help='CPUcores requested by the Job. Used to draw a red line on this level.')\n+def profile_pid(pid, name, interval, children, grandchildren, recursive, dodailyrollover, outdir,\n+                maxvmsinmb, maxrssinmb, maxcpu):\n+    \"\"\"Profile a PID and if specified its children (and so on) using the internal profiler.\"\"\"\n+    from euclidwf.utils.bin_utils import profiling_wrapper\n+    profiling_wrapper(pid, name, interval, children, grandchildren, recursive, dodailyrollover,\n+                      outdir, maxvmsinmb, maxrssinmb, maxcpu)\n+\n+\n+@utils.command()\n+@click.argument('profilingFile', nargs=-1)\n+@click.option('--maxVmsInMB', required=False, type=int, default=0,\n+              help='vmsInMB requested by the Job. Used to draw a red line on this level.')\n+@click.option('--maxRssInMB', required=False, type=int, default=0,\n+              help='rssInMB requested by the Job. Used to draw a red line on this level.')\n+@click.option('--maxCpu', required=False, type=int, default=0,\n+              help='CPUcores requested by the Job. Used to draw a red line on this level.')\n+def profile_plot(profilingfile, maxvmsinmb, maxrssinmb, maxcpu):\n+    \"\"\"Create an SVG profiling image next to the csv profilingFile(s) - use bash glob *.\"\"\"\n+    from euclidwf.utils.bin_utils import prof_plotting_wrapper\n+    prof_plotting_wrapper(profilingfile, maxvmsinmb, maxrssinmb, int(maxcpu)*100)\n+\n+\n @cli.group()\n def docs():\n     \"\"\"Docs of PipelineRunner APIs.\"\"\"\n@@ -489,7 +547,7 @@ def logging(config):\n def database(config):\n     \"\"\"Execute the Database Service.\"\"\"\n     from euclidwf.database_service.database_service import DatabaseService\n-    _start_basic_service(DatabaseService, config)\n+    _start_basic_service(DatabaseService, config, kwds={'report_init_done_using_signal1': True})\n \n \n @service.command()\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/utils/bin_utils.py": [
                        [
                            "@@ -23,6 +23,7 @@ import atexit\n import contextlib\n import dataclasses\n import datetime\n+import glob\n import json\n import logging\n import os\n@@ -34,6 +35,7 @@ import typing\n import signal\n import shutil\n import sys\n+import psutil\n import urllib3\n \n import paramiko\n@@ -49,6 +51,8 @@ from euclidwf.messaging.service import WatchdogServiceShutdown\n from euclidwf.model.config import Config, ConfigMessage, ConfigRequest\n from euclidwf.model.pilot import ShutdownPilotMessage\n from euclidwf.model.run import RunSummaryMessage, RunSummaryReply\n+from euclidwf.pilot.plots import ProfilingPlotter\n+from euclidwf.utils.simple_profiling import SimplePIDProfiling\n from euclidwf._version import __dbversion__\n \n DIR = os.path.dirname\n@@ -552,8 +556,8 @@ class LocalPipeline(Submission):\n         self.event_shutdown.set()\n \n \n-def print_base_pilot_scheduling(config, cpucores, rssinmb, vmsinmb, walltimeinmin):\n-    \"\"\"Print the descision of the base Pilot scheduling for specific resource values.\"\"\"\n+def print_base_pilot_scheduling(config, cpucores, rssinmb, vmsinmb, walltimeinmin, gpus):\n+    \"\"\"Print the decision of the base Pilot scheduling for specific resource values.\"\"\"\n     from euclidwf.pilot_manager.pilot_scheduler import PilotSchedulerService\n     from euclidwf.model.common import Resources\n \n@@ -566,8 +570,65 @@ def print_base_pilot_scheduling(config, cpucores, rssinmb, vmsinmb, walltimeinmi\n             vmsinmb = rssinmb if vmsinmb is None else vmsinmb\n             resources = Resources(CPUcores=cpucores, rssInMB=rssinmb,\n                                   vmsInMB=vmsinmb, walltimeInMin=walltimeinmin,\n-                                  priority=5)\n-            score = PilotSchedulerService.get_fitness_score(pilot_template, resources, conf.pilotfitness[pilot_name])\n+                                  priority=5, GPUs=gpus)\n+            score = PilotSchedulerService.get_fitness_score(pilot_template, resources, conf.pilotfitness[pilot_name],\n+                                                            pilot_delay=conf.pilots_initDelayInMin)\n             print(f\"Pilot {pilot_name} got score: {score:.1f}\")\n         except ValueError:\n             print(f\"Pilot {pilot_name} is not suited for this resources.\")\n+\n+\n+def prof_plotting_wrapper(profilingfile, maxvmsinmb, maxrssinmb, maxcpu):\n+    \"\"\"Create SVG plots of all files listed in profilingfiles.\"\"\"\n+    for f_print in profilingfile:\n+        f_dir, f_file = os.path.split(f_print)\n+        f_name, f_type = os.path.splitext(f_file)\n+        f_svg = os.path.join(f_dir, f\"{f_name}.svg\")\n+        if f_type != \".csv\":\n+            print(f\"Not a csv file, skip {f_file}.\")\n+            continue\n+        if os.path.exists(f_svg):\n+            print(f\"Profiling plot already exists, skip file {f_file}.\")\n+            continue\n+        print(f\"Create new plot {f_name}.svg.\")\n+\n+        try:\n+            plotter = ProfilingPlotter(f_name, f_dir)\n+            plotter.get_full_stat_plot(f_print, f_svg, maxcpu, maxrssinmb, maxvmsinmb, f_name)\n+        except Exception as err:\n+            print(f\"Could not create profiling plot {f_name}: {err}\")\n+\n+\n+def profiling_wrapper(pid, name, interval, children, grandchildren, recursive, dodailyrollover, outdir,\n+                      maxvmsinmb, maxrssinmb, maxcpu):\n+    if outdir == \"\":\n+        outdir = os.path.abspath(os.path.curdir)\n+    os.makedirs(outdir, exist_ok=True)\n+    f_name = f\"profiling_{pid}\" if name is None else name\n+    no_date_base_file = not dodailyrollover\n+    if grandchildren:\n+        children = False\n+    if recursive:\n+        children = False\n+        grandchildren = False\n+    prof = SimplePIDProfiling(outdir, f_name, interval, no_loop=True, no_date_base_file=no_date_base_file,\n+                              profile_child=children, profile_grandchild=grandchildren,\n+                              profile_recursive=recursive, history_in_days=50)\n+    try:\n+        prof.proc = psutil.Process(int(pid))\n+    except psutil.NoSuchProcess:\n+        print(f\"No process with PID {pid}. Exit.\")\n+\n+    with contextlib.suppress(psutil.NoSuchProcess):\n+        prof._profiling_loop()\n+\n+    files_to_plot = []\n+    if dodailyrollover:\n+        for name in glob.glob(os.path.join(outdir, f\"{f_name}__*.csv\")):\n+            with contextlib.suppress(AttributeError):\n+                _y, _m, _d = re.search(r'__(\\d+)-(\\d+)-(\\d+).\\w+$', name).groups()  # type: ignore # -> supress()\n+                files_to_plot.append(name)\n+    else:\n+        files_to_plot.append(os.path.join(outdir, f\"{f_name}.csv\"))\n+\n+    prof_plotting_wrapper(files_to_plot, maxvmsinmb, maxrssinmb, maxcpu)\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/utils/simple_profiling.py": [
                        [
                            "@@ -71,6 +71,7 @@ class SimpleProfiling:\n     last_date: date = dataclasses.field(init=False)\n     _errors: int = 0\n     _max_errors: int = 10\n+    _is_running: bool = True\n \n     def __post_init__(self):\n         try:\n@@ -134,7 +135,7 @@ class SimpleProfiling:\n             write_header = True if os.path.getsize(self.profiling_file) == 0 else False\n         csv = open(self.profiling_file, 'a', encoding='utf-8', buffering=1)\n \n-        while True:  # No need of condition, thread is daemonic\n+        while self._is_running:\n             start = time.time()\n \n             if datetime.now().date() > self.last_date:\n@@ -187,7 +188,11 @@ class SimplePIDProfiling(SimpleProfiling):\n     def _specific_profiling_loop(self, csv, write_header=False) -> float:\n         \"\"\"Code which gets executed in a loop. Returns the time spent for write.\"\"\"\n         t_fs = 0.0\n-        stats = profile_process(self.proc)\n+        try:\n+            stats = profile_process(self.proc)\n+        except psutil.NoSuchProcess:\n+            self._is_running = False\n+            return t_fs\n \n         # Profiling children\n         if self.profile_recursive:\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/utils/tar_util.py": [
                        [
                            "@@ -0,0 +1,93 @@\n+\"\"\"Util functions used to implement a graceful tar with built-in retries.\"\"\"\n+\n+# Copyright (C) 2012-2022 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under the terms of the\n+# GNU Lesser General Public License as published by the Free Software Foundation; either version\n+# 3.0 of the License, or (at your option) any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without\n+# even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n+# Lesser General Public License for more details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License along with this library;\n+# if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,\n+# MA 02110-1301 USA.\n+\n+__author__ = \"Simon Marcin\"\n+__license__ = 'LGPL-3.0'\n+__status__ = 'Production'\n+__copyright__ = 'Copyright (C) 2012-2022 Euclid Science Ground Segment'\n+\n+import tarfile\n+import os\n+import pathlib\n+import logging\n+import dataclasses\n+import time\n+from collections import deque\n+\n+\n+LOGGER = logging.getLogger(__name__)\n+\n+\n+@dataclasses.dataclass\n+class TarFile:\n+    \"\"\"Class representing a single file which should get into the tar archive.\"\"\"\n+    origin: str\n+    dst: str\n+    last_try: float = 0.0\n+    retry: int = 0\n+\n+\n+@dataclasses.dataclass\n+class Tar:\n+    \"\"\"Class implementing retry enabled tar command\"\"\"\n+    tarfile: str\n+    directory: str\n+    file_queue: deque[TarFile] = dataclasses.field(default_factory=deque)\n+    tar_obj: tarfile.TarFile | None = None\n+    retries: int = 3\n+    retry_delay: int = 10\n+\n+    def run(self):\n+        \"\"\"Create tar directory.\"\"\"\n+        os.chdir(self.directory)\n+        if pathlib.Path(self.tarfile).exists():\n+            LOGGER.warning(f\"Tar file {self.tarfile} already exists, will be overwritten.\")\n+            os.remove(self.tarfile)\n+\n+        self.tar_obj = tarfile.open(self.tarfile, \"w:gz\")\n+        try:\n+            self._get_files()\n+            self._process()\n+            LOGGER.info(f\"Finished with tar. {len(self.file_queue)} files failed.\")\n+        except Exception as err:\n+            LOGGER.error(f\"Could not create tar file {self.tarfile}: {err}\")\n+        finally:\n+            self.tar_obj.close()\n+\n+    def _process(self):\n+        \"\"\"Add the files to the tar object.\"\"\"\n+        while self.file_queue:\n+            f_item = self.file_queue.pop()\n+            if f_item.retry >= self.retries:\n+                break\n+            if f_item.last_try > 0 and time.time() - f_item.last_try < self.retry_delay:\n+                time.sleep(abs(self.retry_delay - (time.time() - f_item.last_try)))\n+            try:\n+                self.tar_obj.add(f_item.origin, f_item.dst)\n+            except Exception as err:\n+                LOGGER.warning(f\"Could not add {f_item.origin} to tar file in {f_item.dst} ({f_item.retry}): {err}\")\n+                f_item.retry += 1\n+                f_item.last_try = time.time()\n+                self.file_queue.append(f_item)\n+\n+    def _get_files(self):\n+        \"\"\"Collect all files which need to be archived.\"\"\"\n+        tar_f_resolved = pathlib.Path(self.tarfile).resolve()\n+        for f_path in pathlib.Path(self.directory).rglob(\"*\"):\n+            res_path = f_path.resolve()\n+            if res_path.exists() and res_path != tar_f_resolved:\n+                t_file = TarFile(str(res_path), str(f_path.relative_to(self.directory)))\n+                self.file_queue.append(t_file)\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/web_server/static/base.css": [
                        [
                            "@@ -32,9 +32,13 @@ body \t\t{ background:#ffffff; font-family: 'Arial'; font-size: '12pt'; margin: 0\n \n #navigationbar a:hover { color: #f00000 }\n \n+#no_margin {margin: 0px;}\n+\n #menubar { width: 100%; margin: 0.7em 0 0 0; float: right; color: #f0f0f0; background:darkblue; \n \t\t   font-size: 80%; height: 2em; font-weight: bold }\n \n+.drain { background: #f39c12 !important;}\n+\n #menubar .activesection { color: #f00a0a }\n \n #menubar ul { list-style-type: none; margin: 0.5em 0 }\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/web_server/templates/base.html": [
                        [
                            "@@ -58,7 +58,7 @@\n         </div>\n \n         <!-- MENU -->\n-        <div id=\"menubar\">\n+        <div id=\"menubar\" class=\"{{ \"drain\" if in_drain() else \"\" }}\">\n             <div id=\"menu\">\n                 <ul>\n                 {% block menubar %}\n@@ -66,7 +66,9 @@\n                 </ul>\n             </div>\n             <div id=\"menu_status_info\">\n-                {% block menu_status_info %}####### // {{ now() }} {% endblock %}\n+                {% block menu_status_info %}\n+                <p id=\"no_margin\" style=\"margin: 0px;\"> /// <b>{{ drain_txt() }}</b>    {{ now() }}</p>\n+                {% endblock %}\n             </div>\n         </div>\n \n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/web_server/templates/base_server.html": [
                        [
                            "@@ -33,7 +33,7 @@\n {% endblock %}\n \n <!-- MENU STATUS INFO -->\n-{% block menu_status_info %} #######  {{ now() }}{% endblock %}\n+{% block menu_status_info %} <p id=\"no_margin\" style=\"margin: 0px;\"> /// <b>{{ drain_txt() }}</b>    {{ now() }}</p> {% endblock %}\n \n \n <!-- CONTAINER CONTENT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/euclidwf/web_server/web_server.py": [
                        [
                            "@@ -10,6 +10,7 @@ import os\n import datetime\n import shutil\n import logging\n+import time\n import typing\n import urllib.parse\n import json\n@@ -38,6 +39,7 @@ from euclidwf.messaging.service import WatchdogService\n from euclidwf.model.run import PipelineRunPersistence, create_run_summary\n from euclidwf.model.pilot import PilotPersistence, ShutdownPilotMessage, KillPilotMessage\n from euclidwf.model.payload_job import PayloadJobPersistence\n+from euclidwf.model.common import DrainMode, GenericACK, DrainServices\n from euclidwf.framework.visualizer import TimeoutAGraph\n from euclidwf.utils.persistence import PersistenceError\n from euclidwf.utils.utils import _expand_var_list, SystemInfo\n@@ -152,6 +154,13 @@ class WebServerService (WatchdogService):\n         self.app.route('/api/runs/<runid>/stop', methods=['GET', 'DELETE'])(secured(self.stop_run))\n         self.app.route('/api/runs/<runid>/reset', methods=['GET'])(secured(self.reset_run))\n \n+        self.app.route('/api/drain/short/<timeout>', methods=['GET'])(secured(self.api_drain_short))\n+        self.app.route('/api/drain/medium/<timeout>', methods=['GET'])(secured(self.api_drain_medium))\n+        self.app.route('/api/drain/long/<timeout>', methods=['GET'])(secured(self.api_drain_long))\n+        #self.app.route('/api/drain/planed/<datetime>', methods=['GET'])(secured(self.api_drain_long))\n+        self.app.route('/api/drain/status/', methods=['GET'])(secured(self.api_drain_status))\n+        #self.app.route('/api/drain/cancel/', methods=['GET'])(secured(self.api_drain_short))\n+\n         self.app.route('/', methods=['GET'])(secured(self.index))\n         self.app.route('/view/configuration', methods=['GET'])(secured(self.get_configuration))\n         self.app.route('/view/system', methods=['GET'])(secured(self.system_overview_now))\n@@ -169,6 +178,7 @@ class WebServerService (WatchdogService):\n \n         self.app.context_processor(now)\n         self.app.context_processor(pr_version)\n+        self.app.context_processor(self.context_drain_status)\n         self._start_server_forever()\n \n     def _start_server_forever(self) -> None:\n@@ -198,6 +208,7 @@ class WebServerService (WatchdogService):\n         \"\"\"Hook for new worker process in gunicorn\"\"\"\n         self.service_name = f\"{self.service_name}_{os.getpid()}\"\n         self.init_messaging()\n+        self.messaging.register_callback_for_message(DrainServices, self._drain_msg)\n         # stdout of log_client gets inherited, only the PubLogger needs a reset\n         init_log_client(self.messaging, self.config.logging_level)\n         self.persistence_run = PipelineRunPersistence(self.config)  # Overwrite of __init__\n@@ -431,7 +442,12 @@ class WebServerService (WatchdogService):\n             description: Pipeline submitted, see response body for details.\n             schema:\n               $ref: \"#/definitions/AddPipelineRunReply\"\n+          406:\n+            description: System in DRAIN mode, cannot accept new runs.\n         \"\"\"\n+        if self.in_drain:\n+            return abort(406)\n+\n         data = request.get_json()\n         LOGGER.info(f\"Run submitted with: {data}\", extra={'runid': data['runid']})\n         static_attrs = AddPipelineRunMessage.get_static_attributes()\n@@ -491,6 +507,133 @@ class WebServerService (WatchdogService):\n             reply.append(dict(runid=run.runid, status=run.status))\n         return jsonify(reply)\n \n+    def api_drain_short(self, timeout):\n+        \"\"\"Set the PipelineRunner in DRAIN (short) mode and shutdown.\n+\n+        ---\n+        parameters:\n+          - name: timeout\n+            in: path\n+            required: true\n+            description: Timeout of DRAIN operation in minutes. <= 0 for no timeout!\n+            example: 0\n+            schema:\n+              type : int\n+        responses:\n+          200:\n+            description: DRAIN mode activated.\n+          408:\n+            description: PR server command timed out.\n+          403:\n+            description: Could not set DRAIN mode.\n+          406:\n+            description: Invalid parameters.\n+        \"\"\"\n+        return self.drain_generic(\"SHORT\", timeout)\n+\n+    def api_drain_medium(self, timeout):\n+        \"\"\"Set the PipelineRunner in DRAIN (short) mode and shutdown.\n+\n+        ---\n+        parameters:\n+          - name: timeout\n+            in: path\n+            required: true\n+            description: Timeout of DRAIN operation in minutes. <= 0 for no timeout!\n+            example: 0\n+            schema:\n+              type : int\n+        responses:\n+          200:\n+            description: DRAIN mode activated.\n+          408:\n+            description: PR server command timed out.\n+          403:\n+            description: Could not set DRAIN mode.\n+          406:\n+            description: Invalid parameters.\n+        \"\"\"\n+        return self.drain_generic(\"MEDIUM\", timeout)\n+\n+    def api_drain_long(self, timeout):\n+        \"\"\"Set the PipelineRunner in DRAIN (short) mode and shutdown.\n+\n+        ---\n+        parameters:\n+          - name: timeout\n+            in: path\n+            required: true\n+            description: Timeout of DRAIN operation in minutes. <= 0 for no timeout!\n+            example: 0\n+            schema:\n+              type : int\n+        responses:\n+          200:\n+            description: DRAIN mode activated.\n+          408:\n+            description: PR server command timed out.\n+          403:\n+            description: Could not set DRAIN mode.\n+          406:\n+            description: Invalid parameters.\n+        \"\"\"\n+        return self.drain_generic(\"LONG\", timeout)\n+\n+    def drain_generic(self, mode: str, timeout: int):\n+        \"\"\"Send DRAIN msg to engine.\"\"\"\n+        try:\n+            t_out = int(timeout)\n+            t_out = 0 if t_out < 0 else t_out\n+            ret: GenericACK = self.messaging.send_message_req(DrainMode(mode, t_out), timeout=60.0)\n+        except MessagingError:\n+            LOGGER.error(f\"DRAIN ({mode}) command timed out.\")\n+            return abort(408)\n+        except (TypeError, ValueError):\n+            LOGGER.error(f\"DRAIN ({mode}) with timeout {timeout} is not allowed\")\n+            return abort(406)\n+        if ret.return_code != 0:\n+            LOGGER.warning(f\"Could not set DRAIN ({mode}): {ret.message}\")\n+            return abort(403)\n+        return jsonify(\"OK\")\n+\n+    def _drain_msg(self, msg: DrainServices) -> None:\n+        \"\"\"Overwrite of parent.\"\"\"\n+        if not self.in_drain:\n+            super()._drain_msg(msg)\n+            self.drain_started = True\n+            self.drain_start_time = time.time()\n+            self.drain_state = \"INPROGRESS\"\n+\n+    def _drain_txt(self):\n+        if not self.in_drain:\n+            return \"\"\n+        if self.drain_timeout_min > 0:\n+            t_left = max(0, self.drain_timeout_min - int((time.time() - self.drain_start_time) / 60))\n+            return f\"DRAIN ({self.drain_mode} - max time left: {t_left}min) in progress  ///  \"\n+        return f\"DRAIN ({self.drain_mode} - no timeout) in progress  ///  \"\n+\n+    def context_drain_status(self):\n+        \"\"\"Context processor\"\"\"\n+        return {\"drain_txt\": self._drain_txt,\n+                \"in_drain\": lambda: self.in_drain}\n+\n+    def api_drain_status(self):\n+        \"\"\"Return DRAIN status.\n+\n+        ---\n+        responses:\n+          200:\n+            description: Pipeline submitted, see response body for details.\n+            schema:\n+              id: DrainStatus\n+              properties:\n+                responseStatus:\n+                  type: string\n+                  description: DONE | INPROGRESS | INIT | '']\n+                  example: INPROGRESS\n+        \"\"\"\n+        return jsonify(self.drain_state)\n+\n     def api_kill_pilots_all(self):\n         \"\"\"Wrapper around api_kill_pilots for all pilots\"\"\"\n         return self.api_kill_pilots(pilotid='ALL_PILOTS')\n@@ -1193,7 +1336,12 @@ class WebServerService (WatchdogService):\n         responses:\n           200:\n             description: Sent run reset message.\n+          406:\n+            description: System in DRAIN mode, cannot restart run.\n         \"\"\"\n+        if self.in_drain:\n+            return abort(406)\n+\n         self.messaging.send_message_pub(ResetPipelineRun(str(runid)))\n         return \"OK\"\n \n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/tests/integration_tests/test_payload_scheduler.py": [
                        [
                            "@@ -79,25 +79,34 @@ def start_db_service(conf: str) -> None:\n \n class TestPayloadJobService(unittest.TestCase):\n \n+    counter_test = 0\n+\n     def setUp(self):\n         os.environ[\"PIPELINERUNNER_PACKAGE\"] = os.path.join(DIR(DIR(DIR(os.path.realpath(__file__)))), 'euclidwf')\n         self.job_counter = 0\n-        tmp_conf = \"pipelinerunner.rootDirectory=/tmp/unitest_payloadsched\"\n-        tmp_conf += \",workspace.rootPath=/tmp/unitest_payloadsched/workspace\"\n-        tmp_conf += \",pipelinerunner.services.keepaliveTimeout=50\"\n-        tmp_conf += \",pipelinerunner.messaging.requestTimeoutInSec=60\"\n-        tmp_conf += \",pipelinerunner.logging.useStdOutHandler=True\"\n-        tmp_conf += \",pipelinerunner.profiling.updateIntervalInSec=3\"\n-        tmp_conf += \",pipelinerunner.logging.level=WARNING\"\n-        shutil.rmtree(\"/tmp/unitest_payloadsched\", ignore_errors=True)\n-        os.makedirs(\"/tmp/unitest_payloadsched\", exist_ok=True)\n+        TestPayloadJobService.counter_test += 1\n+        i = TestPayloadJobService.counter_test\n+        tmp_conf = f\"\"\"pipelinerunner.messaging.socketType=ipc,\n+        pipelinerunner.messaging.subSocketBindAddress=sub.sock,\n+        pipelinerunner.messaging.pubSocketBindAddress=pub.sock,\n+        pipelinerunner.socketDirectory=/tmp/unitest_payloadsched_{i},\n+        pipelinerunner.rootDirectory=/tmp/unitest_payloadsched_{i},\n+        workspace.rootPath=/tmp/unitest_payloadsched_{i}/workspace,\n+        pipelinerunner.services.keepaliveTimeout=50,\n+        pipelinerunner.messaging.requestTimeoutInSec=60,\n+        pipelinerunner.logging.useStdOutHandler=True,\n+        pipelinerunner.profiling.updateIntervalInSec=3,\n+        pipelinerunner.logging.level=WARNING,\n+        \"\"\"\n+        shutil.rmtree(f\"/tmp/unitest_payloadsched_{i}\", ignore_errors=True)\n+        os.makedirs(f\"/tmp/unitest_payloadsched_{i}\", exist_ok=True)\n \n         self.p_forwarder = multiprocessing.Process(target=start_forwarder_service, args=(tmp_conf,))\n         self.p_forwarder.start()\n         time.sleep(0.5)  # Slow joiner!\n         self.p_db = multiprocessing.Process(target=start_db_service, args=(tmp_conf,))\n         self.p_db.start()\n-        time.sleep(3)  # Init database\n+        time.sleep(10)  # Init database\n         self.p_queue = multiprocessing.Process(target=start_payloadjob_service, args=(tmp_conf,))\n         self.p_queue.start()\n         self.sim = TraverserSim(service_name='traverser_sim', config=Config(tmp_conf))\n@@ -105,7 +114,8 @@ class TestPayloadJobService(unittest.TestCase):\n \n     def tearDown(self):\n         time.sleep(2)\n-        shutil.rmtree(\"/tmp/unitest_payloadsched\")\n+        i = TestPayloadJobService.counter_test\n+        shutil.rmtree(f\"/tmp/unitest_payloadsched_{i}\")\n         self.p_forwarder.terminate()\n         self.p_queue.terminate()\n         self.p_db.terminate()\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/tests/messaging/test_messaging.py": [
                        [
                            "@@ -90,7 +90,7 @@ class TestForwarder(unittest.TestCase):\n         context.term()\n \n     def test_tcp(self):\n-        self.basic_forwarder('tcp://127.0.0.1:50000', 'tcp://127.0.0.1:50001')\n+        self.basic_forwarder('tcp://127.0.0.1:50005', 'tcp://127.0.0.1:50006')\n \n     def test_unix(self):\n         os.makedirs(\"/tmp/unittest_msgs\", exist_ok=True)\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/tests/pilot/test_profiling.py": [
                        [
                            "@@ -113,8 +113,9 @@ class TestProfiling(unittest.TestCase):\n         prof.LOGGER = MagicMock()\n         self.run_subproc(arguments=(2 ** 28, True, True))\n         time.sleep(2)\n-        prof.LOGGER.warning.assert_any_call(AnyStringWith('CPU which is more'),\n-                                            extra={'runid': 'Run_1__1__retry_0'})\n+        # CPU is hard to test as the machine can have other stuff running\n+        #prof.LOGGER.warning.assert_any_call(AnyStringWith('CPU which is more'),\n+        #                                    extra={'runid': 'Run_1__1__retry_0'})\n         prof.LOGGER.warning.assert_any_call(AnyStringWith('MB RSS memory which is more than'),\n                                             extra={'runid': 'Run_1__1__retry_0'})\n         prof.LOGGER.warning.assert_any_call(AnyStringWith('MB VMS memory which is more than'),\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/tests/pilot_manager/test_scheduler.py": [
                        [
                            "@@ -23,6 +23,7 @@ import copy\n import time\n import sys\n import pathlib\n+import unittest\n \n # Make sure that import works when executed standalone and with pytest as package\n sys.path.append(str(pathlib.Path(__file__).parent.parent.parent))\n@@ -112,6 +113,28 @@ class TestPilotManager(ServiceOrientedTest):\n         time.sleep(0.2)\n         self.assertTrue(len(self.drm_add_pilots) == 7)\n \n+    @unittest.skip\n+    def test_add_loadtest(self):\n+        for i_cpu in range(7):\n+            for i_ram in range(14):\n+                res = Resources(CPUcores=i_cpu, rssInMB=i_ram*1000, walltimeInMin=1000,\n+                                vmsInMB=i_ram*1000, priority=5, GPUs=0)\n+                self.open_res[res] = 100\n+\n+        self.config.pilots['genericHeavy'].maxInstances = 5000\n+        self.config.pilots['genericLight'].maxInstances = 5000\n+        self.config.pilots['genericHeavy'].maxQueued = 50\n+        self.config.pilots['genericLight'].maxQueued = 50\n+\n+        self.manager = PilotSchedulerService('PilotScheduler', self.config, True, True, False)\n+        start = time.time()\n+        for _i in range(100):\n+            self.manager._schedule_pilots()\n+            self.manager.queued_pilot_templates[self.config.pilots['genericHeavy']] = set()\n+            self.manager.queued_pilot_templates[self.config.pilots['genericLight']] = set()\n+        print(f\"Used: {time.time() - start}s\")\n+        time.sleep(0.2)\n+\n     def test_lifecycle(self):\n         \"\"\"Lifecycle of a Pilot without Errors.\"\"\"\n         self.test_add_job()\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/tests/utils/_trial_temp/_trial_marker": [
                        [
                            "",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/tests/utils/test_bin_utils.py": [
                        [
                            "",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/tests/utils/test_tar_util.py": [
                        [
                            "@@ -0,0 +1,138 @@\n+\"\"\"Unit tests of euclidwf.utils.tar_util.\"\"\"\n+\n+# Copyright (C) 2012-2022 Euclid Science Ground Segment\n+#\n+# This library is free software; you can redistribute it and/or modify it under the terms of the\n+# GNU Lesser General Public License as published by the Free Software Foundation; either version\n+# 3.0 of the License, or (at your option) any later version.\n+#\n+# This library is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without\n+# even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n+# Lesser General Public License for more details.\n+#\n+# You should have received a copy of the GNU Lesser General Public License along with this library;\n+# if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,\n+# MA 02110-1301 USA.\n+\n+__author__ = \"Simon Marcin\"\n+__license__ = 'LGPL-3.0'\n+__status__ = 'Production'\n+__copyright__ = 'Copyright (C) 2012-2022 Euclid Science Ground Segment'\n+\n+import os\n+import subprocess\n+import threading\n+import time\n+import unittest\n+import pathlib\n+import shutil\n+import sys\n+import tarfile\n+\n+# Make sure that import works when executed standalone and with pytest as package\n+sys.path.append(str(pathlib.Path(__file__).parent.parent.parent))\n+sys.path.append(str(pathlib.Path(__file__).parent.parent))\n+from euclidwf.utils import tar_util\n+\n+\n+class TestTarUtils(unittest.TestCase):\n+    \"\"\"Contains all tests which cover euclidwf.utils.tar_util explicitly.\"\"\"\n+\n+    def setUp(self) -> None:\n+        \"\"\"Create a test structure of files.\"\"\"\n+        self.prefix = \"/tmp/test_tar_util\"\n+        self.extract_prefix = \"/tmp/test_tar_util_extract\"\n+        self.tar_file = f\"{self.prefix}/test_tar_util.tar.gz\"\n+        self.tearDown()\n+        self.dirs = [f\"{self.prefix}/foo/bar\", f\"{self.prefix}/foo/bar2\", f\"{self.prefix}/foo2\"]\n+        for d_path in self.dirs:\n+            os.makedirs(d_path, exist_ok=True)\n+        os.chdir(self.prefix)\n+        self.files = [\"f1\", \"foo/f2\", \"foo/f3\", \"foo/bar/f4\", \"foo/bar2/f5\"]\n+        for f_path in self.files:\n+            pathlib.Path(f\"{self.prefix}/{f_path}\").write_bytes(b\"TEST_DATA\")\n+        pathlib.Path(\"foo2/s1\").symlink_to(\"../foo/f2\")\n+        pathlib.Path(\"foo2/s2\").symlink_to(f\"{self.prefix}/foo/f2\")\n+        pathlib.Path(\"foo2/s_broken\").symlink_to(f\"foo/broken\")\n+        self.files.append(\"foo2/s1\")\n+        self.files.append(\"foo2/s2\")\n+\n+    def tearDown(self) -> None:\n+        \"\"\"Delete test structure.\"\"\"\n+        os.chdir(\"/tmp\")\n+        shutil.rmtree(self.prefix, ignore_errors=True)\n+        shutil.rmtree(self.extract_prefix, ignore_errors=True)\n+\n+    def test_tar(self) -> None:\n+        t = tar_util.Tar(self.tar_file, \"/tmp/test_tar_util\")\n+        t.run()\n+        self.verify_archive(self.tar_file)\n+\n+    def test_tar_cmd(self) -> None:\n+        pr = pathlib.Path(__file__).parent.parent.parent / \"euclidwf/scripts/pipeline_runner.py\"\n+        ret = subprocess.run([sys.executable, pr, \"utils\", \"tardir\", self.tar_file, \"/tmp/test_tar_util\"])\n+        self.assertTrue(ret.returncode == 0)\n+        self.verify_archive(self.tar_file)\n+\n+    def test_tar_modify(self) -> None:\n+        t = tar_util.Tar(self.tar_file, \"/tmp/test_tar_util\", retry_delay=1)\n+        thread = threading.Thread(target=self.modify_file, args=(\"/tmp/test_tar_util/f1\", 2), daemon=True)\n+        thread.start()\n+        time.sleep(1)\n+        t.run()\n+        self.verify_archive(self.tar_file, skip_check=[\"f1\"])\n+        thread.join()\n+\n+    def test_tar_retry_missing(self) -> None:\n+        t = tar_util.Tar(self.tar_file, \"/tmp/test_tar_util\", retry_delay=2)\n+        t.file_queue.append(tar_util.TarFile(f\"{self.prefix}/m1\", \"m1\"))\n+        self.files.append(\"m1\")\n+        threading.Thread(target=self.add_file, args=(\"/tmp/test_tar_util/m1\", 2), daemon=True).start()\n+        t.run()\n+        self.verify_archive(self.tar_file)\n+\n+    def test_tar_failed_file(self) -> None:\n+        t = tar_util.Tar(self.tar_file, \"/tmp/test_tar_util\", retry_delay=1)\n+        t.file_queue.append(tar_util.TarFile(f\"{self.prefix}/fail\", \"fail\"))\n+        t.run()\n+        self.verify_archive(self.tar_file)\n+\n+    def test_tar_override_archive(self) -> None:\n+        pathlib.Path(self.tar_file).write_bytes(b\"FOOBAR\")\n+        t = tar_util.Tar(self.tar_file, \"/tmp/test_tar_util\", retry_delay=1)\n+        t.run()\n+        self.verify_archive(self.tar_file)\n+\n+    def verify_archive(self, path: str, skip_check=None) -> None:\n+        \"\"\"Check if all files are there, skip_check is a list of relative file names to skip.\"\"\"\n+        if skip_check is None:\n+            skip_check = []\n+        extract_path = pathlib.Path(self.extract_prefix)\n+        os.makedirs(extract_path, exist_ok=True)\n+        tar = tarfile.open(path)\n+        tar.extractall(extract_path)\n+        tar.close()\n+        for f in extract_path.rglob(\"*\"):\n+            if f.is_file():\n+                f_rel = f.relative_to(self.extract_prefix)\n+                if str(f_rel) not in skip_check:\n+                    self.assertTrue(str(f_rel) in self.files)\n+                    self.assertTrue(f.read_bytes() == pathlib.Path(f\"{self.prefix}/{str(f_rel)}\").read_bytes())\n+\n+    @staticmethod\n+    def add_file(f_path: str, wait_time: float) -> None:\n+        \"\"\"Add file f_path after wait_time.\"\"\"\n+        time.sleep(wait_time)\n+        pathlib.Path(f_path).write_bytes(b\"TEST_DATA\")\n+\n+    @staticmethod\n+    def modify_file(f_path: str, mod_time: float) -> None:\n+        \"\"\"Modify a file for mod_time seconds all the time.\"\"\"\n+        t0 = time.time()\n+        with open(f_path, \"wb\") as f_file:\n+            f_file.write(os.urandom(100000000))\n+        while time.time() - t0 < mod_time:\n+            with open(f_path, \"ab\") as f_file:\n+                f_file.write(b\"x\")\n+                f_file.flush()\n+                time.sleep(0.000001)\n",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ],
                    "python/tests/utils/test_utils.py": [
                        [
                            "",
                            "Manual merge of 3.1",
                            "smarcin",
                            "2023-05-04T09:29:39.000+02:00",
                            "2b6ca1437c0302aa7e31e38e661e3e3cdfa50028"
                        ]
                    ]
                },
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "3.1.2",
                        "created_at": "2023-05-02T13:40:35.000+02:00",
                        "author_name": "smarcin"
                    },
                    {
                        "name": "3.2.0",
                        "created_at": "2023-05-10T08:28:44.000+02:00",
                        "author_name": "smarcin"
                    }
                ]
            },
            "ST-IAL/ST_MetaScheduler": {
                "start date": "2023-05-09T16:45:06",
                "end date": "2023-05-11T11:00:54",
                "start tag": "3.1.3",
                "end tag": "3.2.0",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": [
                    {
                        "name": "3.1.3",
                        "created_at": "2023-05-09T16:45:06.000+02:00",
                        "author_name": "Tino Heuberger"
                    },
                    {
                        "name": "3.2.0",
                        "created_at": "2023-05-11T11:00:54.000+00:00",
                        "author_name": "Tino Heuberger"
                    }
                ]
            },
            "ST-IAL/ST_IalTestExecutables": {
                "start date": "-",
                "end date": "-",
                "start tag": "",
                "end tag": "",
                "count_files_modified": "0",
                "modifications_by_file": {},
                "selected_modifications": {},
                "count_selected_modifications": "0",
                "tags_in_period": []
            }
        }
    }
}